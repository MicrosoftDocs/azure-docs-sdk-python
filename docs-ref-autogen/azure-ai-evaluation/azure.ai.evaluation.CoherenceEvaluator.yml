### YamlMime:PythonClass
uid: azure.ai.evaluation.CoherenceEvaluator
name: CoherenceEvaluator
fullName: azure.ai.evaluation.CoherenceEvaluator
module: azure.ai.evaluation
inheritances:
- azure.ai.evaluation._evaluators._common._base_prompty_eval.PromptyEvaluatorBase
summary: 'Evaluates coherence score for a given query and response or a multi-turn
  conversation, including reasoning.


  The coherence measure assesses the ability of the language model to generate text
  that reads naturally,

  flows smoothly, and resembles human-like language in its responses. Use it when
  assessing the readability

  and user-friendliness of a model''s generated responses in real-world applications.


  > [!NOTE]

  > To align with our support of a diverse set of models, an output key without the
  gpt_ prefix has been added.

  >

  > To maintain backwards compatibility, the old key with the gpt_ prefix is still
  be present in the output;

  >

  > however, it is recommended to use the new key moving forward as the old key will
  be deprecated in the future.

  >'
constructor:
  syntax: CoherenceEvaluator(model_config)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
examples:
- "Initialize and call a CoherenceEvaluator with a query and response.<!--[!code-python[Main](les\\\
  evaluation_samples_evaluate.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\
  \\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\
  \\4\\\\azure_ai_evaluation-1.2.0\\\\samples\\\\evaluation_samples_evaluate.py\"\
  , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"highlight_args\"\
  : {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\n   import os\n\
  \   from azure.ai.evaluation import CoherenceEvaluator\n\n   model_config = {\n\
  \       \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n       \"\
  api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n       \"azure_deployment\": os.environ.get(\"\
  AZURE_OPENAI_DEPLOYMENT\"),\n   }\n   coherence_evaluator = CoherenceEvaluator(model_config=model_config)\n\
  \   coherence_evaluator(query=\"What is the capital of France?\", response=\"Paris\
  \ is the capital of France.\")\n\n   ````\n"
attributes:
- uid: azure.ai.evaluation.CoherenceEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureml://registries/azureml/models/Coherence-Evaluator/versions/4'
