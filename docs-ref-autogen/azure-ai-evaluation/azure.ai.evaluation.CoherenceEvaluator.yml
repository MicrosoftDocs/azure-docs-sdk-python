### YamlMime:PythonClass
uid: azure.ai.evaluation.CoherenceEvaluator
name: CoherenceEvaluator
fullName: azure.ai.evaluation.CoherenceEvaluator
module: azure.ai.evaluation
summary: 'Evaluates coherence score for a given query and response or a multi-turn
  conversation, including reasoning.


  The coherence measure assesses the ability of the language model to generate text
  that reads naturally,

  flows smoothly, and resembles human-like language in its responses. Use it when
  assessing the readability

  and user-friendliness of a model''s generated responses in real-world applications.


  > [!NOTE]

  > To align with our support of a diverse set of models, an output key without the
  gpt_ prefix has been added.

  >

  > To maintain backwards compatibility, the old key with the gpt_ prefix is still
  be present in the output;

  >

  > however, it is recommended to use the new key moving forward as the old key will
  be deprecated in the future.

  >'
constructor:
  syntax: CoherenceEvaluator(model_config, *, threshold=3)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
  - name: threshold
    description: The threshold for the coherence evaluator. Default is 3.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: threshold
    defaultValue: '3'
attributes:
- uid: azure.ai.evaluation.CoherenceEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureai://built-in/evaluators/coherence'
