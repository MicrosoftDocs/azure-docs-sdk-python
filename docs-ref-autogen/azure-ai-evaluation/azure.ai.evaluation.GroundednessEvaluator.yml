### YamlMime:PythonClass
uid: azure.ai.evaluation.GroundednessEvaluator
name: GroundednessEvaluator
fullName: azure.ai.evaluation.GroundednessEvaluator
module: azure.ai.evaluation
inheritances:
- azure.ai.evaluation._evaluators._common._base_prompty_eval.PromptyEvaluatorBase
summary: 'Evaluates groundedness score for a given query (optional), response, and
  context or a multi-turn conversation,

  including reasoning.


  The groundedness measure assesses the correspondence between claims in an AI-generated
  answer and the source

  context, making sure that these claims are substantiated by the context. Even if
  the responses from LLM are

  factually correct, they''ll be considered ungrounded if they can''t be verified
  against the provided sources

  (such as your input source or your database). Use the groundedness metric when you
  need to verify that

  AI-generated responses align with and are validated by the provided context.


  Groundedness scores range from 1 to 5, with 1 being the least grounded and 5 being
  the most grounded.


  > [!NOTE]

  > To align with our support of a diverse set of models, an output key without the
  gpt_ prefix has been added.

  >

  > To maintain backwards compatibility, the old key with the gpt_ prefix is still
  be present in the output;

  >

  > however, it is recommended to use the new key moving forward as the old key will
  be deprecated in the future.

  >'
constructor:
  syntax: GroundednessEvaluator(model_config)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
examples:
- "Initialize and call a GroundednessEvaluator.<!--[!code-python[Main](les\\evaluation_samples_evaluate.py\
  \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\\Python\\\
  \\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\4\\\\azure_ai_evaluation-1.2.0\\\
  \\samples\\\\evaluation_samples_evaluate.py\", \"xml:space\": \"preserve\", \"force\"\
  : false, \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"\
  linenos\": false} -->\n\n````python\n\n   import os\n   from azure.ai.evaluation\
  \ import GroundednessEvaluator\n\n   model_config = {\n       \"azure_endpoint\"\
  : os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n       \"api_key\": os.environ.get(\"\
  AZURE_OPENAI_KEY\"),\n       \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"\
  ),\n   }\n\n   groundedness_evaluator = GroundednessEvaluator(model_config=model_config)\n\
  \   groundedness_evaluator(\n       response=\"Paris is the capital of France.\"\
  ,\n       context=(\n           \"France, a country in Western Europe, is known\
  \ for its rich history and cultural heritage.\"\n           \"The city of Paris,\
  \ located in the northern part of the country, serves as its capital.\"\n      \
  \     \"Paris is renowned for its art, fashion, and landmarks such as the Eiffel\
  \ Tower and the Louvre Museum.\"\n       ),\n   )\n\n   ````\n"
attributes:
- uid: azure.ai.evaluation.GroundednessEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureml://registries/azureml/models/Groundedness-Evaluator/versions/4'
