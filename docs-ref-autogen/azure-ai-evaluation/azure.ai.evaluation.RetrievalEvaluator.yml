### YamlMime:PythonClass
uid: azure.ai.evaluation.RetrievalEvaluator
name: RetrievalEvaluator
fullName: azure.ai.evaluation.RetrievalEvaluator
module: azure.ai.evaluation
inheritances:
- azure.ai.evaluation._evaluators._common._base_prompty_eval.PromptyEvaluatorBase
summary: 'Evaluates retrieval score for a given query and context or a multi-turn
  conversation, including reasoning.


  The retrieval measure assesses the AI system''s performance in retrieving information

  for additional context (e.g. a RAG scenario).


  Retrieval scores range from 1 to 5, with 1 being the worst and 5 being the best.


  High retrieval scores indicate that the AI system has successfully extracted and
  ranked

  the most relevant information at the top, without introducing bias from external
  knowledge

  and ignoring factual correctness. Conversely, low retrieval scores suggest that
  the AI system

  has failed to surface the most relevant context chunks at the top of the list

  and/or introduced bias and ignored factual correctness.


  > [!NOTE]

  > To align with our support of a diverse set of models, an output key without the
  gpt_ prefix has been added.

  >

  > To maintain backwards compatibility, the old key with the gpt_ prefix is still
  be present in the output;

  >

  > however, it is recommended to use the new key moving forward as the old key will
  be deprecated in the future.

  >'
constructor:
  syntax: RetrievalEvaluator(model_config)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
examples:
- "Initialize and call a RetrievalEvaluator.<!--[!code-python[Main](les\\evaluation_samples_evaluate.py\
  \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\\Python\\\
  \\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\4\\\\azure_ai_evaluation-1.2.0\\\
  \\samples\\\\evaluation_samples_evaluate.py\", \"xml:space\": \"preserve\", \"force\"\
  : false, \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"\
  linenos\": false} -->\n\n````python\n\n   import os\n   from azure.ai.evaluation\
  \ import RetrievalEvaluator\n\n   model_config = {\n       \"azure_endpoint\": os.environ.get(\"\
  AZURE_OPENAI_ENDPOINT\"),\n       \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"\
  ),\n       \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n\
  \   }\n\n   retrieval_eval = RetrievalEvaluator(model_config=model_config)\n   conversation\
  \ = {\n       \"messages\": [\n           {\n               \"content\": \"What\
  \ is the capital of France?`''\\\"</>{}{{]\",\n               \"role\": \"user\"\
  ,\n               \"context\": \"Customer wants to know the capital of France\"\
  ,\n           },\n           {\"content\": \"Paris\", \"role\": \"assistant\", \"\
  context\": \"Paris is the capital of France\"},\n           {\n               \"\
  content\": \"What is the capital of Hawaii?\",\n               \"role\": \"user\"\
  ,\n               \"context\": \"Customer wants to know the capital of Hawaii\"\
  ,\n           },\n           {\"content\": \"Honolulu\", \"role\": \"assistant\"\
  , \"context\": \"Honolulu is the capital of Hawaii\"},\n       ],\n       \"context\"\
  : \"Global context\",\n   }\n   retrieval_eval(conversation=conversation)\n\n  \
  \ ````\n"
attributes:
- uid: azure.ai.evaluation.RetrievalEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureml://registries/azureml/models/Retrieval-Evaluator/versions/1'
