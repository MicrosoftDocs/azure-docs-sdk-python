### YamlMime:PythonClass
uid: azure.ai.evaluation.TaskAdherenceEvaluator
name: TaskAdherenceEvaluator
fullName: azure.ai.evaluation.TaskAdherenceEvaluator
module: azure.ai.evaluation
summary: "> [!NOTE]\n> This is an experimental class, and may change at any time.\
  \ Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)\
  \ for more information.\n>\n\nThe Task Adherence evaluator assesses how well an\
  \ AI-generated response follows the assigned task based on:\n\n   * Alignment with\
  \ instructions and definitions \n\n   * Accuracy and clarity of the response \n\n\
  \   * Proper use of provided tool definitions \n\nScoring is based on five levels:\n\
  1. Fully Inadherent - Response completely ignores instructions.\n2. Barely Adherent\
  \ - Partial alignment with critical gaps.\n3. Moderately Adherent - Meets core requirements\
  \ but lacks precision.\n4. Mostly Adherent - Clear and accurate with minor issues.\n\
  5. Fully Adherent - Flawless adherence to instructions.\n\nThe evaluation includes\
  \ a step-by-step reasoning process, a brief explanation, and a final integer score."
constructor:
  syntax: TaskAdherenceEvaluator(model_config, *, threshold=3, credential=None, **kwargs)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
  keywordOnlyParameters:
  - name: threshold
    defaultValue: '3'
  - name: credential
    defaultValue: None
examples:
- "Initialize and call TaskAdherenceEvaluator using Azure AI Project URL in the following\
  \ format\n[https:/](https:/)/{resource_name}.services.ai.azure.com/api/projects/{project_name}<!--[!code-python[Main](les\\\
  evaluation_samples_evaluate_fdp.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
  classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"\
  C:\\\\ToolCache\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\
  \\dist_temp\\\\15\\\\azure_ai_evaluation-1.11.1\\\\samples\\\\evaluation_samples_evaluate_fdp.py\"\
  , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"highlight_args\"\
  : {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\n   import os\n\
  \   from azure.ai.evaluation import TaskAdherenceEvaluator\n\n   model_config =\
  \ {\n       \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),  # https://<account_name>.services.ai.azure.com\n\
  \       \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n       \"azure_deployment\"\
  : os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n   }\n\n   task_adherence_evaluator\
  \ = TaskAdherenceEvaluator(model_config=model_config)\n\n   query = [\n       {\"\
  role\": \"system\", \"content\": \"You are a helpful customer service agent.\"},\n\
  \       {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"What\
  \ is the status of my order #123?\"}]},\n   ]\n\n   response = [\n       {\n   \
  \        \"role\": \"assistant\",\n           \"content\": [\n               {\n\
  \                   \"type\": \"tool_call\",\n                   \"tool_call\":\
  \ {\n                       \"id\": \"tool_001\",\n                       \"type\"\
  : \"function\",\n                       \"function\": {\"name\": \"get_order\",\
  \ \"arguments\": {\"order_id\": \"123\"}},\n                   },\n            \
  \   }\n           ],\n       },\n       {\n           \"role\": \"tool\",\n    \
  \       \"tool_call_id\": \"tool_001\",\n           \"content\": [\n           \
  \    {\"type\": \"tool_result\", \"tool_result\": '{ \"order\": { \"id\": \"123\"\
  , \"status\": \"shipped\" } }'}\n           ],\n       },\n       {\"role\": \"\
  assistant\", \"content\": [{\"type\": \"text\", \"text\": \"Your order #123 has\
  \ been shipped.\"}]},\n   ]\n\n   tool_definitions = [\n       {\n           \"\
  name\": \"get_order\",\n           \"description\": \"Get order details.\",\n  \
  \         \"parameters\": {\"type\": \"object\", \"properties\": {\"order_id\":\
  \ {\"type\": \"string\"}}},\n       }\n   ]\n\n   task_adherence_evaluator(query=query,\
  \ response=response, tool_definitions=tool_definitions)\n\n   ````\n"
attributes:
- uid: azure.ai.evaluation.TaskAdherenceEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureai://built-in/evaluators/task_adherence'
