### YamlMime:PythonClass
uid: azure.ai.evaluation.GroundednessProEvaluator
name: GroundednessProEvaluator
fullName: azure.ai.evaluation.GroundednessProEvaluator
module: azure.ai.evaluation
summary: '> [!NOTE]

  > This is an experimental class, and may change at any time. Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)
  for more information.

  >


  Evaluates service-based groundedness score for a given response, context, and query
  or a multi-turn conversation,

  including reasoning.


  The groundedness measure calls Azure AI Evaluation service to assess how well the
  AI-generated answer is grounded

  in the source context. Even if the responses from LLM are factually correct, they''ll
  be considered ungrounded if

  they can''t be verified against the provided sources (such as your input source
  or your database).


  Service-based groundedness scores are boolean values, where True indicates that
  the response is grounded.


  > [!NOTE]

  > If this evaluator is supplied to the evaluate function, the aggregated metric

  >

  > for the groundedness pro label will be "groundedness_pro_passing_rate".

  >'
constructor:
  syntax: 'GroundednessProEvaluator(credential, azure_ai_project, *, threshold: int
    = 5, **kwargs)'
  parameters:
  - name: credential
    description: The credential for connecting to Azure AI project. Required
    isRequired: true
    types:
    - <xref:azure.core.credentials.TokenCredential>
  - name: azure_ai_project
    description: 'The Azure AI project, which can either be a string representing
      the project endpoint

      or an instance of AzureAIProject. It contains subscription id, resource group,
      and project name.'
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:str>, <xref:azure.ai.evaluation.AzureAIProject>]
  - name: threshold
    description: The threshold for the groundedness pro evaluator. Default is 5.
    isRequired: true
    types:
    - <xref:int>
  - name: kwargs
    description: Additional arguments to pass to the evaluator.
    isRequired: true
    types:
    - <xref:typing.Any>
  keywordOnlyParameters:
  - name: threshold
    defaultValue: '5'
examples:
- "Initialize with a specified threshold and call GroundednessProEvaluator with a\
  \ query, response, and context.<!--[!code-python[Main](les\\evaluation_samples_threshold.py\
  \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"source\": \"C:\\\\ToolCache\\\\Python\\\\3.11.9\\\\x64\\\
  \\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\15\\\\azure_ai_evaluation-1.9.0\\\
  \\samples\\\\evaluation_samples_threshold.py\", \"xml:space\": \"preserve\", \"\
  force\": false, \"language\": \"python\", \"highlight_args\": {\"linenostart\":\
  \ 1}, \"linenos\": false} -->\n\n````python\n\n   import os\n   from azure.identity\
  \ import DefaultAzureCredential\n   from azure.ai.evaluation import GroundednessProEvaluator\n\
  \n   azure_ai_project = {\n       \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"\
  ),\n       \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP_NAME\"\
  ),\n       \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n   }\n   credential\
  \ = DefaultAzureCredential()\n\n   groundedness_pro_eval = GroundednessProEvaluator(\n\
  \       azure_ai_project=azure_ai_project, credential=credential, threshold=2\n\
  \   )\n   groundedness_pro_eval(\n       query=\"What shape has 4 equilateral sides?\"\
  ,\n       response=\"Rhombus\",\n       context=\"Rhombus is a shape with 4 equilateral\
  \ sides.\",\n   )\n\n   ````\n"
attributes:
- uid: azure.ai.evaluation.GroundednessProEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'azureml://registries/azureml/models/Groundedness-Pro-Evaluator/versions/1'
