### YamlMime:PythonClass
uid: azure.ai.evaluation.SimilarityEvaluator
name: SimilarityEvaluator
fullName: azure.ai.evaluation.SimilarityEvaluator
module: azure.ai.evaluation
inheritances:
- azure.ai.evaluation._evaluators._common._base_prompty_eval.PromptyEvaluatorBase
summary: 'Evaluates similarity score for a given query, response, and ground truth.


  The similarity measure evaluates the likeness between a ground truth sentence (or
  document) and the

  AI model''s generated prediction. This calculation involves creating sentence-level
  embeddings for both

  the ground truth and the model''s prediction, which are high-dimensional vector
  representations capturing

  the semantic meaning and context of the sentences.


  Use it when you want an objective evaluation of an AI model''s performance, particularly
  in text generation

  tasks where you have access to ground truth responses. Similarity enables you to
  assess the generated

  text''s semantic alignment with the desired content, helping to gauge the model''s
  quality and accuracy.


  Similarity scores range from 1 to 5, with 1 being the least similar and 5 being
  the most similar.


  > [!NOTE]

  > To align with our support of a diverse set of models, an output key without the
  gpt_ prefix has been added.

  >

  > To maintain backwards compatibility, the old key with the gpt_ prefix is still
  be present in the output;

  >

  > however, it is recommended to use the new key moving forward as the old key will
  be deprecated in the future.

  >'
constructor:
  syntax: SimilarityEvaluator(model_config)
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
examples:
- "Initialize and call a RougeScoreEvaluator with a four-gram rouge type.<!--[!code-python[Main](les\\\
  evaluation_samples_evaluate.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\
  \\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\
  \\4\\\\azure_ai_evaluation-1.2.0\\\\samples\\\\evaluation_samples_evaluate.py\"\
  , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"highlight_args\"\
  : {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\n   from azure.ai.evaluation\
  \ import RougeScoreEvaluator, RougeType\n\n   rouge_evaluator = RougeScoreEvaluator(rouge_type=RougeType.ROUGE_4)\n\
  \   rouge_evaluator(response=\"Paris is the capital of France.\", ground_truth=\"\
  France's capital is Paris.\")\n\n   ````\n"
attributes:
- uid: azure.ai.evaluation.SimilarityEvaluator.id
  name: id
  summary: Evaluator identifier, experimental and to be used only with evaluation
    in cloud.
  signature: id = 'similarity'
