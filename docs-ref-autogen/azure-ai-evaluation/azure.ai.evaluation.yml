### YamlMime:PythonPackage
uid: azure.ai.evaluation
name: evaluation
fullName: azure.ai.evaluation
type: rootImport
functions:
- uid: azure.ai.evaluation.evaluate
  name: evaluate
  summary: "Evaluates target or data with built-in or custom evaluators. If both target\
    \ and data are provided,\n   data will be run through target function and then\
    \ results will be evaluated."
  signature: 'evaluate(*, data: str | PathLike, evaluators: Dict[str, Callable], evaluation_name:
    str | None = None, target: Callable | None = None, evaluator_config: Dict[str,
    EvaluatorConfig] | None = None, azure_ai_project: AzureAIProject | None = None,
    output_path: str | PathLike | None = None, fail_on_evaluator_errors: bool = False,
    **kwargs) -> EvaluationResult'
  keywordOnlyParameters:
  - name: data
    description: 'Path to the data to be evaluated or passed to target if target is
      set.

      JSONL and CSV files are supported.  *target* and *data* both cannot be None.
      Required.'
    types:
    - <xref:str>
  - name: evaluators
    description: 'Evaluators to be used for evaluation. It should be a dictionary
      with key as alias for evaluator

      and value as the evaluator function. Required.'
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Callable>]
  - name: evaluation_name
    description: Display name of the evaluation.
    types:
    - <xref:typing.Optional>[<xref:str>]
  - name: target
    description: Target to be evaluated. *target* and *data* both cannot be None
    types:
    - <xref:typing.Optional>[<xref:typing.Callable>]
  - name: evaluator_config
    description: 'Configuration for evaluators. The configuration should be a dictionary
      with evaluator

      names as keys and a values that are dictionaries containing the column mappings.
      The column mappings should

      be a dictionary with keys as the column names in the evaluator input and values
      as the column names in the

      input data or data generated by target.'
    types:
    - <xref:typing.Optional>[<xref:typing.Dict>[<xref:str>, <xref:azure.ai.evaluation.EvaluatorConfig>]]
  - name: output_path
    description: 'The local folder or file path to save evaluation results to if set.
      If folder path is provided

      the results will be saved to a file named *evaluation_results.json* in the folder.'
    types:
    - <xref:typing.Optional>[<xref:str>]
  - name: azure_ai_project
    description: Logs evaluation results to AI Studio if set.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.evaluation.AzureAIProject>]
  - name: fail_on_evaluator_errors
    description: 'Whether or not the evaluation should cancel early with an EvaluationException

      if ANY evaluator fails during their evaluation.

      Defaults to false, which means that evaluations will continue regardless of
      failures.

      If such failures occur, metrics may be missing, and evidence of failures can
      be found in the evaluation''s logs.'
    types:
    - <xref:bool>
  return:
    description: Evaluation results.
    types:
    - <xref:azure.ai.evaluation.EvaluationResult>
  examples:
  - "Run an evaluation on local data with Coherence and Relevance evaluators.<!--[!code-python[Main](les\\\
    evaluation_samples_evaluate.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\\
    hostedtoolcache\\\\windows\\\\Python\\\\3.11.10\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\14\\\\azure_ai_evaluation-1.2.0\\\\samples\\\\evaluation_samples_evaluate.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   import os\n   from azure.ai.evaluation import evaluate, RelevanceEvaluator,\
    \ CoherenceEvaluator\n\n   model_config = {\n       \"azure_endpoint\": os.environ.get(\"\
    AZURE_OPENAI_ENDPOINT\"),\n       \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"\
    ),\n       \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n\
    \   }\n\n   print(os.getcwd())\n   path = \"./sdk/evaluation/azure-ai-evaluation/samples/data/evaluate_test_data.jsonl\"\
    \n\n   evaluate(\n       data=path,\n       evaluators={\n           \"coherence\"\
    : CoherenceEvaluator(model_config=model_config),\n           \"relevance\": RelevanceEvaluator(model_config=model_config),\n\
    \       },\n       evaluator_config={\n           \"coherence\": {\n         \
    \      \"column_mapping\": {\n                   \"response\": \"${data.response}\"\
    ,\n                   \"query\": \"${data.query}\",\n               },\n     \
    \      },\n           \"relevance\": {\n               \"column_mapping\": {\n\
    \                   \"response\": \"${data.response}\",\n                   \"\
    context\": \"${data.context}\",\n                   \"query\": \"${data.query}\"\
    ,\n               },\n           },\n       },\n   )\n\n\n   ````\n"
classes:
- azure.ai.evaluation.AzureAIProject
- azure.ai.evaluation.AzureOpenAIModelConfiguration
- azure.ai.evaluation.BleuScoreEvaluator
- azure.ai.evaluation.CoherenceEvaluator
- azure.ai.evaluation.ContentSafetyEvaluator
- azure.ai.evaluation.ContentSafetyMultimodalEvaluator
- azure.ai.evaluation.Conversation
- azure.ai.evaluation.EvaluationResult
- azure.ai.evaluation.EvaluatorConfig
- azure.ai.evaluation.F1ScoreEvaluator
- azure.ai.evaluation.FluencyEvaluator
- azure.ai.evaluation.GleuScoreEvaluator
- azure.ai.evaluation.GroundednessEvaluator
- azure.ai.evaluation.GroundednessProEvaluator
- azure.ai.evaluation.HateUnfairnessEvaluator
- azure.ai.evaluation.HateUnfairnessMultimodalEvaluator
- azure.ai.evaluation.IndirectAttackEvaluator
- azure.ai.evaluation.Message
- azure.ai.evaluation.MeteorScoreEvaluator
- azure.ai.evaluation.OpenAIModelConfiguration
- azure.ai.evaluation.ProtectedMaterialEvaluator
- azure.ai.evaluation.ProtectedMaterialMultimodalEvaluator
- azure.ai.evaluation.QAEvaluator
- azure.ai.evaluation.RelevanceEvaluator
- azure.ai.evaluation.RetrievalEvaluator
- azure.ai.evaluation.RougeScoreEvaluator
- azure.ai.evaluation.SelfHarmEvaluator
- azure.ai.evaluation.SelfHarmMultimodalEvaluator
- azure.ai.evaluation.SexualEvaluator
- azure.ai.evaluation.SexualMultimodalEvaluator
- azure.ai.evaluation.SimilarityEvaluator
- azure.ai.evaluation.ViolenceEvaluator
- azure.ai.evaluation.ViolenceMultimodalEvaluator
packages:
- azure.ai.evaluation.simulator
enums:
- azure.ai.evaluation.RougeType
