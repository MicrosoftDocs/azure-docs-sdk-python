### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.synapse.operations.SparkBatchOperations.create
  - azure.synapse.operations.SparkBatchOperations.delete
  - azure.synapse.operations.SparkBatchOperations.get
  - azure.synapse.operations.SparkBatchOperations.list
  - azure.synapse.operations.SparkBatchOperations.models
  class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.synapse.operations
  name: SparkBatchOperations
  summary: 'SparkBatchOperations operations.


    You should not instantiate directly this class, but create a Client instance that
    will create it for you and attach it as attribute.'
  syntax:
    content: SparkBatchOperations(client, config, serializer, deserializer)
    parameters:
    - description: Client for service requests.
      id: client
    - description: Configuration of service client.
      id: config
    - description: An object model serializer.
      id: serializer
    - description: An object model deserializer.
      id: deserializer
    variables:
    - description: Alias to model classes used in this operation group.
      id: models
  type: class
  uid: azure.synapse.operations.SparkBatchOperations
- class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations.create
  langs:
  - python
  module: azure.synapse.operations
  name: create(workspace_name, spark_pool_name, livy_request, detailed=None, **kwargs)
  summary: Create new spark batch job.
  syntax:
    content: create(workspace_name, spark_pool_name, livy_request, detailed=None,
      **kwargs)
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Livy compatible batch job request payload.
      id: livy_request
      type:
      - azure.synapse.models.ExtendedLivyBatchRequest
    - defaultValue: None
      description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyBatchResponse
  type: method
  uid: azure.synapse.operations.SparkBatchOperations.create
- class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations.delete
  langs:
  - python
  module: azure.synapse.operations
  name: delete(workspace_name, spark_pool_name, batch_id, **kwargs)
  summary: Cancels a running spark batch job.
  syntax:
    content: delete(workspace_name, spark_pool_name, batch_id, **kwargs)
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Identifier for the batch job.
      id: batch_id
      type:
      - int
    return:
      description: None or the result of cls(response)
      type:
      - None
  type: method
  uid: azure.synapse.operations.SparkBatchOperations.delete
- class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations.get
  langs:
  - python
  module: azure.synapse.operations
  name: get(workspace_name, spark_pool_name, batch_id, detailed=None, **kwargs)
  summary: Gets a single spark batch job.
  syntax:
    content: get(workspace_name, spark_pool_name, batch_id, detailed=None, **kwargs)
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Identifier for the batch job.
      id: batch_id
      type:
      - int
    - defaultValue: None
      description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyBatchResponse
  type: method
  uid: azure.synapse.operations.SparkBatchOperations.get
- class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations.list
  langs:
  - python
  module: azure.synapse.operations
  name: list(workspace_name, spark_pool_name, from_parameter=None, size=None, detailed=None,
    **kwargs)
  summary: List all spark batch jobs which are running under a particular spark pool.
  syntax:
    content: list(workspace_name, spark_pool_name, from_parameter=None, size=None,
      detailed=None, **kwargs)
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - defaultValue: None
      description: Optional param specifying which index the list should begin from.
      id: from_parameter
      type:
      - int
    - defaultValue: None
      description: 'Optional param specifying the size of the returned list.

        By default it is 20 and that is the maximum.'
      id: size
      type:
      - int
    - defaultValue: None
      description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyListBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyListBatchResponse
  type: method
  uid: azure.synapse.operations.SparkBatchOperations.list
- class: azure.synapse.operations.SparkBatchOperations
  fullName: azure.synapse.operations.SparkBatchOperations.models
  langs:
  - python
  module: azure.synapse.operations
  name: models
  syntax:
    content: models = <module 'azure.synapse.models' from 'c:\\hostedtoolcache\\windows\\python\\3.6.8\\x64\\lib\\site-packages\\azure\\synapse\\models\\__init__.py'>
  type: attribute
  uid: azure.synapse.operations.SparkBatchOperations.models
references:
- fullName: azure.synapse.operations.SparkBatchOperations.create
  isExternal: false
  name: create(workspace_name, spark_pool_name, livy_request, detailed=None, **kwargs)
  parent: azure.synapse.operations.SparkBatchOperations
  uid: azure.synapse.operations.SparkBatchOperations.create
- fullName: azure.synapse.operations.SparkBatchOperations.delete
  isExternal: false
  name: delete(workspace_name, spark_pool_name, batch_id, **kwargs)
  parent: azure.synapse.operations.SparkBatchOperations
  uid: azure.synapse.operations.SparkBatchOperations.delete
- fullName: azure.synapse.operations.SparkBatchOperations.get
  isExternal: false
  name: get(workspace_name, spark_pool_name, batch_id, detailed=None, **kwargs)
  parent: azure.synapse.operations.SparkBatchOperations
  uid: azure.synapse.operations.SparkBatchOperations.get
- fullName: azure.synapse.operations.SparkBatchOperations.list
  isExternal: false
  name: list(workspace_name, spark_pool_name, from_parameter=None, size=None, detailed=None,
    **kwargs)
  parent: azure.synapse.operations.SparkBatchOperations
  uid: azure.synapse.operations.SparkBatchOperations.list
- fullName: azure.synapse.operations.SparkBatchOperations.models
  isExternal: false
  name: models
  parent: azure.synapse.operations.SparkBatchOperations
  uid: azure.synapse.operations.SparkBatchOperations.models
