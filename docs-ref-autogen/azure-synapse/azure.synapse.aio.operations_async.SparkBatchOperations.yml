### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.synapse.aio.operations_async.SparkBatchOperations.create
  - azure.synapse.aio.operations_async.SparkBatchOperations.delete
  - azure.synapse.aio.operations_async.SparkBatchOperations.get
  - azure.synapse.aio.operations_async.SparkBatchOperations.list
  - azure.synapse.aio.operations_async.SparkBatchOperations.models
  class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: SparkBatchOperations
  summary: 'SparkBatchOperations async operations.


    You should not instantiate directly this class, but create a Client instance that
    will create it for you and attach it as attribute.'
  syntax:
    content: SparkBatchOperations(client, config, serializer, deserializer) -> None
    parameters:
    - description: Client for service requests.
      id: client
    - description: Configuration of service client.
      id: config
    - description: An object model serializer.
      id: serializer
    - description: An object model deserializer.
      id: deserializer
    variables:
    - description: Alias to model classes used in this operation group.
      id: models
  type: class
  uid: azure.synapse.aio.operations_async.SparkBatchOperations
- class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations.create
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: 'create(workspace_name: str, spark_pool_name: str, livy_request: azure.synapse.models._models_py3.ExtendedLivyBatchRequest,
    detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
  summary: Create new spark batch job.
  syntax:
    content: 'create(workspace_name: str, spark_pool_name: str, livy_request: azure.synapse.models._models_py3.ExtendedLivyBatchRequest,
      detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Livy compatible batch job request payload.
      id: livy_request
      type:
      - azure.synapse.models.ExtendedLivyBatchRequest
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyBatchResponse
  type: method
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.create
- class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations.delete
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: 'delete(workspace_name: str, spark_pool_name: str, batch_id: int, **kwargs)
    -> None'
  summary: Cancels a running spark batch job.
  syntax:
    content: 'delete(workspace_name: str, spark_pool_name: str, batch_id: int, **kwargs)
      -> None'
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Identifier for the batch job.
      id: batch_id
      type:
      - int
    return:
      description: None or the result of cls(response)
      type:
      - None
  type: method
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.delete
- class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations.get
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: 'get(workspace_name: str, spark_pool_name: str, batch_id: int, detailed: typing.Union[bool,
    NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
  summary: Gets a single spark batch job.
  syntax:
    content: 'get(workspace_name: str, spark_pool_name: str, batch_id: int, detailed:
      typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Identifier for the batch job.
      id: batch_id
      type:
      - int
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyBatchResponse
  type: method
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.get
- class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations.list
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: 'list(workspace_name: str, spark_pool_name: str, from_parameter: typing.Union[int,
    NoneType] = None, size: typing.Union[int, NoneType] = None, detailed: typing.Union[bool,
    NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyListBatchResponse'
  summary: List all spark batch jobs which are running under a particular spark pool.
  syntax:
    content: 'list(workspace_name: str, spark_pool_name: str, from_parameter: typing.Union[int,
      NoneType] = None, size: typing.Union[int, NoneType] = None, detailed: typing.Union[bool,
      NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyListBatchResponse'
    parameters:
    - description: The name of the workspace to execute operations on.
      id: workspace_name
      type:
      - str
    - description: Name of the spark pool. "ondemand" targets the ondemand pool.
      id: spark_pool_name
      type:
      - str
    - description: Optional param specifying which index the list should begin from.
      id: from_parameter
      type:
      - int
    - description: 'Optional param specifying the size of the returned list.

        By default it is 20 and that is the maximum.'
      id: size
      type:
      - int
    - description: 'Optional query param specifying whether detailed response is returned
        beyond

        plain livy.'
      id: detailed
      type:
      - bool
    return:
      description: ExtendedLivyListBatchResponse or the result of cls(response)
      type:
      - azure.synapse.models.ExtendedLivyListBatchResponse
  type: method
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.list
- class: azure.synapse.aio.operations_async.SparkBatchOperations
  fullName: azure.synapse.aio.operations_async.SparkBatchOperations.models
  langs:
  - python
  module: azure.synapse.aio.operations_async
  name: models
  syntax:
    content: models = <module 'azure.synapse.models' from 'c:\\hostedtoolcache\\windows\\python\\3.6.8\\x64\\lib\\site-packages\\azure\\synapse\\models\\__init__.py'>
  type: attribute
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.models
references:
- fullName: azure.synapse.aio.operations_async.SparkBatchOperations.create
  isExternal: false
  name: 'create(workspace_name: str, spark_pool_name: str, livy_request: azure.synapse.models._models_py3.ExtendedLivyBatchRequest,
    detailed: typing.Union[bool, NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
  parent: azure.synapse.aio.operations_async.SparkBatchOperations
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.create
- fullName: azure.synapse.aio.operations_async.SparkBatchOperations.delete
  isExternal: false
  name: 'delete(workspace_name: str, spark_pool_name: str, batch_id: int, **kwargs)
    -> None'
  parent: azure.synapse.aio.operations_async.SparkBatchOperations
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.delete
- fullName: azure.synapse.aio.operations_async.SparkBatchOperations.get
  isExternal: false
  name: 'get(workspace_name: str, spark_pool_name: str, batch_id: int, detailed: typing.Union[bool,
    NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyBatchResponse'
  parent: azure.synapse.aio.operations_async.SparkBatchOperations
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.get
- fullName: azure.synapse.aio.operations_async.SparkBatchOperations.list
  isExternal: false
  name: 'list(workspace_name: str, spark_pool_name: str, from_parameter: typing.Union[int,
    NoneType] = None, size: typing.Union[int, NoneType] = None, detailed: typing.Union[bool,
    NoneType] = None, **kwargs) -> azure.synapse.models._models_py3.ExtendedLivyListBatchResponse'
  parent: azure.synapse.aio.operations_async.SparkBatchOperations
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.list
- fullName: azure.synapse.aio.operations_async.SparkBatchOperations.models
  isExternal: false
  name: models
  parent: azure.synapse.aio.operations_async.SparkBatchOperations
  uid: azure.synapse.aio.operations_async.SparkBatchOperations.models
