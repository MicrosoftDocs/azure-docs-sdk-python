### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.file.fileservice.FileService.abort_copy_file
  - azure.storage.file.fileservice.FileService.clear_range
  - azure.storage.file.fileservice.FileService.copy_file
  - azure.storage.file.fileservice.FileService.create_directory
  - azure.storage.file.fileservice.FileService.create_file
  - azure.storage.file.fileservice.FileService.create_file_from_bytes
  - azure.storage.file.fileservice.FileService.create_file_from_path
  - azure.storage.file.fileservice.FileService.create_file_from_stream
  - azure.storage.file.fileservice.FileService.create_file_from_text
  - azure.storage.file.fileservice.FileService.create_share
  - azure.storage.file.fileservice.FileService.delete_directory
  - azure.storage.file.fileservice.FileService.delete_file
  - azure.storage.file.fileservice.FileService.delete_share
  - azure.storage.file.fileservice.FileService.exists
  - azure.storage.file.fileservice.FileService.generate_account_shared_access_signature
  - azure.storage.file.fileservice.FileService.generate_file_shared_access_signature
  - azure.storage.file.fileservice.FileService.generate_share_shared_access_signature
  - azure.storage.file.fileservice.FileService.get_directory_metadata
  - azure.storage.file.fileservice.FileService.get_directory_properties
  - azure.storage.file.fileservice.FileService.get_file_metadata
  - azure.storage.file.fileservice.FileService.get_file_properties
  - azure.storage.file.fileservice.FileService.get_file_service_properties
  - azure.storage.file.fileservice.FileService.get_file_to_bytes
  - azure.storage.file.fileservice.FileService.get_file_to_path
  - azure.storage.file.fileservice.FileService.get_file_to_stream
  - azure.storage.file.fileservice.FileService.get_file_to_text
  - azure.storage.file.fileservice.FileService.get_share_acl
  - azure.storage.file.fileservice.FileService.get_share_metadata
  - azure.storage.file.fileservice.FileService.get_share_properties
  - azure.storage.file.fileservice.FileService.get_share_stats
  - azure.storage.file.fileservice.FileService.list_directories_and_files
  - azure.storage.file.fileservice.FileService.list_ranges
  - azure.storage.file.fileservice.FileService.list_shares
  - azure.storage.file.fileservice.FileService.make_file_url
  - azure.storage.file.fileservice.FileService.resize_file
  - azure.storage.file.fileservice.FileService.set_directory_metadata
  - azure.storage.file.fileservice.FileService.set_file_metadata
  - azure.storage.file.fileservice.FileService.set_file_properties
  - azure.storage.file.fileservice.FileService.set_file_service_properties
  - azure.storage.file.fileservice.FileService.set_share_acl
  - azure.storage.file.fileservice.FileService.set_share_metadata
  - azure.storage.file.fileservice.FileService.set_share_properties
  - azure.storage.file.fileservice.FileService.snapshot_share
  - azure.storage.file.fileservice.FileService.update_range
  - azure.storage.file.fileservice.FileService.MAX_CHUNK_GET_SIZE
  - azure.storage.file.fileservice.FileService.MAX_RANGE_SIZE
  - azure.storage.file.fileservice.FileService.MAX_SINGLE_GET_SIZE
  class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService
  inheritance:
  - inheritance:
    - type: builtins.object
    type: azure.storage.common.storageclient.StorageClient
  langs:
  - python
  module: azure.storage.file.fileservice
  name: FileService
  source:
    id: FileService
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 92
  summary: 'The Server Message Block (SMB) protocol is the preferred file share protocol

    used on premise today. The Microsoft Azure File service enables customers to

    leverage the availability and scalability of Azure''s Cloud Infrastructure as

    a Service (IaaS) SMB without having to rewrite SMB client applications.


    The Azure File service also offers a compelling alternative to traditional

    Direct Attached Storage (DAS) and Storage Area Network (SAN) solutions, which

    are often complex and expensive to install, configure, and operate.
















































    '
  syntax:
    content: FileService(account_name=None, account_key=None, sas_token=None, protocol='https',
      endpoint_suffix='core.windows.net', request_session=None, connection_string=None,
      socket_timeout=None)
    variables:
    - description: 'The size of the first range get performed by get_file_to_* methods
        if

        max_connections is greater than 1. Less data will be returned if the

        file is smaller than this.

        '
      id: MAX_SINGLE_GET_SIZE
      type:
      - int
    - description: 'The size of subsequent range gets performed by get_file_to_* methods
        if

        max_connections is greater than 1 and the file is larger than MAX_SINGLE_GET_SIZE.

        Less data will be returned if the remainder of the file is smaller than

        this. If this is set to larger than 4MB, content_validation will throw an

        error if enabled. However, if content_validation is not desired a size

        greater than 4MB may be optimal. Setting this below 4MB is not recommended.

        '
      id: MAX_CHUNK_GET_SIZE
      type:
      - int
    - description: 'The size of the ranges put by create_file_from_* methods. Smaller
        ranges

        may be put if there is less data provided. The maximum range size the service

        supports is 4MB.

        '
      id: MAX_RANGE_SIZE
      type:
      - int
  type: class
  uid: azure.storage.file.fileservice.FileService
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.abort_copy_file
  langs:
  - python
  module: azure.storage.file.fileservice
  name: abort_copy_file
  source:
    id: abort_copy_file
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1474
  summary: "   Aborts a pending copy_file operation, and leaves a destination file\n\
    \   with zero length and full metadata.\n"
  syntax:
    content: abort_copy_file(share_name, directory_name, file_name, copy_id, timeout=None)
    parameters:
    - description: 'Name of destination share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of destination file.

        '
      id: file_name
      type:
      - str
    - description: 'Copy identifier provided in the copy.id of the original

        copy_file operation.

        '
      id: copy_id
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.abort_copy_file
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.clear_range
  langs:
  - python
  module: azure.storage.file.fileservice
  name: clear_range
  source:
    id: clear_range
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 2379
  summary: 'Clears the specified range and releases the space used in storage for

    that range.

    '
  syntax:
    content: clear_range(share_name, directory_name, file_name, start_range, end_range,
      timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'Start of byte range to use for clearing a section of the file.

        The range can be up to 4 MB in size.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - description: 'End of byte range to use for clearing a section of the file.

        The range can be up to 4 MB in size.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.clear_range
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.copy_file
  langs:
  - python
  module: azure.storage.file.fileservice
  name: copy_file
  source:
    id: copy_file
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1420
  summary: 'Copies a file asynchronously. This operation returns a copy operation

    properties object, including a copy ID you can use to check or abort the

    copy operation. The File service copies files on a best-effort basis.


    If the destination file exists, it will be overwritten. The destination

    file cannot be modified while the copy operation is in progress.

    '
  syntax:
    content: copy_file(share_name, directory_name, file_name, copy_source, metadata=None,
      timeout=None)
    parameters:
    - description: 'Name of the destination share. The share must exist.

        '
      id: share_name
      type:
      - str
    - description: 'Name of the destination directory. The directory must exist.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of the destination file. If the destination file exists,
        it will

        be overwritten. Otherwise, it will be created.

        '
      id: file_name
      type:
      - str
    - description: 'A URL of up to 2 KB in length that specifies an Azure file or
        blob.

        The value should be URL-encoded as it would appear in a request URI.

        If the source is in another account, the source must either be public

        or must be authenticated via a shared access signature. If the source

        is public, no authentication is required.

        Examples:

        [https://myaccount.file.core.windows.net/myshare/mydir/myfile](https://myaccount.file.core.windows.net/myshare/mydir/myfile)

        [https://otheraccount.file.core.windows.net/myshare/mydir/myfile?sastoken](https://otheraccount.file.core.windows.net/myshare/mydir/myfile?sastoken)

        '
      id: copy_source
      type:
      - str
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata. If no name-value

        pairs are specified, the operation will copy the metadata from the

        source blob or file to the destination file. If one or more name-value

        pairs are specified, the destination file is created with the specified

        metadata, and the metadata is not copied from the source blob or file.

        '
      id: metadata
      type:
      - dict(str, str).
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'Copy operation properties such as status, source, and ID.

        '
      type:
      - azure.storage.file.models.CopyProperties
  type: method
  uid: azure.storage.file.fileservice.FileService.copy_file
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_directory
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_directory
  source:
    id: create_directory
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 941
  summary: 'Creates a new directory under the specified share or parent directory.

    If the directory with the same name already exists, the operation fails

    on the service. By default, the exception is swallowed by the client.

    To expose the exception, specify True for fail_on_exists.

    '
  syntax:
    content: create_directory(share_name, directory_name, metadata=None, fail_on_exist=False,
      timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'Name of directory to create, including the path to the parent

        directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'A dict with name_value pairs to associate with the

        share as metadata. Example:{''Category'':''test''}

        '
      id: metadata
      type:
      - 'dict(str, str):'
    - defaultValue: 'False'
      description: 'specify whether to throw an exception when the directory exists.

        False by default.

        '
      id: fail_on_exist
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'True if directory is created, False if directory already exists.

        '
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.create_directory
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_file
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_file
  source:
    id: create_file
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1533
  summary: 'Creates a new file.


    See create_file_from_* for high level functions that handle the

    creation and upload of large files with automatic chunking and

    progress notifications.

    '
  syntax:
    content: create_file(share_name, directory_name, file_name, content_length, content_settings=None,
      metadata=None, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file to create or update.

        '
      id: file_name
      type:
      - str
    - description: 'Length of the file in bytes.

        '
      id: content_length
      type:
      - int
    - defaultValue: None
      description: 'ContentSettings object used to set file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.create_file
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_file_from_bytes
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_file_from_bytes
  source:
    id: create_file_from_bytes
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1675
  summary: 'Creates a new file from an array of bytes, or updates the content

    of an existing file, with automatic chunking and progress

    notifications.

    '
  syntax:
    content: create_file_from_bytes(share_name, directory_name, file_name, file, index=0,
      count=None, content_settings=None, metadata=None, validate_content=False, progress_callback=None,
      max_connections=2, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file to create or update.

        '
      id: file_name
      type:
      - str
    - description: 'Content of file as an array of bytes.

        '
      id: file
      type:
      - str
    - defaultValue: '0'
      description: 'Start index in the array of bytes.

        '
      id: index
      type:
      - int
    - defaultValue: None
      description: 'Number of bytes to upload. Set to None or negative value to upload

        all bytes starting from index.

        '
      id: count
      type:
      - int
    - defaultValue: None
      description: 'ContentSettings object used to set file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: 'False'
      description: 'If true, calculates an MD5 hash for each range of the file. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        file.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)
        where

        current is the number of bytes transfered so far and total is the

        size of the file, or None if the total size is unknown.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'Maximum number of parallel connections to use.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.create_file_from_bytes
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_file_from_path
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_file_from_path
  source:
    id: create_file_from_path
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1577
  summary: 'Creates a new azure file from a local file path, or updates the content
    of an

    existing file, with automatic chunking and progress notifications.

    '
  syntax:
    content: create_file_from_path(share_name, directory_name, file_name, local_file_path,
      content_settings=None, metadata=None, validate_content=False, progress_callback=None,
      max_connections=2, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file to create or update.

        '
      id: file_name
      type:
      - str
    - description: 'Path of the local file to upload as the file content.

        '
      id: local_file_path
      type:
      - str
    - defaultValue: None
      description: 'ContentSettings object used for setting file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: 'False'
      description: 'If true, calculates an MD5 hash for each range of the file. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        file.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)
        where

        current is the number of bytes transfered so far and total is the

        size of the file, or None if the total size is unknown.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'Maximum number of parallel connections to use.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.create_file_from_path
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_file_from_stream
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_file_from_stream
  source:
    id: create_file_from_stream
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1741
  summary: 'Creates a new file from a file/stream, or updates the content of an

    existing file, with automatic chunking and progress notifications.

    '
  syntax:
    content: create_file_from_stream(share_name, directory_name, file_name, stream,
      count, content_settings=None, metadata=None, validate_content=False, progress_callback=None,
      max_connections=2, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file to create or update.

        '
      id: file_name
      type:
      - str
    - description: 'Opened file/stream to upload as the file content.

        '
      id: stream
      type:
      - io.IOBase
    - description: 'Number of bytes to read from the stream. This is required, a

        file cannot be created if the count is unknown.

        '
      id: count
      type:
      - int
    - defaultValue: None
      description: 'ContentSettings object used to set file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: 'False'
      description: 'If true, calculates an MD5 hash for each range of the file. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        file.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)
        where

        current is the number of bytes transfered so far and total is the

        size of the file, or None if the total size is unknown.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'Maximum number of parallel connections to use. Note that parallel
        upload

        requires the stream to be seekable.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.create_file_from_stream
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_file_from_text
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_file_from_text
  source:
    id: create_file_from_text
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1628
  summary: 'Creates a new file from str/unicode, or updates the content of an

    existing file, with automatic chunking and progress notifications.

    '
  syntax:
    content: create_file_from_text(share_name, directory_name, file_name, text, encoding='utf-8',
      content_settings=None, metadata=None, validate_content=False, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file to create or update.

        '
      id: file_name
      type:
      - str
    - description: 'Text to upload to the file.

        '
      id: text
      type:
      - str
    - defaultValue: utf-8
      description: 'Python encoding to use to convert the text to bytes.

        '
      id: encoding
      type:
      - str
    - defaultValue: None
      description: 'ContentSettings object used to set file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'Name-value pairs associated with the file as metadata.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: 'False'
      description: 'If true, calculates an MD5 hash for each range of the file. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        file.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.create_file_from_text
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.create_share
  langs:
  - python
  module: azure.storage.file.fileservice
  name: create_share
  source:
    id: create_share
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 610
  summary: 'Creates a new share under the specified account. If the share

    with the same name already exists, the operation fails on the

    service. By default, the exception is swallowed by the client.

    To expose the exception, specify True for fail_on_exists.

    '
  syntax:
    content: create_share(share_name, metadata=None, quota=None, fail_on_exist=False,
      timeout=None)
    parameters:
    - description: 'Name of share to create.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'A dict with name_value pairs to associate with the

        share as metadata. Example:{''Category'':''test''}

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: None
      description: 'Specifies the maximum size of the share, in gigabytes. Must be

        greater than 0, and less than or equal to 5TB (5120).

        '
      id: quota
      type:
      - int
    - defaultValue: 'False'
      description: 'Specify whether to throw an exception when the share exists.

        False by default.

        '
      id: fail_on_exist
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'True if share is created, False if share already exists.

        '
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.create_share
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.delete_directory
  langs:
  - python
  module: azure.storage.file.fileservice
  name: delete_directory
  source:
    id: delete_directory
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 989
  summary: 'Deletes the specified empty directory. Note that the directory must

    be empty before it can be deleted. Attempting to delete directories

    that are not empty will fail.


    If the directory does not exist, the operation fails on the

    service. By default, the exception is swallowed by the client.

    To expose the exception, specify True for fail_not_exist.

    '
  syntax:
    content: delete_directory(share_name, directory_name, fail_not_exist=False, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'Name of directory to delete, including the path to the parent

        directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: 'False'
      description: 'Specify whether to throw an exception when the directory doesn''t

        exist.

        '
      id: fail_not_exist
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'True if directory is deleted, False otherwise.

        '
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.delete_directory
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.delete_file
  langs:
  - python
  module: azure.storage.file.fileservice
  name: delete_file
  source:
    id: delete_file
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1509
  summary: 'Marks the specified file for deletion. The file is later

    deleted during garbage collection.

    '
  syntax:
    content: delete_file(share_name, directory_name, file_name, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.delete_file
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.delete_share
  langs:
  - python
  module: azure.storage.file.fileservice
  name: delete_share
  source:
    id: delete_share
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 893
  summary: 'Marks the specified share for deletion. If the share

    does not exist, the operation fails on the service. By

    default, the exception is swallowed by the client.

    To expose the exception, specify True for fail_not_exist.

    '
  syntax:
    content: delete_share(share_name, fail_not_exist=False, timeout=None, snapshot=None,
      delete_snapshots=None)
    parameters:
    - description: 'Name of share to delete.

        '
      id: share_name
      type:
      - str
    - defaultValue: 'False'
      description: 'Specify whether to throw an exception when the share doesn''t

        exist. False by default.

        '
      id: fail_not_exist
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        Specify this argument to delete a specific snapshot only.

        delete_snapshots must be None if this is specified.

        '
      id: snapshot
      type:
      - str
    - defaultValue: None
      description: 'To delete a share that has snapshots, this must be specified as
        DeleteSnapshot.Include.

        '
      id: delete_snapshots
      type:
      - azure.storage.file.models.DeleteSnapshot
    return:
      description: 'True if share is deleted, False share doesn''t exist.

        '
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.delete_share
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.exists
  langs:
  - python
  module: azure.storage.file.fileservice
  name: exists
  source:
    id: exists
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1254
  summary: 'Returns a boolean indicating whether the share exists if only share name
    is

    given. If directory_name is specificed a boolean will be returned indicating

    if the directory exists. If file_name is specified as well, a boolean will be

    returned indicating if the file exists.

    '
  syntax:
    content: exists(share_name, directory_name=None, file_name=None, timeout=None,
      snapshot=None)
    parameters:
    - description: 'Name of a share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The path to a directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'Name of a file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A boolean indicating whether the resource exists.

        '
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.exists
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.generate_account_shared_access_signature
  langs:
  - python
  module: azure.storage.file.fileservice
  name: generate_account_shared_access_signature
  source:
    id: generate_account_shared_access_signature
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 224
  summary: 'Generates a shared access signature for the file service.

    Use the returned signature with the sas_token parameter of the FileService.

    '
  syntax:
    content: generate_account_shared_access_signature(resource_types, permission,
      expiry, start=None, ip=None, protocol=None)
    parameters:
    - description: 'Specifies the resource types that are accessible with the account
        SAS.

        '
      id: resource_types
      type:
      - ResourceTypes
    - description: 'The permissions associated with the shared access signature. The

        user is restricted to operations allowed by the permissions.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has been

        specified in an associated stored access policy.

        '
      id: permission
      type:
      - AccountPermissions
    - description: 'The time at which the shared access signature becomes invalid.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has

        been specified in an associated stored access policy. Azure will always

        convert values to UTC. If a date is passed in without timezone info, it

        is assumed to be UTC.

        '
      id: expiry
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'The time at which the shared access signature becomes valid. If

        omitted, start time for this call is assumed to be the time when the

        storage service receives the request. Azure will always convert values

        to UTC. If a date is passed in without timezone info, it is assumed to

        be UTC.

        '
      id: start
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'Specifies an IP address or a range of IP addresses from which
        to accept requests.

        If the IP address from which the request originates does not match the IP
        address

        or address range specified on the SAS token, the request is not authenticated.

        For example, specifying sip=168.1.5.65 or sip=168.1.5.60-168.1.5.70 on the
        SAS

        restricts the request to those IP addresses.

        '
      id: ip
      type:
      - str
    - defaultValue: None
      description: 'Specifies the protocol permitted for a request made. Possible
        values are

        both HTTPS and HTTP (https,http) or HTTPS only (https). The default value

        is https,http. Note that HTTP only is not a permitted value.

        '
      id: protocol
      type:
      - str
    return:
      description: 'A Shared Access Signature (sas) token.

        '
      type:
      - str
  type: method
  uid: azure.storage.file.fileservice.FileService.generate_account_shared_access_signature
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.generate_file_shared_access_signature
  langs:
  - python
  module: azure.storage.file.fileservice
  name: generate_file_shared_access_signature
  source:
    id: generate_file_shared_access_signature
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 364
  summary: 'Generates a shared access signature for the file.

    Use the returned signature with the sas_token parameter of FileService.

    '
  syntax:
    content: generate_file_shared_access_signature(share_name, directory_name=None,
      file_name=None, permission=None, expiry=None, start=None, id=None, ip=None,
      protocol=None, cache_control=None, content_disposition=None, content_encoding=None,
      content_language=None, content_type=None)
    parameters:
    - description: 'Name of share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'Name of directory. SAS tokens cannot be created for directories,
        so

        this parameter should only be present if file_name is provided.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'Name of file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The permissions associated with the shared access signature. The

        user is restricted to operations allowed by the permissions.

        Permissions must be ordered read, create, write, delete, list.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has been

        specified in an associated stored access policy.

        '
      id: permission
      type:
      - FilePermissions
    - defaultValue: None
      description: 'The time at which the shared access signature becomes invalid.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has

        been specified in an associated stored access policy. Azure will always

        convert values to UTC. If a date is passed in without timezone info, it

        is assumed to be UTC.

        '
      id: expiry
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'The time at which the shared access signature becomes valid. If

        omitted, start time for this call is assumed to be the time when the

        storage service receives the request. Azure will always convert values

        to UTC. If a date is passed in without timezone info, it is assumed to

        be UTC.

        '
      id: start
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'A unique value up to 64 characters in length that correlates to
        a

        stored access policy. To create a stored access policy, use

        set_file_service_properties.

        '
      id: id
      type:
      - str
    - defaultValue: None
      description: 'Specifies an IP address or a range of IP addresses from which
        to accept requests.

        If the IP address from which the request originates does not match the IP
        address

        or address range specified on the SAS token, the request is not authenticated.

        For example, specifying sip=168.1.5.65 or sip=168.1.5.60-168.1.5.70 on the
        SAS

        restricts the request to those IP addresses.

        '
      id: ip
      type:
      - str
    - defaultValue: None
      description: 'Specifies the protocol permitted for a request made. Possible
        values are

        both HTTPS and HTTP (https,http) or HTTPS only (https). The default value

        is https,http. Note that HTTP only is not a permitted value.

        '
      id: protocol
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Cache-Control when resource is accessed

        using this shared access signature.

        '
      id: cache_control
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Disposition when resource is
        accessed

        using this shared access signature.

        '
      id: content_disposition
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Encoding when resource is accessed

        using this shared access signature.

        '
      id: content_encoding
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Language when resource is accessed

        using this shared access signature.

        '
      id: content_language
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Type when resource is accessed

        using this shared access signature.

        '
      id: content_type
      type:
      - str
    return:
      description: 'A Shared Access Signature (sas) token.

        '
      type:
      - str
  type: method
  uid: azure.storage.file.fileservice.FileService.generate_file_shared_access_signature
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.generate_share_shared_access_signature
  langs:
  - python
  module: azure.storage.file.fileservice
  name: generate_share_shared_access_signature
  source:
    id: generate_share_shared_access_signature
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 273
  summary: 'Generates a shared access signature for the share.

    Use the returned signature with the sas_token parameter of FileService.

    '
  syntax:
    content: generate_share_shared_access_signature(share_name, permission=None, expiry=None,
      start=None, id=None, ip=None, protocol=None, cache_control=None, content_disposition=None,
      content_encoding=None, content_language=None, content_type=None)
    parameters:
    - description: 'Name of share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The permissions associated with the shared access signature. The

        user is restricted to operations allowed by the permissions.

        Permissions must be ordered read, create, write, delete, list.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has been

        specified in an associated stored access policy.

        '
      id: permission
      type:
      - SharePermissions
    - defaultValue: None
      description: 'The time at which the shared access signature becomes invalid.

        Required unless an id is given referencing a stored access policy

        which contains this field. This field must be omitted if it has

        been specified in an associated stored access policy. Azure will always

        convert values to UTC. If a date is passed in without timezone info, it

        is assumed to be UTC.

        '
      id: expiry
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'The time at which the shared access signature becomes valid. If

        omitted, start time for this call is assumed to be the time when the

        storage service receives the request. Azure will always convert values

        to UTC. If a date is passed in without timezone info, it is assumed to

        be UTC.

        '
      id: start
      type:
      - datetime
      - str
    - defaultValue: None
      description: 'A unique value up to 64 characters in length that correlates to
        a

        stored access policy. To create a stored access policy, use @azure.storage.file.fileservice.set_share_acl.

        '
      id: id
      type:
      - str
    - defaultValue: None
      description: 'Specifies an IP address or a range of IP addresses from which
        to accept requests.

        If the IP address from which the request originates does not match the IP
        address

        or address range specified on the SAS token, the request is not authenticated.

        For example, specifying sip=168.1.5.65 or sip=168.1.5.60-168.1.5.70 on the
        SAS

        restricts the request to those IP addresses.

        '
      id: ip
      type:
      - str
    - defaultValue: None
      description: 'Specifies the protocol permitted for a request made. Possible
        values are

        both HTTPS and HTTP (https,http) or HTTPS only (https). The default value

        is https,http. Note that HTTP only is not a permitted value.

        '
      id: protocol
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Cache-Control when resource is accessed

        using this shared access signature.

        '
      id: cache_control
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Disposition when resource is
        accessed

        using this shared access signature.

        '
      id: content_disposition
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Encoding when resource is accessed

        using this shared access signature.

        '
      id: content_encoding
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Language when resource is accessed

        using this shared access signature.

        '
      id: content_language
      type:
      - str
    - defaultValue: None
      description: 'Response header value for Content-Type when resource is accessed

        using this shared access signature.

        '
      id: content_type
      type:
      - str
    return:
      description: 'A Shared Access Signature (sas) token.

        '
      type:
      - str
  type: method
  uid: azure.storage.file.fileservice.FileService.generate_share_shared_access_signature
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_directory_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_directory_metadata
  source:
    id: get_directory_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1066
  summary: 'Returns all user-defined metadata for the specified directory.

    '
  syntax:
    content: get_directory_metadata(share_name, directory_name, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A dictionary representing the directory metadata name, value pairs.

        '
      type:
      - dict(str, str)
  type: method
  uid: azure.storage.file.fileservice.FileService.get_directory_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_directory_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_directory_properties
  source:
    id: get_directory_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1035
  summary: 'Returns all user-defined metadata and system properties for the

    specified directory. The data returned does not include the directory''s

    list of files.

    '
  syntax:
    content: get_directory_properties(share_name, directory_name, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to an existing directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'properties for the specified directory within a directory object.

        '
      type:
      - azure.storage.file.models.Directory
  type: method
  uid: azure.storage.file.fileservice.FileService.get_directory_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_metadata
  source:
    id: get_file_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1354
  summary: 'Returns all user-defined metadata for the specified file.

    '
  syntax:
    content: get_file_metadata(share_name, directory_name, file_name, timeout=None,
      snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A dictionary representing the file metadata name, value pairs.

        '
      type:
      - dict(str, str)
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_properties
  source:
    id: get_file_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1225
  summary: 'Returns all user-defined metadata, standard HTTP properties, and

    system properties for the file. Returns an instance of @azure.storage.file.models.File
    with

    @azure.storage.file.models.FileProperties and a metadata dict.

    '
  syntax:
    content: get_file_properties(share_name, directory_name, file_name, timeout=None,
      snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'a file object including properties and metadata.

        '
      type:
      - azure.storage.file.models.File
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_service_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_service_properties
  source:
    id: get_file_service_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 501
  summary: 'Gets the properties of a storage account''s File service, including

    Azure Storage Analytics.

    '
  syntax:
    content: get_file_service_properties(timeout=None)
    parameters:
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'The file service properties.

        '
      type:
      - azure.storage.common.models.ServiceProperties
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_service_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_to_bytes
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_to_bytes
  source:
    id: get_file_to_bytes
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 2156
  summary: 'Downloads a file as an array of bytes, with automatic chunking and

    progress notifications. Returns an instance of @azure.storage.file.models.File
    with

    properties, metadata, and content.

    '
  syntax:
    content: get_file_to_bytes(share_name, directory_name, file_name, start_range=None,
      end_range=None, validate_content=False, progress_callback=None, max_connections=2,
      timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        If no end_range is given, all bytes after the start_range will be downloaded.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - defaultValue: None
      description: 'End of byte range to use for downloading a section of the file.

        If end_range is given, start_range must be provided.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: 'False'
      description: 'If set to true, validates an MD5 hash for each retrieved portion
        of

        the file. This is primarily valuable for detecting bitflips on the wire

        if using http instead of https as https (the default) will already

        validate. Note that the service will only return transactional MD5s

        for chunks 4MB or less so the first get request will be of size

        self.MAX_CHUNK_GET_SIZE instead of self.MAX_SINGLE_GET_SIZE. If

        self.MAX_CHUNK_GET_SIZE was set to greater than 4MB an error will be

        thrown. As computing the MD5 takes processing time and more requests

        will need to be done due to the reduced chunk size there may be some

        increase in latency.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)

        where current is the number of bytes transfered so far, and total is

        the size of the file if known.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'If set to 2 or greater, an initial get will be done for the first

        self.MAX_SINGLE_GET_SIZE bytes of the file. If this is the entire file,

        the method returns at this point. If it is not, it will download the

        remaining data parallel using the number of threads equal to

        max_connections. Each chunk will be of size self.MAX_CHUNK_GET_SIZE.

        If set to 1, a single large get request will be done. This is not

        generally recommended but available if very few threads should be

        used, network requests are very expensive, or a non-seekable stream

        prevents parallel download. This may also be valuable if the file is

        being concurrently modified to enforce atomicity or if many files are

        expected to be empty as an extra request is required for empty files

        if max_connections is greater than 1.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A File with properties, content, and metadata.

        '
      type:
      - azure.storage.file.models.File
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_to_bytes
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_to_path
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_to_path
  source:
    id: get_file_to_path
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1874
  summary: 'Downloads a file to a file path, with automatic chunking and progress

    notifications. Returns an instance of File with properties and metadata.

    '
  syntax:
    content: get_file_to_path(share_name, directory_name, file_name, file_path, open_mode='wb',
      start_range=None, end_range=None, validate_content=False, progress_callback=None,
      max_connections=2, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'Path of file to write to.

        '
      id: file_path
      type:
      - str
    - defaultValue: wb
      description: 'Mode to use when opening the file. Note that specifying append
        only

        open_mode prevents parallel download. So, max_connections must be set

        to 1 if this open_mode is used.

        '
      id: open_mode
      type:
      - str
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        If no end_range is given, all bytes after the start_range will be downloaded.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - defaultValue: None
      description: 'End of byte range to use for downloading a section of the file.

        If end_range is given, start_range must be provided.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: 'False'
      description: 'If set to true, validates an MD5 hash for each retrieved portion
        of

        the file. This is primarily valuable for detecting bitflips on the wire

        if using http instead of https as https (the default) will already

        validate. Note that the service will only return transactional MD5s

        for chunks 4MB or less so the first get request will be of size

        self.MAX_CHUNK_GET_SIZE instead of self.MAX_SINGLE_GET_SIZE. If

        self.MAX_CHUNK_GET_SIZE was set to greater than 4MB an error will be

        thrown. As computing the MD5 takes processing time and more requests

        will need to be done due to the reduced chunk size there may be some

        increase in latency.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)

        where current is the number of bytes transfered so far, and total is

        the size of the file if known.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'If set to 2 or greater, an initial get will be done for the first

        self.MAX_SINGLE_GET_SIZE bytes of the file. If this is the entire file,

        the method returns at this point. If it is not, it will download the

        remaining data parallel using the number of threads equal to

        max_connections. Each chunk will be of size self.MAX_CHUNK_GET_SIZE.

        If set to 1, a single large get request will be done. This is not

        generally recommended but available if very few threads should be

        used, network requests are very expensive, or a non-seekable stream

        prevents parallel download. This may also be valuable if the file is

        being concurrently modified to enforce atomicity or if many files are

        expected to be empty as an extra request is required for empty files

        if max_connections is greater than 1.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A File with properties and metadata.

        '
      type:
      - azure.storage.file.models.File
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_to_path
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_to_stream
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_to_stream
  source:
    id: get_file_to_stream
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1958
  summary: 'Downloads a file to a stream, with automatic chunking and progress

    notifications. Returns an instance of @azure.storage.file.models.File with properties

    and metadata.

    '
  syntax:
    content: get_file_to_stream(share_name, directory_name, file_name, stream, start_range=None,
      end_range=None, validate_content=False, progress_callback=None, max_connections=2,
      timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'Opened file/stream to write to.

        '
      id: stream
      type:
      - io.IOBase
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        If no end_range is given, all bytes after the start_range will be downloaded.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - defaultValue: None
      description: 'End of byte range to use for downloading a section of the file.

        If end_range is given, start_range must be provided.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: 'False'
      description: 'If set to true, validates an MD5 hash for each retrieved portion
        of

        the file. This is primarily valuable for detecting bitflips on the wire

        if using http instead of https as https (the default) will already

        validate. Note that the service will only return transactional MD5s

        for chunks 4MB or less so the first get request will be of size

        self.MAX_CHUNK_GET_SIZE instead of self.MAX_SINGLE_GET_SIZE. If

        self.MAX_CHUNK_GET_SIZE was set to greater than 4MB an error will be

        thrown. As computing the MD5 takes processing time and more requests

        will need to be done due to the reduced chunk size there may be some

        increase in latency.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)

        where current is the number of bytes transfered so far, and total is

        the size of the file if known.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'If set to 2 or greater, an initial get will be done for the first

        self.MAX_SINGLE_GET_SIZE bytes of the file. If this is the entire file,

        the method returns at this point. If it is not, it will download the

        remaining data parallel using the number of threads equal to

        max_connections. Each chunk will be of size self.MAX_CHUNK_GET_SIZE.

        If set to 1, a single large get request will be done. This is not

        generally recommended but available if very few threads should be

        used, network requests are very expensive, or a non-seekable stream

        prevents parallel download. This may also be valuable if the file is

        being concurrently modified to enforce atomicity or if many files are

        expected to be empty as an extra request is required for empty files

        if max_connections is greater than 1.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A File with properties and metadata.

        '
      type:
      - azure.storage.file.models.File
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_to_stream
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_file_to_text
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_file_to_text
  source:
    id: get_file_to_text
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 2238
  summary: 'Downloads a file as unicode text, with automatic chunking and progress

    notifications. Returns an instance of @azure.storage.file.models.File with properties,

    metadata, and content.

    '
  syntax:
    content: get_file_to_text(share_name, directory_name, file_name, encoding='utf-8',
      start_range=None, end_range=None, validate_content=False, progress_callback=None,
      max_connections=2, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: utf-8
      description: 'Python encoding to use when decoding the file data.

        '
      id: encoding
      type:
      - str
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        If no end_range is given, all bytes after the start_range will be downloaded.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - defaultValue: None
      description: 'End of byte range to use for downloading a section of the file.

        If end_range is given, start_range must be provided.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: 'False'
      description: 'If set to true, validates an MD5 hash for each retrieved portion
        of

        the file. This is primarily valuable for detecting bitflips on the wire

        if using http instead of https as https (the default) will already

        validate. Note that the service will only return transactional MD5s

        for chunks 4MB or less so the first get request will be of size

        self.MAX_CHUNK_GET_SIZE instead of self.MAX_SINGLE_GET_SIZE. If

        self.MAX_CHUNK_GET_SIZE was set to greater than 4MB an error will be

        thrown. As computing the MD5 takes processing time and more requests

        will need to be done due to the reduced chunk size there may be some

        increase in latency.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'Callback for progress with signature function(current, total)

        where current is the number of bytes transfered so far, and total is

        the size of the file if known.

        '
      id: progress_callback
      type:
      - func(current, total)
    - defaultValue: '2'
      description: 'If set to 2 or greater, an initial get will be done for the first

        self.MAX_SINGLE_GET_SIZE bytes of the file. If this is the entire file,

        the method returns at this point. If it is not, it will download the

        remaining data parallel using the number of threads equal to

        max_connections. Each chunk will be of size self.MAX_CHUNK_GET_SIZE.

        If set to 1, a single large get request will be done. This is not

        generally recommended but available if very few threads should be

        used, network requests are very expensive, or a non-seekable stream

        prevents parallel download. This may also be valuable if the file is

        being concurrently modified to enforce atomicity or if many files are

        expected to be empty as an extra request is required for empty files

        if max_connections is greater than 1.

        '
      id: max_connections
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A File with properties, content, and metadata.

        '
      type:
      - azure.storage.file.models.File
  type: method
  uid: azure.storage.file.fileservice.FileService.get_file_to_text
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_share_acl
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_share_acl
  source:
    id: get_share_acl
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 810
  summary: 'Gets the permissions for the specified share.

    '
  syntax:
    content: get_share_acl(share_name, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'A dictionary of access policies associated with the share.

        '
      type:
      - dict(str, azure.storage.common.models.AccessPolicy)
  type: method
  uid: azure.storage.file.fileservice.FileService.get_share_acl
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_share_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_share_metadata
  source:
    id: get_share_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 752
  summary: 'Returns all user-defined metadata for the specified share.

    '
  syntax:
    content: get_share_metadata(share_name, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A dictionary representing the share metadata name, value pairs.

        '
      type:
      - dict(str, str)
  type: method
  uid: azure.storage.file.fileservice.FileService.get_share_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_share_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_share_properties
  source:
    id: get_share_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 695
  summary: 'Returns all user-defined metadata and system properties for the

    specified share. The data returned does not include the shares''s

    list of files or directories.

    '
  syntax:
    content: get_share_properties(share_name, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'A Share that exposes properties and metadata.

        '
      type:
      - azure.storage.file.models.Share
  type: method
  uid: azure.storage.file.fileservice.FileService.get_share_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.get_share_stats
  langs:
  - python
  module: azure.storage.file.fileservice
  name: get_share_stats
  source:
    id: get_share_stats
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 865
  summary: 'Gets the approximate size of the data stored on the share,

    rounded up to the nearest gigabyte.


    Note that this value may not include all recently created

    or recently resized files.

    '
  syntax:
    content: get_share_stats(share_name, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'the approximate size of the data stored on the share.

        '
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.get_share_stats
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.list_directories_and_files
  langs:
  - python
  module: azure.storage.file.fileservice
  name: list_directories_and_files
  source:
    id: list_directories_and_files
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1130
  summary: 'Returns a generator to list the directories and files under the specified
    share.

    The generator will lazily follow the continuation tokens returned by

    the service and stop when all directories and files have been returned or

    num_results is reached.


    If num_results is specified and the share has more than that number of

    files and directories, the generator will have a populated next_marker

    field once it finishes. This marker can be used to create a new generator

    if more results are desired.

    '
  syntax:
    content: list_directories_and_files(share_name, directory_name=None, num_results=None,
      marker=None, timeout=None, prefix=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'Specifies the maximum number of files to return,

        including all directory elements. If the request does not specify

        num_results or specifies a value greater than 5,000, the server will

        return up to 5,000 items. Setting num_results to a value less than

        or equal to zero results in error response code 400 (Bad Request).

        '
      id: num_results
      type:
      - int
    - defaultValue: None
      description: 'An opaque continuation token. This value can be retrieved from
        the

        next_marker field of a previous generator object if num_results was

        specified and that generator has finished enumerating results. If

        specified, this generator will begin returning results from the point

        where the previous generator stopped.

        '
      id: marker
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'List only the files and/or directories with the given prefix.

        '
      id: prefix
      type:
      - str
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
  type: method
  uid: azure.storage.file.fileservice.FileService.list_directories_and_files
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.list_ranges
  langs:
  - python
  module: azure.storage.file.fileservice
  name: list_ranges
  source:
    id: list_ranges
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 2423
  summary: 'Retrieves the valid ranges for a file.

    '
  syntax:
    content: list_ranges(share_name, directory_name, file_name, start_range=None,
      end_range=None, timeout=None, snapshot=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'Specifies the start offset of bytes over which to list ranges.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - defaultValue: None
      description: 'Specifies the end offset of bytes over which to list ranges.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: None
      description: 'A string that represents the snapshot version, if applicable.

        '
      id: snapshot
      type:
      - str
    return:
      description: 'a list of valid ranges

        '
      type:
      - a list of azure.storage.file.models.FileRange
  type: method
  uid: azure.storage.file.fileservice.FileService.list_ranges
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.list_shares
  langs:
  - python
  module: azure.storage.file.fileservice
  name: list_shares
  source:
    id: list_shares
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 524
  summary: 'Returns a generator to list the shares under the specified account.

    The generator will lazily follow the continuation tokens returned by

    the service and stop when all shares have been returned or num_results

    is reached.


    If num_results is specified and the account has more than that number of

    shares, the generator will have a populated next_marker field once it

    finishes. This marker can be used to create a new generator if more

    results are desired.

    '
  syntax:
    content: list_shares(prefix=None, marker=None, num_results=None, include_metadata=False,
      timeout=None, include_snapshots=False)
    parameters:
    - defaultValue: None
      description: 'Filters the results to return only shares whose names

        begin with the specified prefix.

        '
      id: prefix
      type:
      - str
    - defaultValue: None
      description: 'Specifies the maximum number of shares to return.

        '
      id: num_results
      type:
      - int
    - defaultValue: None
      description: 'Specifies that share metadata be returned in the response.

        '
      id: include_metadata
      type:
      - bool
    - defaultValue: 'False'
      description: 'An opaque continuation token. This value can be retrieved from
        the

        next_marker field of a previous generator object if num_results was

        specified and that generator has finished enumerating results. If

        specified, this generator will begin returning results from the point

        where the previous generator stopped.

        '
      id: marker
      type:
      - str
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    - defaultValue: 'False'
      description: 'Specifies that share snapshots be returned in the response.

        '
      id: include_snapshots
      type:
      - bool
  type: method
  uid: azure.storage.file.fileservice.FileService.list_shares
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.make_file_url
  langs:
  - python
  module: azure.storage.file.fileservice
  name: make_file_url
  source:
    id: make_file_url
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 182
  summary: 'Creates the url to access a file.

    '
  syntax:
    content: make_file_url(share_name, directory_name, file_name, protocol=None, sas_token=None)
    parameters:
    - description: 'Name of share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'Protocol to use: ''http'' or ''https''. If not specified, uses
        the

        protocol specified when FileService was initialized.

        '
      id: protocol
      type:
      - str
    - defaultValue: None
      description: 'Shared access signature token created with

        generate_shared_access_signature.

        '
      id: sas_token
      type:
      - str
    return:
      description: 'file access URL.

        '
      type:
      - str
  type: method
  uid: azure.storage.file.fileservice.FileService.make_file_url
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.resize_file
  langs:
  - python
  module: azure.storage.file.fileservice
  name: resize_file
  source:
    id: resize_file
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1287
  summary: 'Resizes a file to the specified size. If the specified byte

    value is less than the current size of the file, then all

    ranges above the specified byte value are cleared.

    '
  syntax:
    content: resize_file(share_name, directory_name, file_name, content_length, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'The length to resize the file to.

        '
      id: content_length
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.resize_file
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_directory_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_directory_metadata
  source:
    id: set_directory_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1097
  summary: 'Sets one or more user-defined name-value pairs for the specified

    directory. Each call to this operation replaces all existing metadata

    attached to the directory. To remove all metadata from the directory,

    call this operation with no metadata dict.

    '
  syntax:
    content: set_directory_metadata(share_name, directory_name, metadata=None, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - defaultValue: None
      description: 'A dict containing name-value pairs to associate with the directory

        as metadata. Example: {''category'':''test''}

        '
      id: metadata
      type:
      - dict(str, str).
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_directory_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_file_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_file_metadata
  source:
    id: set_file_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1386
  summary: 'Sets user-defined metadata for the specified file as one or more

    name-value pairs.

    '
  syntax:
    content: set_file_metadata(share_name, directory_name, file_name, metadata=None,
      timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'Dict containing name and value pairs. Each call to this operation

        replaces all existing metadata attached to the file. To remove all

        metadata from the file, call this operation with no metadata headers.

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_file_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_file_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_file_properties
  source:
    id: set_file_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 1322
  summary: 'Sets system properties on the file. If one property is set for the

    content_settings, all properties will be overriden.

    '
  syntax:
    content: set_file_properties(share_name, directory_name, file_name, content_settings,
      timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'ContentSettings object used to set the file properties.

        '
      id: content_settings
      type:
      - azure.storage.file.models.ContentSettings
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_file_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_file_service_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_file_service_properties
  source:
    id: set_file_service_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 466
  summary: 'Sets the properties of a storage account''s File service, including

    Azure Storage Analytics. If an element (ex HourMetrics) is left as None, the

    existing settings on the service for that functionality are preserved.

    '
  syntax:
    content: set_file_service_properties(hour_metrics=None, minute_metrics=None, cors=None,
      timeout=None)
    parameters:
    - defaultValue: None
      description: 'The hour metrics settings provide a summary of request

        statistics grouped by API in hourly aggregates for files.

        '
      id: hour_metrics
      type:
      - Metrics
    - defaultValue: None
      description: 'The minute metrics settings provide request statistics

        for each minute for files.

        '
      id: minute_metrics
      type:
      - Metrics
    - defaultValue: None
      description: 'You can include up to five CorsRule elements in the

        list. If an empty list is specified, all CORS rules will be deleted,

        and CORS will be disabled for the service.

        '
      id: cors
      type:
      - list(azure.storage.common.models.CorsRule)
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_file_service_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_share_acl
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_share_acl
  source:
    id: set_share_acl
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 834
  summary: 'Sets the permissions for the specified share or stored access

    policies that may be used with Shared Access Signatures.

    '
  syntax:
    content: set_share_acl(share_name, signed_identifiers=None, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'A dictionary of access policies to associate with the share. The

        dictionary may contain up to 5 elements. An empty dictionary

        will clear the access policies set on the service.

        '
      id: signed_identifiers
      type:
      - dict(str, azure.storage.common.models.AccessPolicy)
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_share_acl
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_share_metadata
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_share_metadata
  source:
    id: set_share_metadata
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 780
  summary: 'Sets one or more user-defined name-value pairs for the specified

    share. Each call to this operation replaces all existing metadata

    attached to the share. To remove all metadata from the share,

    call this operation with no metadata dict.

    '
  syntax:
    content: set_share_metadata(share_name, metadata=None, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'A dict containing name-value pairs to associate with the share
        as

        metadata. Example: {''category'':''test''}

        '
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_share_metadata
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.set_share_properties
  langs:
  - python
  module: azure.storage.file.fileservice
  name: set_share_properties
  source:
    id: set_share_properties
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 723
  summary: 'Sets service-defined properties for the specified share.

    '
  syntax:
    content: set_share_properties(share_name, quota, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'Specifies the maximum size of the share, in gigabytes. Must be

        greater than 0, and less than or equal to 5 TB (5120 GB).

        '
      id: quota
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.set_share_properties
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.snapshot_share
  langs:
  - python
  module: azure.storage.file.fileservice
  name: snapshot_share
  source:
    id: snapshot_share
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 660
  summary: 'Creates a snapshot of an existing share under the specified account.

    '
  syntax:
    content: snapshot_share(share_name, metadata=None, quota=None, timeout=None)
    parameters:
    - description: 'The name of the share to create a snapshot of.

        '
      id: share_name
      type:
      - str
    - defaultValue: None
      description: 'A dict with name_value pairs to associate with the

        share as metadata. Example:{''Category'':''test''}

        '
      id: metadata
      type:
      - 'a dict of str to str:'
    - defaultValue: None
      description: 'Specifies the maximum size of the share, in gigabytes. Must be

        greater than 0, and less than or equal to 5TB (5120).

        '
      id: quota
      type:
      - int
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
    return:
      description: 'snapshot properties

        '
      type:
      - azure.storage.file.models.Share
  type: method
  uid: azure.storage.file.fileservice.FileService.snapshot_share
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.update_range
  langs:
  - python
  module: azure.storage.file.fileservice
  name: update_range
  source:
    id: update_range
    path: azure\storage\file\fileservice.py
    remote:
      branch: master
      path: azure\storage\file\fileservice.py
      repo: https://github.com/Azure/azure-storage-python.git
    startLine: 2322
  summary: 'Writes the bytes specified by the request body into the specified range.

    '
  syntax:
    content: update_range(share_name, directory_name, file_name, data, start_range,
      end_range, validate_content=False, timeout=None)
    parameters:
    - description: 'Name of existing share.

        '
      id: share_name
      type:
      - str
    - description: 'The path to the directory.

        '
      id: directory_name
      type:
      - str
    - description: 'Name of existing file.

        '
      id: file_name
      type:
      - str
    - description: 'Content of the range.

        '
      id: data
      type:
      - bytes
    - description: 'Start of byte range to use for updating a section of the file.

        The range can be up to 4 MB in size.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: start_range
      type:
      - int
    - description: 'End of byte range to use for updating a section of the file.

        The range can be up to 4 MB in size.

        The start_range and end_range params are inclusive.

        Ex: start_range=0, end_range=511 will download first 512 bytes of file.

        '
      id: end_range
      type:
      - int
    - defaultValue: 'False'
      description: 'If true, calculates an MD5 hash of the page content. The storage

        service checks the hash of the content that has arrived

        with the hash that was sent. This is primarily valuable for detecting

        bitflips on the wire if using http instead of https as https (the default)

        will already validate. Note that this MD5 hash is not stored with the

        file.

        '
      id: validate_content
      type:
      - bool
    - defaultValue: None
      description: 'The timeout parameter is expressed in seconds.

        '
      id: timeout
      type:
      - int
  type: method
  uid: azure.storage.file.fileservice.FileService.update_range
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.MAX_CHUNK_GET_SIZE
  langs:
  - python
  module: azure.storage.file.fileservice
  name: MAX_CHUNK_GET_SIZE
  syntax:
    content: MAX_CHUNK_GET_SIZE = 8388608
  type: attribute
  uid: azure.storage.file.fileservice.FileService.MAX_CHUNK_GET_SIZE
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.MAX_RANGE_SIZE
  langs:
  - python
  module: azure.storage.file.fileservice
  name: MAX_RANGE_SIZE
  syntax:
    content: MAX_RANGE_SIZE = 4194304
  type: attribute
  uid: azure.storage.file.fileservice.FileService.MAX_RANGE_SIZE
- class: azure.storage.file.fileservice.FileService
  fullName: azure.storage.file.fileservice.FileService.MAX_SINGLE_GET_SIZE
  langs:
  - python
  module: azure.storage.file.fileservice
  name: MAX_SINGLE_GET_SIZE
  syntax:
    content: MAX_SINGLE_GET_SIZE = 33554432
  type: attribute
  uid: azure.storage.file.fileservice.FileService.MAX_SINGLE_GET_SIZE
references:
- fullName: azure.storage.file.fileservice.FileService.abort_copy_file
  isExternal: false
  name: abort_copy_file
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.abort_copy_file
- fullName: azure.storage.file.fileservice.FileService.clear_range
  isExternal: false
  name: clear_range
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.clear_range
- fullName: azure.storage.file.fileservice.FileService.copy_file
  isExternal: false
  name: copy_file
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.copy_file
- fullName: azure.storage.file.fileservice.FileService.create_directory
  isExternal: false
  name: create_directory
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_directory
- fullName: azure.storage.file.fileservice.FileService.create_file
  isExternal: false
  name: create_file
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_file
- fullName: azure.storage.file.fileservice.FileService.create_file_from_bytes
  isExternal: false
  name: create_file_from_bytes
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_file_from_bytes
- fullName: azure.storage.file.fileservice.FileService.create_file_from_path
  isExternal: false
  name: create_file_from_path
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_file_from_path
- fullName: azure.storage.file.fileservice.FileService.create_file_from_stream
  isExternal: false
  name: create_file_from_stream
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_file_from_stream
- fullName: azure.storage.file.fileservice.FileService.create_file_from_text
  isExternal: false
  name: create_file_from_text
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_file_from_text
- fullName: azure.storage.file.fileservice.FileService.create_share
  isExternal: false
  name: create_share
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.create_share
- fullName: azure.storage.file.fileservice.FileService.delete_directory
  isExternal: false
  name: delete_directory
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.delete_directory
- fullName: azure.storage.file.fileservice.FileService.delete_file
  isExternal: false
  name: delete_file
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.delete_file
- fullName: azure.storage.file.fileservice.FileService.delete_share
  isExternal: false
  name: delete_share
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.delete_share
- fullName: azure.storage.file.fileservice.FileService.exists
  isExternal: false
  name: exists
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.exists
- fullName: azure.storage.file.fileservice.FileService.generate_account_shared_access_signature
  isExternal: false
  name: generate_account_shared_access_signature
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.generate_account_shared_access_signature
- fullName: azure.storage.file.fileservice.FileService.generate_file_shared_access_signature
  isExternal: false
  name: generate_file_shared_access_signature
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.generate_file_shared_access_signature
- fullName: azure.storage.file.fileservice.FileService.generate_share_shared_access_signature
  isExternal: false
  name: generate_share_shared_access_signature
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.generate_share_shared_access_signature
- fullName: azure.storage.file.fileservice.FileService.get_directory_metadata
  isExternal: false
  name: get_directory_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_directory_metadata
- fullName: azure.storage.file.fileservice.FileService.get_directory_properties
  isExternal: false
  name: get_directory_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_directory_properties
- fullName: azure.storage.file.fileservice.FileService.get_file_metadata
  isExternal: false
  name: get_file_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_metadata
- fullName: azure.storage.file.fileservice.FileService.get_file_properties
  isExternal: false
  name: get_file_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_properties
- fullName: azure.storage.file.fileservice.FileService.get_file_service_properties
  isExternal: false
  name: get_file_service_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_service_properties
- fullName: azure.storage.file.fileservice.FileService.get_file_to_bytes
  isExternal: false
  name: get_file_to_bytes
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_to_bytes
- fullName: azure.storage.file.fileservice.FileService.get_file_to_path
  isExternal: false
  name: get_file_to_path
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_to_path
- fullName: azure.storage.file.fileservice.FileService.get_file_to_stream
  isExternal: false
  name: get_file_to_stream
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_to_stream
- fullName: azure.storage.file.fileservice.FileService.get_file_to_text
  isExternal: false
  name: get_file_to_text
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_file_to_text
- fullName: azure.storage.file.fileservice.FileService.get_share_acl
  isExternal: false
  name: get_share_acl
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_share_acl
- fullName: azure.storage.file.fileservice.FileService.get_share_metadata
  isExternal: false
  name: get_share_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_share_metadata
- fullName: azure.storage.file.fileservice.FileService.get_share_properties
  isExternal: false
  name: get_share_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_share_properties
- fullName: azure.storage.file.fileservice.FileService.get_share_stats
  isExternal: false
  name: get_share_stats
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.get_share_stats
- fullName: azure.storage.file.fileservice.FileService.list_directories_and_files
  isExternal: false
  name: list_directories_and_files
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.list_directories_and_files
- fullName: azure.storage.file.fileservice.FileService.list_ranges
  isExternal: false
  name: list_ranges
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.list_ranges
- fullName: azure.storage.file.fileservice.FileService.list_shares
  isExternal: false
  name: list_shares
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.list_shares
- fullName: azure.storage.file.fileservice.FileService.make_file_url
  isExternal: false
  name: make_file_url
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.make_file_url
- fullName: azure.storage.file.fileservice.FileService.resize_file
  isExternal: false
  name: resize_file
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.resize_file
- fullName: azure.storage.file.fileservice.FileService.set_directory_metadata
  isExternal: false
  name: set_directory_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_directory_metadata
- fullName: azure.storage.file.fileservice.FileService.set_file_metadata
  isExternal: false
  name: set_file_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_file_metadata
- fullName: azure.storage.file.fileservice.FileService.set_file_properties
  isExternal: false
  name: set_file_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_file_properties
- fullName: azure.storage.file.fileservice.FileService.set_file_service_properties
  isExternal: false
  name: set_file_service_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_file_service_properties
- fullName: azure.storage.file.fileservice.FileService.set_share_acl
  isExternal: false
  name: set_share_acl
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_share_acl
- fullName: azure.storage.file.fileservice.FileService.set_share_metadata
  isExternal: false
  name: set_share_metadata
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_share_metadata
- fullName: azure.storage.file.fileservice.FileService.set_share_properties
  isExternal: false
  name: set_share_properties
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.set_share_properties
- fullName: azure.storage.file.fileservice.FileService.snapshot_share
  isExternal: false
  name: snapshot_share
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.snapshot_share
- fullName: azure.storage.file.fileservice.FileService.update_range
  isExternal: false
  name: update_range
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.update_range
- fullName: azure.storage.file.fileservice.FileService.MAX_CHUNK_GET_SIZE
  isExternal: false
  name: MAX_CHUNK_GET_SIZE
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.MAX_CHUNK_GET_SIZE
- fullName: azure.storage.file.fileservice.FileService.MAX_RANGE_SIZE
  isExternal: false
  name: MAX_RANGE_SIZE
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.MAX_RANGE_SIZE
- fullName: azure.storage.file.fileservice.FileService.MAX_SINGLE_GET_SIZE
  isExternal: false
  name: MAX_SINGLE_GET_SIZE
  parent: azure.storage.file.fileservice.FileService
  uid: azure.storage.file.fileservice.FileService.MAX_SINGLE_GET_SIZE
- fullName: dict(str, str).
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  - fullName: .
    name: ''
    uid: .
  uid: dict(str, str).
- fullName: 'dict(str, str):'
  name: 'dict(str, str):'
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  - fullName: ':'
    name: ':'
    uid: ':'
  uid: 'dict(str, str):'
- fullName: dict(str, str)
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  uid: dict(str, str)
- fullName: func(current, total)
  name: func(current, total)
  spec.python:
  - fullName: func
    name: func
    uid: func
  - fullName: (
    name: (
  - fullName: current
    name: current
    uid: current
  - fullName: ', '
    name: ', '
  - fullName: total
    name: total
    uid: total
  - fullName: )
    name: )
  uid: func(current, total)
- fullName: dict(str, azure.storage.common.models.AccessPolicy)
  name: dict(str, AccessPolicy)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: azure.storage.common.models.AccessPolicy
    name: AccessPolicy
    uid: azure.storage.common.models.AccessPolicy
  - fullName: )
    name: )
  uid: dict(str, azure.storage.common.models.AccessPolicy)
- fullName: list(azure.storage.common.models.CorsRule)
  name: list(CorsRule)
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: (
    name: (
  - fullName: azure.storage.common.models.CorsRule
    name: CorsRule
    uid: azure.storage.common.models.CorsRule
  - fullName: )
    name: )
  uid: list(azure.storage.common.models.CorsRule)
