### YamlMime:PythonClass
uid: azure.storage.filedatalake.DataLakeServiceClient
name: DataLakeServiceClient
fullName: azure.storage.filedatalake.DataLakeServiceClient
module: azure.storage.filedatalake
inheritances:
- azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
summary: 'A client to interact with the DataLake Service at the account level.


  This client provides operations to retrieve and configure the account properties

  as well as list, create and delete file systems within the account.

  For operations relating to a specific file system, directory or file, clients for
  those entities

  can also be retrieved using the *get_client* functions.'
constructor:
  syntax: DataLakeServiceClient(account_url, credential=None, **kwargs)
  parameters:
  - name: account_url
    description: 'The URL to the DataLake storage account. Any other entities included

      in the URL path (e.g. file system or file) will be discarded. This URL can be
      optionally

      authenticated with a SAS token.'
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token. The value can be a SAS token string,

      an instance of a AzureSasCredential from azure.core.credentials, an account

      shared access key, or an instance of a TokenCredentials class from azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.'
variables:
- description: The full endpoint URL to the datalake service endpoint.
  name: url
  types:
  - <xref:str>
- description: The full primary endpoint URL.
  name: primary_endpoint
  types:
  - <xref:str>
- description: The hostname of the primary endpoint.
  name: primary_hostname
  types:
  - <xref:str>
examples:
- "Creating the DataLakeServiceClient from connection string.<!--[!code-python[Main](les\\\
  datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\
  \\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\\\
  datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"python\"\
  , \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\
  \n   from azure.storage.filedatalake import DataLakeServiceClient\n   datalake_service_client\
  \ = DataLakeServiceClient.from_connection_string(self.connection_string)\n\n   ````\n\
  \nCreating the DataLakeServiceClient with Azure Identity credentials.<!--[!code-python[Main](les\\\
  datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\
  \\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\\\
  datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"python\"\
  , \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\
  \n   from azure.identity import ClientSecretCredential\n   token_credential = ClientSecretCredential(\n\
  \       self.active_directory_tenant_id,\n       self.active_directory_application_id,\n\
  \       self.active_directory_application_secret,\n   )\n   datalake_service_client\
  \ = DataLakeServiceClient(\"https://{}.dfs.core.windows.net\".format(self.account_name),\n\
  \                                                   credential=token_credential)\n\
  \n   ````\n"
methods:
- uid: azure.storage.filedatalake.DataLakeServiceClient.close
  name: close
  summary: 'This method is to close the sockets opened by the client.

    It need not be used when using with a context manager.'
  signature: close()
- uid: azure.storage.filedatalake.DataLakeServiceClient.create_file_system
  name: create_file_system
  summary: 'Creates a new file system under the specified account.


    If the file system with the same name already exists, a ResourceExistsError will

    be raised. This method returns a client with which to interact with the newly

    created file system.'
  signature: create_file_system(file_system, metadata=None, public_access=None, **kwargs)
  parameters:
  - name: file_system
    description: The name of the file system to create.
    isRequired: true
    types:
    - <xref:str>
  - name: metadata
    description: 'A dict with name-value pairs to associate with the

      file system as metadata. Example: *{''Category'':''test''}*'
    defaultValue: None
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  - name: public_access
    description: 'Possible values include: file system, file.'
    defaultValue: None
    types:
    - <xref:azure.storage.filedatalake.PublicAccess>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    isRequired: true
    types:
    - <xref:int>
  return:
    types:
    - <xref:azure.storage.filedatalake.FileSystemClient>
  examples:
  - "Creating a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   datalake_service_client.create_file_system(\"filesystem\")\n\n\
    \   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.delete_file_system
  name: delete_file_system
  summary: 'Marks the specified file system for deletion.


    The file system and any files contained within it are later deleted during garbage
    collection.

    If the file system is not found, a ResourceNotFoundError will be raised.'
  signature: delete_file_system(file_system, **kwargs)
  parameters:
  - name: file_system
    description: 'The file system to delete. This can either be the name of the file
      system,

      or an instance of FileSystemProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  - name: lease
    description: 'If specified, delete_file_system only succeeds if the

      file system''s lease is active and matches this ID.

      Required if the file system has an active lease.'
    isRequired: true
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    isRequired: true
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    isRequired: true
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    isRequired: true
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    isRequired: true
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    isRequired: true
    types:
    - <xref:int>
  return:
    types:
    - <xref:None>
  examples:
  - "Deleting a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   datalake_service_client.delete_file_system(\"filesystem\")\n\n\
    \   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.from_connection_string
  name: from_connection_string
  summary: 'Create DataLakeServiceClient from a Connection String.



    :return a DataLakeServiceClient

    :rtype ~azure.storage.filedatalake.DataLakeServiceClient'
  signature: from_connection_string(conn_str, credential=None, **kwargs)
  parameters:
  - name: conn_str
    description: A connection string to an Azure Storage account.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token, or the connection string already has shared

      access key values. The value can be a SAS token string,

      an instance of a AzureSasCredential from azure.core.credentials, an account
      shared access

      key, or an instance of a TokenCredentials class from azure.identity.

      Credentials provided here will take precedence over those in the connection
      string.'
    isRequired: true
  - name: credential
    defaultValue: None
  examples:
  - "Creating the DataLakeServiceClient from a connection string.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"language\"\
    : \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\
    \n````python\n\n   from azure.storage.filedatalake import DataLakeServiceClient\n\
    \   datalake_service_client = DataLakeServiceClient.from_connection_string(self.connection_string)\n\
    \n   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.get_directory_client
  name: get_directory_client
  summary: 'Get a client to interact with the specified directory.


    The directory need not already exist.'
  signature: get_directory_client(file_system, directory)
  parameters:
  - name: file_system
    description: 'The file system that the directory is in. This can either be the
      name of the file system,

      or an instance of FileSystemProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  return:
    description: A DataLakeDirectoryClient.
    types:
    - <xref:azure.storage.filedatalake.DataLakeDirectoryClient>
  examples:
  - "Getting the directory client to interact with a specific directory.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   directory_client = datalake_service_client.get_directory_client(file_system_client.file_system_name,\n\
    \                                                                   \"mydirectory\"\
    )\n\n   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.get_file_client
  name: get_file_client
  summary: 'Get a client to interact with the specified file.


    The file need not already exist.'
  signature: get_file_client(file_system, file_path)
  parameters:
  - name: file_system
    description: 'The file system that the file is in. This can either be the name
      of the file system,

      or an instance of FileSystemProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  - name: file_path
    description: 'The file with which to interact. This can either be the full path
      of the file(from the root directory),

      or an instance of FileProperties. eg. directory/subdirectory/file'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  return:
    description: A DataLakeFileClient.
    types:
    - <xref:azure.storage.filedatalake..DataLakeFileClient>
  examples:
  - "Getting the file client to interact with a specific file.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   file_client = datalake_service_client.get_file_client(file_system_client.file_system_name,\
    \ \"myfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.get_file_system_client
  name: get_file_system_client
  summary: 'Get a client to interact with the specified file system.


    The file system need not already exist.'
  signature: get_file_system_client(file_system)
  parameters:
  - name: file_system
    description: 'The file system. This can either be the name of the file system,

      or an instance of FileSystemProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  return:
    description: A FileSystemClient.
    types:
    - <xref:azure.storage.filedatalake.FileSystemClient>
  examples:
  - "Getting the file system client to interact with a specific file system.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"language\"\
    : \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\
    \n````python\n\n   # Instantiate a DataLakeServiceClient using a connection string\n\
    \   from azure.storage.filedatalake import DataLakeServiceClient\n   datalake_service_client\
    \ = DataLakeServiceClient.from_connection_string(self.connection_string)\n\n \
    \  # Instantiate a FileSystemClient\n   file_system_client = datalake_service_client.get_file_system_client(\"\
    mynewfilesystem\")\n\n   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.get_user_delegation_key
  name: get_user_delegation_key
  summary: 'Obtain a user delegation key for the purpose of signing SAS tokens.

    A token credential must be present on the service object for this request to succeed.'
  signature: get_user_delegation_key(key_start_time, key_expiry_time, **kwargs)
  parameters:
  - name: key_start_time
    description: A DateTime value. Indicates when the key becomes valid.
    isRequired: true
    types:
    - <xref:datetime.datetime>
  - name: key_expiry_time
    description: A DateTime value. Indicates when the key stops being valid.
    isRequired: true
    types:
    - <xref:datetime.datetime>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    isRequired: true
    types:
    - <xref:int>
  return:
    description: The user delegation key.
    types:
    - <xref:azure.storage.filedatalake.UserDelegationKey>
  examples:
  - "Get user delegation key from datalake service client.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   from datetime import datetime, timedelta\n   user_delegation_key\
    \ = datalake_service_client.get_user_delegation_key(datetime.utcnow(),\n     \
    \                                                                    datetime.utcnow()\
    \ + timedelta(hours=1))\n\n   ````\n"
- uid: azure.storage.filedatalake.DataLakeServiceClient.list_file_systems
  name: list_file_systems
  summary: 'Returns a generator to list the file systems under the specified account.


    The generator will lazily follow the continuation tokens returned by

    the service and stop when all file systems have been returned.'
  signature: list_file_systems(name_starts_with=None, include_metadata=None, **kwargs)
  parameters:
  - name: name_starts_with
    description: 'Filters the results to return only file systems whose names

      begin with the specified prefix.'
    defaultValue: None
    types:
    - <xref:str>
  - name: include_metadata
    description: 'Specifies that file system metadata be returned in the response.

      The default value is *False*.'
    defaultValue: None
    types:
    - <xref:bool>
  - name: results_per_page
    description: 'The maximum number of file system names to retrieve per API

      call. If the request does not specify the server will return up to 5,000 items
      per page.'
    isRequired: true
    types:
    - <xref:int>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    isRequired: true
    types:
    - <xref:int>
  return:
    description: An iterable (auto-paging) of FileSystemProperties.
    types:
    - <xref:azure.core.paging.ItemPaged>[<xref:azure.storage.filedatalake.FileSystemProperties>]
  examples:
  - "Listing the file systems in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\113\\\\azure-storage-file-datalake-12.2.1\\\\samples\\\
    \\datalake_samples_service.py\", \"xml:space\": \"preserve\", \"language\": \"\
    python\", \"linenos\": false, \"highlight_args\": {\"linenostart\": 1}} -->\n\n\
    ````python\n\n   file_systems = datalake_service_client.list_file_systems()\n\
    \   for file_system in file_systems:\n       print(file_system.name)\n\n   ````\n"
