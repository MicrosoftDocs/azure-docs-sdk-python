### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.filedatalake.DataLakeFileClient.append_data
  - azure.storage.filedatalake.DataLakeFileClient.create_file
  - azure.storage.filedatalake.DataLakeFileClient.delete_file
  - azure.storage.filedatalake.DataLakeFileClient.download_file
  - azure.storage.filedatalake.DataLakeFileClient.flush_data
  - azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  - azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  - azure.storage.filedatalake.DataLakeFileClient.rename_file
  - azure.storage.filedatalake.DataLakeFileClient.upload_data
  class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Creating the DataLakeServiceClient from connection string.<!--[!code-python[Main](les\\\
    datalake_samples_instantiate_client.py )]-->\n\n<!-- literal_block {\"ids\": [],\
    \ \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\"\
    : \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\114\\\\azure-storage-file-datalake-12.0.1\\\
    \\samples\\\\datalake_samples_instantiate_client.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   from azure.storage.filedatalake import DataLakeFileClient\n\
    \   DataLakeFileClient.from_connection_string(connection_string, \"myfilesystem\"\
    , \"mydirectory\", \"myfile\")\n\n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
    type: azure.storage.filedatalake._path_client.PathClient
  langs:
  - python
  module: azure.storage.filedatalake
  name: DataLakeFileClient
  summary: A client to interact with the DataLake file, even if the file may not yet
    exist.
  syntax:
    content: DataLakeFileClient(account_url, file_system_name, file_path, credential=None,
      **kwargs)
    parameters:
    - description: The URI to the storage account.
      id: account_url
      type:
      - str
    - description: The file system for the directory or files.
      id: file_system_name
      type:
      - str
    - description: 'The whole file path, so that to interact with a specific file.

        eg. "{directory}/{subdirectory}/{file}"'
      id: file_path
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token. The value can be a SAS token string,
        and account

        shared access key, or an instance of a TokenCredentials class from azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    variables:
    - description: The full endpoint URL to the file system, including SAS token if
        used.
      id: url
      type:
      - str
    - description: The full primary endpoint URL.
      id: primary_endpoint
      type:
      - str
    - description: The hostname of the primary endpoint.
      id: primary_hostname
      type:
      - str
  type: class
  uid: azure.storage.filedatalake.DataLakeFileClient
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Append data to the file.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   file_client.append_data(data=file_content[2048:3072],\
    \ offset=2048, length=1024)\n\n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.append_data
  langs:
  - python
  module: azure.storage.filedatalake
  name: append_data(data, offset, length=None, **kwargs)
  namewithoutparameters: append_data
  summary: Append data to the file.
  syntax:
    content: append_data(data, offset, length=None, **kwargs)
    parameters:
    - description: Content to be appended to file
      id: data
      isRequired: true
    - description: start position of the data to be appended to.
      id: offset
      isRequired: true
    - defaultValue: None
      description: Size of the data in bytes.
      id: length
    return:
      description: dict of the response header
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.append_data
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Create file.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   file_client =\
    \ filesystem_client.get_file_client(file_name)\n   file_client.create_file()\n\
    \n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.create_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: create_file(content_settings=None, metadata=None, **kwargs)
  namewithoutparameters: create_file
  summary: Create a new file.
  syntax:
    content: create_file(content_settings=None, metadata=None, **kwargs)
    parameters:
    - defaultValue: None
      description: ContentSettings object used to set path properties.
      id: content_settings
      type:
      - azure.storage.filedatalake.ContentSettings
    - defaultValue: None
      description: Name-value pairs associated with the file as metadata.
      id: metadata
      type:
      - dict(str, str)
    return:
      description: response dict (Etag and last modified).
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.create_file
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Delete file.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   new_client.delete_file()\n\
    \n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.delete_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: delete_file(**kwargs)
  namewithoutparameters: delete_file
  summary: Marks the specified file for deletion.
  syntax:
    content: delete_file(**kwargs)
    parameters: []
    return:
      description: None
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.delete_file
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Return the downloaded data.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   download = file_client.download_file()\n\
    \   downloaded_bytes = download.readall()\n\n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.download_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: download_file(offset=None, length=None, **kwargs)
  namewithoutparameters: download_file
  summary: 'Downloads a file to the StorageStreamDownloader. The readall() method
    must

    be used to read all the content, or readinto() must be used to download the file
    into

    a stream.'
  syntax:
    content: download_file(offset=None, length=None, **kwargs)
    parameters:
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        Must be set if length is provided.'
      id: offset
      type:
      - int
    - defaultValue: None
      description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      type:
      - int
    return:
      description: A streaming object (StorageStreamDownloader)
      type:
      - azure.storage.filedatalake.StorageStreamDownloader
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.download_file
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Commit the previous appended data.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   with open(SOURCE_FILE,\
    \ \"rb\") as data:\n       file_client = file_system_client.get_file_client(\"\
    myfile\")\n       file_client.create_file()\n       file_client.append_data(data,\
    \ 0)\n       file_client.flush_data(data.tell())\n\n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.flush_data
  langs:
  - python
  module: azure.storage.filedatalake
  name: flush_data(offset, retain_uncommitted_data=False, **kwargs)
  namewithoutparameters: flush_data
  summary: Commit the previous appended data.
  syntax:
    content: flush_data(offset, retain_uncommitted_data=False, **kwargs)
    parameters:
    - description: 'offset is equal to the length of the file after commit the

        previous appended data.'
      id: offset
      isRequired: true
    - defaultValue: 'False'
      description: 'Valid only for flush operations.  If

        "true", uncommitted data is retained after the flush operation

        completes; otherwise, the uncommitted data is deleted after the flush

        operation.  The default is false.  Data at offsets less than the

        specified position are written to the file when flush succeeds, but

        this optional parameter allows data after the flush position to be

        retained for a future flush operation.'
      id: retain_uncommitted_data
      type:
      - bool
    return:
      description: response header in dict
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.flush_data
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  langs:
  - python
  module: azure.storage.filedatalake
  name: from_connection_string(conn_str, file_system_name, file_path, credential=None,
    **kwargs)
  namewithoutparameters: from_connection_string
  summary: 'Create DataLakeFileClient from a Connection String.



    :return a DataLakeFileClient

    :rtype ~azure.storage.filedatalake.DataLakeFileClient'
  syntax:
    content: from_connection_string(conn_str, file_system_name, file_path, credential=None,
      **kwargs)
    parameters:
    - description: A connection string to an Azure Storage account.
      id: conn_str
      isRequired: true
      type:
      - str
    - description: The name of file system to interact with.
      id: file_system_name
      isRequired: true
      type:
      - str
    - description: The name of directory to interact with. The directory is under
        file system.
      id: directory_name
      isRequired: true
      type:
      - str
    - description: The name of file to interact with. The file is under directory.
      id: file_name
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token, or the connection string already has
        shared

        access key values. The value can be a SAS token string, and account shared
        access

        key, or an instance of a TokenCredentials class from azure.identity.

        Credentials provided here will take precedence over those in the connection
        string.'
      id: credential
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Getting the properties for a file.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   properties = file_client.get_file_properties()\n\
    \n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  langs:
  - python
  module: azure.storage.filedatalake
  name: get_file_properties(**kwargs)
  namewithoutparameters: get_file_properties
  summary: 'Returns all user-defined metadata, standard HTTP properties, and

    system properties for the file. It does not return the content of the file.'
  syntax:
    content: get_file_properties(**kwargs)
    parameters: []
    return:
      type:
      - FileProperties
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
- class: azure.storage.filedatalake.DataLakeFileClient
  example:
  - "Rename the source file.<!--[!code-python[Main](les\\datalake_samples_upload_download.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\114\\\\azure-storage-file-datalake-12.0.1\\\\samples\\\\datalake_samples_upload_download.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   new_client = file_client.rename_file(file_client.file_system_name\
    \ + '/' + 'newname')\n\n   ````\n"
  fullName: azure.storage.filedatalake.DataLakeFileClient.rename_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: rename_file(new_name, **kwargs)
  namewithoutparameters: rename_file
  summary: Rename the source file.
  syntax:
    content: rename_file(new_name, **kwargs)
    parameters:
    - description: 'the new file name the user want to rename to.

        The value must have the following format: "{filesystem}/{directory}/{subdirectory}/{file}".'
      id: new_name
      isRequired: true
      type:
      - str
    return:
      description: the renamed file client
      type:
      - DataLakeFileClient
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.rename_file
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.upload_data
  langs:
  - python
  module: azure.storage.filedatalake
  name: upload_data(data, length=None, overwrite=False, **kwargs)
  namewithoutparameters: upload_data
  summary: Upload data to a file.
  syntax:
    content: upload_data(data, length=None, overwrite=False, **kwargs)
    parameters:
    - description: Content to be uploaded to file
      id: data
      isRequired: true
    - defaultValue: None
      description: Size of the data in bytes.
      id: length
      type:
      - int
    - defaultValue: 'False'
      description: to overwrite an existing file or not.
      id: overwrite
      type:
      - bool
    return:
      description: response dict (Etag and last modified).
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.upload_data
references:
- fullName: azure.storage.filedatalake.DataLakeFileClient.append_data
  isExternal: false
  name: append_data(data, offset, length=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.append_data
- fullName: azure.storage.filedatalake.DataLakeFileClient.create_file
  isExternal: false
  name: create_file(content_settings=None, metadata=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.create_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.delete_file
  isExternal: false
  name: delete_file(**kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.delete_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.download_file
  isExternal: false
  name: download_file(offset=None, length=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.download_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.flush_data
  isExternal: false
  name: flush_data(offset, retain_uncommitted_data=False, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.flush_data
- fullName: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  isExternal: false
  name: from_connection_string(conn_str, file_system_name, file_path, credential=None,
    **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
- fullName: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  isExternal: false
  name: get_file_properties(**kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
- fullName: azure.storage.filedatalake.DataLakeFileClient.rename_file
  isExternal: false
  name: rename_file(new_name, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.rename_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.upload_data
  isExternal: false
  name: upload_data(data, length=None, overwrite=False, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.upload_data
- fullName: dict(str, str)
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  uid: dict(str, str)
