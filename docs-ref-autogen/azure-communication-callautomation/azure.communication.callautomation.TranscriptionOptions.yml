### YamlMime:PythonClass
uid: azure.communication.callautomation.TranscriptionOptions
name: TranscriptionOptions
fullName: azure.communication.callautomation.TranscriptionOptions
module: azure.communication.callautomation
summary: Configuration of live transcription.
constructor:
  syntax: 'TranscriptionOptions(*, transport_url: str, transport_type: str | StreamingTransportType,
    locale: str, start_transcription: bool, speech_recognition_model_endpoint_id:
    str | None = None, enable_intermediate_results: bool | None = None)'
  parameters:
  - name: transport_url
    description: Transport URL for live transcription. Required.
    isRequired: true
    types:
    - <xref:str>
  - name: transport_type
    description: 'The type of transport to be used for live transcription, eg. Websocket.

      Required. "websocket"'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.communication.callautomation.StreamingTransportType>
  - name: locale
    description: Defines the locale for the data e.g en-CA, en-AU. Required.
    isRequired: true
    types:
    - <xref:str>
  - name: start_transcription
    description: 'Determines if the transcription should be started immediately after

      call is answered or not. Required.'
    isRequired: true
    types:
    - <xref:bool>
  - name: speech_recognition_model_endpoint_id
    description: Endpoint where the custom model was deployed
    isRequired: true
    types:
    - <xref:str>
  - name: enable_intermediate_results
    description: Enables intermediate results for the transcribed speech
    isRequired: true
    types:
    - <xref:bool>
  keywordOnlyParameters:
  - name: transport_url
    isRequired: true
  - name: transport_type
    isRequired: true
  - name: locale
    isRequired: true
  - name: start_transcription
    isRequired: true
  - name: speech_recognition_model_endpoint_id
    defaultValue: None
  - name: enable_intermediate_results
    defaultValue: None
attributes:
- uid: azure.communication.callautomation.TranscriptionOptions.enable_intermediate_results
  name: enable_intermediate_results
  summary: Enables intermediate results for the transcribed speech.
  signature: 'enable_intermediate_results: bool | None = None'
- uid: azure.communication.callautomation.TranscriptionOptions.locale
  name: locale
  summary: Defines the locale for the data.
  signature: 'locale: str'
- uid: azure.communication.callautomation.TranscriptionOptions.speech_recognition_model_endpoint_id
  name: speech_recognition_model_endpoint_id
  summary: Endpoint where the custom model was deployed.
  signature: 'speech_recognition_model_endpoint_id: str | None = None'
- uid: azure.communication.callautomation.TranscriptionOptions.start_transcription
  name: start_transcription
  summary: Determines if the transcription should be started immediately after call
    is answered or not.
  signature: 'start_transcription: bool'
- uid: azure.communication.callautomation.TranscriptionOptions.transport_type
  name: transport_type
  summary: The type of transport to be used for live transcription.
  signature: 'transport_type: str | StreamingTransportType'
- uid: azure.communication.callautomation.TranscriptionOptions.transport_url
  name: transport_url
  summary: Transport URL for live transcription.
  signature: 'transport_url: str'
