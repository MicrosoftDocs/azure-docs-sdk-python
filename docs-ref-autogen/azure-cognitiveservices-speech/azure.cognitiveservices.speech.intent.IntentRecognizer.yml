### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
  - azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
  - azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
  - azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
  - azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
  - azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
  - azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
  - azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer
  inheritance:
  - inheritance:
    - type: builtins.object
    type: azure.cognitiveservices.speech.Recognizer
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: IntentRecognizer
  summary: 'In addition to performing speech-to-text recognition, the IntentRecognizer
    extracts structured

    information about the intent of the speaker.'
  syntax:
    content: 'IntentRecognizer(speech_config: azure.cognitiveservices.speech.SpeechConfig,
      audio_config: typing.Union[azure.cognitiveservices.speech.audio.AudioConfig,
      NoneType] = None, intents: typing.Union[typing.Iterable[typing.Tuple[typing.Union[str,
      azure.cognitiveservices.speech.intent.LanguageUnderstandingModel], str]], NoneType]
      = None)'
    parameters:
    - description: The config for the speech recognizer.
      id: speech_config
    - description: The config for the audio input.
      id: audio_config
    - description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

        intent_id) to be recognized.'
      id: intents
  type: class
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: 'add_all_intents(model: azure.cognitiveservices.speech.intent.LanguageUnderstandingModel)'
  namewithoutparameters: add_all_intents
  summary: Adds all intents from the specified Language Understanding Model.
  syntax:
    content: 'add_all_intents(model: azure.cognitiveservices.speech.intent.LanguageUnderstandingModel)'
  type: method
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: add_intent(*args)
  namewithoutparameters: add_intent
  summary: "Add an intent to the recognizer. There are different ways to do this:\n\
    \n* *add_intent(simple_phrase)*: Adds a simple phrase that may be spoken by the\
    \ user, indicating a specific user intent. \n\n* *add_intent(simple_phrase, intent_id)*:\
    \ Adds a simple phrase that may be spoken by the user, indicating a specific user\
    \ intent. Once recognized, the result's intent id will match the id supplied here.\
    \ \n\n* *add_intent(model, intent_name)*: Adds a single intent by name from the\
    \ specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>.\
    \ \n\n* *add_intent(model, intent_name, intent_id)*: Adds a single intent by name\
    \ from the specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>."
  syntax:
    content: add_intent(*args)
    parameters:
    - description: The language understanding model containing the intent.
      id: model
      isRequired: true
    - description: 'The name of the single intent to be included from the language

        understanding model.'
      id: intent_name
      isRequired: true
    - description: The phrase corresponding to the intent.
      id: simple_phrase
      isRequired: true
    - description: 'A custom id string to be returned in the

        <xref:azure.cognitiveservices.speech.intent.IntentRecognitionResult>''s *intent_id*
        property.'
      id: intent_id
      isRequired: true
  type: method
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: 'add_intents(intents_iter: typing.Iterable[typing.Tuple[typing.Union[str,
    azure.cognitiveservices.speech.intent.LanguageUnderstandingModel], str]])'
  namewithoutparameters: add_intents
  summary: 'Add intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

    intent_id).'
  syntax:
    content: 'add_intents(intents_iter: typing.Iterable[typing.Tuple[typing.Union[str,
      azure.cognitiveservices.speech.intent.LanguageUnderstandingModel], str]])'
    parameters:
    - description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

        intent_id) to be recognized.'
      id: intents
      isRequired: true
  type: method
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.intent.IntentRecognitionCanceledEventArgs>,
    instance as the single argument.'
  syntax: {}
  type: attribute
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: recognize_once() -> azure.cognitiveservices.speech.intent.IntentRecognitionResult
  namewithoutparameters: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  syntax:
    content: recognize_once() -> azure.cognitiveservices.speech.intent.IntentRecognitionResult
    return:
      description: The result value of the synchronous recognition.
  type: method
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: recognize_once_async() -> azure.cognitiveservices.speech.ResultFuture
  namewithoutparameters: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  syntax:
    content: recognize_once_async() -> azure.cognitiveservices.speech.ResultFuture
    return:
      description: A future containing the result value of the asynchronous recognition.
  type: method
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>,

    instance as the single argument, dependent on the type of recognizer.'
  syntax: {}
  type: attribute
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
- class: azure.cognitiveservices.speech.intent.IntentRecognizer
  fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  langs:
  - python
  module: azure.cognitiveservices.speech.intent
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>,

    instance as the single argument.'
  syntax: {}
  type: attribute
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
references:
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
  isExternal: false
  name: 'add_all_intents(model: azure.cognitiveservices.speech.intent.LanguageUnderstandingModel)'
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
  isExternal: false
  name: add_intent(*args)
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
  isExternal: false
  name: 'add_intents(intents_iter: typing.Iterable[typing.Tuple[typing.Union[str,
    azure.cognitiveservices.speech.intent.LanguageUnderstandingModel], str]])'
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
  isExternal: false
  name: canceled
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
  isExternal: false
  name: recognize_once() -> azure.cognitiveservices.speech.intent.IntentRecognitionResult
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
  isExternal: false
  name: recognize_once_async() -> azure.cognitiveservices.speech.ResultFuture
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
  isExternal: false
  name: recognized
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
- fullName: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  isExternal: false
  name: recognizing
  parent: azure.cognitiveservices.speech.intent.IntentRecognizer
  uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
