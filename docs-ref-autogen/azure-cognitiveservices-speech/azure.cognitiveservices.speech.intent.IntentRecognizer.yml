### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.intent.IntentRecognizer
name: IntentRecognizer
fullName: azure.cognitiveservices.speech.intent.IntentRecognizer
module: azure.cognitiveservices.speech.intent
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: 'In addition to performing speech-to-text recognition, the IntentRecognizer
  extracts structured

  information about the intent of the speaker.'
constructor:
  syntax: 'IntentRecognizer(speech_config: azure.cognitiveservices.speech.SpeechConfig,
    audio_config: Optional[azure.cognitiveservices.speech.audio.AudioConfig] = None,
    intents: Optional[Iterable[Tuple[Union[str, azure.cognitiveservices.speech.intent.LanguageUnderstandingModel],
    str]]] = None)'
  parameters:
  - name: speech_config
    description: The config for the speech recognizer.
    isRequired: true
  - name: audio_config
    description: The config for the audio input.
    isRequired: true
  - name: intents
    description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

      intent_id) to be recognized.'
    isRequired: true
methods:
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
  name: add_all_intents
  summary: Adds all intents from the specified Language Understanding Model.
  signature: 'add_all_intents(model: azure.cognitiveservices.speech.intent.LanguageUnderstandingModel)'
  parameters:
  - name: model
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
  name: add_intent
  summary: "Add an intent to the recognizer. There are different ways to do this:\n\
    * *add_intent(simple_phrase)*: Adds a simple phrase that may be spoken by the\
    \ user, indicating a specific user intent. \n\n* *add_intent(simple_phrase, intent_id)*:\
    \ Adds a simple phrase that may be spoken by the user, indicating a specific user\
    \ intent. Once recognized, the result's intent id will match the id supplied here.\
    \ \n\n* *add_intent(model, intent_name)*: Adds a single intent by name from the\
    \ specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>.\
    \ \n\n* *add_intent(model, intent_name, intent_id)*: Adds a single intent by name\
    \ from the specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>."
  signature: add_intent(*args)
  parameters:
  - name: model
    description: The language understanding model containing the intent.
    isRequired: true
  - name: intent_name
    description: 'The name of the single intent to be included from the language

      understanding model.'
    isRequired: true
  - name: simple_phrase
    description: The phrase corresponding to the intent.
    isRequired: true
  - name: intent_id
    description: 'A custom id string to be returned in the

      <xref:azure.cognitiveservices.speech.intent.IntentRecognitionResult>''s *intent_id*
      property.'
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
  name: add_intents
  summary: 'Add intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

    intent_id).'
  signature: 'add_intents(intents_iter: Iterable[Tuple[Union[str, azure.cognitiveservices.speech.intent.LanguageUnderstandingModel],
    str]])'
  parameters:
  - name: intents
    description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

      intent_id) to be recognized.'
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> azure.cognitiveservices.speech.intent.IntentRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> azure.cognitiveservices.speech.ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
attributes:
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).

    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.intent.IntentRecognitionCanceledEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).

    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>,

    instance as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.

    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>,

    instance as the single argument.'
