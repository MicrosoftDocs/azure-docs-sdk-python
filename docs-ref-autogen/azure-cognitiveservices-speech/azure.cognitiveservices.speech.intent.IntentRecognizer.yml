### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.intent.IntentRecognizer
name: IntentRecognizer
fullName: azure.cognitiveservices.speech.intent.IntentRecognizer
module: azure.cognitiveservices.speech.intent
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: 'In addition to performing speech-to-text recognition, the IntentRecognizer
  extracts structured

  information about the intent of the speaker.'
constructor:
  syntax: 'IntentRecognizer(speech_config: SpeechConfig, audio_config: AudioConfig
    | None = None, intents: Iterable[Tuple[str | LanguageUnderstandingModel, str]]
    | None = None)'
  parameters:
  - name: speech_config
    description: The config for the speech recognizer.
    isRequired: true
  - name: audio_config
    description: The config for the audio input.
    defaultValue: None
  - name: intents
    description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

      intent_id) to be recognized.'
    defaultValue: None
methods:
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_all_intents
  name: add_all_intents
  summary: Adds all intents from the specified Language Understanding Model.
  signature: 'add_all_intents(model: LanguageUnderstandingModel)'
  parameters:
  - name: model
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intent
  name: add_intent
  summary: "Add an intent to the recognizer. There are different ways to do this:\n\
    \n* *add_intent(simple_phrase)*: Adds a simple phrase that may be spoken by the\
    \ user, indicating a specific user intent. \n\n* *add_intent(simple_phrase, intent_id)*:\
    \ Adds a simple phrase that may be spoken by the user, indicating a specific user\
    \ intent. Once recognized, the result's intent id will match the id supplied here.\
    \ \n\n* *add_intent(model, intent_name)*: Adds a single intent by name from the\
    \ specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>.\
    \ \n\n* *add_intent(model, intent_name, intent_id)*: Adds a single intent by name\
    \ from the specified <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>.\
    \ \n\n* *add_intent(trigger, intent_id)*: Adds the IntentTrigger specified. <xref:azure.cognitiveservices.speech.intent.IntentTrigger>."
  signature: add_intent(*args)
  parameters:
  - name: model
    description: The language understanding model containing the intent.
    isRequired: true
  - name: intent_name
    description: 'The name of the single intent to be included from the language

      understanding model.'
    isRequired: true
  - name: simple_phrase
    description: The phrase corresponding to the intent.
    isRequired: true
  - name: intent_id
    description: 'A custom id string to be returned in the

      <xref:azure.cognitiveservices.speech.intent.IntentRecognitionResult>''s *intent_id*
      property.'
    isRequired: true
  - name: trigger
    description: The IntentTrigger corresponding to the intent.
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.add_intents
  name: add_intents
  summary: 'Add intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

    intent_id).'
  signature: 'add_intents(intents_iter: Iterable[Tuple[str | LanguageUnderstandingModel,
    str]])'
  parameters:
  - name: intents
    description: 'Intents from an iterable over pairs of (model, intent_id) or (simple_phrase,

      intent_id) to be recognized.'
    isRequired: true
  - name: intents_iter
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.intent.IntentRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> IntentRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.intent.IntentRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.start_continuous_recognition
  name: start_continuous_recognition
  summary: 'Synchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.intent.IntentRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition()
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.start_continuous_recognition_async
  name: start_continuous_recognition_async
  summary: 'Asynchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.intent.IntentRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition_async() -> ResultFuture
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.start_keyword_recognition
  name: start_keyword_recognition
  summary: 'Synchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition() to end
    the keyword initiated recognition.'
  signature: 'start_keyword_recognition(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.start_keyword_recognition_async
  name: start_keyword_recognition_async
  summary: 'Asynchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition_async()
    to end the keyword initiated recognition.'
  signature: 'start_keyword_recognition_async(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.stop_continuous_recognition
  name: stop_continuous_recognition
  summary: Synchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition()
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.stop_continuous_recognition_async
  name: stop_continuous_recognition_async
  summary: Asynchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.stop_keyword_recognition
  name: stop_keyword_recognition
  summary: Synchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition()
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.stop_keyword_recognition_async
  name: stop_keyword_recognition_async
  summary: Asynchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
attributes:
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.authorization_token
  name: authorization_token
  summary: 'The authorization token that will be used for connecting to the service.


    > [!NOTE]

    > The caller needs to ensure that the authorization token is valid. Before the

    >

    > authorization token expires, the caller needs to refresh it by calling this
    setter with a

    >

    > new valid token. Otherwise, the recognizer will encounter errors during recognition.

    >'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.intent.IntentRecognitionCanceledEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.endpoint_id
  name: endpoint_id
  summary: The endpoint ID of a customized speech model that is used for recognition,
    or a custom voice model for speech synthesis.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.properties
  name: properties
  summary: A collection of properties and their values defined for this Recognizer.
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>

    instance as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.session_started
  name: session_started
  summary: 'Signal for events indicating the start of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.session_stopped
  name: session_stopped
  summary: 'Signal for events indicating the end of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.speech_end_detected
  name: speech_end_detected
  summary: 'Signal for events indicating the end of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.intent.IntentRecognizer.speech_start_detected
  name: speech_start_detected
  summary: 'Signal for events indicating the start of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
