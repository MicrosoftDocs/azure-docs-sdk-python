### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.translation.TranslationRecognizer
name: TranslationRecognizer
fullName: azure.cognitiveservices.speech.translation.TranslationRecognizer
module: azure.cognitiveservices.speech.translation
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: Performs translation on the speech input.
constructor:
  syntax: 'TranslationRecognizer(translation_config: azure.cognitiveservices.speech.translation.SpeechTranslationConfig,
    auto_detect_source_language_config: Optional[azure.cognitiveservices.speech.languageconfig.AutoDetectSourceLanguageConfig]
    = None, audio_config: Optional[azure.cognitiveservices.speech.audio.AudioConfig]
    = None)'
  parameters:
  - name: translation_config
    description: The config for the translation recognizer.
    isRequired: true
  - name: auto_detect_source_language_config
    description: The auto detection source language config
    isRequired: true
  - name: audio_config
    description: The config for the audio input.
    isRequired: true
methods:
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.add_target_language
  name: add_target_language
  summary: 'Add *language* to the list of target languages for translation.

    > [!NOTE]

    > Added in version 1.7.0.

    >'
  signature: 'add_target_language(language: str)'
  parameters:
  - name: language
    description: The language code to add.
    isRequired: true
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> azure.cognitiveservices.speech.translation.TranslationRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.Recognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> azure.cognitiveservices.speech.ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.remove_target_language
  name: remove_target_language
  summary: 'Remove *language* from the list of target languages for translation.

    > [!NOTE]

    > Added in version 1.7.0.

    >'
  signature: 'remove_target_language(language: str)'
  parameters:
  - name: language
    description: The language code to remove.
    isRequired: true
attributes:
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).

    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionCanceledEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).

    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>,
    instance as the single argument, dependent on

    the type of recognizer.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.

    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.synthesizing
  name: synthesizing
  summary: 'The event signals that a translation synthesis result is received.

    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationSynthesisEventArgs>
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.target_languages
  name: target_languages
  summary: 'The target languages for translation.

    > [!NOTE]

    > Added in version 1.7.0.

    >'
