### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.translation.TranslationRecognizer
name: TranslationRecognizer
fullName: azure.cognitiveservices.speech.translation.TranslationRecognizer
module: azure.cognitiveservices.speech.translation
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: Performs translation on the speech input.
constructor:
  syntax: 'TranslationRecognizer(translation_config: SpeechTranslationConfig, auto_detect_source_language_config:
    AutoDetectSourceLanguageConfig | None = None, audio_config: AudioConfig | None
    = None)'
  parameters:
  - name: translation_config
    description: The config for the translation recognizer.
    isRequired: true
  - name: auto_detect_source_language_config
    description: The auto detection source language config
    defaultValue: None
  - name: audio_config
    description: The config for the audio input.
    defaultValue: None
methods:
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.add_target_language
  name: add_target_language
  summary: 'Add *language* to the list of target languages for translation.


    > [!NOTE]

    > Added in version 1.7.0.

    >'
  signature: 'add_target_language(language: str)'
  parameters:
  - name: language
    description: The language code to add.
    isRequired: true
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> TranslationRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.translation.TranslationRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.remove_target_language
  name: remove_target_language
  summary: 'Remove *language* from the list of target languages for translation.


    > [!NOTE]

    > Added in version 1.7.0.

    >'
  signature: 'remove_target_language(language: str)'
  parameters:
  - name: language
    description: The language code to remove.
    isRequired: true
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.start_continuous_recognition
  name: start_continuous_recognition
  summary: 'Synchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition()
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.start_continuous_recognition_async
  name: start_continuous_recognition_async
  summary: 'Asynchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition_async() -> ResultFuture
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.start_keyword_recognition
  name: start_keyword_recognition
  summary: 'Synchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition() to end
    the keyword initiated recognition.'
  signature: 'start_keyword_recognition(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.start_keyword_recognition_async
  name: start_keyword_recognition_async
  summary: 'Asynchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition_async()
    to end the keyword initiated recognition.'
  signature: 'start_keyword_recognition_async(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_continuous_recognition
  name: stop_continuous_recognition
  summary: Synchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition()
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_continuous_recognition_async
  name: stop_continuous_recognition_async
  summary: Asynchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_keyword_recognition
  name: stop_keyword_recognition
  summary: Synchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition()
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.stop_keyword_recognition_async
  name: stop_keyword_recognition_async
  summary: Asynchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
attributes:
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.authorization_token
  name: authorization_token
  summary: 'The authorization token that will be used for connecting to the service.


    > [!NOTE]

    > The caller needs to ensure that the authorization token is valid. Before the

    >

    > authorization token expires, the caller needs to refresh it by calling this
    setter with a

    >

    > new valid token. Otherwise, the recognizer will encounter errors during recognition.

    >'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionCanceledEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.endpoint_id
  name: endpoint_id
  summary: The endpoint ID of a customized speech model that is used for recognition,
    or a custom voice model for speech synthesis.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.properties
  name: properties
  summary: A collection of properties and their values defined for this Recognizer.
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>,
    instance as the single argument, dependent on

    the type of recognizer.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.session_started
  name: session_started
  summary: 'Signal for events indicating the start of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.session_stopped
  name: session_stopped
  summary: 'Signal for events indicating the end of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.speech_end_detected
  name: speech_end_detected
  summary: 'Signal for events indicating the end of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.speech_start_detected
  name: speech_start_detected
  summary: 'Signal for events indicating the start of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.synthesizing
  name: synthesizing
  summary: 'The event signals that a translation synthesis result is received.


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.translation.TranslationSynthesisEventArgs>
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.translation.TranslationRecognizer.target_languages
  name: target_languages
  summary: 'The target languages for translation.


    > [!NOTE]

    > Added in version 1.7.0.

    >'
