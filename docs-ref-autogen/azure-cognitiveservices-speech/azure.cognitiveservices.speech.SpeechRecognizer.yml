### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.SpeechRecognizer
name: SpeechRecognizer
fullName: azure.cognitiveservices.speech.SpeechRecognizer
module: azure.cognitiveservices.speech
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: 'A speech recognizer.

  If you need to specify source language information, please only specify one of these
  three parameters,

  language, source_language_config or auto_detect_source_language_config.'
constructor:
  syntax: 'SpeechRecognizer(speech_config: SpeechConfig, audio_config: AudioConfig
    = None, language: str = None, source_language_config: SourceLanguageConfig = None,
    auto_detect_source_language_config: AutoDetectSourceLanguageConfig = None)'
  parameters:
  - name: speech_config
    description: The config for the speech recognizer
    isRequired: true
  - name: audio_config
    description: The config for the audio input
    defaultValue: None
  - name: language
    description: The source language
    defaultValue: None
  - name: source_language_config
    description: The source language config
    defaultValue: None
  - name: auto_detect_source_language_config
    description: The auto detection source language config
    defaultValue: None
methods:
- uid: azure.cognitiveservices.speech.SpeechRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.SpeechRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> SpeechRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.SpeechRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.start_continuous_recognition
  name: start_continuous_recognition
  summary: 'Synchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.SpeechRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition()
- uid: azure.cognitiveservices.speech.SpeechRecognizer.start_continuous_recognition_async
  name: start_continuous_recognition_async
  summary: 'Asynchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.SpeechRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition_async() -> ResultFuture
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.start_keyword_recognition
  name: start_keyword_recognition
  summary: 'Synchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition() to end
    the keyword initiated recognition.'
  signature: 'start_keyword_recognition(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
- uid: azure.cognitiveservices.speech.SpeechRecognizer.start_keyword_recognition_async
  name: start_keyword_recognition_async
  summary: 'Asynchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition_async()
    to end the keyword initiated recognition.'
  signature: 'start_keyword_recognition_async(model: KeywordRecognitionModel) -> ResultFuture'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.stop_continuous_recognition
  name: stop_continuous_recognition
  summary: Synchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition()
- uid: azure.cognitiveservices.speech.SpeechRecognizer.stop_continuous_recognition_async
  name: stop_continuous_recognition_async
  summary: Asynchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.stop_keyword_recognition
  name: stop_keyword_recognition
  summary: Synchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition()
- uid: azure.cognitiveservices.speech.SpeechRecognizer.stop_keyword_recognition_async
  name: stop_keyword_recognition_async
  summary: Asynchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
attributes:
- uid: azure.cognitiveservices.speech.SpeechRecognizer.authorization_token
  name: authorization_token
  summary: 'The authorization token that will be used for connecting to the service.


    > [!NOTE]

    > The caller needs to ensure that the authorization token is valid. Before the

    >

    > authorization token expires, the caller needs to refresh it by calling this
    setter with a

    >

    > new valid token. Otherwise, the recognizer will encounter errors during recognition.

    >'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.SpeechRecognitionCanceledEventArgs>, instance
    as the single argument.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.endpoint_id
  name: endpoint_id
  summary: The endpoint ID of a customized speech model that is used for recognition,
    or a custom voice model for speech synthesis.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.properties
  name: properties
  summary: A collection of properties and their values defined for this Recognizer.
- uid: azure.cognitiveservices.speech.SpeechRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>

    instance as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.session_started
  name: session_started
  summary: 'Signal for events indicating the start of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.session_stopped
  name: session_stopped
  summary: 'Signal for events indicating the end of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.speech_end_detected
  name: speech_end_detected
  summary: 'Signal for events indicating the end of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.SpeechRecognizer.speech_start_detected
  name: speech_start_detected
  summary: 'Signal for events indicating the start of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
