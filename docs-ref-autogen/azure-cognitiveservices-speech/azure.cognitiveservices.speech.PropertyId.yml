### YamlMime:PythonEnum
uid: azure.cognitiveservices.speech.PropertyId
name: PropertyId
fullName: azure.cognitiveservices.speech.PropertyId
summary: "Defines speech property ids.\n\n*Values:*\n\n   SpeechServiceConnection_Key\n\
  \n\n      The Cognitive Services Speech Service subscription key. If you are using\n\
  \n      an intent recognizer, you need to specify the LUIS endpoint key for your\n\
  \n      particular LUIS app. Under normal circumstances, you shouldn't have to\n\
  \n      use this property directly. Instead, construct a\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig>\
  \ instance from a subscription key.\n\n   SpeechServiceConnection_Endpoint\n\n\n\
  \      The Cognitive Services Speech Service endpoint (url). Under normal\n\n  \
  \    circumstances, you shouldn't have to use this property directly. Instead,\n\
  \n      construct a <xref:azure.cognitiveservices.speech.SpeechConfig> instance\
  \ from a subscription key.\n\n\n      > [!NOTE]\n      > This endpoint is not the\
  \ same as the endpoint used to obtain an access token.\n      >\n\n   SpeechServiceConnection_Region\n\
  \n\n      The Cognitive Services Speech Service region. Under normal circumstances,\n\
  \n      you shouldn't have to use this property directly. Instead, construct a\n\
  \n      <xref:azure.cognitiveservices.speech.SpeechConfig> instance from a subscription\
  \ key, an endpoint, a host,\n\n      or an authorization token.\n\n   SpeechServiceAuthorization_Token\n\
  \n\n      The Cognitive Services Speech Service authorization token (aka access\n\
  \n      token). Under normal circumstances, you shouldn't have to use this\n\n \
  \     property directly. Instead, construct a <xref:azure.cognitiveservices.speech.SpeechConfig>\n\
  \n      instance from an authorization token, or set\n\n      <xref:azure.cognitiveservices.speech.Recognizer.authorization_token>.\n\
  \n   SpeechServiceAuthorization_Type\n\n\n      The Cognitive Services Speech Service\
  \ authorization type. Currently\n\n      unused.\n\n   SpeechServiceConnection_EndpointId\n\
  \n\n      The Cognitive Services Custom Speech or Custom Voice Service endpoint\
  \ id.\n\n      Under normal circumstances, you shouldn't have to use this property\
  \ directly.\n\n      Instead set <xref:azure.cognitiveservices.speech.SpeechConfig.endpoint_id>.\n\
  \n\n      > [!NOTE]\n      > The endpoint id is available in the Custom Speech Portal,\
  \ listed under\n      >\n      > \n      >\n      > Endpoint Details.\n      >\n\
  \n   SpeechServiceConnection_Host\n\n\n      The Cognitive Services Speech Service\
  \ host (url). Under normal\n\n      circumstances, you shouldn't have to use this\
  \ property directly. Instead,\n\n      construct a <xref:azure.cognitiveservices.speech.SpeechConfig>\
  \ instance.\n\n   SpeechServiceConnection_ProxyHostName\n\n\n      The host name\
  \ of the proxy server used to connect to the Cognitive\n\n      Services Speech\
  \ Service. Under normal circumstances, you shouldn't have\n\n      to use this property\
  \ directly. Instead, use\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig.set_proxy>.\n\
  \n   SpeechServiceConnection_ProxyPort\n\n\n      The port of the proxy server used\
  \ to connect to the Cognitive Services\n\n      Speech Service. Under normal circumstances,\
  \ you shouldn't have to use\n\n      this property directly. Instead, use <xref:azure.cognitiveservices.speech.SpeechConfig.set_proxy>.\n\
  \n   SpeechServiceConnection_ProxyUserName\n\n\n      The user name of the proxy\
  \ server used to connect to the Cognitive\n\n      Services Speech Service. Under\
  \ normal circumstances, you shouldn't have\n\n      to use this property directly.\
  \ Instead, use\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig.set_proxy>.\n\
  \n   SpeechServiceConnection_ProxyPassword\n\n\n      The password of the proxy\
  \ server used to connect to the Cognitive\n\n      Services Speech Service. Under\
  \ normal circumstances, you shouldn't have\n\n      to use this property directly.\
  \ Instead, use\n\n      <xref:azure.cognitiveservices.speech.SpeechConfig.set_proxy>.\n\
  \n   SpeechServiceConnection_Url\n\n\n      The URL string built from speech configuration.\
  \ This property is intended\n\n      to be read-only. The SDK is using it internally.\n\
  \n\n      > [!NOTE]\n      > This property id was added in version 1.5.0.\n    \
  \  >\n\n   SpeechServiceConnection_TranslationToLanguages\n\n\n      The list of\
  \ comma separated languages used as target translation\n\n      languages. Under\
  \ normal circumstances, you shouldn't have to use this\n\n      property directly.\
  \ Instead use\n\n      <xref:azure.cognitiveservices.speech.speech_py_impl.SpeechTranslationConfig.add_target_language>\
  \ and\n\n      <xref:azure.cognitiveservices.speech.translation.SpeechTranslationConfig.target_languages>.\n\
  \n   SpeechServiceConnection_TranslationVoice\n\n\n      The name of the Cognitive\
  \ Service Text to Speech Service voice. Under\n\n      normal circumstances, you\
  \ shouldn't have to use this property directly.\n\n      Instead set <xref:azure.cognitiveservices.speech.translation.SpeechTranslationConfig.voice_name>.\n\
  \n\n      > [!NOTE]\n      > Valid voice names can be found [here](https://aka.ms/csspeech/voicenames).\n\
  \      >\n\n   SpeechServiceConnection_TranslationFeatures\n\n\n      Translation\
  \ features. For internal use.\n\n   SpeechServiceConnection_IntentRegion\n\n\n \
  \     The Language Understanding Service region. Under normal circumstances,\n\n\
  \      you shouldn't have to use this property directly. Instead use\n\n      <xref:azure.cognitiveservices.speech.intent.LanguageUnderstandingModel>.\n\
  \n   SpeechServiceConnection_RecoMode\n\n\n      The Cognitive Services Speech Service\
  \ recognition mode. Can be\n\n      \"INTERACTIVE\", \"CONVERSATION\", \"DICTATION\"\
  . This property is intended to\n\n      be read-only. The SDK is using it internally.\n\
  \n   SpeechServiceConnection_RecoLanguage\n\n\n      The spoken language to be recognized\
  \ (in BCP-47 format). Under normal\n\n      circumstances, you shouldn't have to\
  \ use this property directly. Instead,\n\n      use <xref:azure.cognitiveservices.speech.SpeechConfig.speech_recognition_language>.\n\
  \n   Speech_SessionId\n\n\n      The session id. This id is a universally unique\
  \ identifier (aka UUID)\n\n      representing a specific binding of an audio input\
  \ stream and the\n\n      underlying speech recognition instance to which it is\
  \ bound. Under normal\n\n      circumstances, you shouldn't have to use this property\
  \ directly. Instead\n\n      use <xref:azure.cognitiveservices.speech.SessionEventArgs.session_id>.\n\
  \n   SpeechServiceConnection_SynthLanguage\n\n\n      The spoken language to be\
  \ synthesized (e.g. en-US)\n\n\n      > [!NOTE]\n      > This property id was added\
  \ in version 1.7.0.\n      >\n\n   SpeechServiceConnection_SynthVoice\n\n\n    \
  \  The name of the TTS voice to be used for speech synthesis\n\n\n      > [!NOTE]\n\
  \      > This property id was added in version 1.7.0.\n      >\n\n   SpeechServiceConnection_SynthOutputFormat\n\
  \n\n      The string to specify TTS output audio format\n\n\n      > [!NOTE]\n \
  \     > This property id was added in version 1.7.0.\n      >"
module: azure.cognitiveservices.speech
constructor:
  syntax: PropertyId(value)
inheritances:
- enum.Enum
fields:
- name: AudioConfig_AudioProcessingOptions
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioProcessingOptions
- name: AudioConfig_AudioSource
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_AudioSource
- name: AudioConfig_BitsPerSampleForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_BitsPerSampleForCapture
- name: AudioConfig_DeviceNameForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForCapture
- name: AudioConfig_DeviceNameForRender
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_DeviceNameForRender
- name: AudioConfig_NumberOfChannelsForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_NumberOfChannelsForCapture
- name: AudioConfig_PlaybackBufferLengthInMs
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_PlaybackBufferLengthInMs
- name: AudioConfig_SampleRateForCapture
  uid: azure.cognitiveservices.speech.PropertyId.AudioConfig_SampleRateForCapture
- name: CancellationDetails_Reason
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_Reason
- name: CancellationDetails_ReasonDetailedText
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonDetailedText
- name: CancellationDetails_ReasonText
  uid: azure.cognitiveservices.speech.PropertyId.CancellationDetails_ReasonText
- name: Conversation_ApplicationId
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_ApplicationId
- name: Conversation_Connection_Id
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Connection_Id
- name: Conversation_Conversation_Id
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Conversation_Id
- name: Conversation_Custom_Voice_Deployment_Ids
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Custom_Voice_Deployment_Ids
- name: Conversation_DialogType
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_DialogType
- name: Conversation_From_Id
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_From_Id
- name: Conversation_Initial_Silence_Timeout
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Initial_Silence_Timeout
- name: Conversation_ParticipantId
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_ParticipantId
- name: Conversation_Request_Bot_Status_Messages
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Request_Bot_Status_Messages
- name: Conversation_Speech_Activity_Template
  uid: azure.cognitiveservices.speech.PropertyId.Conversation_Speech_Activity_Template
- name: DataBuffer_TimeStamp
  uid: azure.cognitiveservices.speech.PropertyId.DataBuffer_TimeStamp
- name: DataBuffer_UserId
  uid: azure.cognitiveservices.speech.PropertyId.DataBuffer_UserId
- name: LanguageUnderstandingServiceResponse_JsonResult
  uid: azure.cognitiveservices.speech.PropertyId.LanguageUnderstandingServiceResponse_JsonResult
- name: PronunciationAssessment_EnableMiscue
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_EnableMiscue
- name: PronunciationAssessment_GradingSystem
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_GradingSystem
- name: PronunciationAssessment_Granularity
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Granularity
- name: PronunciationAssessment_Json
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Json
- name: PronunciationAssessment_NBestPhonemeCount
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_NBestPhonemeCount
- name: PronunciationAssessment_Params
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_Params
- name: PronunciationAssessment_PhonemeAlphabet
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_PhonemeAlphabet
- name: PronunciationAssessment_ReferenceText
  uid: azure.cognitiveservices.speech.PropertyId.PronunciationAssessment_ReferenceText
- name: SpeakerRecognition_Api_Version
  uid: azure.cognitiveservices.speech.PropertyId.SpeakerRecognition_Api_Version
- name: SpeechServiceAuthorization_Token
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Token
- name: SpeechServiceAuthorization_Type
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceAuthorization_Type
- name: SpeechServiceConnection_AutoDetectSourceLanguageResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
- name: SpeechServiceConnection_AutoDetectSourceLanguages
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguages
- name: SpeechServiceConnection_ContinuousLanguageIdPriority
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ContinuousLanguageIdPriority
- name: SpeechServiceConnection_EnableAudioLogging
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EnableAudioLogging
- name: SpeechServiceConnection_EndSilenceTimeoutMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndSilenceTimeoutMs
- name: SpeechServiceConnection_Endpoint
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Endpoint
- name: SpeechServiceConnection_EndpointId
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_EndpointId
- name: SpeechServiceConnection_Host
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Host
- name: SpeechServiceConnection_InitialSilenceTimeoutMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_InitialSilenceTimeoutMs
- name: SpeechServiceConnection_IntentRegion
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_IntentRegion
- name: SpeechServiceConnection_Key
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Key
- name: SpeechServiceConnection_ProxyHostName
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyHostName
- name: SpeechServiceConnection_ProxyPassword
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPassword
- name: SpeechServiceConnection_ProxyPort
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyPort
- name: SpeechServiceConnection_ProxyUserName
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_ProxyUserName
- name: SpeechServiceConnection_RecoBackend
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoBackend
- name: SpeechServiceConnection_RecoLanguage
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoLanguage
- name: SpeechServiceConnection_RecoMode
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoMode
- name: SpeechServiceConnection_RecoModelIniFile
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelIniFile
- name: SpeechServiceConnection_RecoModelKey
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelKey
- name: SpeechServiceConnection_RecoModelName
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_RecoModelName
- name: SpeechServiceConnection_Region
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Region
- name: SpeechServiceConnection_SingleLanguageIdPriority
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SingleLanguageIdPriority
- name: SpeechServiceConnection_SynthBackend
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthBackend
- name: SpeechServiceConnection_SynthEnableCompressedAudioTransmission
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthEnableCompressedAudioTransmission
- name: SpeechServiceConnection_SynthLanguage
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthLanguage
- name: SpeechServiceConnection_SynthModelKey
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthModelKey
- name: SpeechServiceConnection_SynthOfflineDataPath
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineDataPath
- name: SpeechServiceConnection_SynthOfflineVoice
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOfflineVoice
- name: SpeechServiceConnection_SynthOutputFormat
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthOutputFormat
- name: SpeechServiceConnection_SynthVoice
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_SynthVoice
- name: SpeechServiceConnection_TranslationFeatures
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationFeatures
- name: SpeechServiceConnection_TranslationToLanguages
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationToLanguages
- name: SpeechServiceConnection_TranslationVoice
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_TranslationVoice
- name: SpeechServiceConnection_Url
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_Url
- name: SpeechServiceConnection_UserDefinedQueryParameters
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_UserDefinedQueryParameters
- name: SpeechServiceConnection_VoicesListEndpoint
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceConnection_VoicesListEndpoint
- name: SpeechServiceResponse_JsonErrorDetails
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonErrorDetails
- name: SpeechServiceResponse_JsonResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_JsonResult
- name: SpeechServiceResponse_OutputFormatOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_OutputFormatOption
- name: SpeechServiceResponse_PostProcessingOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_PostProcessingOption
- name: SpeechServiceResponse_ProfanityOption
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_ProfanityOption
- name: SpeechServiceResponse_RecognitionLatencyMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RecognitionLatencyMs
- name: SpeechServiceResponse_RequestDetailedResultTrueFalse
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
- name: SpeechServiceResponse_RequestProfanityFilterTrueFalse
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
- name: SpeechServiceResponse_RequestSnr
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestSnr
- name: SpeechServiceResponse_RequestWordLevelTimestamps
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_RequestWordLevelTimestamps
- name: SpeechServiceResponse_StablePartialResultThreshold
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_StablePartialResultThreshold
- name: SpeechServiceResponse_SynthesisBackend
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisBackend
- name: SpeechServiceResponse_SynthesisFinishLatencyMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFinishLatencyMs
- name: SpeechServiceResponse_SynthesisFirstByteLatencyMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisFirstByteLatencyMs
- name: SpeechServiceResponse_SynthesisUnderrunTimeMs
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_SynthesisUnderrunTimeMs
- name: SpeechServiceResponse_TranslationRequestStablePartialResult
  uid: azure.cognitiveservices.speech.PropertyId.SpeechServiceResponse_TranslationRequestStablePartialResult
- name: Speech_LogFilename
  uid: azure.cognitiveservices.speech.PropertyId.Speech_LogFilename
- name: Speech_SessionId
  uid: azure.cognitiveservices.speech.PropertyId.Speech_SessionId
