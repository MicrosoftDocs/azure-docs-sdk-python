### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.cognitiveservices.speech.AudioDataStream.can_read_data
  - azure.cognitiveservices.speech.AudioDataStream.detach_input
  - azure.cognitiveservices.speech.AudioDataStream.position
  - azure.cognitiveservices.speech.AudioDataStream.read_data
  - azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file
  - azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file_async
  - azure.cognitiveservices.speech.AudioDataStream.status
  class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: AudioDataStream
  summary: 'Represents audio data stream used for operating audio data as a stream.


    Generates an audio data stream from a speech synthesis result (type SpeechSynthesisResult)

    or a keyword recognition result (type KeywordRecognitionResult).'
  syntax:
    content: AudioDataStream(result=None)
    parameters:
    - description: The speech synthesis or keyword recognition result.
      id: result
  type: class
  uid: azure.cognitiveservices.speech.AudioDataStream
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.can_read_data
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: 'can_read_data(requested_bytes: int, pos: typing.Union[int, NoneType] = None)
    -> bool'
  namewithoutparameters: can_read_data
  summary: 'Check whether the stream has enough data to be read,

    starting from the specified position (if specified).'
  syntax:
    content: 'can_read_data(requested_bytes: int, pos: typing.Union[int, NoneType]
      = None) -> bool'
    parameters:
    - description: The requested data size in bytes.
      id: requested_bytes
      isRequired: true
    - description: 'The position to start with.

        Will start from current position if this param is not given.'
      id: pos
      isRequired: true
    return:
      description: A bool indicating the result
  type: method
  uid: azure.cognitiveservices.speech.AudioDataStream.can_read_data
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.detach_input
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: detach_input()
  namewithoutparameters: detach_input
  summary: Stop any more data from getting to the stream.
  syntax:
    content: detach_input()
    parameters: []
  type: method
  uid: azure.cognitiveservices.speech.AudioDataStream.detach_input
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.position
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: position
  summary: Current position of the audio data stream.
  syntax: {}
  type: attribute
  uid: azure.cognitiveservices.speech.AudioDataStream.position
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.read_data
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: 'read_data(audio_buffer: bytes, pos: typing.Union[int, NoneType] = None) ->
    int'
  namewithoutparameters: read_data
  summary: 'Reads the audio data from the audio data stream,

    starting from the specified position (if specified).

    The maximal number of bytes to be read is determined by the size of audio_buffer.

    If there is no data immediately available, read_data() blocks until

    the next data becomes available.'
  syntax:
    content: 'read_data(audio_buffer: bytes, pos: typing.Union[int, NoneType] = None)
      -> int'
    parameters:
    - description: The buffer to receive the audio data.
      id: audio_buffer
      isRequired: true
    - description: 'The position to start with.

        Will start from current position if this param is not given.'
      id: pos
      isRequired: true
    return:
      description: 'The number of bytes filled, or 0 in case the stream hits its end
        and

        there is no more data available.'
  type: method
  uid: azure.cognitiveservices.speech.AudioDataStream.read_data
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: 'save_to_wav_file(file_name: str)'
  namewithoutparameters: save_to_wav_file
  summary: Save the audio data to a file, synchronously.
  syntax:
    content: 'save_to_wav_file(file_name: str)'
    parameters:
    - description: Name of the file to be saved to
      id: file_name
      isRequired: true
  type: method
  uid: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file_async
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: 'save_to_wav_file_async(file_name: str)'
  namewithoutparameters: save_to_wav_file_async
  summary: Save the audio data to a file, asynchronously.
  syntax:
    content: 'save_to_wav_file_async(file_name: str)'
    parameters:
    - description: Name of the file to be saved to
      id: file_name
      isRequired: true
    return:
      description: An asynchronous operation representing the saving.
  type: method
  uid: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file_async
- class: azure.cognitiveservices.speech.AudioDataStream
  fullName: azure.cognitiveservices.speech.AudioDataStream.status
  langs:
  - python
  module: azure.cognitiveservices.speech
  name: status
  summary: Current status of the audio data stream.
  syntax: {}
  type: attribute
  uid: azure.cognitiveservices.speech.AudioDataStream.status
references:
- fullName: azure.cognitiveservices.speech.AudioDataStream.can_read_data
  isExternal: false
  name: 'can_read_data(requested_bytes: int, pos: typing.Union[int, NoneType] = None)
    -> bool'
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.can_read_data
- fullName: azure.cognitiveservices.speech.AudioDataStream.detach_input
  isExternal: false
  name: detach_input()
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.detach_input
- fullName: azure.cognitiveservices.speech.AudioDataStream.position
  isExternal: false
  name: position
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.position
- fullName: azure.cognitiveservices.speech.AudioDataStream.read_data
  isExternal: false
  name: 'read_data(audio_buffer: bytes, pos: typing.Union[int, NoneType] = None) ->
    int'
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.read_data
- fullName: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file
  isExternal: false
  name: 'save_to_wav_file(file_name: str)'
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file
- fullName: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file_async
  isExternal: false
  name: 'save_to_wav_file_async(file_name: str)'
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.save_to_wav_file_async
- fullName: azure.cognitiveservices.speech.AudioDataStream.status
  isExternal: false
  name: status
  parent: azure.cognitiveservices.speech.AudioDataStream
  uid: azure.cognitiveservices.speech.AudioDataStream.status
