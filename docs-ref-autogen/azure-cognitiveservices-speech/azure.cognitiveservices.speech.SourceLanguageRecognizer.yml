### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.SourceLanguageRecognizer
name: SourceLanguageRecognizer
fullName: azure.cognitiveservices.speech.SourceLanguageRecognizer
module: azure.cognitiveservices.speech
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: 'A source language recognizer - standalone language recognizer, can be used
  for single language or continuous language detection.


  > [!NOTE]

  > Added in version 1.18.0.

  >'
constructor:
  syntax: 'SourceLanguageRecognizer(speech_config: SpeechConfig, auto_detect_source_language_config:
    AutoDetectSourceLanguageConfig | None = None, audio_config: AudioConfig | None
    = None)'
  parameters:
  - name: speech_config
    description: The config for the speech recognizer
    isRequired: true
  - name: auto_detect_source_language_config
    description: The auto detection source language config
    defaultValue: None
  - name: audio_config
    description: The config for the audio input
    defaultValue: None
methods:
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.recognize_once
  name: recognize_once
  summary: 'Performs detection in a blocking (synchronous) mode. Returns after a single
    utterance is

    detected. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.SourceLanguageRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> SpeechRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.recognize_once_async
  name: recognize_once_async
  summary: 'Performs detection in a non-blocking (asynchronous) mode. This will detect
    a single

    utterance. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.SourceLanguageRecognizer.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.start_continuous_recognition_async
  name: start_continuous_recognition_async
  summary: 'Asynchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.SourceLanguageRecognizer.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition_async() -> ResultFuture
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.stop_continuous_recognition_async
  name: stop_continuous_recognition_async
  summary: Asynchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
attributes:
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.canceled
  name: canceled
  summary: 'Signal for events containing canceled recognition results (indicating
    a recognition attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.SpeechRecognitionCanceledEventArgs>, instance
    as the single argument.'
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>

    instance as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.SourceLanguageRecognizer.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>

    instance as the single argument.'
