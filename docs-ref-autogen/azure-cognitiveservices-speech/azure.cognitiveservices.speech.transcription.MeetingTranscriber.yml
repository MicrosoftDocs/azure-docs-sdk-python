### YamlMime:PythonClass
uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber
name: MeetingTranscriber
fullName: azure.cognitiveservices.speech.transcription.MeetingTranscriber
module: azure.cognitiveservices.speech.transcription
inheritances:
- azure.cognitiveservices.speech.Recognizer
summary: On object that performs meeting transcription operations.
constructor:
  syntax: 'MeetingTranscriber(audio_config: AudioConfig | None = None)'
  parameters:
  - name: audio_config
    description: The configuration for the audio input.
    defaultValue: None
methods:
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.join_meeting_async
  name: join_meeting_async
  summary: Asynchronously joins a meeting.
  signature: 'join_meeting_async(meeting: Meeting) -> ResultFuture'
  parameters:
  - name: meeting
    isRequired: true
  return:
    description: A future that is fulfilled once joined the meeting.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.leave_meeting_async
  name: leave_meeting_async
  summary: 'Asynchronously leaves a meeting. After leaving a meeting, no transcribing
    or transcribed

    events will be sent to end users. End users need to join a meeting to get the
    events again.'
  signature: leave_meeting_async() -> ResultFuture
  return:
    description: A future that is fulfilled once left the meeting.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.recognize_once
  name: recognize_once
  summary: 'Performs recognition in a blocking (synchronous) mode. Returns after a
    single utterance is

    recognized. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. The task returns the recognition

    text as result. For long-running multi-utterance recognition, use

    <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_continuous_recognition_async>
    instead.'
  signature: recognize_once() -> SpeechRecognitionResult
  return:
    description: The result value of the synchronous recognition.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.recognize_once_async
  name: recognize_once_async
  summary: 'Performs recognition in a non-blocking (asynchronous) mode. This will
    recognize a single

    utterance. The end of a single utterance is determined by listening for silence
    at the end

    or until a maximum of 15 seconds of audio is processed. For long-running multi-utterance

    recognition, use <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_continuous_recognition_async>
    instead.'
  signature: recognize_once_async() -> ResultFuture
  return:
    description: A future containing the result value of the asynchronous recognition.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_continuous_recognition
  name: start_continuous_recognition
  summary: 'Synchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition()
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_continuous_recognition_async
  name: start_continuous_recognition_async
  summary: 'Asynchronously initiates continuous recognition operation. User has to
    connect to

    EventSignal to receive recognition results. Call

    <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_continuous_recognition_async>
    to stop the recognition.'
  signature: start_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_keyword_recognition
  name: start_keyword_recognition
  summary: 'Synchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition() to end
    the keyword initiated recognition.'
  signature: 'start_keyword_recognition(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_keyword_recognition_async
  name: start_keyword_recognition_async
  summary: 'Asynchronously configures the recognizer with the given keyword model.
    After calling this method, the recognizer is listening

    for the keyword to start the recognition. Call stop_keyword_recognition_async()
    to end the keyword initiated recognition.'
  signature: 'start_keyword_recognition_async(model: KeywordRecognitionModel)'
  parameters:
  - name: model
    description: the keyword recognition model that specifies the keyword to be recognized.
    isRequired: true
  return:
    description: A future that is fulfilled once recognition has been initialized.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.start_transcribing_async
  name: start_transcribing_async
  summary: Asynchronously starts meeting transcribing.
  signature: start_transcribing_async() -> ResultFuture
  return:
    description: A future that is fulfilled once meeting transcription is started.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_continuous_recognition
  name: stop_continuous_recognition
  summary: Synchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition()
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_continuous_recognition_async
  name: stop_continuous_recognition_async
  summary: Asynchronously terminates ongoing continuous recognition operation.
  signature: stop_continuous_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_keyword_recognition
  name: stop_keyword_recognition
  summary: Synchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition()
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_keyword_recognition_async
  name: stop_keyword_recognition_async
  summary: Asynchronously ends the keyword initiated recognition.
  signature: stop_keyword_recognition_async()
  return:
    description: A future that is fulfilled once recognition has been stopped.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.stop_transcribing_async
  name: stop_transcribing_async
  summary: Asynchronously stops meeting transcribing.
  signature: stop_transcribing_async() -> ResultFuture
  return:
    description: A future that is fulfilled once meeting transcription is stopped.
attributes:
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.authorization_token
  name: authorization_token
  summary: 'The authorization token that will be used for connecting to the service.


    > [!NOTE]

    > The caller needs to ensure that the authorization token is valid. Before the

    >

    > authorization token expires, the caller needs to refresh it by calling this
    setter with a

    >

    > new valid token. As configuration values are copied when creating a new recognizer,
    the

    >

    > new token value will not apply to recognizers that have already been created.
    For

    >

    > recognizers that have been created before, you need to set authorization token
    of the

    >

    > corresponding recognizer to refresh the token. Otherwise, the recognizers will
    encounter

    >

    > errors during transcription.

    >'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.canceled
  name: canceled
  summary: 'Signal for events containing canceled transcription results (indicating
    a transcription attempt

    that was canceled as a result or a direct cancellation request or, alternatively,
    a

    transport or protocol failure).


    Callbacks connected to this signal are called with a

    <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriptionCanceledEventArgs>,
    instance as the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.endpoint_id
  name: endpoint_id
  summary: The endpoint ID of a customized speech model that is used for recognition,
    or a custom voice model for speech synthesis.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.properties
  name: properties
  summary: A collection of properties and their values defined for this Participant.
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.recognized
  name: recognized
  summary: 'Signal for events containing final recognition results (indicating a successful

    recognition attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>,

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>
    or <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs> instance

    as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.recognizing
  name: recognizing
  summary: 'Signal for events containing intermediate recognition results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SpeechRecognitionEventArgs>,

    <xref:azure.cognitiveservices.speech.translation.TranslationRecognitionEventArgs>
    or <xref:azure.cognitiveservices.speech.intent.IntentRecognitionEventArgs> instance

    as the single argument, dependent on the type of recognizer.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.session_started
  name: session_started
  summary: 'Signal for events indicating the start of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.session_stopped
  name: session_stopped
  summary: 'Signal for events indicating the end of a recognition session (operation).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.SessionEventArgs>
    instance as

    the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.speech_end_detected
  name: speech_end_detected
  summary: 'Signal for events indicating the end of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.speech_start_detected
  name: speech_start_detected
  summary: 'Signal for events indicating the start of speech.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.RecognitionEventArgs>

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.transcribed
  name: transcribed
  summary: 'Signal for events containing final transcription results (indicating a
    successful

    transcription attempt).


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriptionEventArgs>,

    instance as the single argument.'
- uid: azure.cognitiveservices.speech.transcription.MeetingTranscriber.transcribing
  name: transcribing
  summary: 'Signal for events containing intermediate transcription results.


    Callbacks connected to this signal are called with a <xref:azure.cognitiveservices.speech.transcription.MeetingTranscriptionEventArgs>,

    instance as the single argument.'
