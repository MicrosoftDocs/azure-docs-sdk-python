### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.datalake.store.core.AzureDLFileSystem.access
  - azure.datalake.store.core.AzureDLFileSystem.cat
  - azure.datalake.store.core.AzureDLFileSystem.chmod
  - azure.datalake.store.core.AzureDLFileSystem.chown
  - azure.datalake.store.core.AzureDLFileSystem.concat
  - azure.datalake.store.core.AzureDLFileSystem.connect
  - azure.datalake.store.core.AzureDLFileSystem.cp
  - azure.datalake.store.core.AzureDLFileSystem.current
  - azure.datalake.store.core.AzureDLFileSystem.df
  - azure.datalake.store.core.AzureDLFileSystem.du
  - azure.datalake.store.core.AzureDLFileSystem.exists
  - azure.datalake.store.core.AzureDLFileSystem.get
  - azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  - azure.datalake.store.core.AzureDLFileSystem.glob
  - azure.datalake.store.core.AzureDLFileSystem.head
  - azure.datalake.store.core.AzureDLFileSystem.info
  - azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  - azure.datalake.store.core.AzureDLFileSystem.listdir
  - azure.datalake.store.core.AzureDLFileSystem.ls
  - azure.datalake.store.core.AzureDLFileSystem.merge
  - azure.datalake.store.core.AzureDLFileSystem.mkdir
  - azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  - azure.datalake.store.core.AzureDLFileSystem.mv
  - azure.datalake.store.core.AzureDLFileSystem.open
  - azure.datalake.store.core.AzureDLFileSystem.put
  - azure.datalake.store.core.AzureDLFileSystem.read_block
  - azure.datalake.store.core.AzureDLFileSystem.remove
  - azure.datalake.store.core.AzureDLFileSystem.remove_acl
  - azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  - azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  - azure.datalake.store.core.AzureDLFileSystem.rename
  - azure.datalake.store.core.AzureDLFileSystem.rm
  - azure.datalake.store.core.AzureDLFileSystem.rmdir
  - azure.datalake.store.core.AzureDLFileSystem.set_acl
  - azure.datalake.store.core.AzureDLFileSystem.set_expiry
  - azure.datalake.store.core.AzureDLFileSystem.stat
  - azure.datalake.store.core.AzureDLFileSystem.tail
  - azure.datalake.store.core.AzureDLFileSystem.touch
  - azure.datalake.store.core.AzureDLFileSystem.unlink
  - azure.datalake.store.core.AzureDLFileSystem.walk
  class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.datalake.store.core
  name: AzureDLFileSystem
  source:
    id: AzureDLFileSystem
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 42
  summary: Access Azure DataLake Store as if it were a file-system
  syntax:
    content: AzureDLFileSystem(token=None, per_call_timeout_seconds=60, **kwargs)
    parameters:
    - description: Store name to connect to.
      id: store_name
      type:
      - str ("")
    - description: 'When setting up a new connection, this contains the authorization

        credentials (see *lib.auth()*).'
      id: token
      type:
      - credentials object
    - description: 'Domain to send REST requests to. The end-point URL is constructed

        using this and the store_name. If None, use default.'
      id: url_suffix
      type:
      - str (None)
    - description: 'The API version to target with requests. Changing this value will

        change the behavior of the requests, and can cause unexpected behavior or

        breaking changes. Changes to this value should be undergone with caution.'
      id: api_version
      type:
      - str (2018-09-01)
    - description: This is the timeout for each requests library call.
      id: per_call_timeout_seconds
      type:
      - float(60)
    - description: 'See `lib.auth()`; full list: tenant_id, username, password, client_id,

        client_secret, resource'
      id: kwargs
      type:
      - optional key/values
  type: class
  uid: azure.datalake.store.core.AzureDLFileSystem
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.access
  langs:
  - python
  module: azure.datalake.store.core
  name: access(path, invalidate_cache=True)
  namewithoutparameters: access
  source:
    id: access
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 602
  summary: Does such a file/directory exist?
  syntax:
    content: access(path, invalidate_cache=True)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'True'
      description: Whether to invalidate cache
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - 'True'
      - false depending on whether the path exists.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.access
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.cat
  langs:
  - python
  module: azure.datalake.store.core
  name: cat(path)
  namewithoutparameters: cat
  source:
    id: cat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 623
  summary: Return contents of file
  syntax:
    content: cat(path)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    return:
      type:
      - Contents of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.cat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.chmod
  langs:
  - python
  module: azure.datalake.store.core
  name: chmod(path, mod)
  namewithoutparameters: chmod
  source:
    id: chmod
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 377
  summary: 'Change access mode of path


    Note this is not recursive.'
  syntax:
    content: chmod(path, mod)
    parameters:
    - description: Location to change
      id: path
      isRequired: true
      type:
      - str
    - description: 'Octal representation of access, e.g., "0777" for public read/write.

        See [docs]([http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Permission](http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Permission))'
      id: mod
      isRequired: true
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.chmod
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.chown
  langs:
  - python
  module: azure.datalake.store.core
  name: chown(path, owner=None, group=None)
  namewithoutparameters: chown
  source:
    id: chown
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 576
  summary: 'Change owner and/or owning group


    Note this is not recursive.'
  syntax:
    content: chown(path, owner=None, group=None)
    parameters:
    - description: Location to change
      id: path
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: UUID of owning entity
      id: owner
      type:
      - str
    - defaultValue: None
      description: UUID of group
      id: group
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.chown
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.concat
  langs:
  - python
  module: azure.datalake.store.core
  name: concat(outfile, filelist, delete_source=False)
  namewithoutparameters: concat
  source:
    id: concat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 787
  summary: Concatenate a list of files into one new file
  syntax:
    content: concat(outfile, filelist, delete_source=False)
    parameters:
    - description: 'The file which will be concatenated to. If it already exists,

        the extra pieces will be appended.'
      id: outfile
      isRequired: true
      type:
      - path
    - description: Existing adl files to concatenate, in order
      id: filelist
      isRequired: true
      type:
      - list of paths
    - defaultValue: 'False'
      description: 'If True, assume that the paths to concatenate exist alone in a

        directory, and delete that whole directory when done.'
      id: delete_source
      type:
      - bool (False)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.concat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.connect
  langs:
  - python
  module: azure.datalake.store.core
  name: connect()
  namewithoutparameters: connect
  source:
    id: connect
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 86
  summary: Establish connection object.
  syntax:
    content: connect()
    parameters: []
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.connect
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.cp
  langs:
  - python
  module: azure.datalake.store.core
  name: cp(path1, path2)
  namewithoutparameters: cp
  source:
    id: cp
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 821
  summary: Not implemented. Copy file between locations on ADL
  syntax:
    content: cp(path1, path2)
    parameters:
    - id: path1
      isRequired: true
    - id: path2
      isRequired: true
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.cp
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.current
  langs:
  - python
  module: azure.datalake.store.core
  name: current()
  namewithoutparameters: current
  source:
    id: current
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 77
  summary: Return the most recently created AzureDLFileSystem
  syntax:
    content: current()
    parameters:
    - id: cls
      isRequired: true
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.current
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.df
  langs:
  - python
  module: azure.datalake.store.core
  name: df(path)
  namewithoutparameters: df
  source:
    id: df
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 350
  summary: Resource summary of path
  syntax:
    content: df(path)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.df
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.du
  langs:
  - python
  module: azure.datalake.store.core
  name: du(path, total=False, deep=False, invalidate_cache=True)
  namewithoutparameters: du
  source:
    id: du
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 321
  summary: Bytes in keys at path
  syntax:
    content: du(path, total=False, deep=False, invalidate_cache=True)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: Return the sum on list
      id: total
      type:
      - bool
    - defaultValue: 'False'
      description: Recursively enumerate or just use files under current dir
      id: deep
      type:
      - bool
    - defaultValue: 'True'
      description: Whether to invalidate cache
      id: invalidate_cache
      type:
      - bool
    return:
      description: '**List of dict of name**'
      type:
      - size pairs
      - total size.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.du
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.exists
  langs:
  - python
  module: azure.datalake.store.core
  name: exists(path, invalidate_cache=True)
  namewithoutparameters: exists
  source:
    id: exists
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 602
  summary: Does such a file/directory exist?
  syntax:
    content: exists(path, invalidate_cache=True)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'True'
      description: Whether to invalidate cache
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - 'True'
      - false depending on whether the path exists.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.exists
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.get
  langs:
  - python
  module: azure.datalake.store.core
  name: get(path, filename)
  namewithoutparameters: get
  source:
    id: get
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 679
  summary: Stream data from file at path to local filename
  syntax:
    content: get(path, filename)
    parameters:
    - description: ADL Path to read
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - description: Local file path to write to
      id: filename
      isRequired: true
      type:
      - str
      - Path
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.get
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  langs:
  - python
  module: azure.datalake.store.core
  name: get_acl_status(path)
  namewithoutparameters: get_acl_status
  source:
    id: get_acl_status
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 536
  summary: Gets Access Control List (ACL) entries for the specified file or directory.
  syntax:
    content: get_acl_status(path)
    parameters:
    - description: Location to get the ACL.
      id: path
      isRequired: true
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.glob
  langs:
  - python
  module: azure.datalake.store.core
  name: glob(path, details=False, invalidate_cache=True)
  namewithoutparameters: glob
  source:
    id: glob
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 295
  summary: Find files (not directories) by glob-matching.
  syntax:
    content: glob(path, details=False, invalidate_cache=True)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: Whether to include file details
      id: details
      type:
      - bool
    - defaultValue: 'True'
      description: Whether to invalidate cache
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - List of files
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.glob
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.head
  langs:
  - python
  module: azure.datalake.store.core
  name: head(path, size=1024)
  namewithoutparameters: head
  source:
    id: head
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 661
  summary: Return first bytes of file
  syntax:
    content: head(path, size=1024)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: '1024'
      description: How many bytes to return
      id: size
      type:
      - int
    return:
      type:
      - First(size) bytes of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.head
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.info
  langs:
  - python
  module: azure.datalake.store.core
  name: info(path, invalidate_cache=True, expected_error_code=None)
  namewithoutparameters: info
  source:
    id: info
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 182
  summary: File information for path
  syntax:
    content: info(path, invalidate_cache=True, expected_error_code=None)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'True'
      description: Whether to invalidate cache or not
      id: invalidate_cache
      type:
      - bool
    - defaultValue: None
      description: Optionally indicates a specific, expected error code, if any.
      id: expected_error_code
      type:
      - int
    return:
      type:
      - File information
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.info
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  langs:
  - python
  module: azure.datalake.store.core
  name: invalidate_cache(path=None)
  namewithoutparameters: invalidate_cache
  source:
    id: invalidate_cache
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 852
  summary: Remove entry from object file-cache
  syntax:
    content: invalidate_cache(path=None)
    parameters:
    - defaultValue: None
      description: Remove the path from object file-cache
      id: path
      type:
      - str
      - AzureDLPath
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.listdir
  langs:
  - python
  module: azure.datalake.store.core
  name: listdir(path='', detail=False, invalidate_cache=True)
  namewithoutparameters: listdir
  source:
    id: listdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 150
  summary: List all elements under directory specified with path
  syntax:
    content: listdir(path='', detail=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      description: Path to query
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: Detailed info or not.
      id: detail
      type:
      - bool
    - defaultValue: 'True'
      description: Whether to invalidate cache or not
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - List of elements under directory specified with path
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.listdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.ls
  langs:
  - python
  module: azure.datalake.store.core
  name: ls(path='', detail=False, invalidate_cache=True)
  namewithoutparameters: ls
  source:
    id: ls
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 150
  summary: List all elements under directory specified with path
  syntax:
    content: ls(path='', detail=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      description: Path to query
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: Detailed info or not.
      id: detail
      type:
      - bool
    - defaultValue: 'True'
      description: Whether to invalidate cache or not
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - List of elements under directory specified with path
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.ls
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.merge
  langs:
  - python
  module: azure.datalake.store.core
  name: merge(outfile, filelist, delete_source=False)
  namewithoutparameters: merge
  source:
    id: merge
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 787
  summary: Concatenate a list of files into one new file
  syntax:
    content: merge(outfile, filelist, delete_source=False)
    parameters:
    - description: 'The file which will be concatenated to. If it already exists,

        the extra pieces will be appended.'
      id: outfile
      isRequired: true
      type:
      - path
    - description: Existing adl files to concatenate, in order
      id: filelist
      isRequired: true
      type:
      - list of paths
    - defaultValue: 'False'
      description: 'If True, assume that the paths to concatenate exist alone in a

        directory, and delete that whole directory when done.'
      id: delete_source
      type:
      - bool (False)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.merge
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.mkdir
  langs:
  - python
  module: azure.datalake.store.core
  name: mkdir(path)
  namewithoutparameters: mkdir
  source:
    id: mkdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 727
  summary: Make new directory
  syntax:
    content: mkdir(path)
    parameters:
    - description: Path to create directory
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.mkdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  langs:
  - python
  module: azure.datalake.store.core
  name: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  namewithoutparameters: modify_acl_entries
  source:
    id: modify_acl_entries
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 487
  summary: 'Modify existing Access Control List (ACL) entries on a file or folder.

    If the entry does not exist it is added, otherwise it is updated based on the
    spec passed in.

    No entries are removed by this process (unlike set_acl).


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to set the ACL entries on.
      id: path
      isRequired: true
      type:
      - str
    - description: 'The ACL specification to use in modifying the ACL at the path
        in the format

        ''[default:]user|group|other:[entity id or UPN]:r|-w|-x|-,[default:]user|group|other:[entity
        id or UPN]:r|-w|-x|-,...'''
      id: acl_spec
      isRequired: true
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to modify ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.mv
  langs:
  - python
  module: azure.datalake.store.core
  name: mv(path1, path2)
  namewithoutparameters: mv
  source:
    id: mv
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 765
  summary: Move file between locations on ADL
  syntax:
    content: mv(path1, path2)
    parameters:
    - description: Source Path
      id: path1
      isRequired: true
    - description: Destination path
      id: path2
      isRequired: true
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.mv
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.open
  langs:
  - python
  module: azure.datalake.store.core
  name: open(path, mode='rb', blocksize=33554432, delimiter=None)
  namewithoutparameters: open
  source:
    id: open
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 97
  summary: Open a file for reading or writing
  syntax:
    content: open(path, mode='rb', blocksize=33554432, delimiter=None)
    parameters:
    - description: Path of file on ADL
      id: path
      isRequired: true
      type:
      - string
    - defaultValue: rb
      description: One of 'rb', 'ab' or 'wb'
      id: mode
      type:
      - string
    - defaultValue: '33554432'
      description: Size of data-node blocks if reading
      id: blocksize
      type:
      - int
    - defaultValue: None
      description: For writing delimiter-ended blocks
      id: delimiter
      type:
      - byte(s)
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.open
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.put
  langs:
  - python
  module: azure.datalake.store.core
  name: put(filename, path, delimiter=None)
  namewithoutparameters: put
  source:
    id: put
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 702
  summary: Stream data from local filename to file at path
  syntax:
    content: put(filename, path, delimiter=None)
    parameters:
    - description: Local file path to read from
      id: filename
      isRequired: true
      type:
      - str
      - Path
    - description: ADL Path to write to
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: None
      description: Optional delimeter for delimiter-ended blocks
      id: delimiter
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.put
- class: azure.datalake.store.core.AzureDLFileSystem
  example:
  - '

    ```


    >>> adl.read_block(''data/file.csv'', 0, 13)  # doctest: +SKIP

    b''Alice, 100\nBo''

    >>> adl.read_block(''data/file.csv'', 0, 13, delimiter=b''\n'')  # doctest: +SKIP

    b''Alice, 100\nBob, 200\n''

    ```


    Use `length=None` to read to the end of the file.

    >>> adl.read_block(''data/file.csv'', 0, None, delimiter=b''n'')  # doctest: +SKIP

    b''Alice, 100nBob, 200nCharlie, 300''

    '
  fullName: azure.datalake.store.core.AzureDLFileSystem.read_block
  langs:
  - python
  module: azure.datalake.store.core
  name: read_block(fn, offset, length, delimiter=None)
  namewithoutparameters: read_block
  seealsoContent: '  <xref:distributed.utils.read_block>

    '
  source:
    id: read_block
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 889
  summary: 'Read a block of bytes from an ADL file


    Starting at `offset` of the file, read `length` bytes.  If

    `delimiter` is set then we ensure that the read starts and stops at

    delimiter boundaries that follow the locations `offset` and `offset

    + length`.  If `offset` is zero then we start at zero.  The

    bytestring returned WILL include the end delimiter string.


    If offset+length is beyond the eof, reads to eof.'
  syntax:
    content: read_block(fn, offset, length, delimiter=None)
    parameters:
    - description: Path to filename on ADL
      id: fn
      isRequired: true
      type:
      - string
    - description: Byte offset to start read
      id: offset
      isRequired: true
      type:
      - int
    - description: Number of bytes to read
      id: length
      isRequired: true
      type:
      - int
    - defaultValue: None
      description: Ensure reading starts and stops at delimiter bytestring
      id: delimiter
      type:
      - bytes (optional)
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.read_block
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove
  langs:
  - python
  module: azure.datalake.store.core
  name: remove(path, recursive=False)
  namewithoutparameters: remove
  source:
    id: remove
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 826
  summary: Remove a file or directory
  syntax:
    content: remove(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_acl(path)
  namewithoutparameters: remove_acl
  source:
    id: remove_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 547
  summary: 'Remove the entire, non default, ACL from the file or folder, including
    unnamed entries.

    Default entries cannot be removed this way, please use remove_default_acl for
    that.


    Note: this is not recursive, and applies only to the file or folder specified.'
  syntax:
    content: remove_acl(path)
    parameters:
    - description: Location to remove the ACL.
      id: path
      isRequired: true
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  namewithoutparameters: remove_acl_entries
  source:
    id: remove_acl_entries
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 511
  summary: 'Remove existing, named, Access Control List (ACL) entries on a file or
    folder.

    If the entry does not exist already it is ignored.

    Default entries cannot be removed this way, please use remove_default_acl for
    that.

    Unnamed entries cannot be removed in this way, please use remove_acl for that.


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to remove the ACL entries.
      id: path
      isRequired: true
      type:
      - str
    - description: 'The ACL specification to remove from the ACL at the path in the
        format (note that the permission portion is missing)

        ''[default:]user|group|other:[entity id or UPN],[default:]user|group|other:[entity
        id or UPN],...'''
      id: acl_spec
      isRequired: true
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to remove ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_default_acl(path)
  namewithoutparameters: remove_default_acl
  source:
    id: remove_default_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 561
  summary: 'Remove the entire default ACL from the folder.

    Default entries do not exist on files, if a file

    is specified, this operation does nothing.


    Note: this is not recursive, and applies only to the folder specified.'
  syntax:
    content: remove_default_acl(path)
    parameters:
    - description: Location to set the ACL on.
      id: path
      isRequired: true
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rename
  langs:
  - python
  module: azure.datalake.store.core
  name: rename(path1, path2)
  namewithoutparameters: rename
  source:
    id: rename
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 765
  summary: Move file between locations on ADL
  syntax:
    content: rename(path1, path2)
    parameters:
    - description: Source Path
      id: path1
      isRequired: true
    - description: Destination path
      id: path2
      isRequired: true
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rename
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rm
  langs:
  - python
  module: azure.datalake.store.core
  name: rm(path, recursive=False)
  namewithoutparameters: rm
  source:
    id: rm
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 826
  summary: Remove a file or directory
  syntax:
    content: rm(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rm
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rmdir
  langs:
  - python
  module: azure.datalake.store.core
  name: rmdir(path)
  namewithoutparameters: rmdir
  source:
    id: rmdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 745
  summary: Remove empty directory
  syntax:
    content: rmdir(path)
    parameters:
    - description: Directory  path to remove
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rmdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.set_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
  namewithoutparameters: set_acl
  source:
    id: set_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 465
  summary: 'Set the Access Control List (ACL) for a file or folder.


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to set the ACL on.
      id: path
      isRequired: true
      type:
      - str
    - description: 'The ACL specification to set on the path in the format

        ''[default:]user|group|other:[entity id or UPN]:r|-w|-x|-,[default:]user|group|other:[entity
        id or UPN]:r|-w|-x|-,...'''
      id: acl_spec
      isRequired: true
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to set ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.set_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.set_expiry
  langs:
  - python
  module: azure.datalake.store.core
  name: set_expiry(path, expiry_option, expire_time=None)
  namewithoutparameters: set_expiry
  source:
    id: set_expiry
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 394
  summary: 'Set or remove the expiration time on the specified file.

    This operation can only be executed against files.


    Note: Folders are not supported.'
  syntax:
    content: set_expiry(path, expiry_option, expire_time=None)
    parameters:
    - description: File path to set or remove expiration time
      id: path
      isRequired: true
      type:
      - str
    - description: The time that the file will expire, corresponding to the expiry_option
        that was set
      id: expire_time
      isRequired: true
      type:
      - int
    - defaultValue: None
      description: "Indicates the type of expiration to use for the file:\n   1. NeverExpire:\
        \ ExpireTime is ignored. \n\n   2. RelativeToNow: ExpireTime is an integer\
        \ in milliseconds representing the expiration date relative to when file expiration\
        \ is updated. \n\n   3. RelativeToCreationDate: ExpireTime is an integer in\
        \ milliseconds representing the expiration date relative to file creation.\
        \ \n\n   4. Absolute: ExpireTime is an integer in milliseconds, as a Unix\
        \ timestamp relative to 1/1/1970 00:00:00."
      id: expiry_option
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.set_expiry
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.stat
  langs:
  - python
  module: azure.datalake.store.core
  name: stat(path, invalidate_cache=True, expected_error_code=None)
  namewithoutparameters: stat
  source:
    id: stat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 182
  summary: File information for path
  syntax:
    content: stat(path, invalidate_cache=True, expected_error_code=None)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'True'
      description: Whether to invalidate cache or not
      id: invalidate_cache
      type:
      - bool
    - defaultValue: None
      description: Optionally indicates a specific, expected error code, if any.
      id: expected_error_code
      type:
      - int
    return:
      type:
      - File information
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.stat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.tail
  langs:
  - python
  module: azure.datalake.store.core
  name: tail(path, size=1024)
  namewithoutparameters: tail
  source:
    id: tail
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 639
  summary: Return last bytes of file
  syntax:
    content: tail(path, size=1024)
    parameters:
    - description: Path to query
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: '1024'
      description: How many bytes to return
      id: size
      type:
      - int
    return:
      type:
      - Last(size) bytes of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.tail
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.touch
  langs:
  - python
  module: azure.datalake.store.core
  name: touch(path)
  namewithoutparameters: touch
  source:
    id: touch
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 873
  summary: Create empty file
  syntax:
    content: touch(path)
    parameters:
    - description: Path of file to create
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.touch
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.unlink
  langs:
  - python
  module: azure.datalake.store.core
  name: unlink(path, recursive=False)
  namewithoutparameters: unlink
  source:
    id: unlink
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 826
  summary: Remove a file or directory
  syntax:
    content: unlink(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      isRequired: true
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.unlink
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.walk
  langs:
  - python
  module: azure.datalake.store.core
  name: walk(path='', details=False, invalidate_cache=True)
  namewithoutparameters: walk
  source:
    id: walk
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 276
  summary: Get all files below given path
  syntax:
    content: walk(path='', details=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      description: Path to query
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: Whether to include file details
      id: details
      type:
      - bool
    - defaultValue: 'True'
      description: Whether to invalidate cache
      id: invalidate_cache
      type:
      - bool
    return:
      type:
      - List of files
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.walk
references:
- fullName: azure.datalake.store.core.AzureDLFileSystem.access
  isExternal: false
  name: access(path, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.access
- fullName: azure.datalake.store.core.AzureDLFileSystem.cat
  isExternal: false
  name: cat(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.cat
- fullName: azure.datalake.store.core.AzureDLFileSystem.chmod
  isExternal: false
  name: chmod(path, mod)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.chmod
- fullName: azure.datalake.store.core.AzureDLFileSystem.chown
  isExternal: false
  name: chown(path, owner=None, group=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.chown
- fullName: azure.datalake.store.core.AzureDLFileSystem.concat
  isExternal: false
  name: concat(outfile, filelist, delete_source=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.concat
- fullName: azure.datalake.store.core.AzureDLFileSystem.connect
  isExternal: false
  name: connect()
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.connect
- fullName: azure.datalake.store.core.AzureDLFileSystem.cp
  isExternal: false
  name: cp(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.cp
- fullName: azure.datalake.store.core.AzureDLFileSystem.current
  isExternal: false
  name: current()
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.current
- fullName: azure.datalake.store.core.AzureDLFileSystem.df
  isExternal: false
  name: df(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.df
- fullName: azure.datalake.store.core.AzureDLFileSystem.du
  isExternal: false
  name: du(path, total=False, deep=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.du
- fullName: azure.datalake.store.core.AzureDLFileSystem.exists
  isExternal: false
  name: exists(path, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.exists
- fullName: azure.datalake.store.core.AzureDLFileSystem.get
  isExternal: false
  name: get(path, filename)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.get
- fullName: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  isExternal: false
  name: get_acl_status(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
- fullName: azure.datalake.store.core.AzureDLFileSystem.glob
  isExternal: false
  name: glob(path, details=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.glob
- fullName: azure.datalake.store.core.AzureDLFileSystem.head
  isExternal: false
  name: head(path, size=1024)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.head
- fullName: azure.datalake.store.core.AzureDLFileSystem.info
  isExternal: false
  name: info(path, invalidate_cache=True, expected_error_code=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.info
- fullName: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  isExternal: false
  name: invalidate_cache(path=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
- fullName: azure.datalake.store.core.AzureDLFileSystem.listdir
  isExternal: false
  name: listdir(path='', detail=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.listdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.ls
  isExternal: false
  name: ls(path='', detail=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.ls
- fullName: azure.datalake.store.core.AzureDLFileSystem.merge
  isExternal: false
  name: merge(outfile, filelist, delete_source=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.merge
- fullName: azure.datalake.store.core.AzureDLFileSystem.mkdir
  isExternal: false
  name: mkdir(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.mkdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  isExternal: false
  name: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
- fullName: azure.datalake.store.core.AzureDLFileSystem.mv
  isExternal: false
  name: mv(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.mv
- fullName: azure.datalake.store.core.AzureDLFileSystem.open
  isExternal: false
  name: open(path, mode='rb', blocksize=33554432, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.open
- fullName: azure.datalake.store.core.AzureDLFileSystem.put
  isExternal: false
  name: put(filename, path, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.put
- fullName: azure.datalake.store.core.AzureDLFileSystem.read_block
  isExternal: false
  name: read_block(fn, offset, length, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.read_block
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove
  isExternal: false
  name: remove(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl
  isExternal: false
  name: remove_acl(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  isExternal: false
  name: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  isExternal: false
  name: remove_default_acl(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.rename
  isExternal: false
  name: rename(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rename
- fullName: azure.datalake.store.core.AzureDLFileSystem.rm
  isExternal: false
  name: rm(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rm
- fullName: azure.datalake.store.core.AzureDLFileSystem.rmdir
  isExternal: false
  name: rmdir(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rmdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.set_acl
  isExternal: false
  name: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.set_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.set_expiry
  isExternal: false
  name: set_expiry(path, expiry_option, expire_time=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.set_expiry
- fullName: azure.datalake.store.core.AzureDLFileSystem.stat
  isExternal: false
  name: stat(path, invalidate_cache=True, expected_error_code=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.stat
- fullName: azure.datalake.store.core.AzureDLFileSystem.tail
  isExternal: false
  name: tail(path, size=1024)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.tail
- fullName: azure.datalake.store.core.AzureDLFileSystem.touch
  isExternal: false
  name: touch(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.touch
- fullName: azure.datalake.store.core.AzureDLFileSystem.unlink
  isExternal: false
  name: unlink(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.unlink
- fullName: azure.datalake.store.core.AzureDLFileSystem.walk
  isExternal: false
  name: walk(path='', details=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.walk
- fullName: str ("")
  name: str ("")
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: '""'
    name: '""'
    uid: '""'
  - fullName: )
    name: )
  uid: str ("")
- fullName: str (None)
  name: str (None)
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: None
    name: None
    uid: None
  - fullName: )
    name: )
  uid: str (None)
- fullName: str (2018-09-01)
  name: str (2018-09-01)
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: '2018-09-01'
    name: '2018-09-01'
    uid: '2018-09-01'
  - fullName: )
    name: )
  uid: str (2018-09-01)
- fullName: float(60)
  name: float(60)
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: (
    name: (
  - fullName: '60'
    name: '60'
    uid: '60'
  - fullName: )
    name: )
  uid: float(60)
- fullName: bool (False)
  name: bool (False)
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: (
    name: (
  - fullName: 'False'
    name: 'False'
    uid: 'False'
  - fullName: )
    name: )
  uid: bool (False)
- fullName: First(size) bytes of file
  name: First(size) bytes of file
  spec.python:
  - fullName: First
    name: First
    uid: First
  - fullName: (
    name: (
  - fullName: size
    name: size
    uid: size
  - fullName: )
    name: )
  - fullName: ' bytes of file'
    name: ' bytes of file'
    uid: ' bytes of file'
  uid: First(size) bytes of file
- fullName: byte(s)
  name: byte(s)
  spec.python:
  - fullName: byte
    name: byte
    uid: byte
  - fullName: (
    name: (
  - fullName: s
    name: s
    uid: s
  - fullName: )
    name: )
  uid: byte(s)
- fullName: bytes (optional)
  name: bytes (optional)
  spec.python:
  - fullName: 'bytes '
    name: 'bytes '
    uid: 'bytes '
  - fullName: (
    name: (
  - fullName: optional
    name: optional
    uid: optional
  - fullName: )
    name: )
  uid: bytes (optional)
- fullName: bool (True)
  name: bool (True)
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: (
    name: (
  - fullName: 'True'
    name: 'True'
    uid: 'True'
  - fullName: )
    name: )
  uid: bool (True)
- fullName: Last(size) bytes of file
  name: Last(size) bytes of file
  spec.python:
  - fullName: Last
    name: Last
    uid: Last
  - fullName: (
    name: (
  - fullName: size
    name: size
    uid: size
  - fullName: )
    name: )
  - fullName: ' bytes of file'
    name: ' bytes of file'
    uid: ' bytes of file'
  uid: Last(size) bytes of file
