### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.datalake.store.core.AzureDLFileSystem.access
  - azure.datalake.store.core.AzureDLFileSystem.cat
  - azure.datalake.store.core.AzureDLFileSystem.chmod
  - azure.datalake.store.core.AzureDLFileSystem.chown
  - azure.datalake.store.core.AzureDLFileSystem.concat
  - azure.datalake.store.core.AzureDLFileSystem.connect
  - azure.datalake.store.core.AzureDLFileSystem.cp
  - azure.datalake.store.core.AzureDLFileSystem.current
  - azure.datalake.store.core.AzureDLFileSystem.df
  - azure.datalake.store.core.AzureDLFileSystem.du
  - azure.datalake.store.core.AzureDLFileSystem.exists
  - azure.datalake.store.core.AzureDLFileSystem.get
  - azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  - azure.datalake.store.core.AzureDLFileSystem.glob
  - azure.datalake.store.core.AzureDLFileSystem.head
  - azure.datalake.store.core.AzureDLFileSystem.info
  - azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  - azure.datalake.store.core.AzureDLFileSystem.listdir
  - azure.datalake.store.core.AzureDLFileSystem.ls
  - azure.datalake.store.core.AzureDLFileSystem.merge
  - azure.datalake.store.core.AzureDLFileSystem.mkdir
  - azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  - azure.datalake.store.core.AzureDLFileSystem.mv
  - azure.datalake.store.core.AzureDLFileSystem.open
  - azure.datalake.store.core.AzureDLFileSystem.put
  - azure.datalake.store.core.AzureDLFileSystem.read_block
  - azure.datalake.store.core.AzureDLFileSystem.remove
  - azure.datalake.store.core.AzureDLFileSystem.remove_acl
  - azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  - azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  - azure.datalake.store.core.AzureDLFileSystem.rename
  - azure.datalake.store.core.AzureDLFileSystem.rm
  - azure.datalake.store.core.AzureDLFileSystem.rmdir
  - azure.datalake.store.core.AzureDLFileSystem.set_acl
  - azure.datalake.store.core.AzureDLFileSystem.set_expiry
  - azure.datalake.store.core.AzureDLFileSystem.stat
  - azure.datalake.store.core.AzureDLFileSystem.tail
  - azure.datalake.store.core.AzureDLFileSystem.touch
  - azure.datalake.store.core.AzureDLFileSystem.unlink
  - azure.datalake.store.core.AzureDLFileSystem.walk
  class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.datalake.store.core
  name: AzureDLFileSystem
  source:
    id: AzureDLFileSystem
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 43
  summary: Access Azure DataLake Store as if it were a file-system
  syntax:
    content: AzureDLFileSystem(token=None, per_call_timeout_seconds=60, **kwargs)
    parameters:
    - description: Store name to connect to
      id: store_name
      type:
      - str ("")
    - description: 'When setting up a new connection, this contains the authorization

        credentials (see *lib.auth()*).'
      id: token
      type:
      - credentials object
    - description: 'Domain to send REST requests to. The end-point URL is constructed

        using this and the store_name. If None, use default.'
      id: url_suffix
      type:
      - str (None)
    - description: 'The API version to target with requests. Changing this value will

        change the behavior of the requests, and can cause unexpected behavior or

        breaking changes. Changes to this value should be undergone with caution.'
      id: api_version
      type:
      - str (2018-09-01)
    - description: This is the timeout for each requests library call.
      id: per_call_timeout_seconds
      type:
      - float(60)
    - description: 'See `lib.auth()`; full list: tenant_id, username, password, client_id,

        client_secret, resource'
      id: kwargs
      type:
      - optional key/values
  type: class
  uid: azure.datalake.store.core.AzureDLFileSystem
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.access
  langs:
  - python
  module: azure.datalake.store.core
  name: access(path, invalidate_cache=True)
  source:
    id: access
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 587
  summary: 'Does such a file/directory exist?

    :param path: Path to query

    :type path: str or AzureDLPath

    :param invalidate_cache: Whether to invalidate cache

    :type invalidate_cache: bool'
  syntax:
    content: access(path, invalidate_cache=True)
    parameters:
    - id: path
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - 'True'
      - false depending on whether the path exists.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.access
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.cat
  langs:
  - python
  module: azure.datalake.store.core
  name: cat(path)
  source:
    id: cat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 606
  summary: 'Return contents of file

    :param path: Path to query

    :type path: str or AzureDLPath'
  syntax:
    content: cat(path)
    parameters:
    - id: path
    return:
      type:
      - Contents of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.cat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.chmod
  langs:
  - python
  module: azure.datalake.store.core
  name: chmod(path, mod)
  source:
    id: chmod
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 368
  summary: 'Change access mode of path


    Note this is not recursive.'
  syntax:
    content: chmod(path, mod)
    parameters:
    - description: Location to change
      id: path
      type:
      - str
    - description: 'Octal representation of access, e.g., "0777" for public read/write.

        See [docs]([http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Permission](http://hadoop.apache.org/docs/r2.4.1/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Permission))'
      id: mod
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.chmod
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.chown
  langs:
  - python
  module: azure.datalake.store.core
  name: chown(path, owner=None, group=None)
  source:
    id: chown
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 561
  summary: 'Change owner and/or owning group


    Note this is not recursive.'
  syntax:
    content: chown(path, owner=None, group=None)
    parameters:
    - description: Location to change
      id: path
      type:
      - str
    - defaultValue: None
      description: UUID of owning entity
      id: owner
      type:
      - str
    - defaultValue: None
      description: UUID of group
      id: group
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.chown
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.concat
  langs:
  - python
  module: azure.datalake.store.core
  name: concat(outfile, filelist, delete_source=False)
  source:
    id: concat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 757
  summary: Concatenate a list of files into one new file
  syntax:
    content: concat(outfile, filelist, delete_source=False)
    parameters:
    - description: 'The file which will be concatenated to. If it already exists,

        the extra pieces will be appended.'
      id: outfile
      type:
      - path
    - description: Existing adl files to concatenate, in order
      id: filelist
      type:
      - list of paths
    - defaultValue: 'False'
      description: 'If True, assume that the paths to concatenate exist alone in a

        directory, and delete that whole directory when done.'
      id: delete_source
      type:
      - bool (False)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.concat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.connect
  langs:
  - python
  module: azure.datalake.store.core
  name: connect()
  source:
    id: connect
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 87
  summary: Establish connection object.
  syntax:
    content: connect()
    parameters: []
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.connect
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.cp
  langs:
  - python
  module: azure.datalake.store.core
  name: cp(path1, path2)
  source:
    id: cp
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 791
  summary: Not implemented. Copy file between locations on ADL
  syntax:
    content: cp(path1, path2)
    parameters:
    - id: path1
    - id: path2
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.cp
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.current
  langs:
  - python
  module: azure.datalake.store.core
  name: current()
  source:
    id: current
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 78
  summary: Return the most recently created AzureDLFileSystem
  syntax:
    content: current()
    parameters:
    - id: cls
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.current
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.df
  langs:
  - python
  module: azure.datalake.store.core
  name: df(path)
  source:
    id: df
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 342
  summary: "Resource summary of path\n   Parameters\n\n\n\npath: str\n   Path to query"
  syntax:
    content: df(path)
    parameters:
    - id: path
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.df
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.du
  langs:
  - python
  module: azure.datalake.store.core
  name: du(path, total=False, deep=False, invalidate_cache=True)
  source:
    id: du
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 314
  summary: 'Bytes in keys at path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param total: Return the sum on list

    :type total: bool

    :param deep: Recursively enumerate or just use files under current dir

    :type deep: bool

    :param invalidate_cache: Whether to invalidate cache

    :type invalidate_cache: bool'
  syntax:
    content: du(path, total=False, deep=False, invalidate_cache=True)
    parameters:
    - id: path
    - defaultValue: 'False'
      id: total
    - defaultValue: 'False'
      id: deep
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      description: '**List of dict of name**'
      type:
      - size pairs
      - total size.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.du
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.exists
  langs:
  - python
  module: azure.datalake.store.core
  name: exists(path, invalidate_cache=True)
  source:
    id: exists
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 587
  summary: 'Does such a file/directory exist?

    :param path: Path to query

    :type path: str or AzureDLPath

    :param invalidate_cache: Whether to invalidate cache

    :type invalidate_cache: bool'
  syntax:
    content: exists(path, invalidate_cache=True)
    parameters:
    - id: path
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - 'True'
      - false depending on whether the path exists.
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.exists
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.get
  langs:
  - python
  module: azure.datalake.store.core
  name: get(path, filename)
  source:
    id: get
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 658
  summary: 'Stream data from file at path to local filename

    :param path: ADL Path to read

    :type path: str or AzureDLPath

    :param filename: Local file path to write to

    :type filename: str or Path'
  syntax:
    content: get(path, filename)
    parameters:
    - id: path
    - id: filename
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.get
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  langs:
  - python
  module: azure.datalake.store.core
  name: get_acl_status(path)
  source:
    id: get_acl_status
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 521
  summary: Gets Access Control List (ACL) entries for the specified file or directory.
  syntax:
    content: get_acl_status(path)
    parameters:
    - description: Location to get the ACL.
      id: path
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.glob
  langs:
  - python
  module: azure.datalake.store.core
  name: glob(path, details=False, invalidate_cache=True)
  source:
    id: glob
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 289
  summary: 'Find files (not directories) by glob-matching.

    :param path: Path to query

    :type path: str or AzureDLPath

    :param details: Whether to include file details

    :type details: bool

    :param invalidate_cache: Whether to invalidate cache

    :type invalidate_cache: bool'
  syntax:
    content: glob(path, details=False, invalidate_cache=True)
    parameters:
    - id: path
    - defaultValue: 'False'
      id: details
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - List of files
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.glob
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.head
  langs:
  - python
  module: azure.datalake.store.core
  name: head(path, size=1024)
  source:
    id: head
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 641
  summary: 'Return first bytes of file

    :param path: Path to query

    :type path: str or AzureDLPath

    :param size: How many bytes to return

    :type size: int'
  syntax:
    content: head(path, size=1024)
    parameters:
    - id: path
    - defaultValue: '1024'
      id: size
    return:
      type:
      - First(size) bytes of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.head
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.info
  langs:
  - python
  module: azure.datalake.store.core
  name: info(path, invalidate_cache=True, expected_error_code=None)
  source:
    id: info
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 181
  summary: 'File information for path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param invalidate_cache: Whether to invalidate cache or not

    :type invalidate_cache: bool

    :param expected_error_code: Optionally indicates a specific, expected error code,
    if any.

    :type expected_error_code: int'
  syntax:
    content: info(path, invalidate_cache=True, expected_error_code=None)
    parameters:
    - id: path
    - defaultValue: 'True'
      id: invalidate_cache
    - defaultValue: None
      id: expected_error_code
    return:
      type:
      - File information
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.info
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  langs:
  - python
  module: azure.datalake.store.core
  name: invalidate_cache(path=None)
  source:
    id: invalidate_cache
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 822
  summary: 'Remove entry from object file-cache

    :param path: Remove the path from object file-cache

    :type path: str or AzureDLPath'
  syntax:
    content: invalidate_cache(path=None)
    parameters:
    - defaultValue: None
      id: path
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.listdir
  langs:
  - python
  module: azure.datalake.store.core
  name: listdir(path='', detail=False, invalidate_cache=True)
  source:
    id: listdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 151
  summary: 'List all elements under directory specified with path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param detail: Detailed info or not.

    :type detail: bool

    :param invalidate_cache: Whether to invalidate cache or not

    :type invalidate_cache: bool'
  syntax:
    content: listdir(path='', detail=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      id: path
    - defaultValue: 'False'
      id: detail
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - List of elements under directory specified with path
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.listdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.ls
  langs:
  - python
  module: azure.datalake.store.core
  name: ls(path='', detail=False, invalidate_cache=True)
  source:
    id: ls
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 151
  summary: 'List all elements under directory specified with path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param detail: Detailed info or not.

    :type detail: bool

    :param invalidate_cache: Whether to invalidate cache or not

    :type invalidate_cache: bool'
  syntax:
    content: ls(path='', detail=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      id: path
    - defaultValue: 'False'
      id: detail
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - List of elements under directory specified with path
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.ls
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.merge
  langs:
  - python
  module: azure.datalake.store.core
  name: merge(outfile, filelist, delete_source=False)
  source:
    id: merge
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 757
  summary: Concatenate a list of files into one new file
  syntax:
    content: merge(outfile, filelist, delete_source=False)
    parameters:
    - description: 'The file which will be concatenated to. If it already exists,

        the extra pieces will be appended.'
      id: outfile
      type:
      - path
    - description: Existing adl files to concatenate, in order
      id: filelist
      type:
      - list of paths
    - defaultValue: 'False'
      description: 'If True, assume that the paths to concatenate exist alone in a

        directory, and delete that whole directory when done.'
      id: delete_source
      type:
      - bool (False)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.merge
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.mkdir
  langs:
  - python
  module: azure.datalake.store.core
  name: mkdir(path)
  source:
    id: mkdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 702
  summary: 'Make new directory

    :param path: Path to create directory

    :type path: str or AzureDLPath'
  syntax:
    content: mkdir(path)
    parameters:
    - id: path
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.mkdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  langs:
  - python
  module: azure.datalake.store.core
  name: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  source:
    id: modify_acl_entries
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 474
  summary: 'Modify existing Access Control List (ACL) entries on a file or folder.

    If the entry does not exist it is added, otherwise it is updated based on the
    spec passed in.

    No entries are removed by this process (unlike set_acl).


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to set the ACL entries on.
      id: path
      type:
      - str
    - description: 'The ACL specification to use in modifying the ACL at the path
        in the format

        ''[default:]user|group|other:[entity id or UPN]:r|-w|-x|-,[default:]user|group|other:[entity
        id or UPN]:r|-w|-x|-,...'''
      id: acl_spec
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to modify ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.mv
  langs:
  - python
  module: azure.datalake.store.core
  name: mv(path1, path2)
  source:
    id: mv
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 736
  summary: 'Move file between locations on ADL

    :param path1: Source Path

    :param path2: Destination path'
  syntax:
    content: mv(path1, path2)
    parameters:
    - id: path1
    - id: path2
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.mv
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.open
  langs:
  - python
  module: azure.datalake.store.core
  name: open(path, mode='rb', blocksize=33554432, delimiter=None)
  source:
    id: open
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 98
  summary: Open a file for reading or writing
  syntax:
    content: open(path, mode='rb', blocksize=33554432, delimiter=None)
    parameters:
    - description: Path of file on ADL
      id: path
      type:
      - string
    - defaultValue: rb
      description: One of 'rb', 'ab' or 'wb'
      id: mode
      type:
      - string
    - defaultValue: '33554432'
      description: Size of data-node blocks if reading
      id: blocksize
      type:
      - int
    - defaultValue: None
      description: For writing delimiter-ended blocks
      id: delimiter
      type:
      - byte(s)
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.open
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.put
  langs:
  - python
  module: azure.datalake.store.core
  name: put(filename, path, delimiter=None)
  source:
    id: put
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 679
  summary: 'Stream data from local filename to file at path

    :param filename: Local file path to read from

    :type filename: str or Path

    :param path: ADL Path to write to

    :type path: str or AzureDLPath

    :param delimiter: Optional delimeter for delimiter-ended blocks'
  syntax:
    content: put(filename, path, delimiter=None)
    parameters:
    - id: filename
    - id: path
    - defaultValue: None
      id: delimiter
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.put
- class: azure.datalake.store.core.AzureDLFileSystem
  example:
  - '

    ```


    >>> adl.read_block(''data/file.csv'', 0, 13)  # doctest: +SKIP

    b''Alice, 100\nBo''

    >>> adl.read_block(''data/file.csv'', 0, 13, delimiter=b''\n'')  # doctest: +SKIP

    b''Alice, 100\nBob, 200\n''

    ```


    Use `length=None` to read to the end of the file.

    >>> adl.read_block(''data/file.csv'', 0, None, delimiter=b''n'')  # doctest: +SKIP

    b''Alice, 100nBob, 200nCharlie, 300''

    '
  fullName: azure.datalake.store.core.AzureDLFileSystem.read_block
  langs:
  - python
  module: azure.datalake.store.core
  name: read_block(fn, offset, length, delimiter=None)
  seealsoContent: '  <xref:distributed.utils.read_block>

    '
  source:
    id: read_block
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 856
  summary: 'Read a block of bytes from an ADL file


    Starting at `offset` of the file, read `length` bytes.  If

    `delimiter` is set then we ensure that the read starts and stops at

    delimiter boundaries that follow the locations `offset` and `offset

    + length`.  If `offset` is zero then we start at zero.  The

    bytestring returned WILL include the end delimiter string.


    If offset+length is beyond the eof, reads to eof.'
  syntax:
    content: read_block(fn, offset, length, delimiter=None)
    parameters:
    - description: Path to filename on ADL
      id: fn
      type:
      - string
    - description: Byte offset to start read
      id: offset
      type:
      - int
    - description: Number of bytes to read
      id: length
      type:
      - int
    - defaultValue: None
      description: Ensure reading starts and stops at delimiter bytestring
      id: delimiter
      type:
      - bytes (optional)
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.read_block
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove
  langs:
  - python
  module: azure.datalake.store.core
  name: remove(path, recursive=False)
  source:
    id: remove
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 796
  summary: Remove a file or directory
  syntax:
    content: remove(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_acl(path)
  source:
    id: remove_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 532
  summary: 'Remove the entire, non default, ACL from the file or folder, including
    unnamed entries.

    Default entries cannot be removed this way, please use remove_default_acl for
    that.


    Note: this is not recursive, and applies only to the file or folder specified.'
  syntax:
    content: remove_acl(path)
    parameters:
    - description: Location to remove the ACL.
      id: path
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  source:
    id: remove_acl_entries
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 497
  summary: 'Remove existing, named, Access Control List (ACL) entries on a file or
    folder.

    If the entry does not exist already it is ignored.

    Default entries cannot be removed this way, please use remove_default_acl for
    that.

    Unnamed entries cannot be removed in this way, please use remove_acl for that.


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to remove the ACL entries.
      id: path
      type:
      - str
    - description: 'The ACL specification to remove from the ACL at the path in the
        format (note that the permission portion is missing)

        ''[default:]user|group|other:[entity id or UPN],[default:]user|group|other:[entity
        id or UPN],...'''
      id: acl_spec
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to remove ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: remove_default_acl(path)
  source:
    id: remove_default_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 546
  summary: 'Remove the entire default ACL from the folder.

    Default entries do not exist on files, if a file

    is specified, this operation does nothing.


    Note: this is not recursive, and applies only to the folder specified.'
  syntax:
    content: remove_default_acl(path)
    parameters:
    - description: Location to set the ACL on.
      id: path
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rename
  langs:
  - python
  module: azure.datalake.store.core
  name: rename(path1, path2)
  source:
    id: rename
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 736
  summary: 'Move file between locations on ADL

    :param path1: Source Path

    :param path2: Destination path'
  syntax:
    content: rename(path1, path2)
    parameters:
    - id: path1
    - id: path2
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rename
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rm
  langs:
  - python
  module: azure.datalake.store.core
  name: rm(path, recursive=False)
  source:
    id: rm
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 796
  summary: Remove a file or directory
  syntax:
    content: rm(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rm
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.rmdir
  langs:
  - python
  module: azure.datalake.store.core
  name: rmdir(path)
  source:
    id: rmdir
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 718
  summary: 'Remove empty directory

    :param path: Directory  path to remove

    :type path: str or AzureDLPath'
  syntax:
    content: rmdir(path)
    parameters:
    - id: path
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.rmdir
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.set_acl
  langs:
  - python
  module: azure.datalake.store.core
  name: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
  source:
    id: set_acl
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 453
  summary: 'Set the Access Control List (ACL) for a file or folder.


    Note: this is by default not recursive, and applies only to the file or folder
    specified.'
  syntax:
    content: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
    parameters:
    - description: Location to set the ACL on.
      id: path
      type:
      - str
    - description: 'The ACL specification to set on the path in the format

        ''[default:]user|group|other:[entity id or UPN]:r|-w|-x|-,[default:]user|group|other:[entity
        id or UPN]:r|-w|-x|-,...'''
      id: acl_spec
      type:
      - str
    - defaultValue: 'False'
      description: Specifies whether to set ACLs recursively or not
      id: recursive
      type:
      - bool
    - defaultValue: None
      id: number_of_sub_process
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.set_acl
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.set_expiry
  langs:
  - python
  module: azure.datalake.store.core
  name: set_expiry(path, expiry_option, expire_time=None)
  source:
    id: set_expiry
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 385
  summary: 'Set or remove the expiration time on the specified file.

    This operation can only be executed against files.


    Note: Folders are not supported.'
  syntax:
    content: set_expiry(path, expiry_option, expire_time=None)
    parameters:
    - description: File path to set or remove expiration time
      id: path
      type:
      - str
    - description: The time that the file will expire, corresponding to the expiry_option
        that was set
      id: expire_time
      type:
      - int
    - defaultValue: None
      description: "Indicates the type of expiration to use for the file:\n   1. NeverExpire:\
        \ ExpireTime is ignored. \n\n   2. RelativeToNow: ExpireTime is an integer\
        \ in milliseconds representing the expiration date relative to when file expiration\
        \ is updated. \n\n   3. RelativeToCreationDate: ExpireTime is an integer in\
        \ milliseconds representing the expiration date relative to file creation.\
        \ \n\n   4. Absolute: ExpireTime is an integer in milliseconds, as a Unix\
        \ timestamp relative to 1/1/1970 00:00:00."
      id: expiry_option
      type:
      - str
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.set_expiry
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.stat
  langs:
  - python
  module: azure.datalake.store.core
  name: stat(path, invalidate_cache=True, expected_error_code=None)
  source:
    id: stat
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 181
  summary: 'File information for path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param invalidate_cache: Whether to invalidate cache or not

    :type invalidate_cache: bool

    :param expected_error_code: Optionally indicates a specific, expected error code,
    if any.

    :type expected_error_code: int'
  syntax:
    content: stat(path, invalidate_cache=True, expected_error_code=None)
    parameters:
    - id: path
    - defaultValue: 'True'
      id: invalidate_cache
    - defaultValue: None
      id: expected_error_code
    return:
      type:
      - File information
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.stat
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.tail
  langs:
  - python
  module: azure.datalake.store.core
  name: tail(path, size=1024)
  source:
    id: tail
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 620
  summary: 'Return last bytes of file

    :param path: Path to query

    :type path: str or AzureDLPath

    :param size: How many bytes to return

    :type size: int'
  syntax:
    content: tail(path, size=1024)
    parameters:
    - id: path
    - defaultValue: '1024'
      id: size
    return:
      type:
      - Last(size) bytes of file
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.tail
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.touch
  langs:
  - python
  module: azure.datalake.store.core
  name: touch(path)
  source:
    id: touch
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 841
  summary: Create empty file
  syntax:
    content: touch(path)
    parameters:
    - description: Path of file to create
      id: path
      type:
      - str
      - AzureDLPath
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.touch
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.unlink
  langs:
  - python
  module: azure.datalake.store.core
  name: unlink(path, recursive=False)
  source:
    id: unlink
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 796
  summary: Remove a file or directory
  syntax:
    content: unlink(path, recursive=False)
    parameters:
    - description: The location to remove.
      id: path
      type:
      - str
      - AzureDLPath
    - defaultValue: 'False'
      description: 'Whether to remove also all entries below, i.e., which are returned

        by *walk()*.'
      id: recursive
      type:
      - bool (True)
    return:
      type:
      - None
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.unlink
- class: azure.datalake.store.core.AzureDLFileSystem
  fullName: azure.datalake.store.core.AzureDLFileSystem.walk
  langs:
  - python
  module: azure.datalake.store.core
  name: walk(path='', details=False, invalidate_cache=True)
  source:
    id: walk
    path: azure\datalake\store\core.py
    remote:
      branch: master
      path: azure\datalake\store\core.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 271
  summary: 'Get all files below given path

    :param path: Path to query

    :type path: str or AzureDLPath

    :param details: Whether to include file details

    :type details: bool

    :param invalidate_cache: Whether to invalidate cache

    :type invalidate_cache: bool'
  syntax:
    content: walk(path='', details=False, invalidate_cache=True)
    parameters:
    - defaultValue: ''
      id: path
    - defaultValue: 'False'
      id: details
    - defaultValue: 'True'
      id: invalidate_cache
    return:
      type:
      - List of files
  type: method
  uid: azure.datalake.store.core.AzureDLFileSystem.walk
references:
- fullName: azure.datalake.store.core.AzureDLFileSystem.access
  isExternal: false
  name: access(path, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.access
- fullName: azure.datalake.store.core.AzureDLFileSystem.cat
  isExternal: false
  name: cat(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.cat
- fullName: azure.datalake.store.core.AzureDLFileSystem.chmod
  isExternal: false
  name: chmod(path, mod)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.chmod
- fullName: azure.datalake.store.core.AzureDLFileSystem.chown
  isExternal: false
  name: chown(path, owner=None, group=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.chown
- fullName: azure.datalake.store.core.AzureDLFileSystem.concat
  isExternal: false
  name: concat(outfile, filelist, delete_source=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.concat
- fullName: azure.datalake.store.core.AzureDLFileSystem.connect
  isExternal: false
  name: connect()
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.connect
- fullName: azure.datalake.store.core.AzureDLFileSystem.cp
  isExternal: false
  name: cp(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.cp
- fullName: azure.datalake.store.core.AzureDLFileSystem.current
  isExternal: false
  name: current()
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.current
- fullName: azure.datalake.store.core.AzureDLFileSystem.df
  isExternal: false
  name: df(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.df
- fullName: azure.datalake.store.core.AzureDLFileSystem.du
  isExternal: false
  name: du(path, total=False, deep=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.du
- fullName: azure.datalake.store.core.AzureDLFileSystem.exists
  isExternal: false
  name: exists(path, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.exists
- fullName: azure.datalake.store.core.AzureDLFileSystem.get
  isExternal: false
  name: get(path, filename)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.get
- fullName: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
  isExternal: false
  name: get_acl_status(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.get_acl_status
- fullName: azure.datalake.store.core.AzureDLFileSystem.glob
  isExternal: false
  name: glob(path, details=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.glob
- fullName: azure.datalake.store.core.AzureDLFileSystem.head
  isExternal: false
  name: head(path, size=1024)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.head
- fullName: azure.datalake.store.core.AzureDLFileSystem.info
  isExternal: false
  name: info(path, invalidate_cache=True, expected_error_code=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.info
- fullName: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
  isExternal: false
  name: invalidate_cache(path=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.invalidate_cache
- fullName: azure.datalake.store.core.AzureDLFileSystem.listdir
  isExternal: false
  name: listdir(path='', detail=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.listdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.ls
  isExternal: false
  name: ls(path='', detail=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.ls
- fullName: azure.datalake.store.core.AzureDLFileSystem.merge
  isExternal: false
  name: merge(outfile, filelist, delete_source=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.merge
- fullName: azure.datalake.store.core.AzureDLFileSystem.mkdir
  isExternal: false
  name: mkdir(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.mkdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
  isExternal: false
  name: modify_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.modify_acl_entries
- fullName: azure.datalake.store.core.AzureDLFileSystem.mv
  isExternal: false
  name: mv(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.mv
- fullName: azure.datalake.store.core.AzureDLFileSystem.open
  isExternal: false
  name: open(path, mode='rb', blocksize=33554432, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.open
- fullName: azure.datalake.store.core.AzureDLFileSystem.put
  isExternal: false
  name: put(filename, path, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.put
- fullName: azure.datalake.store.core.AzureDLFileSystem.read_block
  isExternal: false
  name: read_block(fn, offset, length, delimiter=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.read_block
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove
  isExternal: false
  name: remove(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl
  isExternal: false
  name: remove_acl(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
  isExternal: false
  name: remove_acl_entries(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_acl_entries
- fullName: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
  isExternal: false
  name: remove_default_acl(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.remove_default_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.rename
  isExternal: false
  name: rename(path1, path2)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rename
- fullName: azure.datalake.store.core.AzureDLFileSystem.rm
  isExternal: false
  name: rm(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rm
- fullName: azure.datalake.store.core.AzureDLFileSystem.rmdir
  isExternal: false
  name: rmdir(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.rmdir
- fullName: azure.datalake.store.core.AzureDLFileSystem.set_acl
  isExternal: false
  name: set_acl(path, acl_spec, recursive=False, number_of_sub_process=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.set_acl
- fullName: azure.datalake.store.core.AzureDLFileSystem.set_expiry
  isExternal: false
  name: set_expiry(path, expiry_option, expire_time=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.set_expiry
- fullName: azure.datalake.store.core.AzureDLFileSystem.stat
  isExternal: false
  name: stat(path, invalidate_cache=True, expected_error_code=None)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.stat
- fullName: azure.datalake.store.core.AzureDLFileSystem.tail
  isExternal: false
  name: tail(path, size=1024)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.tail
- fullName: azure.datalake.store.core.AzureDLFileSystem.touch
  isExternal: false
  name: touch(path)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.touch
- fullName: azure.datalake.store.core.AzureDLFileSystem.unlink
  isExternal: false
  name: unlink(path, recursive=False)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.unlink
- fullName: azure.datalake.store.core.AzureDLFileSystem.walk
  isExternal: false
  name: walk(path='', details=False, invalidate_cache=True)
  parent: azure.datalake.store.core.AzureDLFileSystem
  uid: azure.datalake.store.core.AzureDLFileSystem.walk
- fullName: str ("")
  name: str ("")
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: '""'
    name: '""'
    uid: '""'
  - fullName: )
    name: )
  uid: str ("")
- fullName: str (None)
  name: str (None)
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: None
    name: None
    uid: None
  - fullName: )
    name: )
  uid: str (None)
- fullName: str (2018-09-01)
  name: str (2018-09-01)
  spec.python:
  - fullName: 'str '
    name: 'str '
    uid: 'str '
  - fullName: (
    name: (
  - fullName: '2018-09-01'
    name: '2018-09-01'
    uid: '2018-09-01'
  - fullName: )
    name: )
  uid: str (2018-09-01)
- fullName: float(60)
  name: float(60)
  spec.python:
  - fullName: float
    name: float
    uid: float
  - fullName: (
    name: (
  - fullName: '60'
    name: '60'
    uid: '60'
  - fullName: )
    name: )
  uid: float(60)
- fullName: bool (False)
  name: bool (False)
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: (
    name: (
  - fullName: 'False'
    name: 'False'
    uid: 'False'
  - fullName: )
    name: )
  uid: bool (False)
- fullName: First(size) bytes of file
  name: First(size) bytes of file
  spec.python:
  - fullName: First
    name: First
    uid: First
  - fullName: (
    name: (
  - fullName: size
    name: size
    uid: size
  - fullName: )
    name: )
  - fullName: ' bytes of file'
    name: ' bytes of file'
    uid: ' bytes of file'
  uid: First(size) bytes of file
- fullName: byte(s)
  name: byte(s)
  spec.python:
  - fullName: byte
    name: byte
    uid: byte
  - fullName: (
    name: (
  - fullName: s
    name: s
    uid: s
  - fullName: )
    name: )
  uid: byte(s)
- fullName: bytes (optional)
  name: bytes (optional)
  spec.python:
  - fullName: 'bytes '
    name: 'bytes '
    uid: 'bytes '
  - fullName: (
    name: (
  - fullName: optional
    name: optional
    uid: optional
  - fullName: )
    name: )
  uid: bytes (optional)
- fullName: bool (True)
  name: bool (True)
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: (
    name: (
  - fullName: 'True'
    name: 'True'
    uid: 'True'
  - fullName: )
    name: )
  uid: bool (True)
- fullName: Last(size) bytes of file
  name: Last(size) bytes of file
  spec.python:
  - fullName: Last
    name: Last
    uid: Last
  - fullName: (
    name: (
  - fullName: size
    name: size
    uid: size
  - fullName: )
    name: )
  - fullName: ' bytes of file'
    name: ' bytes of file'
    uid: ' bytes of file'
  uid: Last(size) bytes of file
