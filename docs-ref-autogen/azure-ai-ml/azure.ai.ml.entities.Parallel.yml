### YamlMime:PythonClass
uid: azure.ai.ml.entities.Parallel
name: Parallel
fullName: azure.ai.ml.entities.Parallel
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._builders.base_node.BaseNode
- azure.ai.ml.entities._job.pipeline._io.mixin.NodeWithGroupInputMixin
summary: 'Base class for parallel node, used for parallel component version consumption.


  You should not instantiate this class directly. Instead, you should

  create from builder function: parallel.'
constructor:
  syntax: 'Parallel(*, component: ParallelComponent | str, compute: str | None = None,
    inputs: Dict[str, NodeOutput | Input | str | bool | int | float | Enum] | None
    = None, outputs: Dict[str, str | Output] | None = None, retry_settings: RetrySettings
    | Dict[str, str] | None = None, logging_level: str | None = None, max_concurrency_per_instance:
    int | None = None, error_threshold: int | None = None, mini_batch_error_threshold:
    int | None = None, input_data: str | None = None, task: ParallelTask | RunFunction
    | Dict | None = None, partition_keys: List | None = None, mini_batch_size: int
    | str | None = None, resources: JobResourceConfiguration | None = None, environment_variables:
    Dict | None = None, identity: Dict | ManagedIdentityConfiguration | AmlTokenConfiguration
    | UserIdentityConfiguration | None = None, **kwargs: Any)'
  parameters:
  - name: component
    description: Id or instance of the parallel component/job to be run for the step
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities._component.parallel_component.parallelComponent>
  - name: name
    description: Name of the parallel
    isRequired: true
    types:
    - <xref:str>
  - name: description
    description: Description of the commad
    isRequired: true
    types:
    - <xref:str>
  - name: tags
    description: Tag dictionary. Tags can be added, removed, and updated
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: properties
    description: The job property dictionary
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: display_name
    description: Display name of the job
    isRequired: true
    types:
    - <xref:str>
  - name: retry_settings
    description: Parallel job run failed retry
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.BatchRetrySettings>
  - name: logging_level
    description: A string of the logging level name
    isRequired: true
    types:
    - <xref:str>
  - name: max_concurrency_per_instance
    description: The max parallellism that each compute instance has
    isRequired: true
    types:
    - <xref:int>
  - name: error_threshold
    description: The number of item processing failures should be ignored
    isRequired: true
    types:
    - <xref:int>
  - name: mini_batch_error_threshold
    description: The number of mini batch processing failures should be ignored
    isRequired: true
    types:
    - <xref:int>
  - name: task
    description: The parallel task
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.ParallelTask>
  - name: mini_batch_size
    description: 'For FileDataset input, this field is the number of files

      a user script can process in one run() call.

      For TabularDataset input, this field is the approximate size of data

      the user script can process in one run() call.

      Example values are 1024, 1024KB, 10MB, and 1GB. (optional, default value is
      10 files

      for FileDataset and 1MB for TabularDataset.)

      This value could be set through PipelineParameter'
    isRequired: true
    types:
    - <xref:str>
  - name: partition_keys
    description: 'The keys used to partition dataset into mini-batches. If specified,

      the data with the same key will be partitioned into the same mini-batch.

      If both partition_keys and mini_batch_size are specified,

      the partition keys will take effect.

      The input(s) must be partitioned dataset(s),

      and the partition_keys must be a subset of the keys of every input dataset for
      this to work.'
    isRequired: true
    types:
    - <xref:typing.List>
  - name: input_data
    description: The input data
    isRequired: true
    types:
    - <xref:str>
  - name: inputs
    description: Inputs of the component/job
    isRequired: true
    types:
    - <xref:dict>
  - name: outputs
    description: Outputs of the component/job
    isRequired: true
    types:
    - <xref:dict>
  keywordOnlyParameters:
  - name: identity
    description: The identity that the command job will use while running on compute.
    types:
    - <xref:typing.Optional>[<xref:typing.Union>[ <xref:dict>[<xref:str>, <xref:str>],
      <xref:azure.ai.ml.entities.ManagedIdentityConfiguration>, <xref:azure.ai.ml.entities.AmlTokenConfiguration>,
      <xref:azure.ai.ml.entities.UserIdentityConfiguration>]]
  - name: component
    isRequired: true
  - name: compute
    isRequired: true
  - name: inputs
    isRequired: true
  - name: outputs
    isRequired: true
  - name: retry_settings
    isRequired: true
  - name: logging_level
    isRequired: true
  - name: max_concurrency_per_instance
    isRequired: true
  - name: error_threshold
    isRequired: true
  - name: mini_batch_error_threshold
    isRequired: true
  - name: input_data
    isRequired: true
  - name: task
    isRequired: true
  - name: partition_keys
    isRequired: true
  - name: mini_batch_size
    isRequired: true
  - name: resources
    isRequired: true
  - name: environment_variables
    isRequired: true
methods:
- uid: azure.ai.ml.entities.Parallel.clear
  name: clear
  signature: clear() -> None.  Remove all items from D.
- uid: azure.ai.ml.entities.Parallel.copy
  name: copy
  signature: copy() -> a shallow copy of D
- uid: azure.ai.ml.entities.Parallel.dump
  name: dump
  summary: Dumps the job content into a file in YAML format.
  signature: 'dump(dest: str | PathLike | IO, **kwargs: Any) -> None'
  parameters:
  - name: dest
    description: 'The local path or file stream to write the YAML content to.

      If dest is a file path, a new file will be created.

      If dest is an open file, the file will be written to directly.'
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:PathLike>, <xref:str>, <xref:typing.IO>[<xref:typing.AnyStr>]]
  keywordOnlyParameters:
  - name: kwargs
    description: Additional arguments to pass to the YAML serializer.
    types:
    - <xref:dict>
  exceptions:
  - type: FileExistsError
    description: Raised if dest is a file path and the file already exists.
  - type: IOError
    description: Raised if dest is an open file and the file is not writable.
- uid: azure.ai.ml.entities.Parallel.fromkeys
  name: fromkeys
  summary: Create a new dictionary with keys from iterable and values set to value.
  signature: fromkeys(value=None, /)
  positionalOnlyParameters:
  - name: iterable
    isRequired: true
  - name: value
    defaultValue: None
  parameters:
  - name: type
    isRequired: true
- uid: azure.ai.ml.entities.Parallel.get
  name: get
  summary: Return the value for key if key is in the dictionary, else default.
  signature: get(key, default=None, /)
  positionalOnlyParameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.ml.entities.Parallel.items
  name: items
  signature: items() -> a set-like object providing a view on D's items
- uid: azure.ai.ml.entities.Parallel.keys
  name: keys
  signature: keys() -> a set-like object providing a view on D's keys
- uid: azure.ai.ml.entities.Parallel.pop
  name: pop
  summary: 'If the key is not found, return the default if given; otherwise,

    raise a KeyError.'
  signature: pop(k, [d]) -> v, remove specified key and return the corresponding value.
- uid: azure.ai.ml.entities.Parallel.popitem
  name: popitem
  summary: 'Remove and return a (key, value) pair as a 2-tuple.


    Pairs are returned in LIFO (last-in, first-out) order.

    Raises KeyError if the dict is empty.'
  signature: popitem()
- uid: azure.ai.ml.entities.Parallel.set_resources
  name: set_resources
  summary: Set the resources for the parallel job.
  signature: 'set_resources(*, instance_type: str | List[str] | None = None, instance_count:
    int | None = None, properties: Dict | None = None, docker_args: str | None = None,
    shm_size: str | None = None, **kwargs: Any) -> None'
  keywordOnlyParameters:
  - name: instance_type
    description: The instance type or a list of instance types used as supported by
      the compute target.
    types:
    - <xref:typing.Union>[<xref:str>, <xref:typing.List>[<xref:str>]]
  - name: instance_count
    description: The number of instances or nodes used by the compute target.
    types:
    - <xref:int>
  - name: properties
    description: The property dictionary for the resources.
    types:
    - <xref:dict>
  - name: docker_args
    description: Extra arguments to pass to the Docker run command.
    types:
    - <xref:str>
  - name: shm_size
    description: Size of the Docker container's shared memory block.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.Parallel.setdefault
  name: setdefault
  summary: 'Insert key with a value of default if key is not in the dictionary.


    Return the value for key if key is in the dictionary, else default.'
  signature: setdefault(key, default=None, /)
  positionalOnlyParameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.ml.entities.Parallel.update
  name: update
  summary: 'If E is present and has a .keys() method, then does:  for k in E: D[k]
    = E[k]

    If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] =
    v

    In either case, this is followed by: for k in F:  D[k] = F[k]'
  signature: update([E], **F) -> None.  Update D from dict/iterable E and F.
- uid: azure.ai.ml.entities.Parallel.values
  name: values
  signature: values() -> an object providing a view on D's values
attributes:
- uid: azure.ai.ml.entities.Parallel.base_path
  name: base_path
  summary: The base path of the resource.
  return:
    description: The base path of the resource.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.Parallel.component
  name: component
  summary: Get the component of the parallel job.
  return:
    description: The component of the parallel job.
    types:
    - <xref:str>
    - <xref:azure.ai.ml.entities.ParallelComponent>
- uid: azure.ai.ml.entities.Parallel.creation_context
  name: creation_context
  summary: The creation context of the resource.
  return:
    description: The creation metadata for the resource.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.SystemData>]
- uid: azure.ai.ml.entities.Parallel.id
  name: id
  summary: The resource ID.
  return:
    description: The global ID of the resource, an Azure Resource Manager (ARM) ID.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.Parallel.identity
  name: identity
  summary: The identity that the job will use while running on compute.
  return:
    description: The identity that the job will use while running on compute.
    types:
    - <xref:typing.Optional>[<xref:typing.Union>[<xref:azure.ai.ml.ManagedIdentityConfiguration>,
      <xref:azure.ai.ml.AmlTokenConfiguration>, <xref:azure.ai.ml.UserIdentityConfiguration>]]
- uid: azure.ai.ml.entities.Parallel.inputs
  name: inputs
  summary: Get the inputs for the object.
  return:
    description: A dictionary containing the inputs for the object.
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Union>[<xref:azure.ai.ml.Input>,
      <xref:str>, <xref:bool>, <xref:int>, <xref:float>]]
- uid: azure.ai.ml.entities.Parallel.log_files
  name: log_files
  summary: Job output files.
  return:
    description: The dictionary of log names and URLs.
    types:
    - <xref:typing.Optional>[<xref:typing.Dict>[<xref:str>, <xref:str>]]
- uid: azure.ai.ml.entities.Parallel.name
  name: name
  summary: Get the name of the node.
  return:
    description: The name of the node.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.Parallel.outputs
  name: outputs
  summary: Get the outputs of the object.
  return:
    description: A dictionary containing the outputs for the object.
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Union>[<xref:str>, <xref:azure.ai.ml.Output>]]
- uid: azure.ai.ml.entities.Parallel.resources
  name: resources
  summary: Get the resource configuration for the parallel job.
  return:
    description: The resource configuration for the parallel job.
    types:
    - <xref:azure.ai.ml.entities.JobResourceConfiguration>
- uid: azure.ai.ml.entities.Parallel.retry_settings
  name: retry_settings
  summary: Get the retry settings for the parallel job.
  return:
    description: The retry settings for the parallel job.
    types:
    - <xref:azure.ai.ml.entities.RetrySettings>
- uid: azure.ai.ml.entities.Parallel.status
  name: status
  summary: "The status of the job.\n\nCommon values returned include \"Running\",\
    \ \"Completed\", and \"Failed\". All possible values are:\n\n   * NotStarted -\
    \ This is a temporary state that client-side Run objects are in before cloud submission.\
    \ \n\n   * Starting - The Run has started being processed in the cloud. The caller\
    \ has a run ID at this point. \n\n   * Provisioning - On-demand compute is being\
    \ created for a given job submission. \n\n   * Preparing - The run environment\
    \ is being prepared and is in one of two stages:\n\n        * Docker image build\
    \ \n\n        * conda environment setup \n\n   * Queued - The job is queued on\
    \ the compute target. For example, in BatchAI, the job is in a queued state\n\n\
    \        while waiting for all the requested nodes to be ready.\n\n   * Running\
    \ - The job has started to run on the compute target. \n\n   * Finalizing - User\
    \ code execution has completed, and the run is in post-processing stages. \n\n\
    \   * CancelRequested - Cancellation has been requested for the job. \n\n   *\
    \ Completed - The run has completed successfully. This includes both the user\
    \ code execution and run\n\n        post-processing stages.\n\n   * Failed - The\
    \ run failed. Usually the Error property on a run will provide details as to why.\
    \ \n\n   * Canceled - Follows a cancellation request and indicates that the run\
    \ is now successfully cancelled. \n\n   * NotResponding - For runs that have Heartbeats\
    \ enabled, no heartbeat has been recently sent."
  return:
    description: Status of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.Parallel.studio_url
  name: studio_url
  summary: Azure ML studio endpoint.
  return:
    description: The URL to the job details page.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.Parallel.task
  name: task
  summary: Get the parallel task.
  return:
    description: The parallel task.
    types:
    - <xref:azure.ai.ml.entities.ParallelTask>
- uid: azure.ai.ml.entities.Parallel.type
  name: type
  summary: The type of the job.
  return:
    description: The type of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
