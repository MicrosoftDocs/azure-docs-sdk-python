### YamlMime:PythonClass
uid: azure.ai.ml.entities.Parallel
name: Parallel
fullName: azure.ai.ml.entities.Parallel
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._builders.base_node.BaseNode
summary: 'Base class for parallel node, used for parallel component version

  consumption.


  You should not instantiate this class directly. Instead, you should

  create from builder function: parallel.'
constructor:
  syntax: 'Parallel(*, component: ParallelComponent | str, compute: str | None = None,
    inputs: Dict[str, NodeOutput | Input | str | bool | int | float | Enum] | None
    = None, outputs: Dict[str, str | Output] | None = None, retry_settings: Dict[str,
    RetrySettings | str] | None = None, logging_level: str | None = None, max_concurrency_per_instance:
    int | None = None, error_threshold: int | None = None, mini_batch_error_threshold:
    int | None = None, input_data: str | None = None, task: Dict[str, ParallelTask
    | str] | None = None, partition_keys: List | None = None, mini_batch_size: int
    | None = None, resources: JobResourceConfiguration | None = None, environment_variables:
    Dict | None = None, **kwargs)'
  parameters:
  - name: component
    description: Id or instance of the parallel component/job to be run for the step
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.parallelComponent>
  - name: name
    description: Name of the parallel.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: description
    description: Description of the commad.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: tags
    description: Tag dictionary. Tags can be added, removed, and updated.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>[<xref:azure.ai.ml.entities.str>, <xref:azure.ai.ml.entities.str>]
  - name: properties
    description: The job property dictionary.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>[<xref:azure.ai.ml.entities.str>, <xref:azure.ai.ml.entities.str>]
  - name: display_name
    description: Display name of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: retry_settings
    description: parallel job run failed retry
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.BatchRetrySettings>
  - name: logging_level
    description: A string of the logging level name
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: max_concurrency_per_instance
    description: The max parallellism that each compute instance has.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: error_threshold
    description: The number of item processing failures should be ignored.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: mini_batch_error_threshold
    description: The number of mini batch processing failures should be ignored.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: task
    description: The parallel task.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.ParallelTask>
  - name: mini_batch_size
    description: 'For FileDataset input, this field is the number of files a user
      script can process

      in one run() call. For TabularDataset input, this field is the approximate size
      of data the user script

      can process in one run() call. Example values are 1024, 1024KB, 10MB, and 1GB.

      (optional, default value is 10 files for FileDataset and 1MB for TabularDataset.)
      This value could be set

      through PipelineParameter'
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: partition_keys
    description: 'The keys used to partition dataset into mini-batches.

      If specified, the data with the same key will be partitioned into the same mini-batch.

      If both partition_keys and mini_batch_size are specified, the partition keys
      will take effect.

      The input(s) must be partitioned dataset(s),

      and the partition_keys must be a subset of the keys of every input dataset for
      this to work.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.List>
  - name: input_data
    description: The input data.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: inputs
    description: Inputs of the component/job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>
  - name: outputs
    description: Outputs of the component/job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>
methods:
- uid: azure.ai.ml.entities.Parallel.set_resources
  name: set_resources
  summary: Set resources for Parallel.
  signature: 'set_resources(*, instance_type: str | List[str] | None = None, instance_count:
    int | None = None, properties: Dict | None = None, docker_args: str | None = None,
    shm_size: str | None = None, **kwargs)'
attributes:
- uid: azure.ai.ml.entities.Parallel.component
  name: component
- uid: azure.ai.ml.entities.Parallel.resources
  name: resources
- uid: azure.ai.ml.entities.Parallel.retry_settings
  name: retry_settings
- uid: azure.ai.ml.entities.Parallel.task
  name: task
