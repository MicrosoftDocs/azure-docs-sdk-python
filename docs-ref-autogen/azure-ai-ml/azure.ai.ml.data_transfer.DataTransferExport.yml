### YamlMime:PythonClass
uid: azure.ai.ml.data_transfer.DataTransferExport
name: DataTransferExport
fullName: azure.ai.ml.data_transfer.DataTransferExport
module: azure.ai.ml.data_transfer
inheritances:
- azure.ai.ml.entities._builders.data_transfer.DataTransfer
summary: '> [!NOTE]

  > This is an experimental class, and may change at any time. Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)
  for more information.

  >


  Base class for data transfer export node.


  You should not instantiate this class directly. Instead, you should

  create from builder function: export_data.'
constructor:
  syntax: 'DataTransferExport(*, component: str | DataTransferCopyComponent | DataTransferImportComponent,
    compute: str | None = None, sink: Dict | Database | FileSystem | None = None,
    inputs: Dict[str, NodeOutput | Input | str] | None = None, **kwargs: Any)'
  parameters:
  - name: component
    description: Id of the data transfer built in component to be run for the step
    isRequired: true
    types:
    - <xref:str>
  - name: sink
    description: The sink of external data and databases.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:typing.Dict>, <xref:azure.ai.ml.data_transfer.Database>,
      <xref:azure.ai.ml.data_transfer.FileSystem>]
  - name: inputs
    description: Mapping of input data bindings used in the job.
    isRequired: true
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Union>[<xref:NodeOutput>, <xref:azure.ai.ml.Input>,
      <xref:str>, <xref:azure.ai.ml.Input>]]
  - name: name
    description: Name of the data transfer.
    isRequired: true
    types:
    - <xref:str>
  - name: description
    description: Description of the data transfer.
    isRequired: true
    types:
    - <xref:str>
  - name: tags
    description: Tag dictionary. Tags can be added, removed, and updated.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: display_name
    description: Display name of the job.
    isRequired: true
    types:
    - <xref:str>
  - name: experiment_name
    description: 'Name of the experiment the job will be created under,

      if None is provided, default will be set to current directory name.'
    isRequired: true
    types:
    - <xref:str>
  - name: compute
    description: The compute target the job runs on.
    isRequired: true
    types:
    - <xref:str>
methods:
- uid: azure.ai.ml.data_transfer.DataTransferExport.clear
  name: clear
  signature: clear() -> None.  Remove all items from D.
- uid: azure.ai.ml.data_transfer.DataTransferExport.copy
  name: copy
  signature: copy() -> a shallow copy of D
- uid: azure.ai.ml.data_transfer.DataTransferExport.dump
  name: dump
  summary: Dumps the job content into a file in YAML format.
  signature: 'dump(dest: str | PathLike | IO, **kwargs: Any) -> None'
  parameters:
  - name: dest
    description: 'The local path or file stream to write the YAML content to.

      If dest is a file path, a new file will be created.

      If dest is an open file, the file will be written to directly.'
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:PathLike>, <xref:str>, <xref:typing.IO>[<xref:typing.AnyStr>]]
  keywordOnlyParameters:
  - name: kwargs
    description: Additional arguments to pass to the YAML serializer.
    types:
    - <xref:dict>
  exceptions:
  - type: FileExistsError
    description: Raised if dest is a file path and the file already exists.
  - type: IOError
    description: Raised if dest is an open file and the file is not writable.
- uid: azure.ai.ml.data_transfer.DataTransferExport.fromkeys
  name: fromkeys
  summary: Create a new dictionary with keys from iterable and values set to value.
  signature: fromkeys(value=None, /)
  positionalOnlyParameters:
  - name: iterable
    isRequired: true
  - name: value
    defaultValue: None
  parameters:
  - name: type
    isRequired: true
- uid: azure.ai.ml.data_transfer.DataTransferExport.get
  name: get
  summary: Return the value for key if key is in the dictionary, else default.
  signature: get(key, default=None, /)
  positionalOnlyParameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.ml.data_transfer.DataTransferExport.items
  name: items
  signature: items() -> a set-like object providing a view on D's items
- uid: azure.ai.ml.data_transfer.DataTransferExport.keys
  name: keys
  signature: keys() -> a set-like object providing a view on D's keys
- uid: azure.ai.ml.data_transfer.DataTransferExport.pop
  name: pop
  summary: 'If the key is not found, return the default if given; otherwise,

    raise a KeyError.'
  signature: pop(k, [d]) -> v, remove specified key and return the corresponding value.
- uid: azure.ai.ml.data_transfer.DataTransferExport.popitem
  name: popitem
  summary: 'Remove and return a (key, value) pair as a 2-tuple.


    Pairs are returned in LIFO (last-in, first-out) order.

    Raises KeyError if the dict is empty.'
  signature: popitem()
- uid: azure.ai.ml.data_transfer.DataTransferExport.setdefault
  name: setdefault
  summary: 'Insert key with a value of default if key is not in the dictionary.


    Return the value for key if key is in the dictionary, else default.'
  signature: setdefault(key, default=None, /)
  positionalOnlyParameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.ml.data_transfer.DataTransferExport.update
  name: update
  summary: 'If E is present and has a .keys() method, then does:  for k in E: D[k]
    = E[k]

    If E is present and lacks a .keys() method, then does:  for k, v in E: D[k] =
    v

    In either case, this is followed by: for k in F:  D[k] = F[k]'
  signature: update([E], **F) -> None.  Update D from dict/iterable E and F.
- uid: azure.ai.ml.data_transfer.DataTransferExport.values
  name: values
  signature: values() -> an object providing a view on D's values
attributes:
- uid: azure.ai.ml.data_transfer.DataTransferExport.base_path
  name: base_path
  summary: The base path of the resource.
  return:
    description: The base path of the resource.
    types:
    - <xref:str>
- uid: azure.ai.ml.data_transfer.DataTransferExport.component
  name: component
- uid: azure.ai.ml.data_transfer.DataTransferExport.creation_context
  name: creation_context
  summary: The creation context of the resource.
  return:
    description: The creation metadata for the resource.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.SystemData>]
- uid: azure.ai.ml.data_transfer.DataTransferExport.id
  name: id
  summary: The resource ID.
  return:
    description: The global ID of the resource, an Azure Resource Manager (ARM) ID.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.data_transfer.DataTransferExport.inputs
  name: inputs
  summary: Get the inputs for the object.
  return:
    description: A dictionary containing the inputs for the object.
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Union>[<xref:azure.ai.ml.Input>,
      <xref:str>, <xref:bool>, <xref:int>, <xref:float>]]
- uid: azure.ai.ml.data_transfer.DataTransferExport.log_files
  name: log_files
  summary: Job output files.
  return:
    description: The dictionary of log names and URLs.
    types:
    - <xref:typing.Optional>[<xref:typing.Dict>[<xref:str>, <xref:str>]]
- uid: azure.ai.ml.data_transfer.DataTransferExport.name
  name: name
  summary: Get the name of the node.
  return:
    description: The name of the node.
    types:
    - <xref:str>
- uid: azure.ai.ml.data_transfer.DataTransferExport.outputs
  name: outputs
  summary: Get the outputs of the object.
  return:
    description: A dictionary containing the outputs for the object.
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:typing.Union>[<xref:str>, <xref:azure.ai.ml.Output>]]
- uid: azure.ai.ml.data_transfer.DataTransferExport.sink
  name: sink
  summary: The sink of external data and databases.
  return:
    description: The sink of external data and databases.
    types:
    - <xref:typing.Union>[<xref:None>, <xref:azure.ai.ml.data_transfer.Database>,
      <xref:azure.ai.ml.data_transfer.FileSystem>]
- uid: azure.ai.ml.data_transfer.DataTransferExport.status
  name: status
  summary: "The status of the job.\n\nCommon values returned include \"Running\",\
    \ \"Completed\", and \"Failed\". All possible values are:\n\n   * NotStarted -\
    \ This is a temporary state that client-side Run objects are in before cloud submission.\
    \ \n\n   * Starting - The Run has started being processed in the cloud. The caller\
    \ has a run ID at this point. \n\n   * Provisioning - On-demand compute is being\
    \ created for a given job submission. \n\n   * Preparing - The run environment\
    \ is being prepared and is in one of two stages:\n\n        * Docker image build\
    \ \n\n        * conda environment setup \n\n   * Queued - The job is queued on\
    \ the compute target. For example, in BatchAI, the job is in a queued state\n\n\
    \        while waiting for all the requested nodes to be ready.\n\n   * Running\
    \ - The job has started to run on the compute target. \n\n   * Finalizing - User\
    \ code execution has completed, and the run is in post-processing stages. \n\n\
    \   * CancelRequested - Cancellation has been requested for the job. \n\n   *\
    \ Completed - The run has completed successfully. This includes both the user\
    \ code execution and run\n\n        post-processing stages.\n\n   * Failed - The\
    \ run failed. Usually the Error property on a run will provide details as to why.\
    \ \n\n   * Canceled - Follows a cancellation request and indicates that the run\
    \ is now successfully cancelled. \n\n   * NotResponding - For runs that have Heartbeats\
    \ enabled, no heartbeat has been recently sent."
  return:
    description: Status of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.data_transfer.DataTransferExport.studio_url
  name: studio_url
  summary: Azure ML studio endpoint.
  return:
    description: The URL to the job details page.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.data_transfer.DataTransferExport.type
  name: type
  summary: The type of the job.
  return:
    description: The type of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
