### YamlMime:PythonClass
uid: azure.ai.ml.entities.CommandJob
name: CommandJob
fullName: azure.ai.ml.entities.CommandJob
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._job.job.Job
- azure.ai.ml.entities._job.parameterized_command.ParameterizedCommand
- azure.ai.ml.entities._job.job_io_mixin.JobIOMixin
summary: Command job.
constructor:
  syntax: 'CommandJob(*, inputs: Dict[str, Input | str | bool | int | float] | None
    = None, outputs: Dict[str, Output] | None = None, limits: CommandJobLimits | None
    = None, identity: Dict | ManagedIdentityConfiguration | AmlTokenConfiguration
    | UserIdentityConfiguration | None = None, services: Dict[str, JobService | JupyterLabJobService
    | SshJobService | TensorBoardJobService | VsCodeJobService] | None = None, **kwargs:
    Any)'
  keywordOnlyParameters:
  - name: services
    description: Read-only information on services associated with the job.
    types:
    - <xref:typing.Optional>[<xref:dict>[<xref:str>, <xref:azure.ai.ml.entities.JobService>]]
  - name: inputs
    description: Mapping of output data bindings used in the command.
    types:
    - <xref:typing.Optional>[<xref:dict>[<xref:str>, <xref:typing.Union>[<xref:azure.ai.ml.Input>,
      <xref:str>, <xref:bool>, <xref:int>, <xref:float>]]]
  - name: outputs
    description: Mapping of output data bindings used in the job.
    types:
    - <xref:typing.Optional>[<xref:dict>[<xref:str>, <xref:azure.ai.ml.Output>]]
  - name: identity
    description: The identity that the job will use while running on compute.
    types:
    - <xref:typing.Optional>[<xref:typing.Union>[<xref:azure.ai.ml.ManagedIdentityConfiguration>,
      <xref:azure.ai.ml.AmlTokenConfiguration>, <xref:azure.ai.ml.UserIdentityConfiguration>]]
  - name: limits
    description: The limits for the job.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.CommandJobLimits>]
  - name: kwargs
    description: A dictionary of additional configuration parameters.
    types:
    - <xref:dict>
examples:
- "Configuring a CommandJob.<!--[!code-python[Main](les\\ml_samples_command_configurations.py\
  \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\\Python\\\
  \\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\8\\\\azure_ai_ml-1.18.0\\\
  \\samples\\\\ml_samples_command_configurations.py\", \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {\"linenostart\"\
  : 1}, \"linenos\": false} -->\n\n````python\n\n   command_job = CommandJob(\n  \
  \     code=\"./src\",\n       command=\"python train.py --ss {search_space.ss}\"\
  ,\n       inputs={\"input1\": Input(path=\"trial.csv\")},\n       outputs={\"default\"\
  : Output(path=\"./foo\")},\n       compute=\"trial\",\n       environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:33\"\
  ,\n       limits=CommandJobLimits(timeout=120),\n   )\n\n   ````\n"
methods:
- uid: azure.ai.ml.entities.CommandJob.dump
  name: dump
  summary: Dumps the job content into a file in YAML format.
  signature: 'dump(dest: str | PathLike | IO, **kwargs: Any) -> None'
  parameters:
  - name: dest
    description: 'The local path or file stream to write the YAML content to.

      If dest is a file path, a new file will be created.

      If dest is an open file, the file will be written to directly.'
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:PathLike>, <xref:str>, <xref:typing.IO>[<xref:typing.AnyStr>]]
  exceptions:
  - type: FileExistsError
    description: Raised if dest is a file path and the file already exists.
  - type: IOError
    description: Raised if dest is an open file and the file is not writable.
attributes:
- uid: azure.ai.ml.entities.CommandJob.base_path
  name: base_path
  summary: The base path of the resource.
  return:
    description: The base path of the resource.
    types:
    - <xref:str>
- uid: azure.ai.ml.entities.CommandJob.creation_context
  name: creation_context
  summary: The creation context of the resource.
  return:
    description: The creation metadata for the resource.
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.SystemData>]
- uid: azure.ai.ml.entities.CommandJob.distribution
  name: distribution
  summary: The configuration for the distributed command component or job.
  return:
    description: The distribution configuration.
    types:
    - <xref:typing.Union>[<xref:azure.ai.ml.PyTorchDistribution>, <xref:azure.ai.ml.MpiDistribution>,
      <xref:azure.ai.ml.TensorFlowDistribution>, <xref:azure.ai.ml.RayDistribution>]
- uid: azure.ai.ml.entities.CommandJob.id
  name: id
  summary: The resource ID.
  return:
    description: The global ID of the resource, an Azure Resource Manager (ARM) ID.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.CommandJob.inputs
  name: inputs
- uid: azure.ai.ml.entities.CommandJob.log_files
  name: log_files
  summary: Job output files.
  return:
    description: The dictionary of log names and URLs.
    types:
    - <xref:typing.Optional>[<xref:typing.Dict>[<xref:str>, <xref:str>]]
- uid: azure.ai.ml.entities.CommandJob.outputs
  name: outputs
- uid: azure.ai.ml.entities.CommandJob.parameters
  name: parameters
  summary: MLFlow parameters.
  return:
    description: MLFlow parameters logged in job.
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
- uid: azure.ai.ml.entities.CommandJob.resources
  name: resources
  summary: The compute resource configuration for the command component or job.
  return:
    description: The compute resource configuration for the command component or job.
    types:
    - <xref:azure.ai.ml.entities.JobResourceConfiguration>
- uid: azure.ai.ml.entities.CommandJob.status
  name: status
  summary: "The status of the job.\n\nCommon values returned include \"Running\",\
    \ \"Completed\", and \"Failed\". All possible values are:\n\n   * NotStarted -\
    \ This is a temporary state that client-side Run objects are in before cloud submission.\
    \ \n\n   * Starting - The Run has started being processed in the cloud. The caller\
    \ has a run ID at this point. \n\n   * Provisioning - On-demand compute is being\
    \ created for a given job submission. \n\n   * Preparing - The run environment\
    \ is being prepared and is in one of two stages:\n\n        * Docker image build\
    \ \n\n        * conda environment setup \n\n   * Queued - The job is queued on\
    \ the compute target. For example, in BatchAI, the job is in a queued state\n\n\
    \        while waiting for all the requested nodes to be ready.\n\n   * Running\
    \ - The job has started to run on the compute target. \n\n   * Finalizing - User\
    \ code execution has completed, and the run is in post-processing stages. \n\n\
    \   * CancelRequested - Cancellation has been requested for the job. \n\n   *\
    \ Completed - The run has completed successfully. This includes both the user\
    \ code execution and run\n\n        post-processing stages.\n\n   * Failed - The\
    \ run failed. Usually the Error property on a run will provide details as to why.\
    \ \n\n   * Canceled - Follows a cancellation request and indicates that the run\
    \ is now successfully cancelled. \n\n   * NotResponding - For runs that have Heartbeats\
    \ enabled, no heartbeat has been recently sent."
  return:
    description: Status of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.CommandJob.studio_url
  name: studio_url
  summary: Azure ML studio endpoint.
  return:
    description: The URL to the job details page.
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.ai.ml.entities.CommandJob.type
  name: type
  summary: The type of the job.
  return:
    description: The type of the job.
    types:
    - <xref:typing.Optional>[<xref:str>]
