### YamlMime:PythonClass
uid: azure.ai.ml.entities.GenerationTokenStatisticsSignal
name: GenerationTokenStatisticsSignal
fullName: azure.ai.ml.entities.GenerationTokenStatisticsSignal
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._mixins.RestTranslatableMixin
summary: '> [!NOTE]

  > This is an experimental class, and may change at any time. Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)
  for more information.

  >


  Generation token statistics signal definition.'
constructor:
  syntax: 'GenerationTokenStatisticsSignal(*, production_data: LlmData | None = None,
    metric_thresholds: GenerationTokenStatisticsMonitorMetricThreshold | None = None,
    alert_enabled: bool = False, properties: Dict[str, str] | None = None, sampling_rate:
    float | None = None)'
  keywordOnlyParameters:
  - name: production_data
    description: input dataset for monitoring.
  - name: metric_thresholds
    description: Metrics to calculate and their associated thresholds. Defaults to
      App Traces
    types:
    - <xref:typing.Optional>[<xref:azure.ai.ml.entities.GenerationTokenStatisticsMonitorMetricThreshold>]
  - name: alert_enabled
    description: Whether or not to enable alerts for the signal. Defaults to True.
    types:
    - <xref:bool>
  - name: properties
    description: The properties of the signal
    types:
    - <xref:typing.Optional>[<xref:typing.Dict>[<xref:str>, <xref:str>]]
  - name: sampling_rate
    description: 'The sample rate of the target data, should be greater

      than 0 and at most 1.'
    types:
    - <xref:float>
variables:
- description: The type of the signal. Set to "generationtokenstatisticssignal" for
    this class.
  name: type
  types:
  - <xref:str>
examples:
- "Set Token Statistics Monitor.<!--[!code-python[Main](les\\ml_samples_genAI_monitors_configuration.py\
  \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\\Python\\\
  \\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\8\\\\azure_ai_ml-1.24.0\\\
  \\samples\\\\ml_samples_genAI_monitors_configuration.py\", \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {\"linenostart\"\
  : 1}, \"linenos\": false} -->\n\n````python\n\n   spark_compute = ServerlessSparkCompute(instance_type=\"\
  standard_e4s_v3\", runtime_version=\"3.3\")\n   monitoring_target = MonitoringTarget(\n\
  \       ml_task=MonitorTargetTasks.QUESTION_ANSWERING,\n       endpoint_deployment_id=f\"\
  azureml:{endpoint_name}:{deployment_name}\",\n   )\n   monitoring_target = MonitoringTarget(\n\
  \       ml_task=MonitorTargetTasks.QUESTION_ANSWERING,\n       endpoint_deployment_id=f\"\
  azureml:{endpoint_name}:{deployment_name}\",\n   )\n   monitor_settings = MonitorDefinition(compute=spark_compute,\
  \ monitoring_target=monitoring_target)\n   model_monitor = MonitorSchedule(\n  \
  \     name=\"qa_model_monitor\", trigger=CronTrigger(expression=\"15 10 * * *\"\
  ), create_monitor=monitor_settings\n   )\n   ml_client.schedules.begin_create_or_update(model_monitor)\n\
  \n   ````\n"
