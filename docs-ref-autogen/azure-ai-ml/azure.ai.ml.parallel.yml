### YamlMime:PythonPackage
uid: azure.ai.ml.parallel
name: parallel
fullName: azure.ai.ml.parallel
type: import
functions:
- uid: azure.ai.ml.parallel.parallel_run_function
  name: parallel_run_function
  summary: "Create a Parallel object which can be used inside dsl.pipeline as a function\
    \ and can also be created as a\nstandalone parallel job.\n\nFor an example of\
    \ using ParallelRunStep, see the notebook\n[https://aka.ms/parallel-example-notebook](https://aka.ms/parallel-example-notebook)\n\
    \n> [!NOTE]\n> To use parallel_run_function:\n>\n> \n>\n> Create a <xref:azure.ai.ml.entities._builders.Parallel>\
    \ object to specify how parallel run is performed,\n>\n> with parameters to control\
    \ batch size,number of nodes per compute target, and a\n>\n> reference to your\
    \ custom Python script.\n>\n> \n>\n> Build pipeline with the parallel object as\
    \ a function. defines inputs and\n>\n> outputs for the step.\n>\n> \n>\n> Sumbit\
    \ the pipeline to run.\n>\n\n<!-- literal_block {\"ids\": [], \"classes\": [],\
    \ \"names\": [], \"dupnames\": [], \"backrefs\": [], \"force\": false, \"highlight_args\"\
    : {}, \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false}\
    \ -->\n\n````python\n\n   from azure.ai.ml import Input, Output, parallel\n\n\
    \   parallel_run = parallel_run_function(\n       name=\"batch_score_with_tabular_input\"\
    ,\n       display_name=\"Batch Score with Tabular Dataset\",\n       description=\"\
    parallel component for batch score\",\n       inputs=dict(\n           job_data_path=Input(\n\
    \               type=AssetTypes.MLTABLE,\n               description=\"The data\
    \ to be split and scored in parallel\",\n           ),\n           score_model=Input(\n\
    \               type=AssetTypes.URI_FOLDER, description=\"The model for batch\
    \ score.\"\n           ),\n       ),\n       outputs=dict(job_output_path=Output(type=AssetTypes.MLTABLE)),\n\
    \       input_data=\"${{inputs.job_data_path}}\",\n       max_concurrency_per_instance=2,\
    \  # Optional, default is 1\n       mini_batch_size=\"100\",  # optional\n   \
    \    mini_batch_error_threshold=5,  # Optional, allowed failed count on mini batch\
    \ items, default is -1\n       logging_level=\"DEBUG\",  # Optional, default is\
    \ INFO\n       error_threshold=5,  # Optional, allowed failed count totally, default\
    \ is -1\n       retry_settings=dict(max_retries=2, timeout=60),  # Optional\n\
    \       task=RunFunction(\n           code=\"./src\",\n           entry_script=\"\
    tabular_batch_inference.py\",\n           environment=Environment(\n         \
    \      image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n       \
    \        conda_file=\"./src/environment_parallel.yml\",\n           ),\n     \
    \      program_arguments=\"--model ${{inputs.score_model}}\",\n           append_row_to=\"\
    ${{outputs.job_output_path}}\",  # Optional, if not set, summary_only\n      \
    \ ),\n   )\n   ````"
  signature: 'parallel_run_function(*, name: str | None = None, description: str |
    None = None, tags: Dict | None = None, properties: Dict | None = None, display_name:
    str | None = None, experiment_name: str | None = None, compute: str | None = None,
    retry_settings: BatchRetrySettings | None = None, environment_variables: Dict
    | None = None, logging_level: str | None = None, max_concurrency_per_instance:
    int | None = None, error_threshold: int | None = None, mini_batch_error_threshold:
    int | None = None, task: RunFunction | None = None, mini_batch_size: str | None
    = None, partition_keys: List | None = None, input_data: str | None = None, inputs:
    Dict | None = None, outputs: Dict | None = None, instance_count: int | None =
    None, instance_type: str | None = None, docker_args: str | None = None, shm_size:
    str | None = None, identity: ManagedIdentityConfiguration | AmlTokenConfiguration
    | UserIdentityConfiguration | None = None, is_deterministic: bool = True, **kwargs:
    Any) -> Parallel'
  keywordOnlyParameters:
  - name: name
    description: Name of the parallel job or component created.
    types:
    - <xref:str>
  - name: description
    description: A friendly description of the parallel.
    types:
    - <xref:str>
  - name: tags
    description: Tags to be attached to this parallel.
    types:
    - <xref:typing.Dict>
  - name: properties
    description: The asset property dictionary.
    types:
    - <xref:typing.Dict>
  - name: display_name
    description: A friendly name.
    types:
    - <xref:str>
  - name: experiment_name
    description: 'Name of the experiment the job will be created under,

      if None is provided, default will be set to current directory name.

      Will be ignored as a pipeline step.'
    types:
    - <xref:str>
  - name: compute
    description: 'The name of the compute where the parallel job is executed (will
      not be used

      if the parallel is used as a component/function).'
    types:
    - <xref:str>
  - name: retry_settings
    description: Parallel component run failed retry
    types:
    - <xref:azure.ai.ml.entities.BatchRetrySettings>
  - name: environment_variables
    description: 'A dictionary of environment variables names and values.

      These environment variables are set on the process

      where user script is being executed.'
    types:
    - <xref:typing.Dict>[<xref:str>, <xref:str>]
  - name: logging_level
    description: 'A string of the logging level name, which is defined in ''logging''.

      Possible values are ''WARNING'', ''INFO'', and ''DEBUG''. (optional, default
      value is ''INFO''.)

      This value could be set through PipelineParameter.'
    types:
    - <xref:str>
  - name: max_concurrency_per_instance
    description: The max parallellism that each compute instance has.
    types:
    - <xref:int>
  - name: error_threshold
    description: 'The number of record failures for Tabular Dataset and file failures
      for File Dataset

      that should be ignored during processing.

      If the error count goes above this value, then the job will be aborted.

      Error threshold is for the entire input rather

      than the individual mini-batch sent to run() method.

      The range is [-1, int.max]. -1 indicates ignore all failures during processing'
    types:
    - <xref:int>
  - name: mini_batch_error_threshold
    description: The number of mini batch processing failures should be ignored
    types:
    - <xref:int>
  - name: task
    description: The parallel task
    types:
    - <xref:azure.ai.ml.parallel.RunFunction>
  - name: mini_batch_size
    description: 'For FileDataset input,

      this field is the number of files a user script can process in one run() call.

      For TabularDataset input, this field is the approximate size of data

      the user script can process in one run() call.

      Example values are 1024, 1024KB, 10MB, and 1GB.

      (optional, default value is 10 files for FileDataset and 1MB for TabularDataset.)

      This value could be set through PipelineParameter.'
    types:
    - <xref:str>
  - name: partition_keys
    description: 'The keys used to partition dataset into mini-batches. If specified,

      the data with the same key will be partitioned into the same mini-batch.

      If both partition_keys and mini_batch_size are specified,

      the partition keys will take effect.

      The input(s) must be partitioned dataset(s),

      and the partition_keys must be a subset of the keys of every input dataset for
      this to work'
    types:
    - <xref:typing.List>
  - name: input_data
    description: The input data.
    types:
    - <xref:str>
  - name: inputs
    description: A dict of inputs used by this parallel.
    types:
    - <xref:typing.Dict>
  - name: outputs
    description: The outputs of this parallel
    types:
    - <xref:typing.Dict>
  - name: instance_count
    description: 'Optional number of instances or nodes used by the compute target.

      Defaults to 1'
    types:
    - <xref:int>
  - name: instance_type
    description: Optional type of VM used as supported by the compute target..
    types:
    - <xref:str>
  - name: docker_args
    description: 'Extra arguments to pass to the Docker run command.

      This would override any parameters that have already been set by the system,

      or in this section.

      This parameter is only supported for Azure ML compute types.'
    types:
    - <xref:str>
  - name: shm_size
    description: 'Size of the docker container''s shared memory block.

      This should be in the format of (number)(unit) where number as to be greater
      than 0

      and the unit can be one of b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).'
    types:
    - <xref:str>
  - name: identity
    description: Identity that PRS job will use while running on compute.
    types:
    - <xref:typing.Optional>[<xref:typing.Union>[ <xref:azure.ai.ml.entities.ManagedIdentityConfiguration>,
      <xref:azure.ai.ml.entities.AmlTokenConfiguration>, <xref:azure.ai.ml.entities.UserIdentityConfiguration>]]
  - name: is_deterministic
    description: 'Specify whether the parallel will return same output given same
      input.

      If a parallel (component) is deterministic, when use it as a node/step in a
      pipeline,

      it will reuse results from a previous submitted job in current workspace

      which has same inputs and settings.

      In this case, this step will not use any compute resource. Defaults to True,

      specify is_deterministic=False if you would like to avoid such reuse behavior,

      defaults to True.'
    defaultValue: 'True'
    types:
    - <xref:bool>
  return:
    description: The parallel node
    types:
    - <xref:azure.ai.ml.entities.Parallel>
classes:
- azure.ai.ml.parallel.ParallelJob
- azure.ai.ml.parallel.RunFunction
