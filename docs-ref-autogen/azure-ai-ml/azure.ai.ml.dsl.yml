### YamlMime:PythonPackage
uid: azure.ai.ml.dsl
name: dsl
fullName: azure.ai.ml.dsl
type: import
functions:
- uid: azure.ai.ml.dsl.pipeline
  name: pipeline
  summary: Build a pipeline which contains all component nodes defined in this function.
  signature: 'pipeline(func: Callable[[P], T] | None = None, *, name: str | None =
    None, version: str | None = None, display_name: str | None = None, description:
    str | None = None, experiment_name: str | None = None, tags: Dict[str, str] |
    str | None = None, **kwargs: Any) -> Callable[[Callable[[P], T]], Callable[[P],
    PipelineJob]] | Callable[[P], PipelineJob]'
  parameters:
  - name: func
    description: The user pipeline function to be decorated.
    defaultValue: None
    types:
    - <xref:types.FunctionType>
  keywordOnlyParameters:
  - name: name
    description: The name of pipeline component, defaults to function name.
    types:
    - <xref:str>
  - name: version
    description: The version of pipeline component, defaults to "1".
    types:
    - <xref:str>
  - name: display_name
    description: The display name of pipeline component, defaults to function name.
    types:
    - <xref:str>
  - name: description
    description: The description of the built pipeline.
    types:
    - <xref:str>
  - name: experiment_name
    description: Name of the experiment the job will be created under,         if
      None is provided, experiment will be set to current directory.
    types:
    - <xref:str>
  - name: tags
    description: The tags of pipeline component.
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: kwargs
    description: A dictionary of additional configuration parameters.
    types:
    - <xref:dict>
  return:
    description: 'Either

      * A decorator, if *func* is None

      * The decorated *func*'
    types:
    - "<xref:typing.Union>[  <xref:typing.Callable>[[<xref:typing.Callable>], <xref:typing.Callable>[\u2026\
      , ~<xref:azure.ai.ml.entities.PipelineJob>]], <xref:typing.Callable>[<xref:P>,\
      \ ~<xref:azure.ai.ml.entities.PipelineJob>]]"
  examples:
  - "Shows how to create a pipeline using this decorator.<!--[!code-python[Main](les\\\
    ml_samples_pipeline_job_configurations.py )]-->\n\n<!-- literal_block {\"ids\"\
    : [], \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\"\
    : \"C:\\\\hostedtoolcache\\\\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\10\\\\azure-ai-ml-1.15.0\\\\samples\\\\ml_samples_pipeline_job_configurations.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   from azure.ai.ml import load_component\n   from azure.ai.ml.dsl import pipeline\n\
    \n   component_func = load_component(\n       source=\"./sdk/ml/azure-ai-ml/tests/test_configs/components/helloworld_component.yml\"\
    \n   )\n\n   # Define a pipeline with decorator\n   @pipeline(name=\"sample_pipeline\"\
    , description=\"pipeline description\")\n   def sample_pipeline_func(pipeline_input1,\
    \ pipeline_input2):\n       # component1 and component2 will be added into the\
    \ current pipeline\n       component1 = component_func(component_in_number=pipeline_input1,\
    \ component_in_path=uri_file_input)\n       component2 = component_func(component_in_number=pipeline_input2,\
    \ component_in_path=uri_file_input)\n       # A decorated pipeline function needs\
    \ to return outputs.\n       # In this case, the pipeline has two outputs: component1's\
    \ output1 and component2's output1,\n       # and let's rename them to 'pipeline_output1'\
    \ and 'pipeline_output2'\n       return {\n           \"pipeline_output1\": component1.outputs.component_out_path,\n\
    \           \"pipeline_output2\": component2.outputs.component_out_path,\n   \
    \    }\n\n   # E.g.: This call returns a pipeline job with nodes=[component1,\
    \ component2],\n   pipeline_job = sample_pipeline_func(\n       pipeline_input1=1.0,\n\
    \       pipeline_input2=2.0,\n   )\n   ml_client.jobs.create_or_update(pipeline_job,\
    \ experiment_name=\"pipeline_samples\", compute=\"cpu-cluster\")\n\n   ````\n"
