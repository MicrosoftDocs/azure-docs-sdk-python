### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
  - azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
  class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: ComputerVisionClientOperationsMixin
  summary: ''
  syntax: {}
  type: class
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: analyze_image(url, visual_features=None, details=None, language='en', description_exclude=None,
    custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: analyze_image
  summary: 'This operation extracts a rich set of visual features based on the

    image content.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL. Within your request, there is an optional

    parameter to allow you to choose which features to return. By default,

    image categories are returned in the response.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: analyze_image(url, visual_features=None, details=None, language='en',
      description_exclude=None, custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: 'A string indicating what visual feature types

        to return. Multiple values should be comma-separated. Valid visual

        feature types include: Categories - categorizes image content

        according to a taxonomy defined in documentation. Tags - tags the

        image with a detailed list of words related to the image content.

        Description - describes the image content with a complete English

        sentence. Faces - detects if faces are present. If present, generate

        coordinates, gender and age. ImageType - detects if image is clipart

        or a line drawing. Color - determines the accent color, dominant

        color, and whether an image is black&white. Adult - detects if the

        image is pornographic in nature (depicts nudity or a sex act), or is

        gory (depicts extreme violence or blood). Sexually suggestive content

        (aka racy content) is also detected. Objects - detects various objects

        within an image, including the approximate location. The Objects

        argument is only available in English. Brands - detects various brands

        within an image, including the approximate location. The Brands

        argument is only available in English.'
      id: visual_features
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes]
    - defaultValue: None
      description: 'A string indicating which domain-specific details to

        return. Multiple values should be comma-separated. Valid visual

        feature types include: Celebrities - identifies celebrities if

        detected in the image, Landmarks - identifies notable landmarks in the

        image.'
      id: details
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.Details]
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: 'Turn off specified domain models when

        generating the description.'
      id: description_exclude
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ImageAnalysis or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ImageAnalysis
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: analyze_image_by_domain(model, url, language='en', custom_headers=None, raw=False,
    **operation_config)
  namewithoutparameters: analyze_image_by_domain
  summary: 'This operation recognizes content within an image by applying a

    domain-specific model. The list of domain-specific models that are

    supported by the Computer Vision API can be retrieved using the /models

    GET request. Currently, the API provides following domain-specific

    models: celebrities, landmarks.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON.

    If the request failed, the response will contain an error code and a

    message to help understand what went wrong.'
  syntax:
    content: analyze_image_by_domain(model, url, language='en', custom_headers=None,
      raw=False, **operation_config)
    parameters:
    - description: The domain-specific content to recognize.
      id: model
      isRequired: true
      type:
      - str
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: DomainModelResults or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.DomainModelResults
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: analyze_image_by_domain_in_stream(model, image, language='en', custom_headers=None,
    raw=False, callback=None, **operation_config)
  namewithoutparameters: analyze_image_by_domain_in_stream
  summary: 'This operation recognizes content within an image by applying a

    domain-specific model. The list of domain-specific models that are

    supported by the Computer Vision API can be retrieved using the /models

    GET request. Currently, the API provides following domain-specific

    models: celebrities, landmarks.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON.

    If the request failed, the response will contain an error code and a

    message to help understand what went wrong.'
  syntax:
    content: analyze_image_by_domain_in_stream(model, image, language='en', custom_headers=None,
      raw=False, callback=None, **operation_config)
    parameters:
    - description: The domain-specific content to recognize.
      id: model
      isRequired: true
      type:
      - str
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: DomainModelResults or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.DomainModelResults
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: analyze_image_in_stream(image, visual_features=None, details=None, language='en',
    description_exclude=None, custom_headers=None, raw=False, callback=None, **operation_config)
  namewithoutparameters: analyze_image_in_stream
  summary: 'This operation extracts a rich set of visual features based on the

    image content.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL. Within your request, there is an optional

    parameter to allow you to choose which features to return. By default,

    image categories are returned in the response.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: analyze_image_in_stream(image, visual_features=None, details=None, language='en',
      description_exclude=None, custom_headers=None, raw=False, callback=None, **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: None
      description: 'A string indicating what visual feature types

        to return. Multiple values should be comma-separated. Valid visual

        feature types include: Categories - categorizes image content

        according to a taxonomy defined in documentation. Tags - tags the

        image with a detailed list of words related to the image content.

        Description - describes the image content with a complete English

        sentence. Faces - detects if faces are present. If present, generate

        coordinates, gender and age. ImageType - detects if image is clipart

        or a line drawing. Color - determines the accent color, dominant

        color, and whether an image is black&white. Adult - detects if the

        image is pornographic in nature (depicts nudity or a sex act), or is

        gory (depicts extreme violence or blood). Sexually suggestive content

        (aka racy content) is also detected. Objects - detects various objects

        within an image, including the approximate location. The Objects

        argument is only available in English. Brands - detects various brands

        within an image, including the approximate location. The Brands

        argument is only available in English.'
      id: visual_features
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes]
    - defaultValue: None
      description: 'A string indicating which domain-specific details to

        return. Multiple values should be comma-separated. Valid visual

        feature types include: Celebrities - identifies celebrities if

        detected in the image, Landmarks - identifies notable landmarks in the

        image.'
      id: details
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.Details]
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: 'Turn off specified domain models when

        generating the description.'
      id: description_exclude
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ImageAnalysis or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ImageAnalysis
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: describe_image(url, max_candidates=1, language='en', description_exclude=None,
    custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: describe_image
  summary: 'This operation generates a description of an image in human readable

    language with complete sentences. The description is based on a

    collection of content tags, which are also returned by the operation.

    More than one description can be generated for each image. Descriptions

    are ordered by their confidence score. Descriptions may include results

    from celebrity and landmark domain models, if applicable.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: describe_image(url, max_candidates=1, language='en', description_exclude=None,
      custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: '1'
      description: 'Maximum number of candidate descriptions to be

        returned.  The default is 1.'
      id: max_candidates
      type:
      - int
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: 'Turn off specified domain models when

        generating the description.'
      id: description_exclude
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ImageDescription or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ImageDescription
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: describe_image_in_stream(image, max_candidates=1, language='en', description_exclude=None,
    custom_headers=None, raw=False, callback=None, **operation_config)
  namewithoutparameters: describe_image_in_stream
  summary: 'This operation generates a description of an image in human readable

    language with complete sentences. The description is based on a

    collection of content tags, which are also returned by the operation.

    More than one description can be generated for each image. Descriptions

    are ordered by their confidence score. Descriptions may include results

    from celebrity and landmark domain models, if applicable.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: describe_image_in_stream(image, max_candidates=1, language='en', description_exclude=None,
      custom_headers=None, raw=False, callback=None, **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: '1'
      description: 'Maximum number of candidate descriptions to be

        returned.  The default is 1.'
      id: max_candidates
      type:
      - int
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: 'Turn off specified domain models when

        generating the description.'
      id: description_exclude
      type:
      - list[str
      - azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ImageDescription or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ImageDescription
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: detect_objects(url, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: detect_objects
  summary: 'Performs object detection on the specified image.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: detect_objects(url, custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: DetectResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.DetectResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: detect_objects_in_stream(image, custom_headers=None, raw=False, callback=None,
    **operation_config)
  namewithoutparameters: detect_objects_in_stream
  summary: 'Performs object detection on the specified image.

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: detect_objects_in_stream(image, custom_headers=None, raw=False, callback=None,
      **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: DetectResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.DetectResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: msrest.exceptions.HttpOperationError
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: generate_thumbnail(width, height, url, smart_cropping=False, custom_headers=None,
    raw=False, callback=None, **operation_config)
  namewithoutparameters: generate_thumbnail
  summary: 'This operation generates a thumbnail image with the user-specified

    width and height. By default, the service analyzes the image,

    identifies the region of interest (ROI), and generates smart cropping

    coordinates based on the ROI. Smart cropping helps when you specify an

    aspect ratio that differs from that of the input image.

    A successful response contains the thumbnail image binary. If the

    request failed, the response contains an error code and a message to

    help determine what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,

    FailedToProcess, Timeout, or InternalServerError.'
  syntax:
    content: generate_thumbnail(width, height, url, smart_cropping=False, custom_headers=None,
      raw=False, callback=None, **operation_config)
    parameters:
    - description: 'Width of the thumbnail, in pixels. It must be between 1

        and 1024. Recommended minimum of 50.'
      id: width
      isRequired: true
      type:
      - int
    - description: 'Height of the thumbnail, in pixels. It must be between

        1 and 1024. Recommended minimum of 50.'
      id: height
      isRequired: true
      type:
      - int
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: 'False'
      description: Boolean flag for enabling smart cropping.
      id: smart_cropping
      type:
      - bool
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: object or ClientRawResponse if raw=true
      type:
      - Generator
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: msrest.exceptions.HttpOperationError
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: generate_thumbnail_in_stream(width, height, image, smart_cropping=False, custom_headers=None,
    raw=False, callback=None, **operation_config)
  namewithoutparameters: generate_thumbnail_in_stream
  summary: 'This operation generates a thumbnail image with the user-specified

    width and height. By default, the service analyzes the image,

    identifies the region of interest (ROI), and generates smart cropping

    coordinates based on the ROI. Smart cropping helps when you specify an

    aspect ratio that differs from that of the input image.

    A successful response contains the thumbnail image binary. If the

    request failed, the response contains an error code and a message to

    help determine what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,

    FailedToProcess, Timeout, or InternalServerError.'
  syntax:
    content: generate_thumbnail_in_stream(width, height, image, smart_cropping=False,
      custom_headers=None, raw=False, callback=None, **operation_config)
    parameters:
    - description: 'Width of the thumbnail, in pixels. It must be between 1

        and 1024. Recommended minimum of 50.'
      id: width
      isRequired: true
      type:
      - int
    - description: 'Height of the thumbnail, in pixels. It must be between

        1 and 1024. Recommended minimum of 50.'
      id: height
      isRequired: true
      type:
      - int
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: 'False'
      description: Boolean flag for enabling smart cropping.
      id: smart_cropping
      type:
      - bool
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: object or ClientRawResponse if raw=true
      type:
      - Generator
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: get_area_of_interest(url, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: get_area_of_interest
  summary: 'This operation returns a bounding box around the most important area of

    the image.

    A successful response will be returned in JSON. If the request failed,

    the response contains an error code and a message to help determine

    what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or

    InternalServerError.'
  syntax:
    content: get_area_of_interest(url, custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: AreaOfInterestResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: get_area_of_interest_in_stream(image, custom_headers=None, raw=False, callback=None,
    **operation_config)
  namewithoutparameters: get_area_of_interest_in_stream
  summary: 'This operation returns a bounding box around the most important area of

    the image.

    A successful response will be returned in JSON. If the request failed,

    the response contains an error code and a message to help determine

    what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or

    InternalServerError.'
  syntax:
    content: get_area_of_interest_in_stream(image, custom_headers=None, raw=False,
      callback=None, **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: AreaOfInterestResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: get_read_result(operation_id, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: get_read_result
  summary: 'This interface is used for getting OCR results of Read operation. The

    URL to this interface should be retrieved from ''Operation-Location''

    field returned from Read interface.'
  syntax:
    content: get_read_result(operation_id, custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: 'Id of read operation returned in the response of

        the ''Read'' interface.'
      id: operation_id
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ReadOperationResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ReadOperationResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: list_models(custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: list_models
  summary: 'This operation returns the list of domain-specific models that are

    supported by the Computer Vision API. Currently, the API supports

    following domain-specific models: celebrity recognizer, landmark

    recognizer.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: list_models(custom_headers=None, raw=False, **operation_config)
    parameters:
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: ListModelsResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.ListModelsResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: read(url, language='en', custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: read
  summary: "Use this interface to get the result of a Read operation, employing the\n\
    state-of-the-art Optical Character Recognition (OCR) algorithms\noptimized for\
    \ text-heavy documents. When you use the Read interface,\nthe response contains\
    \ a field called 'Operation-Location'. The\n'Operation-Location' field contains\
    \ the URL that you must use for your\n'GetReadResult' operation to access OCR\
    \ results.\u200B."
  syntax:
    content: read(url, language='en', custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: en
      description: "The BCP-47 language code of the text in the document.\nCurrently,\
        \ only English ('en'), Dutch (\u2018nl\u2019), French (\u2018fr\u2019), German\n\
        (\u2018de\u2019), Italian (\u2018it\u2019), Portuguese (\u2018pt), and Spanish\
        \ ('es') are\nsupported. Read supports auto language identification and\n\
        multi-language documents, so only provide a language code if you would\nlike\
        \ to force the documented to be processed as that specific\nlanguage. Possible\
        \ values include: 'en', 'es', 'fr', 'de', 'it', 'nl',\n'pt'"
      id: language
      type:
      - str
      - azure.cognitiveservices.vision.computervision.models.OcrDetectionLanguage
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: None or ClientRawResponse if raw=true
      type:
      - None
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: read_in_stream(image, language='en', custom_headers=None, raw=False, callback=None,
    **operation_config)
  namewithoutparameters: read_in_stream
  summary: "Use this interface to get the result of a Read operation, employing the\n\
    state-of-the-art Optical Character Recognition (OCR) algorithms\noptimized for\
    \ text-heavy documents. When you use the Read interface,\nthe response contains\
    \ a field called 'Operation-Location'. The\n'Operation-Location' field contains\
    \ the URL that you must use for your\n'GetReadResult' operation to access OCR\
    \ results.\u200B."
  syntax:
    content: read_in_stream(image, language='en', custom_headers=None, raw=False,
      callback=None, **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: en
      description: "The BCP-47 language code of the text in the document.\nCurrently,\
        \ only English ('en'), Dutch (\u2018nl\u2019), French (\u2018fr\u2019), German\n\
        (\u2018de\u2019), Italian (\u2018it\u2019), Portuguese (\u2018pt), and Spanish\
        \ ('es') are\nsupported. Read supports auto language identification and\n\
        multi-language documents, so only provide a language code if you would\nlike\
        \ to force the documented to be processed as that specific\nlanguage. Possible\
        \ values include: 'en', 'es', 'fr', 'de', 'it', 'nl',\n'pt'"
      id: language
      type:
      - str
      - azure.cognitiveservices.vision.computervision.models.OcrDetectionLanguage
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: None or ClientRawResponse if raw=true
      type:
      - None
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: recognize_printed_text(url, detect_orientation=True, language='unk', custom_headers=None,
    raw=False, **operation_config)
  namewithoutparameters: recognize_printed_text
  summary: 'Optical Character Recognition (OCR) detects text in an image and

    extracts the recognized characters into a machine-usable character

    stream.

    Upon success, the OCR results will be returned.

    Upon failure, the error code together with an error message will be

    returned. The error code can be one of InvalidImageUrl,

    InvalidImageFormat, InvalidImageSize, NotSupportedImage,

    NotSupportedLanguage, or InternalServerError.'
  syntax:
    content: recognize_printed_text(url, detect_orientation=True, language='unk',
      custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: 'Whether detect the text orientation in the

        image. With detectOrientation=true the OCR service tries to detect the

        image orientation and correct it before further processing (e.g. if

        it''s upside-down).'
      id: detect_orientation
      isRequired: true
      type:
      - bool
    - defaultValue: 'True'
      description: Publicly reachable URL of an image.
      id: url
      type:
      - str
    - defaultValue: unk
      description: 'The BCP-47 language code of the text to be detected

        in the image. The default value is ''unk''. Possible values include:

        ''unk'', ''zh-Hans'', ''zh-Hant'', ''cs'', ''da'', ''nl'', ''en'', ''fi'',
        ''fr'', ''de'',

        ''el'', ''hu'', ''it'', ''ja'', ''ko'', ''nb'', ''pl'', ''pt'', ''ru'', ''es'',
        ''sv'',

        ''tr'', ''ar'', ''ro'', ''sr-Cyrl'', ''sr-Latn'', ''sk'''
      id: language
      type:
      - str
      - azure.cognitiveservices.vision.computervision.models.OcrLanguages
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: OcrResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.OcrResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: recognize_printed_text_in_stream(image, detect_orientation=True, language='unk',
    custom_headers=None, raw=False, callback=None, **operation_config)
  namewithoutparameters: recognize_printed_text_in_stream
  summary: 'Optical Character Recognition (OCR) detects text in an image and

    extracts the recognized characters into a machine-usable character

    stream.

    Upon success, the OCR results will be returned.

    Upon failure, the error code together with an error message will be

    returned. The error code can be one of InvalidImageUrl,

    InvalidImageFormat, InvalidImageSize, NotSupportedImage,

    NotSupportedLanguage, or InternalServerError.'
  syntax:
    content: recognize_printed_text_in_stream(image, detect_orientation=True, language='unk',
      custom_headers=None, raw=False, callback=None, **operation_config)
    parameters:
    - description: 'Whether detect the text orientation in the

        image. With detectOrientation=true the OCR service tries to detect the

        image orientation and correct it before further processing (e.g. if

        it''s upside-down).'
      id: detect_orientation
      isRequired: true
      type:
      - bool
    - defaultValue: 'True'
      description: An image stream.
      id: image
      type:
      - Generator
    - defaultValue: unk
      description: 'The BCP-47 language code of the text to be detected

        in the image. The default value is ''unk''. Possible values include:

        ''unk'', ''zh-Hans'', ''zh-Hant'', ''cs'', ''da'', ''nl'', ''en'', ''fi'',
        ''fr'', ''de'',

        ''el'', ''hu'', ''it'', ''ja'', ''ko'', ''nb'', ''pl'', ''pt'', ''ru'', ''es'',
        ''sv'',

        ''tr'', ''ar'', ''ro'', ''sr-Cyrl'', ''sr-Latn'', ''sk'''
      id: language
      type:
      - str
      - azure.cognitiveservices.vision.computervision.models.OcrLanguages
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: OcrResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.OcrResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: tag_image(url, language='en', custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: tag_image
  summary: 'This operation generates a list of words, or tags, that are relevant to

    the content of the supplied image. The Computer Vision API can return

    tags based on objects, living beings, scenery or actions found in

    images. Unlike categories, tags are not organized according to a

    hierarchical classification system, but correspond to image content.

    Tags may contain hints to avoid ambiguity or provide context, for

    example the tag "ascomycete" may be accompanied by the hint "fungus".

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: tag_image(url, language='en', custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image.
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: TagResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.TagResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
- class: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorException
  fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.computervision.operations
  name: tag_image_in_stream(image, language='en', custom_headers=None, raw=False,
    callback=None, **operation_config)
  namewithoutparameters: tag_image_in_stream
  summary: 'This operation generates a list of words, or tags, that are relevant to

    the content of the supplied image. The Computer Vision API can return

    tags based on objects, living beings, scenery or actions found in

    images. Unlike categories, tags are not organized according to a

    hierarchical classification system, but correspond to image content.

    Tags may contain hints to avoid ambiguity or provide context, for

    example the tag "ascomycete" may be accompanied by the hint "fungus".

    Two input methods are supported -- (1) Uploading an image or (2)

    specifying an image URL.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  syntax:
    content: tag_image_in_stream(image, language='en', custom_headers=None, raw=False,
      callback=None, **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: en
      description: 'The desired language for output generation. If this

        parameter is not specified, the default value is

        &quot;en&quot;.Supported languages:en - English, Default. es -

        Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

        Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
      id: language
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: TagResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.computervision.models.TagResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
references:
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
  isExternal: false
  name: analyze_image(url, visual_features=None, details=None, language='en', description_exclude=None,
    custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
  isExternal: false
  name: analyze_image_by_domain(model, url, language='en', custom_headers=None, raw=False,
    **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
  isExternal: false
  name: analyze_image_by_domain_in_stream(model, image, language='en', custom_headers=None,
    raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
  isExternal: false
  name: analyze_image_in_stream(image, visual_features=None, details=None, language='en',
    description_exclude=None, custom_headers=None, raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
  isExternal: false
  name: describe_image(url, max_candidates=1, language='en', description_exclude=None,
    custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
  isExternal: false
  name: describe_image_in_stream(image, max_candidates=1, language='en', description_exclude=None,
    custom_headers=None, raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
  isExternal: false
  name: detect_objects(url, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
  isExternal: false
  name: detect_objects_in_stream(image, custom_headers=None, raw=False, callback=None,
    **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
  isExternal: false
  name: generate_thumbnail(width, height, url, smart_cropping=False, custom_headers=None,
    raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
  isExternal: false
  name: generate_thumbnail_in_stream(width, height, image, smart_cropping=False, custom_headers=None,
    raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
  isExternal: false
  name: get_area_of_interest(url, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
  isExternal: false
  name: get_area_of_interest_in_stream(image, custom_headers=None, raw=False, callback=None,
    **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
  isExternal: false
  name: get_read_result(operation_id, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
  isExternal: false
  name: list_models(custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
  isExternal: false
  name: read(url, language='en', custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
  isExternal: false
  name: read_in_stream(image, language='en', custom_headers=None, raw=False, callback=None,
    **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
  isExternal: false
  name: recognize_printed_text(url, detect_orientation=True, language='unk', custom_headers=None,
    raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
  isExternal: false
  name: recognize_printed_text_in_stream(image, detect_orientation=True, language='unk',
    custom_headers=None, raw=False, callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
  isExternal: false
  name: tag_image(url, language='en', custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
- fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
  isExternal: false
  name: tag_image_in_stream(image, language='en', custom_headers=None, raw=False,
    callback=None, **operation_config)
  parent: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
  uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
- fullName: list[str
  name: list[str
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  uid: list[str
- fullName: azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes]
  name: VisualFeatureTypes]
  spec.python:
  - fullName: azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes
    name: VisualFeatureTypes
    uid: azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes
  - fullName: ']'
    name: ']'
  uid: azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes]
- fullName: list[str
  name: list[str
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  uid: list[str
- fullName: azure.cognitiveservices.vision.computervision.models.Details]
  name: Details]
  spec.python:
  - fullName: azure.cognitiveservices.vision.computervision.models.Details
    name: Details
    uid: azure.cognitiveservices.vision.computervision.models.Details
  - fullName: ']'
    name: ']'
  uid: azure.cognitiveservices.vision.computervision.models.Details]
- fullName: list[str
  name: list[str
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  uid: list[str
- fullName: azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
  name: DescriptionExclude]
  spec.python:
  - fullName: azure.cognitiveservices.vision.computervision.models.DescriptionExclude
    name: DescriptionExclude
    uid: azure.cognitiveservices.vision.computervision.models.DescriptionExclude
  - fullName: ']'
    name: ']'
  uid: azure.cognitiveservices.vision.computervision.models.DescriptionExclude]
- fullName: Callable[Bytes, response=None]
  name: Callable[Bytes, response=None]
  spec.python:
  - fullName: Callable
    name: Callable
    uid: Callable
  - fullName: '['
    name: '['
  - fullName: Bytes
    name: Bytes
    uid: Bytes
  - fullName: ', '
    name: ', '
  - fullName: response=None
    name: response=None
    uid: response=None
  - fullName: ']'
    name: ']'
  uid: Callable[Bytes, response=None]
