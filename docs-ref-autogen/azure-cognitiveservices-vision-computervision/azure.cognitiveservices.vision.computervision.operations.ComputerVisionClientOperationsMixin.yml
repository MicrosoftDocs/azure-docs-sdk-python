### YamlMime:PythonClass
uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
name: ComputerVisionClientOperationsMixin
fullName: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin
module: azure.cognitiveservices.vision.computervision.operations
inheritances:
- builtins.object
constructor:
  syntax: ComputerVisionClientOperationsMixin()
methods:
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image
  name: analyze_image
  summary: "This operation extracts a rich set of visual features based on the\nimage\
    \ content.\nTwo input methods are supported \u2013 (1) Uploading an image or (2)\n\
    specifying an image URL. Within your request, there is an optional\nparameter\
    \ to allow you to choose which features to return. By default,\nimage categories\
    \ are returned in the response.\nA successful response will be returned in JSON.\
    \ If the request failed,\nthe response will contain an error code and a message\
    \ to help\nunderstand what went wrong."
  signature: analyze_image(url, visual_features=None, details=None, language='en',
    description_exclude=None, model_version='latest', custom_headers=None, raw=False,
    **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: visual_features
    description: 'A string indicating what visual feature types

      to return. Multiple values should be comma-separated. Valid visual

      feature types include: Categories - categorizes image content

      according to a taxonomy defined in documentation. Tags - tags the

      image with a detailed list of words related to the image content.

      Description - describes the image content with a complete English

      sentence. Faces - detects if faces are present. If present, generate

      coordinates, gender and age. ImageType - detects if image is clipart

      or a line drawing. Color - determines the accent color, dominant

      color, and whether an image is black&white. Adult - detects if the

      image is pornographic in nature (depicts nudity or a sex act), or is

      gory (depicts extreme violence or blood). Sexually suggestive content

      (aka racy content) is also detected. Objects - detects various objects

      within an image, including the approximate location. The Objects

      argument is only available in English. Brands - detects various brands

      within an image, including the approximate location. The Brands

      argument is only available in English.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes>]
  - name: details
    description: 'A string indicating which domain-specific details to

      return. Multiple values should be comma-separated. Valid visual

      feature types include: Celebrities - identifies celebrities if

      detected in the image, Landmarks - identifies notable landmarks in the

      image.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.Details>]
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: description_exclude
    description: 'Turn off specified domain models when

      generating the description.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.DescriptionExclude>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ImageAnalysis or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ImageAnalysis>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain
  name: analyze_image_by_domain
  summary: "This operation recognizes content within an image by applying a\ndomain-specific\
    \ model. The list of domain-specific models that are\nsupported by the Computer\
    \ Vision API can be retrieved using the /models\nGET request. Currently, the API\
    \ provides following domain-specific\nmodels: celebrities, landmarks.\nTwo input\
    \ methods are supported \u2013 (1) Uploading an image or (2)\nspecifying an image\
    \ URL.\nA successful response will be returned in JSON.\nIf the request failed,\
    \ the response will contain an error code and a\nmessage to help understand what\
    \ went wrong."
  signature: analyze_image_by_domain(model, url, language='en', model_version='latest',
    custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: model
    description: The domain-specific content to recognize.
    isRequired: true
    types:
    - <xref:str>
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: DomainModelResults or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.DomainModelResults>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_by_domain_in_stream
  name: analyze_image_by_domain_in_stream
  summary: "This operation recognizes content within an image by applying a\ndomain-specific\
    \ model. The list of domain-specific models that are\nsupported by the Computer\
    \ Vision API can be retrieved using the /models\nGET request. Currently, the API\
    \ provides following domain-specific\nmodels: celebrities, landmarks.\nTwo input\
    \ methods are supported \u2013 (1) Uploading an image or (2)\nspecifying an image\
    \ URL.\nA successful response will be returned in JSON.\nIf the request failed,\
    \ the response will contain an error code and a\nmessage to help understand what\
    \ went wrong."
  signature: analyze_image_by_domain_in_stream(model, image, language='en', model_version='latest',
    custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: model
    description: The domain-specific content to recognize.
    isRequired: true
    types:
    - <xref:str>
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: DomainModelResults or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.DomainModelResults>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.analyze_image_in_stream
  name: analyze_image_in_stream
  summary: "This operation extracts a rich set of visual features based on the\nimage\
    \ content.\nTwo input methods are supported \u2013 (1) Uploading an image or (2)\n\
    specifying an image URL. Within your request, there is an optional\nparameter\
    \ to allow you to choose which features to return. By default,\nimage categories\
    \ are returned in the response.\nA successful response will be returned in JSON.\
    \ If the request failed,\nthe response will contain an error code and a message\
    \ to help\nunderstand what went wrong."
  signature: analyze_image_in_stream(image, visual_features=None, details=None, language='en',
    description_exclude=None, model_version='latest', custom_headers=None, raw=False,
    callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: visual_features
    description: 'A string indicating what visual feature types

      to return. Multiple values should be comma-separated. Valid visual

      feature types include: Categories - categorizes image content

      according to a taxonomy defined in documentation. Tags - tags the

      image with a detailed list of words related to the image content.

      Description - describes the image content with a complete English

      sentence. Faces - detects if faces are present. If present, generate

      coordinates, gender and age. ImageType - detects if image is clipart

      or a line drawing. Color - determines the accent color, dominant

      color, and whether an image is black&white. Adult - detects if the

      image is pornographic in nature (depicts nudity or a sex act), or is

      gory (depicts extreme violence or blood). Sexually suggestive content

      (aka racy content) is also detected. Objects - detects various objects

      within an image, including the approximate location. The Objects

      argument is only available in English. Brands - detects various brands

      within an image, including the approximate location. The Brands

      argument is only available in English.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.VisualFeatureTypes>]
  - name: details
    description: 'A string indicating which domain-specific details to

      return. Multiple values should be comma-separated. Valid visual

      feature types include: Celebrities - identifies celebrities if

      detected in the image, Landmarks - identifies notable landmarks in the

      image.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.Details>]
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: description_exclude
    description: 'Turn off specified domain models when

      generating the description.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.DescriptionExclude>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ImageAnalysis or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ImageAnalysis>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image
  name: describe_image
  summary: "This operation generates a description of an image in human readable\n\
    language with complete sentences. The description is based on a\ncollection of\
    \ content tags, which are also returned by the operation.\nMore than one description\
    \ can be generated for each image. Descriptions\nare ordered by their confidence\
    \ score. Descriptions may include results\nfrom celebrity and landmark domain\
    \ models, if applicable.\nTwo input methods are supported \u2013 (1) Uploading\
    \ an image or (2)\nspecifying an image URL.\nA successful response will be returned\
    \ in JSON. If the request failed,\nthe response will contain an error code and\
    \ a message to help\nunderstand what went wrong."
  signature: describe_image(url, max_candidates=1, language='en', description_exclude=None,
    model_version='latest', custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: max_candidates
    description: 'Maximum number of candidate descriptions to be

      returned.  The default is 1.'
    defaultValue: '1'
    types:
    - <xref:int>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: description_exclude
    description: 'Turn off specified domain models when

      generating the description.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.DescriptionExclude>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ImageDescription or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ImageDescription>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.describe_image_in_stream
  name: describe_image_in_stream
  summary: "This operation generates a description of an image in human readable\n\
    language with complete sentences. The description is based on a\ncollection of\
    \ content tags, which are also returned by the operation.\nMore than one description\
    \ can be generated for each image. Descriptions\nare ordered by their confidence\
    \ score. Descriptions may include results\nfrom celebrity and landmark domain\
    \ models, if applicable.\nTwo input methods are supported \u2013 (1) Uploading\
    \ an image or (2)\nspecifying an image URL.\nA successful response will be returned\
    \ in JSON. If the request failed,\nthe response will contain an error code and\
    \ a message to help\nunderstand what went wrong."
  signature: describe_image_in_stream(image, max_candidates=1, language='en', description_exclude=None,
    model_version='latest', custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: max_candidates
    description: 'Maximum number of candidate descriptions to be

      returned.  The default is 1.'
    defaultValue: '1'
    types:
    - <xref:int>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: description_exclude
    description: 'Turn off specified domain models when

      generating the description.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.DescriptionExclude>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ImageDescription or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ImageDescription>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects
  name: detect_objects
  summary: "Performs object detection on the specified image.\nTwo input methods are\
    \ supported \u2013 (1) Uploading an image or (2)\nspecifying an image URL.\nA\
    \ successful response will be returned in JSON. If the request failed,\nthe response\
    \ will contain an error code and a message to help\nunderstand what went wrong."
  signature: detect_objects(url, model_version='latest', custom_headers=None, raw=False,
    **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: DetectResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.DetectResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.detect_objects_in_stream
  name: detect_objects_in_stream
  summary: "Performs object detection on the specified image.\nTwo input methods are\
    \ supported \u2013 (1) Uploading an image or (2)\nspecifying an image URL.\nA\
    \ successful response will be returned in JSON. If the request failed,\nthe response\
    \ will contain an error code and a message to help\nunderstand what went wrong."
  signature: detect_objects_in_stream(image, model_version='latest', custom_headers=None,
    raw=False, callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: DetectResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.DetectResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail
  name: generate_thumbnail
  summary: 'This operation generates a thumbnail image with the user-specified

    width and height. By default, the service analyzes the image,

    identifies the region of interest (ROI), and generates smart cropping

    coordinates based on the ROI. Smart cropping helps when you specify an

    aspect ratio that differs from that of the input image.

    A successful response contains the thumbnail image binary. If the

    request failed, the response contains an error code and a message to

    help determine what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,

    FailedToProcess, Timeout, or InternalServerError.'
  signature: generate_thumbnail(width, height, url, smart_cropping=False, model_version='latest',
    custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: width
    description: 'Width of the thumbnail, in pixels. It must be between 1

      and 1024. Recommended minimum of 50.'
    isRequired: true
    types:
    - <xref:int>
  - name: height
    description: 'Height of the thumbnail, in pixels. It must be between

      1 and 1024. Recommended minimum of 50.'
    isRequired: true
    types:
    - <xref:int>
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: smart_cropping
    description: Boolean flag for enabling smart cropping.
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: object or ClientRawResponse if raw=true
    types:
    - <xref:Generator>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: msrest.exceptions.HttpOperationError
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.generate_thumbnail_in_stream
  name: generate_thumbnail_in_stream
  summary: 'This operation generates a thumbnail image with the user-specified

    width and height. By default, the service analyzes the image,

    identifies the region of interest (ROI), and generates smart cropping

    coordinates based on the ROI. Smart cropping helps when you specify an

    aspect ratio that differs from that of the input image.

    A successful response contains the thumbnail image binary. If the

    request failed, the response contains an error code and a message to

    help determine what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, InvalidThumbnailSize, NotSupportedImage,

    FailedToProcess, Timeout, or InternalServerError.'
  signature: generate_thumbnail_in_stream(width, height, image, smart_cropping=False,
    model_version='latest', custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: width
    description: 'Width of the thumbnail, in pixels. It must be between 1

      and 1024. Recommended minimum of 50.'
    isRequired: true
    types:
    - <xref:int>
  - name: height
    description: 'Height of the thumbnail, in pixels. It must be between

      1 and 1024. Recommended minimum of 50.'
    isRequired: true
    types:
    - <xref:int>
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: smart_cropping
    description: Boolean flag for enabling smart cropping.
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: object or ClientRawResponse if raw=true
    types:
    - <xref:Generator>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: msrest.exceptions.HttpOperationError
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest
  name: get_area_of_interest
  summary: 'This operation returns a bounding box around the most important area of

    the image.

    A successful response will be returned in JSON. If the request failed,

    the response contains an error code and a message to help determine

    what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or

    InternalServerError.'
  signature: get_area_of_interest(url, model_version='latest', custom_headers=None,
    raw=False, **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: AreaOfInterestResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_area_of_interest_in_stream
  name: get_area_of_interest_in_stream
  summary: 'This operation returns a bounding box around the most important area of

    the image.

    A successful response will be returned in JSON. If the request failed,

    the response contains an error code and a message to help determine

    what went wrong.

    Upon failure, the error code and an error message are returned. The

    error code could be one of InvalidImageUrl, InvalidImageFormat,

    InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout, or

    InternalServerError.'
  signature: get_area_of_interest_in_stream(image, model_version='latest', custom_headers=None,
    raw=False, callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: AreaOfInterestResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.AreaOfInterestResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.get_read_result
  name: get_read_result
  summary: 'This interface is used for getting OCR results of Read operation. The

    URL to this interface should be retrieved from ''Operation-Location''

    field returned from Read interface.'
  signature: get_read_result(operation_id, custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: operation_id
    description: 'Id of read operation returned in the response of

      the ''Read'' interface.'
    isRequired: true
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ReadOperationResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ReadOperationResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionOcrErrorException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.list_models
  name: list_models
  summary: 'This operation returns the list of domain-specific models that are

    supported by the Computer Vision API. Currently, the API supports

    following domain-specific models: celebrity recognizer, landmark

    recognizer.

    A successful response will be returned in JSON. If the request failed,

    the response will contain an error code and a message to help

    understand what went wrong.'
  signature: list_models(custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: ListModelsResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.ListModelsResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read
  name: read
  summary: "Use this interface to get the result of a Read operation, employing the\n\
    state-of-the-art Optical Character Recognition (OCR) algorithms\noptimized for\
    \ text-heavy documents. When you use the Read interface,\nthe response contains\
    \ a field called 'Operation-Location'. The\n'Operation-Location' field contains\
    \ the URL that you must use for your\n'GetReadResult' operation to access OCR\
    \ results.\u200B."
  signature: read(url, language=None, pages=None, model_version='latest', reading_order='basic',
    custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: language
    description: 'The BCP-47 language code of the text in the document.

      Read supports auto language identification and multi-language

      documents, so only provide a language code if you would like to force

      the document to be processed in that specific language. See

      [https://aka.ms/ocr-languages](https://aka.ms/ocr-languages) for list of supported
      languages. Possible

      values include: ''af'', ''ast'', ''bi'', ''br'', ''ca'', ''ceb'', ''ch'', ''co'',

      ''crh'', ''cs'', ''csb'', ''da'', ''de'', ''en'', ''es'', ''et'', ''eu'', ''fi'',
      ''fil'',

      ''fj'', ''fr'', ''fur'', ''fy'', ''ga'', ''gd'', ''gil'', ''gl'', ''gv'', ''hni'',
      ''hsb'',

      ''ht'', ''hu'', ''ia'', ''id'', ''it'', ''iu'', ''ja'', ''jv'', ''kaa'', ''kac'',
      ''kea'',

      ''kha'', ''kl'', ''ko'', ''ku'', ''kw'', ''lb'', ''ms'', ''mww'', ''nap'', ''nl'',
      ''no'',

      ''oc'', ''pl'', ''pt'', ''quc'', ''rm'', ''sco'', ''sl'', ''sq'', ''sv'', ''sw'',
      ''tet'',

      ''tr'', ''tt'', ''uz'', ''vo'', ''wae'', ''yua'', ''za'', ''zh-Hans'', ''zh-Hant'',
      ''zu'''
    defaultValue: None
    types:
    - <xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrDetectionLanguage>
  - name: pages
    description: 'Custom page numbers for multi-page documents(PDF/TIFF),

      input the number of the pages you want to get OCR result. For a range

      of pages, use a hyphen. Separate each page or range with a comma.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      OCR model used for text extraction. Accepted values are: "latest",

      "latest-preview", "2021-04-12". Defaults to "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: reading_order
    description: 'Optional parameter to specify which reading

      order algorithm should be applied when ordering the extract text

      elements. Can be either ''basic'' or ''natural''. Will default to ''basic''

      if not specified'
    defaultValue: basic
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: None or ClientRawResponse if raw=true
    types:
    - <xref:None>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionOcrErrorException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.read_in_stream
  name: read_in_stream
  summary: "Use this interface to get the result of a Read operation, employing the\n\
    state-of-the-art Optical Character Recognition (OCR) algorithms\noptimized for\
    \ text-heavy documents. When you use the Read interface,\nthe response contains\
    \ a field called 'Operation-Location'. The\n'Operation-Location' field contains\
    \ the URL that you must use for your\n'GetReadResult' operation to access OCR\
    \ results.\u200B."
  signature: read_in_stream(image, language=None, pages=None, model_version='latest',
    reading_order='basic', custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: language
    description: 'The BCP-47 language code of the text in the document.

      Read supports auto language identification and multi-language

      documents, so only provide a language code if you would like to force

      the document to be processed in that specific language. See

      [https://aka.ms/ocr-languages](https://aka.ms/ocr-languages) for list of supported
      languages. Possible

      values include: ''af'', ''ast'', ''bi'', ''br'', ''ca'', ''ceb'', ''ch'', ''co'',

      ''crh'', ''cs'', ''csb'', ''da'', ''de'', ''en'', ''es'', ''et'', ''eu'', ''fi'',
      ''fil'',

      ''fj'', ''fr'', ''fur'', ''fy'', ''ga'', ''gd'', ''gil'', ''gl'', ''gv'', ''hni'',
      ''hsb'',

      ''ht'', ''hu'', ''ia'', ''id'', ''it'', ''iu'', ''ja'', ''jv'', ''kaa'', ''kac'',
      ''kea'',

      ''kha'', ''kl'', ''ko'', ''ku'', ''kw'', ''lb'', ''ms'', ''mww'', ''nap'', ''nl'',
      ''no'',

      ''oc'', ''pl'', ''pt'', ''quc'', ''rm'', ''sco'', ''sl'', ''sq'', ''sv'', ''sw'',
      ''tet'',

      ''tr'', ''tt'', ''uz'', ''vo'', ''wae'', ''yua'', ''za'', ''zh-Hans'', ''zh-Hant'',
      ''zu'''
    defaultValue: None
    types:
    - <xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrDetectionLanguage>
  - name: pages
    description: 'Custom page numbers for multi-page documents(PDF/TIFF),

      input the number of the pages you want to get OCR result. For a range

      of pages, use a hyphen. Separate each page or range with a comma.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>]
  - name: model_version
    description: 'Optional parameter to specify the version of the

      OCR model used for text extraction. Accepted values are: "latest",

      "latest-preview", "2021-04-12". Defaults to "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: reading_order
    description: 'Optional parameter to specify which reading

      order algorithm should be applied when ordering the extract text

      elements. Can be either ''basic'' or ''natural''. Will default to ''basic''

      if not specified'
    defaultValue: basic
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: None or ClientRawResponse if raw=true
    types:
    - <xref:None>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionOcrErrorException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text
  name: recognize_printed_text
  summary: 'Optical Character Recognition (OCR) detects text in an image and

    extracts the recognized characters into a machine-usable character

    stream.

    Upon success, the OCR results will be returned.

    Upon failure, the error code together with an error message will be

    returned. The error code can be one of InvalidImageUrl,

    InvalidImageFormat, InvalidImageSize, NotSupportedImage,

    NotSupportedLanguage, or InternalServerError.'
  signature: recognize_printed_text(url, detect_orientation=True, language='unk',
    model_version='latest', custom_headers=None, raw=False, **operation_config)
  parameters:
  - name: detect_orientation
    description: 'Whether detect the text orientation in the

      image. With detectOrientation=true the OCR service tries to detect the

      image orientation and correct it before further processing (e.g. if

      it''s upside-down).'
    isRequired: true
    types:
    - <xref:bool>
  - name: url
    description: Publicly reachable URL of an image.
    defaultValue: 'True'
    types:
    - <xref:str>
  - name: language
    description: 'The BCP-47 language code of the text to be detected

      in the image. The default value is ''unk''. Possible values include:

      ''unk'', ''zh-Hans'', ''zh-Hant'', ''cs'', ''da'', ''nl'', ''en'', ''fi'', ''fr'',
      ''de'',

      ''el'', ''hu'', ''it'', ''ja'', ''ko'', ''nb'', ''pl'', ''pt'', ''ru'', ''es'',
      ''sv'',

      ''tr'', ''ar'', ''ro'', ''sr-Cyrl'', ''sr-Latn'', ''sk'''
    defaultValue: unk
    types:
    - <xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrLanguages>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: OcrResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.recognize_printed_text_in_stream
  name: recognize_printed_text_in_stream
  summary: 'Optical Character Recognition (OCR) detects text in an image and

    extracts the recognized characters into a machine-usable character

    stream.

    Upon success, the OCR results will be returned.

    Upon failure, the error code together with an error message will be

    returned. The error code can be one of InvalidImageUrl,

    InvalidImageFormat, InvalidImageSize, NotSupportedImage,

    NotSupportedLanguage, or InternalServerError.'
  signature: recognize_printed_text_in_stream(image, detect_orientation=True, language='unk',
    model_version='latest', custom_headers=None, raw=False, callback=None, **operation_config)
  parameters:
  - name: detect_orientation
    description: 'Whether detect the text orientation in the

      image. With detectOrientation=true the OCR service tries to detect the

      image orientation and correct it before further processing (e.g. if

      it''s upside-down).'
    isRequired: true
    types:
    - <xref:bool>
  - name: image
    description: An image stream.
    defaultValue: 'True'
    types:
    - <xref:Generator>
  - name: language
    description: 'The BCP-47 language code of the text to be detected

      in the image. The default value is ''unk''. Possible values include:

      ''unk'', ''zh-Hans'', ''zh-Hant'', ''cs'', ''da'', ''nl'', ''en'', ''fi'', ''fr'',
      ''de'',

      ''el'', ''hu'', ''it'', ''ja'', ''ko'', ''nb'', ''pl'', ''pt'', ''ru'', ''es'',
      ''sv'',

      ''tr'', ''ar'', ''ro'', ''sr-Cyrl'', ''sr-Latn'', ''sk'''
    defaultValue: unk
    types:
    - <xref:str>
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrLanguages>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: OcrResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.OcrResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image
  name: tag_image
  summary: "This operation generates a list of words, or tags, that are relevant to\n\
    the content of the supplied image. The Computer Vision API can return\ntags based\
    \ on objects, living beings, scenery or actions found in\nimages. Unlike categories,\
    \ tags are not organized according to a\nhierarchical classification system, but\
    \ correspond to image content.\nTags may contain hints to avoid ambiguity or provide\
    \ context, for\nexample the tag \"ascomycete\" may be accompanied by the hint\
    \ \"fungus\".\nTwo input methods are supported \u2013 (1) Uploading an image or\
    \ (2)\nspecifying an image URL.\nA successful response will be returned in JSON.\
    \ If the request failed,\nthe response will contain an error code and a message\
    \ to help\nunderstand what went wrong."
  signature: tag_image(url, language='en', model_version='latest', custom_headers=None,
    raw=False, **operation_config)
  parameters:
  - name: url
    description: Publicly reachable URL of an image.
    isRequired: true
    types:
    - <xref:str>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: TagResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.TagResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
- uid: azure.cognitiveservices.vision.computervision.operations.ComputerVisionClientOperationsMixin.tag_image_in_stream
  name: tag_image_in_stream
  summary: "This operation generates a list of words, or tags, that are relevant to\n\
    the content of the supplied image. The Computer Vision API can return\ntags based\
    \ on objects, living beings, scenery or actions found in\nimages. Unlike categories,\
    \ tags are not organized according to a\nhierarchical classification system, but\
    \ correspond to image content.\nTags may contain hints to avoid ambiguity or provide\
    \ context, for\nexample the tag \"ascomycete\" may be accompanied by the hint\
    \ \"fungus\".\nTwo input methods are supported \u2013 (1) Uploading an image or\
    \ (2)\nspecifying an image URL.\nA successful response will be returned in JSON.\
    \ If the request failed,\nthe response will contain an error code and a message\
    \ to help\nunderstand what went wrong."
  signature: tag_image_in_stream(image, language='en', model_version='latest', custom_headers=None,
    raw=False, callback=None, **operation_config)
  parameters:
  - name: image
    description: An image stream.
    isRequired: true
    types:
    - <xref:Generator>
  - name: language
    description: 'The desired language for output generation. If this

      parameter is not specified, the default value is

      &quot;en&quot;.Supported languages:en - English, Default. es -

      Spanish, ja - Japanese, pt - Portuguese, zh - Simplified Chinese.

      Possible values include: ''en'', ''es'', ''ja'', ''pt'', ''zh'''
    defaultValue: en
    types:
    - <xref:str>
  - name: model_version
    description: 'Optional parameter to specify the version of the

      AI model. Accepted values are: "latest", "2021-04-01". Defaults to

      "latest".'
    defaultValue: latest
    types:
    - <xref:str>
  - name: custom_headers
    description: headers that will be added to the request
    defaultValue: None
    types:
    - <xref:dict>
  - name: raw
    description: 'returns the direct response alongside the

      deserialized response'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: callback
    description: 'When specified, will be called with each chunk of

      data that is streamed. The callback should take two arguments, the

      bytes of the current chunk of data and the response object. If the

      data is uploading, response will be None.'
    defaultValue: None
    types:
    - <xref:Callable>[<xref:Bytes>, <xref:response=None>]
  - name: operation_config
    description: '*Operation configuration

      overrides*.'
    isRequired: true
  return:
    description: TagResult or ClientRawResponse if raw=true
    types:
    - <xref:azure.cognitiveservices.vision.computervision.models.TagResult>
    - <xref:msrest.pipeline.ClientRawResponse>
  exceptions:
  - type: azure.cognitiveservices.vision.computervision.models.ComputerVisionErrorResponseException
