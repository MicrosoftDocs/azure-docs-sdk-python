### YamlMime:PythonPackage
uid: azure.storage.blob.aio
name: aio
fullName: azure.storage.blob.aio
type: import
functions:
- uid: azure.storage.blob.aio.upload_blob_to_url
  name: upload_blob_to_url
  summary: 'Upload data to a given URL


    The data will be uploaded as a block blob.'
  signature: upload_blob_to_url(blob_url, data, credential=None, **kwargs)
  parameters:
  - name: blob_url
    description: The full URI to the blob. This can also include a SAS token.
    types:
    - <xref:str>
  - name: data
    description: 'The data to upload. This can be bytes, text, an iterable or a file-like
      object.'
    types:
    - <xref:bytes>
    - <xref:str>
    - <xref:Iterable>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      blob URL already has a SAS token. The value can be a SAS token string,

      an instance of a AzureSasCredential from azure.core.credentials, an account

      shared access key, or an instance of a TokenCredentials class from azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.'
    defaultValue: None
  - name: overwrite
    description: 'Whether the blob to be uploaded should overwrite the current data.

      If True, upload_blob_to_url will overwrite any existing data. If set to False,
      the

      operation will fail with a ResourceExistsError.'
    types:
    - <xref:bool>
  - name: max_concurrency
    description: The number of parallel connections with which to download.
    types:
    - <xref:int>
  - name: length
    description: 'Number of bytes to read from the stream. This is optional, but

      should be supplied for optimal performance.'
    types:
    - <xref:int>
  - name: metadata
    description: 'Name-value pairs associated with the blob as metadata.'
    types:
    - <xref:dict>(<xref:str,str>)
  - name: validate_content
    description: 'If true, calculates an MD5 hash for each chunk of the blob. The
      storage

      service checks the hash of the content that has arrived with the hash

      that was sent. This is primarily valuable for detecting bitflips on

      the wire if using http instead of https as https (the default) will

      already validate. Note that this MD5 hash is not stored with the

      blob. Also note that if enabled, the memory-efficient upload algorithm

      will not be used, because computing the MD5 hash requires buffering

      entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
    types:
    - <xref:bool>
  - name: encoding
    description: Encoding to use if text is supplied as input. Defaults to UTF-8.
    types:
    - <xref:str>
  return:
    description: Blob-updated property dict (Etag and last modified)
    types:
    - <xref:dict>(<xref:str>, <xref:Any>)
- uid: azure.storage.blob.aio.download_blob_from_url
  name: download_blob_from_url
  summary: Download the contents of a blob to a local file or stream.
  signature: download_blob_from_url(blob_url, output, credential=None, **kwargs)
  parameters:
  - name: blob_url
    description: The full URI to the blob. This can also include a SAS token.
    types:
    - <xref:str>
  - name: output
    description: 'Where the data should be downloaded to. This could be either a file
      path to write to,

      or an open IO handle to write to.'
    types:
    - <xref:str>
    - <xref:writable stream>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      blob URL already has a SAS token or the blob is public. The value can be a SAS
      token string,

      an instance of a AzureSasCredential from azure.core.credentials,

      an account shared access key, or an instance of a TokenCredentials class from
      azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.'
    defaultValue: None
  - name: overwrite
    description: 'Whether the local file should be overwritten if it already exists.
      The default value is

      *False* - in which case a ValueError will be raised if the file already exists.
      If set to

      *True*, an attempt will be made to write to the existing file. If a stream handle
      is passed

      in, this value is ignored.'
    types:
    - <xref:bool>
  - name: max_concurrency
    description: The number of parallel connections with which to download.
    types:
    - <xref:int>
  - name: offset
    description: 'Start of byte range to use for downloading a section of the blob.

      Must be set if length is provided.'
    types:
    - <xref:int>
  - name: length
    description: 'Number of bytes to read from the stream. This is optional, but

      should be supplied for optimal performance.'
    types:
    - <xref:int>
  - name: validate_content
    description: 'If true, calculates an MD5 hash for each chunk of the blob. The
      storage

      service checks the hash of the content that has arrived with the hash

      that was sent. This is primarily valuable for detecting bitflips on

      the wire if using http instead of https as https (the default) will

      already validate. Note that this MD5 hash is not stored with the

      blob. Also note that if enabled, the memory-efficient upload algorithm

      will not be used, because computing the MD5 hash requires buffering

      entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
    types:
    - <xref:bool>
  return:
    types:
    - <xref:None>
classes:
- azure.storage.blob.aio.BlobServiceClient
- azure.storage.blob.aio.ContainerClient
- azure.storage.blob.aio.BlobClient
- azure.storage.blob.aio.BlobLeaseClient
- azure.storage.blob.aio.ExponentialRetry
- azure.storage.blob.aio.LinearRetry
- azure.storage.blob.aio.StorageStreamDownloader
