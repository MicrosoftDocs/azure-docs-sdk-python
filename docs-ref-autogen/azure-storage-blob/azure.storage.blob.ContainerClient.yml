### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.blob.ContainerClient.acquire_lease
  - azure.storage.blob.ContainerClient.create_container
  - azure.storage.blob.ContainerClient.delete_blob
  - azure.storage.blob.ContainerClient.delete_blobs
  - azure.storage.blob.ContainerClient.delete_container
  - azure.storage.blob.ContainerClient.download_blob
  - azure.storage.blob.ContainerClient.from_connection_string
  - azure.storage.blob.ContainerClient.from_container_url
  - azure.storage.blob.ContainerClient.get_account_information
  - azure.storage.blob.ContainerClient.get_blob_client
  - azure.storage.blob.ContainerClient.get_container_access_policy
  - azure.storage.blob.ContainerClient.get_container_properties
  - azure.storage.blob.ContainerClient.list_blobs
  - azure.storage.blob.ContainerClient.set_container_access_policy
  - azure.storage.blob.ContainerClient.set_container_metadata
  - azure.storage.blob.ContainerClient.set_premium_page_blob_tier_blobs
  - azure.storage.blob.ContainerClient.set_standard_blob_tier_blobs
  - azure.storage.blob.ContainerClient.upload_blob
  - azure.storage.blob.ContainerClient.walk_blobs
  class: azure.storage.blob.ContainerClient
  example:
  - "Get a ContainerClient from an existing BlobServiceClient.<!--[!code-python[Main](les\\\
    blob_samples_containers.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   # Instantiate\
    \ a BlobServiceClient using a connection string\n   from azure.storage.blob import\
    \ BlobServiceClient\n   blob_service_client = BlobServiceClient.from_connection_string(self.connection_string)\n\
    \n   # Instantiate a ContainerClient\n   container_client = blob_service_client.get_container_client(\"\
    mynewcontainer\")\n\n   ````\n\nCreating the container client directly.<!--[!code-python[Main](les\\\
    blob_samples_containers.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.storage.blob\
    \ import ContainerClient\n\n   sas_url = \"https://account.blob.core.windows.net/mycontainer?sv=2015-04-05&st=2015-04-29T22%3A18%3A26Z&se=2015-04-30T02%3A23%3A26Z&sr=b&sp=rw&sip=168.1.5.60-168.1.5.70&spr=https&sig=Z%2FRHIX5Xcg0Mq2rqI3OlWTjEg2tYkboXr1P9ZUXDtkk%3D\"\
    \n   container = ContainerClient.from_container_url(sas_url)\n\n   ````\n"
  fullName: azure.storage.blob.ContainerClient
  inheritance:
  - inheritance:
    - type: builtins.object
    type: azure.storage.blob._shared.base_client.StorageAccountHostsMixin
  langs:
  - python
  module: azure.storage.blob
  name: ContainerClient
  summary: 'A client to interact with a specific container, although that container

    may not yet exist.


    For operations relating to a specific blob within this container, a blob client
    can be

    retrieved using the <xref:azure.storage.blob.ContainerClient.get_blob_client>
    function.'
  syntax:
    content: ContainerClient(account_url, container_name, credential=None, **kwargs)
    parameters:
    - description: 'The URI to the storage account. In order to create a client given
        the full URI to the container,

        use the <xref:azure.storage.blob.ContainerClient.from_container_url> classmethod.'
      id: account_url
      type:
      - str
    - description: The name of the container for the blob.
      id: container_name
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token. The value can be a SAS token string,
        an account

        shared access key, or an instance of a TokenCredentials class from azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    - description: 'The Storage API version to use for requests. Default value is
        ''2019-07-07''.

        Setting to an older version may result in reduced feature compatibility.


        New in version 12.2.0.'
      id: api_version
      type:
      - str
    - description: The hostname of the secondary endpoint.
      id: secondary_hostname
      type:
      - str
    - description: 'The maximum chunk size for uploading a block blob in chunks.

        Defaults to 4*1024*1024, or 4MB.'
      id: max_block_size
      type:
      - int
    - description: 'If the blob size is less than max_single_put_size, then the blob
        will be

        uploaded with only one http PUT request. If the blob size is larger than max_single_put_size,

        the blob will be uploaded in chunks. Defaults to 64*1024*1024, or 64MB.'
      id: max_single_put_size
      type:
      - int
    - description: 'The minimum chunk size required to use the memory efficient

        algorithm when uploading a block blob. Defaults to 4*1024*1024+1.'
      id: min_large_block_upload_threshold
      type:
      - int
    - description: Use a byte buffer for block blob uploads. Defaults to False.
      id: use_byte_buffer
      type:
      - bool
    - description: The maximum chunk size for uploading a page blob. Defaults to 4*1024*1024,
        or 4MB.
      id: max_page_size
      type:
      - int
    - description: 'The maximum size for a blob to be downloaded in a single call,

        the exceeded part will be downloaded in chunks (could be parallel). Defaults
        to 32*1024*1024, or 32MB.'
      id: max_single_get_size
      type:
      - int
    - description: 'The maximum chunk size used for downloading a blob. Defaults to
        4*1024*1024,

        or 4MB.'
      id: max_chunk_get_size
      type:
      - int
  type: class
  uid: azure.storage.blob.ContainerClient
- class: azure.storage.blob.ContainerClient
  example:
  - "Acquiring a lease on the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   # Acquire a lease\
    \ on the container\n   lease = container_client.acquire_lease()\n\n   # Delete\
    \ container by passing in the lease\n   container_client.delete_container(lease=lease)\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.acquire_lease
  langs:
  - python
  module: azure.storage.blob
  name: acquire_lease(lease_duration=-1, lease_id=None, **kwargs)
  namewithoutparameters: acquire_lease
  summary: 'Requests a new lease. If the container does not have an active lease,

    the Blob service creates a lease on the container and returns a new

    lease ID.'
  syntax:
    content: acquire_lease(lease_duration=-1, lease_id=None, **kwargs)
    parameters:
    - description: 'Specifies the duration of the lease, in seconds, or negative one

        (-1) for a lease that never expires. A non-infinite lease can be

        between 15 and 60 seconds. A lease duration cannot be changed

        using renew or change. Default is -1 (infinite lease).'
      id: lease_duration
      isRequired: true
      type:
      - int
    - description: 'Proposed lease ID, in a GUID string format. The Blob service returns

        400 (Invalid request) if the proposed lease ID is not in the correct format.'
      id: lease_id
      isRequired: true
      type:
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: A BlobLeaseClient object, that can be run in a context manager.
      type:
      - azure.storage.blob.BlobLeaseClient
  type: method
  uid: azure.storage.blob.ContainerClient.acquire_lease
- class: azure.storage.blob.ContainerClient
  example:
  - "Creating a container to store blobs.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   container_client.create_container()\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.create_container
  langs:
  - python
  module: azure.storage.blob
  name: create_container(metadata=None, public_access=None, **kwargs)
  namewithoutparameters: create_container
  summary: 'Creates a new container under the specified account. If the container

    with the same name already exists, the operation fails.'
  syntax:
    content: create_container(metadata=None, public_access=None, **kwargs)
    parameters:
    - description: 'A dict with name_value pairs to associate with the

        container as metadata. Example:{''Category'':''test''}'
      id: metadata
      isRequired: true
      type:
      - dict[str, str]
    - description: 'Possible values include: ''container'', ''blob''.'
      id: public_access
      isRequired: true
      type:
      - azure.storage.blob.PublicAccess
    - description: 'Specifies the default encryption scope to set on the container
        and use for

        all future writes.


        New in version 12.2.0.'
      id: container_encryption_scope
      isRequired: true
      type:
      - dict
      - azure.storage.blob.ContainerEncryptionScope
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      type:
      - None
  type: method
  uid: azure.storage.blob.ContainerClient.create_container
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.delete_blob
  langs:
  - python
  module: azure.storage.blob
  name: delete_blob(blob, delete_snapshots=None, **kwargs)
  namewithoutparameters: delete_blob
  summary: 'Marks the specified blob or snapshot for deletion.


    The blob is later deleted during garbage collection.

    Note that in order to delete a blob, you must delete all of its

    snapshots. You can delete both at the same time with the delete_blob

    operation.


    If a delete retention policy is enabled for the service, then this operation soft
    deletes the blob or snapshot

    and retains the blob or snapshot for specified number of days.

    After specified number of days, blob''s data is removed from the service during
    garbage collection.

    Soft deleted blob or snapshot is accessible through <xref:azure.storage.blob.list_blobs>
    specifying *include=["deleted"]*

    option. Soft-deleted blob or snapshot can be restored using <xref:BlobClient.undelete>'
  syntax:
    content: delete_blob(blob, delete_snapshots=None, **kwargs)
    parameters:
    - description: 'The blob with which to interact. If specified, this value will
        override

        a blob value specified in the blob URL.'
      id: blob
      isRequired: true
      type:
      - str
      - azure.storage.blob.BlobProperties
    - description: "Required if the blob has associated snapshots. Values include:\n\
        \   * \"only\": Deletes only the blobs snapshots. \n\n   * \"include\": Deletes\
        \ the blob along with all snapshots."
      id: delete_snapshots
      isRequired: true
      type:
      - str
    - description: 'Required if the blob has an active lease. Value can be a BlobLeaseClient
        object

        or the lease ID as a string.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      type:
      - None
  type: method
  uid: azure.storage.blob.ContainerClient.delete_blob
- class: azure.storage.blob.ContainerClient
  example:
  - "Deleting multiple blobs.<!--[!code-python[Main](les\\blob_samples_common.py )]-->\n\
    \n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
    : [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\90\\\\\
    azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_common.py\", \"xml:space\"\
    : \"preserve\", \"language\": \"python\", \"linenos\": false, \"highlight_args\"\
    : {\"linenostart\": 1}} -->\n\n````python\n\n   # Delete multiple blobs in the\
    \ container by name\n   container_client.delete_blobs(\"my_blob1\", \"my_blob2\"\
    )\n\n   # Delete multiple blobs by properties iterator\n   my_blobs = container_client.list_blobs(name_starts_with=\"\
    my_blob\")\n   container_client.delete_blobs(*my_blobs)\n\n   ````\n"
  fullName: azure.storage.blob.ContainerClient.delete_blobs
  langs:
  - python
  module: azure.storage.blob
  name: delete_blobs(*blobs, **kwargs)
  namewithoutparameters: delete_blobs
  summary: 'Marks the specified blobs or snapshots for deletion.


    The blobs are later deleted during garbage collection.

    Note that in order to delete blobs, you must delete all of their

    snapshots. You can delete both at the same time with the delete_blobs operation.


    If a delete retention policy is enabled for the service, then this operation soft
    deletes the blobs or snapshots

    and retains the blobs or snapshots for specified number of days.

    After specified number of days, blobs'' data is removed from the service during
    garbage collection.

    Soft deleted blobs or snapshots are accessible through <xref:azure.storage.blob.list_blobs>
    specifying *include=["deleted"]*

    Soft-deleted blobs or snapshots can be restored using <xref:BlobClient.undelete>'
  syntax:
    content: delete_blobs(*blobs, **kwargs)
    parameters:
    - description: "The blobs to delete. This can be a single blob, or multiple values\
        \ can\nbe supplied, where each value is either the name of the blob (str)\
        \ or BlobProperties.\n\n\n> [!NOTE]\n> When the blob type is dict, here's\
        \ a list of keys, value rules.\n>\n> \n>\n> blob name:\n>\n> \n>\n> key: 'name',\
        \ value type: str\n>\n> \n>\n> snapshot you want to delete:\n>\n> \n>\n> key:\
        \ 'snapshot', value type: str\n>\n> \n>\n> whether to delete snapthots when\
        \ deleting blob:\n>\n> \n>\n> key: 'delete_snapshots', value: 'include' or\
        \ 'only'\n>\n> \n>\n> if the blob modified or not:\n>\n> \n>\n> key: 'if_modified_since',\
        \ 'if_unmodified_since', value type: datetime\n>\n> \n>\n> etag:\n>\n> \n\
        >\n> key: 'etag', value type: str\n>\n> \n>\n> match the etag or not:\n>\n\
        > \n>\n> key: 'match_condition', value type: MatchConditions\n>\n> \n>\n>\
        \ lease:\n>\n> \n>\n> key: 'lease_id', value type: Union[str, LeaseClient]\n\
        >\n> \n>\n> timeout for subrequest:\n>\n> \n>\n> key: 'timeout', value type:\
        \ int\n>"
      id: blobs
      isRequired: true
      type:
      - list[str], list[dict],
      - list[azure.storage.blob.BlobProperties]
    - description: "Required if a blob has associated snapshots. Values include:\n\
        \   * \"only\": Deletes only the blobs snapshots. \n\n   * \"include\": Deletes\
        \ the blob along with all snapshots."
      id: delete_snapshots
      isRequired: true
      type:
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'This is a boolean param which defaults to True. When this is set,
        an exception

        is raised even if there is a single operation failure.'
      id: raise_on_any_failure
      isRequired: true
      type:
      - bool
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: An iterator of responses, one for each blob in order
      type:
      - Iterator[azure.core.pipeline.transport.HttpResponse]
  type: method
  uid: azure.storage.blob.ContainerClient.delete_blobs
- class: azure.storage.blob.ContainerClient
  example:
  - "Delete a container.<!--[!code-python[Main](les\\blob_samples_containers.py )]-->\n\
    \n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
    : [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\90\\\\\
    azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\", \"xml:space\"\
    : \"preserve\", \"language\": \"python\", \"linenos\": false, \"highlight_args\"\
    : {\"linenostart\": 1}} -->\n\n````python\n\n   container_client.delete_container()\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.delete_container
  langs:
  - python
  module: azure.storage.blob
  name: delete_container(**kwargs)
  namewithoutparameters: delete_container
  summary: 'Marks the specified container for deletion. The container and any blobs

    contained within it are later deleted during garbage collection.'
  syntax:
    content: delete_container(**kwargs)
    parameters:
    - description: 'If specified, delete_container only succeeds if the

        container''s lease is active and matches this ID.

        Required if the container has an active lease.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      type:
      - None
  type: method
  uid: azure.storage.blob.ContainerClient.delete_container
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.download_blob
  langs:
  - python
  module: azure.storage.blob
  name: download_blob(blob, offset=None, length=None, **kwargs)
  namewithoutparameters: download_blob
  summary: 'Downloads a blob to the StorageStreamDownloader. The readall() method
    must

    be used to read all the content or readinto() must be used to download the blob
    into

    a stream.'
  syntax:
    content: download_blob(blob, offset=None, length=None, **kwargs)
    parameters:
    - description: 'The blob with which to interact. If specified, this value will
        override

        a blob value specified in the blob URL.'
      id: blob
      isRequired: true
      type:
      - str
      - azure.storage.blob.BlobProperties
    - description: 'Start of byte range to use for downloading a section of the blob.

        Must be set if length is provided.'
      id: offset
      isRequired: true
      type:
      - int
    - description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      isRequired: true
      type:
      - int
    - description: 'If true, calculates an MD5 hash for each chunk of the blob. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https, as https (the default), will

        already validate. Note that this MD5 hash is not stored with the

        blob. Also note that if enabled, the memory-efficient upload algorithm

        will not be used because computing the MD5 hash requires buffering

        entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
      id: validate_content
      isRequired: true
      type:
      - bool
    - description: 'Required if the blob has an active lease. If specified, download_blob
        only

        succeeds if the blob''s lease is active and matches this ID. Value can be
        a

        BlobLeaseClient object or the lease ID as a string.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: 'Encrypts the data on the service-side with the given key.

        Use of customer-provided keys must be done over HTTPS.

        As the encryption key itself is provided in the request,

        a secure connection must be established to transfer the key.'
      id: cpk
      isRequired: true
      type:
      - azure.storage.blob.CustomerProvidedEncryptionKey
    - description: The number of parallel connections with which to download.
      id: max_concurrency
      isRequired: true
      type:
      - int
    - description: Encoding to decode the downloaded bytes. Default is None, i.e.
        no decoding.
      id: encoding
      isRequired: true
      type:
      - str
    - description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.'
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: A streaming object (StorageStreamDownloader)
      type:
      - azure.storage.blob.StorageStreamDownloader
  type: method
  uid: azure.storage.blob.ContainerClient.download_blob
- class: azure.storage.blob.ContainerClient
  example:
  - "Creating the ContainerClient from a connection string.<!--[!code-python[Main](les\\\
    blob_samples_authentication.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_authentication.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.storage.blob\
    \ import ContainerClient\n   container_client = ContainerClient.from_connection_string(\n\
    \       self.connection_string, container_name=\"mycontainer\")\n\n   ````\n"
  fullName: azure.storage.blob.ContainerClient.from_connection_string
  langs:
  - python
  module: azure.storage.blob
  name: from_connection_string(conn_str, container_name, credential=None, **kwargs)
  namewithoutparameters: from_connection_string
  summary: Create ContainerClient from a Connection String.
  syntax:
    content: from_connection_string(conn_str, container_name, credential=None, **kwargs)
    parameters:
    - description: A connection string to an Azure Storage account.
      id: conn_str
      isRequired: true
      type:
      - str
    - description: The container name for the blob.
      id: container_name
      isRequired: true
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token, or the connection string already has
        shared

        access key values. The value can be a SAS token string, an account shared
        access

        key, or an instance of a TokenCredentials class from azure.identity.

        Credentials provided here will take precedence over those in the connection
        string.'
      id: credential
      isRequired: true
    - defaultValue: None
      id: credential
    return:
      description: A container client.
      type:
      - azure.storage.blob.ContainerClient
  type: method
  uid: azure.storage.blob.ContainerClient.from_connection_string
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.from_container_url
  langs:
  - python
  module: azure.storage.blob
  name: from_container_url(container_url, credential=None, **kwargs)
  namewithoutparameters: from_container_url
  summary: Create ContainerClient from a container url.
  syntax:
    content: from_container_url(container_url, credential=None, **kwargs)
    parameters:
    - description: 'The full endpoint URL to the Container, including SAS token if
        used. This could be

        either the primary endpoint, or the secondary endpoint depending on the current
        *location_mode*.'
      id: container_url
      isRequired: true
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token, or the connection string already has
        shared

        access key values. The value can be a SAS token string, an account shared
        access

        key, or an instance of a TokenCredentials class from azure.identity.

        Credentials provided here will take precedence over those in the connection
        string.'
      id: credential
      isRequired: true
    - defaultValue: None
      id: credential
    return:
      description: A container client.
      type:
      - azure.storage.blob.ContainerClient
  type: method
  uid: azure.storage.blob.ContainerClient.from_container_url
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.get_account_information
  langs:
  - python
  module: azure.storage.blob
  name: get_account_information(**kwargs)
  namewithoutparameters: get_account_information
  summary: 'Gets information related to the storage account.


    The information can also be retrieved if the user has a SAS to a container or
    blob.

    The keys in the returned dictionary include ''sku_name'' and ''account_kind''.'
  syntax:
    content: get_account_information(**kwargs)
    return:
      description: A dict of account information (SKU and account type).
      type:
      - dict(str, str)
  type: method
  uid: azure.storage.blob.ContainerClient.get_account_information
- class: azure.storage.blob.ContainerClient
  example:
  - "Get the blob client.<!--[!code-python[Main](les\\blob_samples_containers.py )]-->\n\
    \n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
    : [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\90\\\\\
    azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\", \"xml:space\"\
    : \"preserve\", \"language\": \"python\", \"linenos\": false, \"highlight_args\"\
    : {\"linenostart\": 1}} -->\n\n````python\n\n   # Get the BlobClient from the\
    \ ContainerClient to interact with a specific blob\n   blob_client = container_client.get_blob_client(\"\
    mynewblob\")\n\n   ````\n"
  fullName: azure.storage.blob.ContainerClient.get_blob_client
  langs:
  - python
  module: azure.storage.blob
  name: get_blob_client(blob, snapshot=None)
  namewithoutparameters: get_blob_client
  summary: 'Get a client to interact with the specified blob.


    The blob need not already exist.'
  syntax:
    content: get_blob_client(blob, snapshot=None)
    parameters:
    - description: The blob with which to interact.
      id: blob
      isRequired: true
      type:
      - str
      - azure.storage.blob.BlobProperties
    - defaultValue: None
      description: 'The optional blob snapshot on which to operate. This can be the
        snapshot ID string

        or the response returned from <xref:BlobClient.create_snapshot>.'
      id: snapshot
      type:
      - str
    return:
      description: A BlobClient.
      type:
      - azure.storage.blob.BlobClient
  type: method
  uid: azure.storage.blob.ContainerClient.get_blob_client
- class: azure.storage.blob.ContainerClient
  example:
  - "Getting the access policy on the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   policy = container_client.get_container_access_policy()\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.get_container_access_policy
  langs:
  - python
  module: azure.storage.blob
  name: get_container_access_policy(**kwargs)
  namewithoutparameters: get_container_access_policy
  summary: 'Gets the permissions for the specified container.

    The permissions indicate whether container data may be accessed publicly.'
  syntax:
    content: get_container_access_policy(**kwargs)
    parameters:
    - description: 'If specified, get_container_access_policy only succeeds if the

        container''s lease is active and matches this ID.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: Access policy information in a dict.
      type:
      - dict[str, Any]
  type: method
  uid: azure.storage.blob.ContainerClient.get_container_access_policy
- class: azure.storage.blob.ContainerClient
  example:
  - "Getting properties on the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   properties = container_client.get_container_properties()\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.get_container_properties
  langs:
  - python
  module: azure.storage.blob
  name: get_container_properties(**kwargs)
  namewithoutparameters: get_container_properties
  summary: 'Returns all user-defined metadata and system properties for the specified

    container. The data returned does not include the container''s list of blobs.'
  syntax:
    content: get_container_properties(**kwargs)
    parameters:
    - description: 'If specified, get_container_properties only succeeds if the

        container''s lease is active and matches this ID.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: Properties for the specified container within a container object.
      type:
      - azure.storage.blob.ContainerProperties
  type: method
  uid: azure.storage.blob.ContainerClient.get_container_properties
- class: azure.storage.blob.ContainerClient
  example:
  - "List the blobs in the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   blobs_list = container_client.list_blobs()\n\
    \   for blob in blobs_list:\n       print(blob.name + '\\n')\n\n   ````\n"
  fullName: azure.storage.blob.ContainerClient.list_blobs
  langs:
  - python
  module: azure.storage.blob
  name: list_blobs(name_starts_with=None, include=None, **kwargs)
  namewithoutparameters: list_blobs
  summary: 'Returns a generator to list the blobs under the specified container.

    The generator will lazily follow the continuation tokens returned by

    the service.'
  syntax:
    content: list_blobs(name_starts_with=None, include=None, **kwargs)
    parameters:
    - description: 'Filters the results to return only blobs whose names

        begin with the specified prefix.'
      id: name_starts_with
      isRequired: true
      type:
      - str
    - description: 'Specifies one or more additional datasets to include in the response.

        Options include: ''snapshots'', ''metadata'', ''uncommittedblobs'', ''copy'',
        ''deleted''.'
      id: include
      isRequired: true
      type:
      - list[str]
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: An iterable (auto-paging) response of BlobProperties.
      type:
      - azure.core.paging.ItemPaged[azure.storage.blob.BlobProperties]
  type: method
  uid: azure.storage.blob.ContainerClient.list_blobs
- class: azure.storage.blob.ContainerClient
  example:
  - "Setting access policy on the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   # Create access\
    \ policy\n   from azure.storage.blob import AccessPolicy, ContainerSasPermissions\n\
    \   access_policy = AccessPolicy(permission=ContainerSasPermissions(read=True),\n\
    \                                expiry=datetime.utcnow() + timedelta(hours=1),\n\
    \                                start=datetime.utcnow() - timedelta(minutes=1))\n\
    \n   identifiers = {'test': access_policy}\n\n   # Set the access policy on the\
    \ container\n   container_client.set_container_access_policy(signed_identifiers=identifiers)\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.set_container_access_policy
  langs:
  - python
  module: azure.storage.blob
  name: set_container_access_policy(signed_identifiers, public_access=None, **kwargs)
  namewithoutparameters: set_container_access_policy
  summary: 'Sets the permissions for the specified container or stored access

    policies that may be used with Shared Access Signatures. The permissions

    indicate whether blobs in a container may be accessed publicly.'
  syntax:
    content: set_container_access_policy(signed_identifiers, public_access=None, **kwargs)
    parameters:
    - description: 'A dictionary of access policies to associate with the container.
        The

        dictionary may contain up to 5 elements. An empty dictionary

        will clear the access policies set on the service.'
      id: signed_identifiers
      isRequired: true
      type:
      - dict[str, azure.storage.blob.AccessPolicy]
    - description: 'Possible values include: ''container'', ''blob''.'
      id: public_access
      isRequired: true
      type:
      - azure.storage.blob.PublicAccess
    - description: 'Required if the container has an active lease. Value can be a
        BlobLeaseClient object

        or the lease ID as a string.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A datetime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified date/time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A datetime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: Container-updated property dict (Etag and last modified).
      type:
      - dict[str, str
      - datetime.datetime]
  type: method
  uid: azure.storage.blob.ContainerClient.set_container_access_policy
- class: azure.storage.blob.ContainerClient
  example:
  - "Setting metadata on the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   # Create key,\
    \ value pairs for metadata\n   metadata = {'type': 'test'}\n\n   # Set metadata\
    \ on the container\n   container_client.set_container_metadata(metadata=metadata)\n\
    \n   ````\n"
  fullName: azure.storage.blob.ContainerClient.set_container_metadata
  langs:
  - python
  module: azure.storage.blob
  name: set_container_metadata(metadata=None, **kwargs)
  namewithoutparameters: set_container_metadata
  summary: 'Sets one or more user-defined name-value pairs for the specified

    container. Each call to this operation replaces all existing metadata

    attached to the container. To remove all metadata from the container,

    call this operation with no metadata dict.'
  syntax:
    content: set_container_metadata(metadata=None, **kwargs)
    parameters:
    - description: 'A dict containing name-value pairs to associate with the container
        as

        metadata. Example: {''category'':''test''}'
      id: metadata
      isRequired: true
      type:
      - dict[str, str]
    - description: 'If specified, set_container_metadata only succeeds if the

        container''s lease is active and matches this ID.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: Container-updated property dict (Etag and last modified).
      type:
      - dict[str, str
      - datetime]
  type: method
  uid: azure.storage.blob.ContainerClient.set_container_metadata
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.set_premium_page_blob_tier_blobs
  langs:
  - python
  module: azure.storage.blob
  name: set_premium_page_blob_tier_blobs(premium_page_blob_tier, *blobs, **kwargs)
  namewithoutparameters: set_premium_page_blob_tier_blobs
  summary: Sets the page blob tiers on all blobs. This API is only supported for page
    blobs on premium accounts.
  syntax:
    content: set_premium_page_blob_tier_blobs(premium_page_blob_tier, *blobs, **kwargs)
    parameters:
    - description: 'A page blob tier value to set the blob to. The tier correlates
        to the size of the

        blob and number of allowed IOPS. This is only applicable to page blobs on

        premium storage accounts.



        > [!NOTE]

        > If you want to set different tier on different blobs please set this positional
        parameter to None.

        >

        > Then the blob tier on every BlobProperties will be taken.

        >'
      id: premium_page_blob_tier
      isRequired: true
      type:
      - azure.storage.blob.PremiumPageBlobTier
    - description: "The blobs with which to interact. This can be a single blob, or\
        \ multiple values can\nbe supplied, where each value is either the name of\
        \ the blob (str) or BlobProperties.\n\n\n> [!NOTE]\n> When the blob type is\
        \ dict, here's a list of keys, value rules.\n>\n> \n>\n> blob name:\n>\n>\
        \ \n>\n> key: 'name', value type: str\n>\n> \n>\n> premium blob tier:\n>\n\
        > \n>\n> key: 'blob_tier', value type: PremiumPageBlobTier\n>\n> \n>\n> lease:\n\
        >\n> \n>\n> key: 'lease_id', value type: Union[str, LeaseClient]\n>\n> \n\
        >\n> timeout for subrequest:\n>\n> \n>\n> key: 'timeout', value type: int\n\
        >"
      id: blobs
      isRequired: true
      type:
      - list[str], list[dict],
      - list[azure.storage.blob.BlobProperties]
    - description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.'
      id: timeout
      isRequired: true
      type:
      - int
    - description: 'This is a boolean param which defaults to True. When this is set,
        an exception

        is raised even if there is a single operation failure.'
      id: raise_on_any_failure
      isRequired: true
      type:
      - bool
    return:
      description: An iterator of responses, one for each blob in order
      type:
      - iterator[azure.core.pipeline.transport.HttpResponse]
  type: method
  uid: azure.storage.blob.ContainerClient.set_premium_page_blob_tier_blobs
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.set_standard_blob_tier_blobs
  langs:
  - python
  module: azure.storage.blob
  name: set_standard_blob_tier_blobs(standard_blob_tier, *blobs, **kwargs)
  namewithoutparameters: set_standard_blob_tier_blobs
  summary: 'This operation sets the tier on block blobs.


    A block blob''s tier determines Hot/Cool/Archive storage type.

    This operation does not update the blob''s ETag.'
  syntax:
    content: set_standard_blob_tier_blobs(standard_blob_tier, *blobs, **kwargs)
    parameters:
    - description: 'Indicates the tier to be set on all blobs. Options include ''Hot'',
        ''Cool'',

        ''Archive''. The hot tier is optimized for storing data that is accessed

        frequently. The cool storage tier is optimized for storing data that

        is infrequently accessed and stored for at least a month. The archive

        tier is optimized for storing data that is rarely accessed and stored

        for at least six months with flexible latency requirements.



        > [!NOTE]

        > If you want to set different tier on different blobs please set this positional
        parameter to None.

        >

        > Then the blob tier on every BlobProperties will be taken.

        >'
      id: standard_blob_tier
      isRequired: true
      type:
      - str
      - azure.storage.blob.StandardBlobTier
    - description: "The blobs with which to interact. This can be a single blob, or\
        \ multiple values can\nbe supplied, where each value is either the name of\
        \ the blob (str) or BlobProperties.\n\n\n> [!NOTE]\n> When the blob type is\
        \ dict, here's a list of keys, value rules.\n>\n> \n>\n> blob name:\n>\n>\
        \ \n>\n> key: 'name', value type: str\n>\n> \n>\n> standard blob tier:\n>\n\
        > \n>\n> key: 'blob_tier', value type: StandardBlobTier\n>\n> \n>\n> rehydrate\
        \ priority:\n>\n> \n>\n> key: 'rehydrate_priority', value type: RehydratePriority\n\
        >\n> \n>\n> lease:\n>\n> \n>\n> key: 'lease_id', value type: Union[str, LeaseClient]\n\
        >\n> \n>\n> timeout for subrequest:\n>\n> \n>\n> key: 'timeout', value type:\
        \ int\n>"
      id: blobs
      isRequired: true
      type:
      - list[str], list[dict],
      - list[azure.storage.blob.BlobProperties]
    - description: Indicates the priority with which to rehydrate an archived blob
      id: rehydrate_priority
      isRequired: true
      type:
      - azure.storage.blob.RehydratePriority
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    - description: 'This is a boolean param which defaults to True. When this is set,
        an exception

        is raised even if there is a single operation failure.'
      id: raise_on_any_failure
      isRequired: true
      type:
      - bool
    return:
      description: An iterator of responses, one for each blob in order
      type:
      - Iterator[azure.core.pipeline.transport.HttpResponse]
  type: method
  uid: azure.storage.blob.ContainerClient.set_standard_blob_tier_blobs
- class: azure.storage.blob.ContainerClient
  example:
  - "Upload blob to the container.<!--[!code-python[Main](les\\blob_samples_containers.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\90\\\\azure-storage-blob-12.3.2\\\\samples\\\\blob_samples_containers.py\",\
    \ \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   with open(SOURCE_FILE,\
    \ \"rb\") as data:\n       blob_client = container_client.upload_blob(name=\"\
    myblob\", data=data)\n\n   properties = blob_client.get_blob_properties()\n\n\
    \   ````\n"
  fullName: azure.storage.blob.ContainerClient.upload_blob
  langs:
  - python
  module: azure.storage.blob
  name: 'upload_blob(name, data, blob_type=<BlobType.BlockBlob: ''BlockBlob''>, length=None,
    metadata=None, **kwargs)'
  namewithoutparameters: upload_blob
  summary: Creates a new blob from a data source with automatic chunking.
  syntax:
    content: 'upload_blob(name, data, blob_type=<BlobType.BlockBlob: ''BlockBlob''>,
      length=None, metadata=None, **kwargs)'
    parameters:
    - description: 'The blob with which to interact. If specified, this value will
        override

        a blob value specified in the blob URL.'
      id: name
      isRequired: true
      type:
      - str
      - azure.storage.blob.BlobProperties
    - description: The blob data to upload.
      id: data
      isRequired: true
    - description: 'The type of the blob. This can be

        either BlockBlob, PageBlob or AppendBlob. The default value is BlockBlob.'
      id: blob_type
      isRequired: true
      type:
      - azure.storage.blob.BlobType
    - description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      isRequired: true
      type:
      - int
    - description: Name-value pairs associated with the blob as metadata.
      id: metadata
      isRequired: true
      type:
      - dict(str, str)
    - description: 'Whether the blob to be uploaded should overwrite the current data.

        If True, upload_blob will overwrite the existing data. If set to False, the

        operation will fail with ResourceExistsError. The exception to the above is
        with Append

        blob types: if set to False and the data already exists, an error will not
        be raised

        and the data will be appended to the existing blob. If set overwrite=True,
        then the existing

        append blob will be deleted, and a new one created. Defaults to False.'
      id: overwrite
      isRequired: true
      type:
      - bool
    - description: 'ContentSettings object used to set blob properties. Used to set
        content type, encoding,

        language, disposition, md5, and cache control.'
      id: content_settings
      isRequired: true
      type:
      - azure.storage.blob.ContentSettings
    - description: 'If true, calculates an MD5 hash for each chunk of the blob. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https, as https (the default), will

        already validate. Note that this MD5 hash is not stored with the

        blob. Also note that if enabled, the memory-efficient upload algorithm

        will not be used, because computing the MD5 hash requires buffering

        entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
      id: validate_content
      isRequired: true
      type:
      - bool
    - description: 'Required if the container has an active lease. Value can be a
        BlobLeaseClient object

        or the lease ID as a string.'
      id: lease
      isRequired: true
      type:
      - azure.storage.blob.BlobLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: 'The timeout parameter is expressed in seconds. This method may
        make

        multiple calls to the Azure service and the timeout will apply to

        each call individually.'
      id: timeout
      isRequired: true
      type:
      - int
    - description: 'A page blob tier value to set the blob to. The tier correlates
        to the size of the

        blob and number of allowed IOPS. This is only applicable to page blobs on

        premium storage accounts.'
      id: premium_page_blob_tier
      isRequired: true
      type:
      - azure.storage.blob.PremiumPageBlobTier
    - description: 'A standard blob tier value to set the blob to. For this version
        of the library,

        this is only applicable to block blobs on standard storage accounts.'
      id: standard_blob_tier
      isRequired: true
      type:
      - azure.storage.blob.StandardBlobTier
    - description: 'Optional conditional header. The max length in bytes permitted
        for

        the append blob. If the Append Block operation would cause the blob

        to exceed that limit or if the blob size is already greater than the

        value specified in this header, the request will fail with

        MaxBlobSizeConditionNotMet error (HTTP status code 412 - Precondition Failed).'
      id: maxsize_condition
      isRequired: true
      type:
      - int
    - description: 'Maximum number of parallel connections to use when the blob size
        exceeds

        64MB.'
      id: max_concurrency
      isRequired: true
      type:
      - int
    - description: 'Encrypts the data on the service-side with the given key.

        Use of customer-provided keys must be done over HTTPS.

        As the encryption key itself is provided in the request,

        a secure connection must be established to transfer the key.'
      id: cpk
      isRequired: true
      type:
      - azure.storage.blob.CustomerProvidedEncryptionKey
    - description: 'A predefined encryption scope used to encrypt the data on the
        service. An encryption

        scope can be created using the Management API and referenced here by name.
        If a default

        encryption scope has been defined at the container, this value will override
        it if the

        container-level scope is configured to allow overrides. Otherwise an error
        will be raised.


        New in version 12.2.0.'
      id: encryption_scope
      isRequired: true
      type:
      - str
    - description: Defaults to UTF-8.
      id: encoding
      isRequired: true
      type:
      - str
    return:
      description: A BlobClient to interact with the newly uploaded blob.
      type:
      - azure.storage.blob.BlobClient
  type: method
  uid: azure.storage.blob.ContainerClient.upload_blob
- class: azure.storage.blob.ContainerClient
  fullName: azure.storage.blob.ContainerClient.walk_blobs
  langs:
  - python
  module: azure.storage.blob
  name: walk_blobs(name_starts_with=None, include=None, delimiter='/', **kwargs)
  namewithoutparameters: walk_blobs
  summary: 'Returns a generator to list the blobs under the specified container.

    The generator will lazily follow the continuation tokens returned by

    the service. This operation will list blobs in accordance with a hierarchy,

    as delimited by the specified delimiter character.'
  syntax:
    content: walk_blobs(name_starts_with=None, include=None, delimiter='/', **kwargs)
    parameters:
    - description: 'Filters the results to return only blobs whose names

        begin with the specified prefix.'
      id: name_starts_with
      isRequired: true
      type:
      - str
    - description: 'Specifies one or more additional datasets to include in the response.

        Options include: ''snapshots'', ''metadata'', ''uncommittedblobs'', ''copy'',
        ''deleted''.'
      id: include
      isRequired: true
      type:
      - list[str]
    - description: 'When the request includes this parameter, the operation returns
        a BlobPrefix

        element in the response body that acts as a placeholder for all blobs whose

        names begin with the same substring up to the appearance of the delimiter

        character. The delimiter may be a single character or a string.'
      id: delimiter
      isRequired: true
      type:
      - str
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: An iterable (auto-paging) response of BlobProperties.
      type:
      - azure.core.paging.ItemPaged[azure.storage.blob.BlobProperties]
  type: method
  uid: azure.storage.blob.ContainerClient.walk_blobs
references:
- fullName: azure.storage.blob.ContainerClient.acquire_lease
  isExternal: false
  name: acquire_lease(lease_duration=-1, lease_id=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.acquire_lease
- fullName: azure.storage.blob.ContainerClient.create_container
  isExternal: false
  name: create_container(metadata=None, public_access=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.create_container
- fullName: azure.storage.blob.ContainerClient.delete_blob
  isExternal: false
  name: delete_blob(blob, delete_snapshots=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.delete_blob
- fullName: azure.storage.blob.ContainerClient.delete_blobs
  isExternal: false
  name: delete_blobs(*blobs, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.delete_blobs
- fullName: azure.storage.blob.ContainerClient.delete_container
  isExternal: false
  name: delete_container(**kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.delete_container
- fullName: azure.storage.blob.ContainerClient.download_blob
  isExternal: false
  name: download_blob(blob, offset=None, length=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.download_blob
- fullName: azure.storage.blob.ContainerClient.from_connection_string
  isExternal: false
  name: from_connection_string(conn_str, container_name, credential=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.from_connection_string
- fullName: azure.storage.blob.ContainerClient.from_container_url
  isExternal: false
  name: from_container_url(container_url, credential=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.from_container_url
- fullName: azure.storage.blob.ContainerClient.get_account_information
  isExternal: false
  name: get_account_information(**kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.get_account_information
- fullName: azure.storage.blob.ContainerClient.get_blob_client
  isExternal: false
  name: get_blob_client(blob, snapshot=None)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.get_blob_client
- fullName: azure.storage.blob.ContainerClient.get_container_access_policy
  isExternal: false
  name: get_container_access_policy(**kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.get_container_access_policy
- fullName: azure.storage.blob.ContainerClient.get_container_properties
  isExternal: false
  name: get_container_properties(**kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.get_container_properties
- fullName: azure.storage.blob.ContainerClient.list_blobs
  isExternal: false
  name: list_blobs(name_starts_with=None, include=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.list_blobs
- fullName: azure.storage.blob.ContainerClient.set_container_access_policy
  isExternal: false
  name: set_container_access_policy(signed_identifiers, public_access=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.set_container_access_policy
- fullName: azure.storage.blob.ContainerClient.set_container_metadata
  isExternal: false
  name: set_container_metadata(metadata=None, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.set_container_metadata
- fullName: azure.storage.blob.ContainerClient.set_premium_page_blob_tier_blobs
  isExternal: false
  name: set_premium_page_blob_tier_blobs(premium_page_blob_tier, *blobs, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.set_premium_page_blob_tier_blobs
- fullName: azure.storage.blob.ContainerClient.set_standard_blob_tier_blobs
  isExternal: false
  name: set_standard_blob_tier_blobs(standard_blob_tier, *blobs, **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.set_standard_blob_tier_blobs
- fullName: azure.storage.blob.ContainerClient.upload_blob
  isExternal: false
  name: 'upload_blob(name, data, blob_type=<BlobType.BlockBlob: ''BlockBlob''>, length=None,
    metadata=None, **kwargs)'
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.upload_blob
- fullName: azure.storage.blob.ContainerClient.walk_blobs
  isExternal: false
  name: walk_blobs(name_starts_with=None, include=None, delimiter='/', **kwargs)
  parent: azure.storage.blob.ContainerClient
  uid: azure.storage.blob.ContainerClient.walk_blobs
- fullName: dict[str, str]
  name: dict[str, str]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: ']'
    name: ']'
  uid: dict[str, str]
- fullName: list[str], list[dict],
  name: list[str], list[dict],
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ']'
    name: ']'
  - fullName: ', '
    name: ', '
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: dict
    name: dict
    uid: dict
  - fullName: ']'
    name: ']'
  - fullName: ','
    name: ','
    uid: ','
  uid: list[str], list[dict],
- fullName: list[azure.storage.blob.BlobProperties]
  name: list[BlobProperties]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: azure.storage.blob.BlobProperties
    name: BlobProperties
    uid: azure.storage.blob.BlobProperties
  - fullName: ']'
    name: ']'
  uid: list[azure.storage.blob.BlobProperties]
- fullName: Iterator[azure.core.pipeline.transport.HttpResponse]
  name: Iterator[HttpResponse]
  spec.python:
  - fullName: Iterator
    name: Iterator
    uid: Iterator
  - fullName: '['
    name: '['
  - fullName: azure.core.pipeline.transport.HttpResponse
    name: HttpResponse
    uid: azure.core.pipeline.transport.HttpResponse
  - fullName: ']'
    name: ']'
  uid: Iterator[azure.core.pipeline.transport.HttpResponse]
- fullName: dict(str, str)
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  uid: dict(str, str)
- fullName: dict[str, Any]
  name: dict[str, Any]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: Any
    name: Any
    uid: Any
  - fullName: ']'
    name: ']'
  uid: dict[str, Any]
- fullName: list[str]
  name: list[str]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ']'
    name: ']'
  uid: list[str]
- fullName: azure.core.paging.ItemPaged[azure.storage.blob.BlobProperties]
  name: ItemPaged[BlobProperties]
  spec.python:
  - fullName: azure.core.paging.ItemPaged
    name: ItemPaged
    uid: azure.core.paging.ItemPaged
  - fullName: '['
    name: '['
  - fullName: azure.storage.blob.BlobProperties
    name: BlobProperties
    uid: azure.storage.blob.BlobProperties
  - fullName: ']'
    name: ']'
  uid: azure.core.paging.ItemPaged[azure.storage.blob.BlobProperties]
- fullName: dict[str, azure.storage.blob.AccessPolicy]
  name: dict[str, AccessPolicy]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: azure.storage.blob.AccessPolicy
    name: AccessPolicy
    uid: azure.storage.blob.AccessPolicy
  - fullName: ']'
    name: ']'
  uid: dict[str, azure.storage.blob.AccessPolicy]
- fullName: dict[str, str
  name: dict[str, str
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  uid: dict[str, str
- fullName: datetime.datetime]
  name: datetime]
  spec.python:
  - fullName: datetime.datetime
    name: datetime
    uid: datetime.datetime
  - fullName: ']'
    name: ']'
  uid: datetime.datetime]
- fullName: datetime]
  name: datetime]
  spec.python:
  - fullName: datetime
    name: datetime
    uid: datetime
  - fullName: ']'
    name: ']'
  uid: datetime]
- fullName: iterator[azure.core.pipeline.transport.HttpResponse]
  name: iterator[HttpResponse]
  spec.python:
  - fullName: iterator
    name: iterator
    uid: iterator
  - fullName: '['
    name: '['
  - fullName: azure.core.pipeline.transport.HttpResponse
    name: HttpResponse
    uid: azure.core.pipeline.transport.HttpResponse
  - fullName: ']'
    name: ']'
  uid: iterator[azure.core.pipeline.transport.HttpResponse]
