### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: azure.mgmt.datafactory.models.AzureDatabricksLinkedService
  fullName: azure.mgmt.datafactory.models.AzureDatabricksLinkedService
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: msrest.serialization.Model
    type: azure.mgmt.datafactory.models._models_py3.LinkedService
  langs:
  - python
  module: azure.mgmt.datafactory.models
  name: AzureDatabricksLinkedService
  summary: 'Azure Databricks linked service.


    All required parameters must be populated in order to send to Azure.'
  syntax:
    content: 'AzureDatabricksLinkedService(*, domain, access_token, additional_properties=None,
      connect_via=None, description: str = None, parameters=None, annotations=None,
      existing_cluster_id=None, instance_pool_id=None, new_cluster_version=None, new_cluster_num_of_worker=None,
      new_cluster_node_type=None, new_cluster_spark_conf=None, new_cluster_spark_env_vars=None,
      new_cluster_custom_tags=None, new_cluster_log_destination=None, new_cluster_driver_node_type=None,
      new_cluster_init_scripts=None, new_cluster_enable_elastic_disk=None, encrypted_credential=None,
      **kwargs) -> None'
    parameters:
    - description: 'Unmatched properties from the message are

        deserialized this collection'
      id: additional_properties
      type:
      - dict[str, object]
    - description: The integration runtime reference.
      id: connect_via
      type:
      - azure.mgmt.datafactory.models.IntegrationRuntimeReference
    - description: Linked service description.
      id: description
      type:
      - str
    - description: Parameters for linked service.
      id: parameters
      type:
      - dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
    - description: 'List of tags that can be used for describing the

        linked service.'
      id: annotations
      type:
      - list[object]
    - description: Required. Constant filled by server.
      id: type
      type:
      - str
    - description: 'Required. <REGION>.azuredatabricks.net, domain name of your

        Databricks deployment. Type: string (or Expression with resultType

        string).'
      id: domain
      type:
      - object
    - description: 'Required. Access token for databricks REST API. Refer

        to [https://docs.azuredatabricks.net/api/latest/authentication.html](https://docs.azuredatabricks.net/api/latest/authentication.html).
        Type:

        string (or Expression with resultType string).'
      id: access_token
      type:
      - azure.mgmt.datafactory.models.SecretBase
    - description: 'The id of an existing interactive cluster that

        will be used for all runs of this activity. Type: string (or Expression

        with resultType string).'
      id: existing_cluster_id
      type:
      - object
    - description: 'The id of an existing instance pool that will be

        used for all runs of this activity. Type: string (or Expression with

        resultType string).'
      id: instance_pool_id
      type:
      - object
    - description: 'If not using an existing interactive cluster,

        this specifies the Spark version of a new job cluster or instance pool

        nodes created for each run of this activity. Required if instancePoolId is

        specified. Type: string (or Expression with resultType string).'
      id: new_cluster_version
      type:
      - object
    - description: 'If not using an existing interactive

        cluster, this specifies the number of worker nodes to use for the new job

        cluster or instance pool. For new job clusters, this a string-formatted

        Int32, like ''1'' means numOfWorker is 1 or ''1:10'' means auto-scale from
        1

        (min) to 10 (max). For instance pools, this is a string-formatted Int32,

        and can only specify a fixed number of worker nodes, such as ''2''. Required

        if newClusterVersion is specified. Type: string (or Expression with

        resultType string).'
      id: new_cluster_num_of_worker
      type:
      - object
    - description: 'The node type of the new job cluster. This

        property is required if newClusterVersion is specified and instancePoolId

        is not specified. If instancePoolId is specified, this property is

        ignored. Type: string (or Expression with resultType string).'
      id: new_cluster_node_type
      type:
      - object
    - description: 'A set of optional, user-specified Spark

        configuration key-value pairs.'
      id: new_cluster_spark_conf
      type:
      - dict[str, object]
    - description: 'A set of optional, user-specified Spark

        environment variables key-value pairs.'
      id: new_cluster_spark_env_vars
      type:
      - dict[str, object]
    - description: 'Additional tags for cluster resources.

        This property is ignored in instance pool configurations.'
      id: new_cluster_custom_tags
      type:
      - dict[str, object]
    - description: 'Specify a location to deliver Spark

        driver, worker, and event logs. Type: string (or Expression with

        resultType string).'
      id: new_cluster_log_destination
      type:
      - object
    - description: 'The driver node type for the new job

        cluster. This property is ignored in instance pool configurations. Type:

        string (or Expression with resultType string).'
      id: new_cluster_driver_node_type
      type:
      - object
    - description: 'User-defined initialization scripts for

        the new cluster. Type: array of strings (or Expression with resultType

        array of strings).'
      id: new_cluster_init_scripts
      type:
      - object
    - description: 'Enable the elastic disk on the new

        cluster. This property is now ignored, and takes the default elastic disk

        behavior in Databricks (elastic disks are always enabled). Type: boolean

        (or Expression with resultType boolean).'
      id: new_cluster_enable_elastic_disk
      type:
      - object
    - description: 'The encrypted credential used for

        authentication. Credentials are encrypted using the integration runtime

        credential manager. Type: string (or Expression with resultType string).'
      id: encrypted_credential
      type:
      - object
  type: class
  uid: azure.mgmt.datafactory.models.AzureDatabricksLinkedService
references:
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
  name: dict[ParameterSpecification]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str,azure.mgmt.datafactory.models.ParameterSpecification
    name: ParameterSpecification
    uid: str,azure.mgmt.datafactory.models.ParameterSpecification
  - fullName: ']'
    name: ']'
  uid: dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
- fullName: list[object]
  name: list[object]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: list[object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
