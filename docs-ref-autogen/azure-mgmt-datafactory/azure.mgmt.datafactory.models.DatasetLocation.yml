### YamlMime:PythonClass
uid: azure.mgmt.datafactory.models.DatasetLocation
name: DatasetLocation
fullName: azure.mgmt.datafactory.models.DatasetLocation
module: azure.mgmt.datafactory.models
inheritances:
- azure.mgmt.datafactory._serialization.Model
summary: 'Dataset location.


  You probably want to use the sub-classes and not this class directly. Known sub-classes
  are:

  AmazonS3CompatibleLocation, AmazonS3Location, AzureBlobFSLocation, AzureBlobStorageLocation,

  AzureDataLakeStoreLocation, AzureFileStorageLocation, FileServerLocation, FtpServerLocation,

  GoogleCloudStorageLocation, HdfsLocation, HttpServerLocation, OracleCloudStorageLocation,

  SftpLocation


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'DatasetLocation(*, additional_properties: Dict[str, MutableMapping[str,
    Any]] | None = None, folder_path: MutableMapping[str, Any] | None = None, file_name:
    MutableMapping[str, Any] | None = None, **kwargs)'
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:azure.mgmt.datafactory.models.dict>[<xref:azure.mgmt.datafactory.models.str>,
    <xref:azure.mgmt.datafactory.models.JSON>]
- description: Type of dataset storage location. Required.
  name: type
  types:
  - <xref:azure.mgmt.datafactory.models.str>
- description: 'Specify the folder path of dataset. Type: string (or Expression with

    resultType string).'
  name: folder_path
  types:
  - <xref:azure.mgmt.datafactory.models.JSON>
- description: 'Specify the file name of dataset. Type: string (or Expression with
    resultType

    string).'
  name: file_name
  types:
  - <xref:azure.mgmt.datafactory.models.JSON>
