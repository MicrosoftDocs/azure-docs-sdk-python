### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: azure.mgmt.datafactory.models.SapTableSource
  fullName: azure.mgmt.datafactory.models.SapTableSource
  inheritance:
  - inheritance:
    - inheritance:
      - inheritance:
        - type: builtins.object
        type: msrest.serialization.Model
      type: azure.mgmt.datafactory.models._models_py3.CopySource
    type: azure.mgmt.datafactory.models._models_py3.TabularSource
  langs:
  - python
  module: azure.mgmt.datafactory.models
  name: SapTableSource
  summary: 'A copy activity source for SAP Table source.


    All required parameters must be populated in order to send to Azure.'
  syntax:
    content: SapTableSource(*, additional_properties=None, source_retry_count=None,
      source_retry_wait=None, max_concurrent_connections=None, query_timeout=None,
      additional_columns=None, row_count=None, row_skips=None, rfc_table_fields=None,
      rfc_table_options=None, batch_size=None, custom_rfc_read_table_function_module=None,
      sap_data_column_delimiter=None, partition_option=None, partition_settings=None,
      **kwargs) -> None
    parameters:
    - description: 'Unmatched properties from the message are

        deserialized this collection'
      id: additional_properties
      type:
      - dict[str, object]
    - description: 'Source retry count. Type: integer (or

        Expression with resultType integer).'
      id: source_retry_count
      type:
      - object
    - description: 'Source retry wait. Type: string (or Expression

        with resultType string), pattern:

        ((d+).)?(dd):(60|([0-5][0-9])):(60|([0-5][0-9])).'
      id: source_retry_wait
      type:
      - object
    - description: 'The maximum concurrent connection count

        for the source data store. Type: integer (or Expression with resultType

        integer).'
      id: max_concurrent_connections
      type:
      - object
    - description: Required. Constant filled by server.
      id: type
      type:
      - str
    - description: 'Query timeout. Type: string (or Expression with

        resultType string), pattern:

        ((d+).)?(dd):(60|([0-5][0-9])):(60|([0-5][0-9])).'
      id: query_timeout
      type:
      - object
    - description: 'Specifies the additional columns to be added to

        source data. Type: array of objects (or Expression with resultType array

        of objects).'
      id: additional_columns
      type:
      - list[azure.mgmt.datafactory.models.AdditionalColumns]
    - description: 'The number of rows to be retrieved. Type: integer(or

        Expression with resultType integer).'
      id: row_count
      type:
      - object
    - description: 'The number of rows that will be skipped. Type: integer

        (or Expression with resultType integer).'
      id: row_skips
      type:
      - object
    - description: 'The fields of the SAP table that will be

        retrieved. For example, column0, column1. Type: string (or Expression with

        resultType string).'
      id: rfc_table_fields
      type:
      - object
    - description: 'The options for the filtering of the SAP Table.

        For example, COLUMN0 EQ SOME VALUE. Type: string (or Expression with

        resultType string).'
      id: rfc_table_options
      type:
      - object
    - description: 'Specifies the maximum number of rows that will be

        retrieved at a time when retrieving data from SAP Table. Type: integer (or

        Expression with resultType integer).'
      id: batch_size
      type:
      - object
    - description: 'Specifies the custom RFC

        function module that will be used to read data from SAP Table. Type:

        string (or Expression with resultType string).'
      id: custom_rfc_read_table_function_module
      type:
      - object
    - description: 'The single character that will be used

        as delimiter passed to SAP RFC as well as splitting the output data

        retrieved. Type: string (or Expression with resultType string).'
      id: sap_data_column_delimiter
      type:
      - object
    - description: 'The partition mechanism that will be used for SAP

        table read in parallel. Possible values include: ''None'', ''PartitionOnInt'',

        ''PartitionOnCalendarYear'', ''PartitionOnCalendarMonth'',

        ''PartitionOnCalendarDate'', ''PartitionOnTime'''
      id: partition_option
      type:
      - str
      - azure.mgmt.datafactory.models.SapTablePartitionOption
    - description: 'The settings that will be leveraged for SAP

        table source partitioning.'
      id: partition_settings
      type:
      - azure.mgmt.datafactory.models.SapTablePartitionSettings
  type: class
  uid: azure.mgmt.datafactory.models.SapTableSource
references:
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: list[azure.mgmt.datafactory.models.AdditionalColumns]
  name: list[AdditionalColumns]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: azure.mgmt.datafactory.models.AdditionalColumns
    name: AdditionalColumns
    uid: azure.mgmt.datafactory.models.AdditionalColumns
  - fullName: ']'
    name: ']'
  uid: list[azure.mgmt.datafactory.models.AdditionalColumns]
