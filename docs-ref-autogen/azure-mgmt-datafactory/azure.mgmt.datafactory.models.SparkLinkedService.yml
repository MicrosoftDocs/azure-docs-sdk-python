### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: azure.mgmt.datafactory.models.SparkLinkedService
  fullName: azure.mgmt.datafactory.models.SparkLinkedService
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: msrest.serialization.Model
    type: azure.mgmt.datafactory.models._models_py3.LinkedService
  langs:
  - python
  module: azure.mgmt.datafactory.models
  name: SparkLinkedService
  summary: 'Spark Server linked service.


    All required parameters must be populated in order to send to Azure.'
  syntax:
    content: 'SparkLinkedService(*, host, port, authentication_type, additional_properties=None,
      connect_via=None, description: str = None, parameters=None, annotations=None,
      server_type=None, thrift_transport_protocol=None, username=None, password=None,
      http_path=None, enable_ssl=None, trusted_cert_path=None, use_system_trust_store=None,
      allow_host_name_cn_mismatch=None, allow_self_signed_server_cert=None, encrypted_credential=None,
      **kwargs) -> None'
    parameters:
    - description: 'Unmatched properties from the message are

        deserialized this collection'
      id: additional_properties
      type:
      - dict[str, object]
    - description: The integration runtime reference.
      id: connect_via
      type:
      - azure.mgmt.datafactory.models.IntegrationRuntimeReference
    - description: Linked service description.
      id: description
      type:
      - str
    - description: Parameters for linked service.
      id: parameters
      type:
      - dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
    - description: 'List of tags that can be used for describing the

        linked service.'
      id: annotations
      type:
      - list[object]
    - description: Required. Constant filled by server.
      id: type
      type:
      - str
    - description: Required. IP address or host name of the Spark server
      id: host
      type:
      - object
    - description: 'Required. The TCP port that the Spark server uses to listen

        for client connections.'
      id: port
      type:
      - object
    - description: 'The type of Spark server. Possible values include:

        ''SharkServer'', ''SharkServer2'', ''SparkThriftServer'''
      id: server_type
      type:
      - str
      - azure.mgmt.datafactory.models.SparkServerType
    - description: 'The transport protocol to use in the

        Thrift layer. Possible values include: ''Binary'', ''SASL'', ''HTTP '''
      id: thrift_transport_protocol
      type:
      - str
      - azure.mgmt.datafactory.models.SparkThriftTransportProtocol
    - description: 'Required. The authentication method used to

        access the Spark server. Possible values include: ''Anonymous'', ''Username'',

        ''UsernameAndPassword'', ''WindowsAzureHDInsightService'''
      id: authentication_type
      type:
      - str
      - azure.mgmt.datafactory.models.SparkAuthenticationType
    - description: The user name that you use to access Spark Server.
      id: username
      type:
      - object
    - description: 'The password corresponding to the user name that you

        provided in the Username field'
      id: password
      type:
      - azure.mgmt.datafactory.models.SecretBase
    - description: The partial URL corresponding to the Spark server.
      id: http_path
      type:
      - object
    - description: 'Specifies whether the connections to the server are

        encrypted using SSL. The default value is false.'
      id: enable_ssl
      type:
      - object
    - description: 'The full path of the .pem file containing

        trusted CA certificates for verifying the server when connecting over SSL.

        This property can only be set when using SSL on self-hosted IR. The

        default value is the cacerts.pem file installed with the IR.'
      id: trusted_cert_path
      type:
      - object
    - description: 'Specifies whether to use a CA certificate

        from the system trust store or from a specified PEM file. The default

        value is false.'
      id: use_system_trust_store
      type:
      - object
    - description: 'Specifies whether to require a

        CA-issued SSL certificate name to match the host name of the server when

        connecting over SSL. The default value is false.'
      id: allow_host_name_cn_mismatch
      type:
      - object
    - description: 'Specifies whether to allow

        self-signed certificates from the server. The default value is false.'
      id: allow_self_signed_server_cert
      type:
      - object
    - description: 'The encrypted credential used for

        authentication. Credentials are encrypted using the integration runtime

        credential manager. Type: string (or Expression with resultType string).'
      id: encrypted_credential
      type:
      - object
  type: class
  uid: azure.mgmt.datafactory.models.SparkLinkedService
references:
- fullName: dict[str, object]
  name: dict[str, object]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: dict[str, object]
- fullName: dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
  name: dict[ParameterSpecification]
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: '['
    name: '['
  - fullName: str,azure.mgmt.datafactory.models.ParameterSpecification
    name: ParameterSpecification
    uid: str,azure.mgmt.datafactory.models.ParameterSpecification
  - fullName: ']'
    name: ']'
  uid: dict[str,azure.mgmt.datafactory.models.ParameterSpecification]
- fullName: list[object]
  name: list[object]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: object
    name: object
    uid: object
  - fullName: ']'
    name: ']'
  uid: list[object]
