### YamlMime:PythonClass
uid: azure.mgmt.datafactory.models.HDInsightSparkActivity
name: HDInsightSparkActivity
fullName: azure.mgmt.datafactory.models.HDInsightSparkActivity
module: azure.mgmt.datafactory.models
inheritances:
- azure.mgmt.datafactory.models._models_py3.ExecutionActivity
summary: 'HDInsight Spark activity.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'HDInsightSparkActivity(*, name: str, root_path: MutableMapping[str, Any],
    entry_file_path: MutableMapping[str, Any], additional_properties: Dict[str, MutableMapping[str,
    Any]] | None = None, description: str | None = None, depends_on: List[_models.ActivityDependency]
    | None = None, user_properties: List[_models.UserProperty] | None = None, linked_service_name:
    _models.LinkedServiceReference | None = None, policy: _models.ActivityPolicy |
    None = None, arguments: List[MutableMapping[str, Any]] | None = None, get_debug_info:
    str | _models.HDInsightActivityDebugInfoOption | None = None, spark_job_linked_service:
    _models.LinkedServiceReference | None = None, class_name: str | None = None, proxy_user:
    MutableMapping[str, Any] | None = None, spark_config: Dict[str, MutableMapping[str,
    Any]] | None = None, **kwargs)'
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:dict>[<xref:str>, <xref:azure.mgmt.datafactory.models.JSON>]
- description: Activity name. Required.
  name: name
  types:
  - <xref:str>
- description: Type of activity. Required.
  name: type
  types:
  - <xref:str>
- description: Activity description.
  name: description
  types:
  - <xref:str>
- description: Activity depends on condition.
  name: depends_on
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.ActivityDependency>]
- description: Activity user properties.
  name: user_properties
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.UserProperty>]
- description: Linked service reference.
  name: linked_service_name
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: Activity policy.
  name: policy
  types:
  - <xref:azure.mgmt.datafactory.models.ActivityPolicy>
- description: 'The root path in ''sparkJobLinkedService'' for all the job''s files.
    Type: string

    (or Expression with resultType string). Required.'
  name: root_path
  types:
  - <xref:azure.mgmt.datafactory.models.JSON>
- description: 'The relative path to the root folder of the code/package to be executed.

    Type: string (or Expression with resultType string). Required.'
  name: entry_file_path
  types:
  - <xref:azure.mgmt.datafactory.models.JSON>
- description: The user-specified arguments to HDInsightSparkActivity.
  name: arguments
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.JSON>]
- description: 'Debug info option. Known values are: "None", "Always", and "Failure".'
  name: get_debug_info
  types:
  - <xref:str>
  - <xref:azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption>
- description: 'The storage linked service for uploading the entry file and

    dependencies, and for receiving logs.'
  name: spark_job_linked_service
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: The application's Java/Spark main class.
  name: class_name
  types:
  - <xref:str>
- description: 'The user to impersonate that will execute the job. Type: string (or

    Expression with resultType string).'
  name: proxy_user
  types:
  - <xref:azure.mgmt.datafactory.models.JSON>
- description: Spark configuration property.
  name: spark_config
  types:
  - <xref:dict>[<xref:str>, <xref:azure.mgmt.datafactory.models.JSON>]
