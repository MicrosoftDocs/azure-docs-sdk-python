### YamlMime:PythonClass
uid: azure.mgmt.datafactory.models.HDInsightSparkActivity
name: HDInsightSparkActivity
fullName: azure.mgmt.datafactory.models.HDInsightSparkActivity
module: azure.mgmt.datafactory.models
inheritances:
- azure.mgmt.datafactory.models._models_py3.ExecutionActivity
summary: 'HDInsight Spark activity.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'HDInsightSparkActivity(*, name: str, root_path: Any, entry_file_path: Any,
    additional_properties: Optional[Dict[str, Any]] = None, description: Optional[str]
    = None, depends_on: Optional[List[azure.mgmt.datafactory.models._models_py3.ActivityDependency]]
    = None, user_properties: Optional[List[azure.mgmt.datafactory.models._models_py3.UserProperty]]
    = None, linked_service_name: Optional[azure.mgmt.datafactory.models._models_py3.LinkedServiceReference]
    = None, policy: Optional[azure.mgmt.datafactory.models._models_py3.ActivityPolicy]
    = None, arguments: Optional[List[Any]] = None, get_debug_info: Optional[Union[str,
    azure.mgmt.datafactory.models._data_factory_management_client_enums.HDInsightActivityDebugInfoOption]]
    = None, spark_job_linked_service: Optional[azure.mgmt.datafactory.models._models_py3.LinkedServiceReference]
    = None, class_name: Optional[str] = None, proxy_user: Optional[Any] = None, spark_config:
    Optional[Dict[str, Any]] = None, **kwargs)'
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:dict>[<xref:str>, <xref:any>]
- description: Required. Activity name.
  name: name
  types:
  - <xref:str>
- description: Required. Type of activity.Constant filled by server.
  name: type
  types:
  - <xref:str>
- description: Activity description.
  name: description
  types:
  - <xref:str>
- description: Activity depends on condition.
  name: depends_on
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.ActivityDependency>]
- description: Activity user properties.
  name: user_properties
  types:
  - <xref:list>[<xref:azure.mgmt.datafactory.models.UserProperty>]
- description: Linked service reference.
  name: linked_service_name
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: Activity policy.
  name: policy
  types:
  - <xref:azure.mgmt.datafactory.models.ActivityPolicy>
- description: 'Required. The root path in ''sparkJobLinkedService'' for all the job''s
    files.

    Type: string (or Expression with resultType string).'
  name: root_path
  types:
  - <xref:any>
- description: 'Required. The relative path to the root folder of the code/package
    to be

    executed. Type: string (or Expression with resultType string).'
  name: entry_file_path
  types:
  - <xref:any>
- description: The user-specified arguments to HDInsightSparkActivity.
  name: arguments
  types:
  - <xref:list>[<xref:any>]
- description: 'Debug info option. Possible values include: "None", "Always", "Failure".'
  name: get_debug_info
  types:
  - <xref:str>
  - <xref:azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption>
- description: 'The storage linked service for uploading the entry file and

    dependencies, and for receiving logs.'
  name: spark_job_linked_service
  types:
  - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
- description: The application's Java/Spark main class.
  name: class_name
  types:
  - <xref:str>
- description: 'The user to impersonate that will execute the job. Type: string (or

    Expression with resultType string).'
  name: proxy_user
  types:
  - <xref:any>
- description: Spark configuration property.
  name: spark_config
  types:
  - <xref:dict>[<xref:str>, <xref:any>]
