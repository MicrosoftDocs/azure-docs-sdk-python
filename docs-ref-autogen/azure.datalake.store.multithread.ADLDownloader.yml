### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.datalake.store.multithread.ADLDownloader.active
  - azure.datalake.store.multithread.ADLDownloader.clear_saved
  - azure.datalake.store.multithread.ADLDownloader.load
  - azure.datalake.store.multithread.ADLDownloader.run
  - azure.datalake.store.multithread.ADLDownloader.save
  - azure.datalake.store.multithread.ADLDownloader.successful
  class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.datalake.store.multithread
  name: ADLDownloader
  seealsoContent: "See also: @azure.datalake.store.transfer.ADLTransferClient \n"
  source:
    id: ADLDownloader
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 57
  summary: 'Download remote file(s) using chunks and threads


    Launches multiple threads for efficient downloading, with *chunksize*

    assigned to each. The remote path can be a single file, a directory

    of files or a glob pattern.








    '
  syntax:
    content: ADLDownloader(adlfs, rpath, lpath, nthreads=None, chunksize=268435456,
      buffersize=4194304, blocksize=4194304, client=None, run=True, overwrite=False,
      verbose=False, progress_callback=None)
    parameters:
    - description: ''
      id: adlfs
      type:
      - ADL filesystem instance
    - description: 'remote path/globstring to use to find remote files. Recursive
        glob

        patterns using **** are not supported.

        '
      id: rpath
      type:
      - str
    - description: 'local path. If downloading a single file, will write to this specific

        file, unless it is an existing directory, in which case a file is

        created within it. If downloading multiple files, this is the root

        directory to write within. Will create directories as required.

        '
      id: lpath
      type:
      - str
    - description: 'Number of threads to use. If None, uses the number of cores.

        '
      id: nthreads
      type:
      - int [None]
    - description: 'Number of bytes for a chunk. Large files are split into chunks.
        Files

        smaller than this number will always be transferred in a single thread.

        '
      id: chunksize
      type:
      - int [2**28]
    - description: 'Number of bytes for internal buffer. This block cannot be bigger
        than

        a chunk and cannot be smaller than a block.

        '
      id: buffersize
      type:
      - int [2**22]
    - description: 'Number of bytes for a block. Within each chunk, we write a smaller

        block for each API call. This block cannot be bigger than a chunk.

        '
      id: blocksize
      type:
      - int [2**22]
    - description: 'Set an instance of ADLTransferClient when finer-grained control
        over

        transfer parameters is needed. Ignores *nthreads* and *chunksize* set

        by constructor.

        '
      id: client
      type:
      - ADLTransferClient [None]
    - description: 'Whether to begin executing immediately.

        '
      id: run
      type:
      - bool [True]
    - description: 'Whether to forcibly overwrite existing files/directories. If False
        and

        local path is a directory, will quit regardless if any files would be

        overwritten or not. If True, only matching filenames are actually

        overwritten.

        '
      id: overwrite
      type:
      - bool [False]
    - description: 'Callback for progress with signature function(current, total)
        where

        current is the number of bytes transfered so far, and total is the

        size of the blob, or None if the total size is unknown.

        '
      id: progress_callback
      type:
      - callable [None]
  type: class
  uid: azure.datalake.store.multithread.ADLDownloader
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.active
  langs:
  - python
  module: azure.datalake.store.multithread
  name: active
  source:
    id: active
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 247
  summary: 'Return whether the downloader is active

    '
  syntax:
    content: active()
    parameters: []
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.active
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.clear_saved
  langs:
  - python
  module: azure.datalake.store.multithread
  name: clear_saved
  source:
    id: clear_saved
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 179
  summary: 'Remove references to all persisted downloads.

    '
  syntax:
    content: clear_saved()
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.clear_saved
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.load
  langs:
  - python
  module: azure.datalake.store.multithread
  name: load
  source:
    id: load
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 166
  summary: 'Load list of persisted transfers from disk, for possible resumption.

    '
  syntax:
    content: load()
    return:
      description: "* *A dictionary of download instances. The hashes are auto-* \n\
        \n* *generated unique. The state of the chunks completed, errored, etc.,*\
        \ \n\n* *can be seen in the status attribute. Instances can be resumed with*\
        \ \n\n* `run()`. \n"
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.load
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.run
  langs:
  - python
  module: azure.datalake.store.multithread
  name: run
  source:
    id: run
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 225
  summary: 'Populate transfer queue and execute downloads

    '
  syntax:
    content: run(nthreads=None, monitor=True)
    parameters:
    - defaultValue: None
      description: 'Override default nthreads, if given

        '
      id: nthreads
      type:
      - int [None]
    - defaultValue: 'True'
      description: 'To watch and wait (block) until completion.

        '
      id: monitor
      type:
      - bool [True]
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.run
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.save
  langs:
  - python
  module: azure.datalake.store.multithread
  name: save
  source:
    id: save
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 145
  summary: 'Persist this download


    Saves a copy of this transfer process in its current state to disk.

    This is done automatically for a running transfer, so that as a chunk

    is completed, this is reflected. Thus, if a transfer is interrupted,

    e.g., by user action, the transfer can be restarted at another time.

    All chunks that were not already completed will be restarted at that

    time.


    See methods `load` to retrieved saved transfers and `run` to

    resume a stopped transfer.

    '
  syntax:
    content: save(keep=True)
    parameters:
    - defaultValue: 'True'
      description: 'If True, transfer will be saved if some chunks remain to be

        completed; the transfer will be sure to be removed otherwise.

        '
      id: keep
      type:
      - bool (True)
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.save
- class: azure.datalake.store.multithread.ADLDownloader
  fullName: azure.datalake.store.multithread.ADLDownloader.successful
  langs:
  - python
  module: azure.datalake.store.multithread
  name: successful
  source:
    id: successful
    path: azure\datalake\store\multithread.py
    remote:
      branch: master
      path: azure\datalake\store\multithread.py
      repo: https://github.com/Azure/azure-data-lake-store-python
    startLine: 251
  summary: 'Return whether the downloader completed successfully.


    It will raise AssertionError if the downloader is active.

    '
  syntax:
    content: successful()
    parameters: []
  type: method
  uid: azure.datalake.store.multithread.ADLDownloader.successful
references:
- fullName: azure.datalake.store.multithread.ADLDownloader.active
  isExternal: false
  name: active
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.active
- fullName: azure.datalake.store.multithread.ADLDownloader.clear_saved
  isExternal: false
  name: clear_saved
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.clear_saved
- fullName: azure.datalake.store.multithread.ADLDownloader.load
  isExternal: false
  name: load
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.load
- fullName: azure.datalake.store.multithread.ADLDownloader.run
  isExternal: false
  name: run
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.run
- fullName: azure.datalake.store.multithread.ADLDownloader.save
  isExternal: false
  name: save
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.save
- fullName: azure.datalake.store.multithread.ADLDownloader.successful
  isExternal: false
  name: successful
  parent: azure.datalake.store.multithread.ADLDownloader
  uid: azure.datalake.store.multithread.ADLDownloader.successful
- fullName: int [None]
  name: int [None]
  spec.python:
  - fullName: 'int '
    name: 'int '
    uid: 'int '
  - fullName: '['
    name: '['
  - fullName: None
    name: None
    uid: None
  - fullName: ']'
    name: ']'
  uid: int [None]
- fullName: int [2**28]
  name: int [2**28]
  spec.python:
  - fullName: 'int '
    name: 'int '
    uid: 'int '
  - fullName: '['
    name: '['
  - fullName: 2**28
    name: 2**28
    uid: 2**28
  - fullName: ']'
    name: ']'
  uid: int [2**28]
- fullName: int [2**22]
  name: int [2**22]
  spec.python:
  - fullName: 'int '
    name: 'int '
    uid: 'int '
  - fullName: '['
    name: '['
  - fullName: 2**22
    name: 2**22
    uid: 2**22
  - fullName: ']'
    name: ']'
  uid: int [2**22]
- fullName: int [2**22]
  name: int [2**22]
  spec.python:
  - fullName: 'int '
    name: 'int '
    uid: 'int '
  - fullName: '['
    name: '['
  - fullName: 2**22
    name: 2**22
    uid: 2**22
  - fullName: ']'
    name: ']'
  uid: int [2**22]
- fullName: ADLTransferClient [None]
  name: ADLTransferClient [None]
  spec.python:
  - fullName: 'ADLTransferClient '
    name: 'ADLTransferClient '
    uid: 'ADLTransferClient '
  - fullName: '['
    name: '['
  - fullName: None
    name: None
    uid: None
  - fullName: ']'
    name: ']'
  uid: ADLTransferClient [None]
- fullName: bool [True]
  name: bool [True]
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: '['
    name: '['
  - fullName: 'True'
    name: 'True'
    uid: 'True'
  - fullName: ']'
    name: ']'
  uid: bool [True]
- fullName: bool [False]
  name: bool [False]
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: '['
    name: '['
  - fullName: 'False'
    name: 'False'
    uid: 'False'
  - fullName: ']'
    name: ']'
  uid: bool [False]
- fullName: callable [None]
  name: callable [None]
  spec.python:
  - fullName: 'callable '
    name: 'callable '
    uid: 'callable '
  - fullName: '['
    name: '['
  - fullName: None
    name: None
    uid: None
  - fullName: ']'
    name: ']'
  uid: callable [None]
- fullName: bool (True)
  name: bool (True)
  spec.python:
  - fullName: 'bool '
    name: 'bool '
    uid: 'bool '
  - fullName: (
    name: (
  - fullName: 'True'
    name: 'True'
    uid: 'True'
  - fullName: )
    name: )
  uid: bool (True)
