### YamlMime:PythonClass
uid: azure.mgmt.media.models.VideoAnalyzerPreset
name: VideoAnalyzerPreset
fullName: azure.mgmt.media.models.VideoAnalyzerPreset
module: azure.mgmt.media.models
inheritances:
- azure.mgmt.media.models._models_py3.AudioAnalyzerPreset
summary: 'A video analyzer preset that extracts insights (rich metadata) from both
  audio and video, and outputs a JSON format file.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'VideoAnalyzerPreset(*, audio_language: str | None = None, mode: str | _models.AudioAnalysisMode
    | None = None, experimental_options: Dict[str, str] | None = None, insights_to_extract:
    str | _models.InsightsType | None = None, **kwargs)'
  keywordOnlyParameters:
  - name: audio_language
    description: 'The language for the audio payload in the input using the BCP-47

      format of ''language tag-region'' (e.g: ''en-US'').  If you know the language
      of your content, it

      is recommended that you specify it. The language must be specified explicitly
      for

      AudioAnalysisMode::Basic, since automatic language detection is not included
      in basic mode. If

      the language isn''t specified or set to null, automatic language detection will
      choose the first

      language detected and process with the selected language for the duration of
      the file. It does

      not currently support dynamically switching between languages after the first
      language is

      detected. The automatic detection works best with audio recordings with clearly
      discernable

      speech. If automatic detection fails to find the language, transcription would
      fallback to

      ''en-US''." The list of supported languages is available here:

      https://go.microsoft.com/fwlink/?linkid=2109463.'
    types:
    - <xref:str>
  - name: mode
    description: 'Determines the set of audio analysis operations to be performed.
      If unspecified,

      the Standard AudioAnalysisMode would be chosen. Known values are: "Standard"
      and "Basic".'
    types:
    - <xref:str>
    - <xref:azure.mgmt.media.models.AudioAnalysisMode>
  - name: experimental_options
    description: 'Dictionary containing key value pairs for parameters not exposed

      in the preset itself.'
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: insights_to_extract
    description: 'Defines the type of insights that you want the service to

      generate. The allowed values are ''AudioInsightsOnly'', ''VideoInsightsOnly'',
      and ''AllInsights''.

      The default is AllInsights. If you set this to AllInsights and the input is
      audio only, then

      only audio insights are generated. Similarly if the input is video only, then
      only video

      insights are generated. It is recommended that you not use AudioInsightsOnly
      if you expect some

      of your inputs to be video only; or use VideoInsightsOnly if you expect some
      of your inputs to

      be audio only. Your Jobs in such conditions would error out. Known values are:

      "AudioInsightsOnly", "VideoInsightsOnly", and "AllInsights".'
    types:
    - <xref:str>
    - <xref:azure.mgmt.media.models.InsightsType>
variables:
- description: The discriminator for derived types. Required.
  name: odata_type
  types:
  - <xref:str>
- description: 'The language for the audio payload in the input using the BCP-47 format

    of ''language tag-region'' (e.g: ''en-US'').  If you know the language of your
    content, it is

    recommended that you specify it. The language must be specified explicitly for

    AudioAnalysisMode::Basic, since automatic language detection is not included in
    basic mode. If

    the language isn''t specified or set to null, automatic language detection will
    choose the first

    language detected and process with the selected language for the duration of the
    file. It does

    not currently support dynamically switching between languages after the first
    language is

    detected. The automatic detection works best with audio recordings with clearly
    discernable

    speech. If automatic detection fails to find the language, transcription would
    fallback to

    ''en-US''." The list of supported languages is available here:

    https://go.microsoft.com/fwlink/?linkid=2109463.'
  name: audio_language
  types:
  - <xref:str>
- description: 'Determines the set of audio analysis operations to be performed. If
    unspecified,

    the Standard AudioAnalysisMode would be chosen. Known values are: "Standard" and
    "Basic".'
  name: mode
  types:
  - <xref:str>
  - <xref:azure.mgmt.media.models.AudioAnalysisMode>
- description: 'Dictionary containing key value pairs for parameters not exposed in

    the preset itself.'
  name: experimental_options
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
- description: 'Defines the type of insights that you want the service to generate.

    The allowed values are ''AudioInsightsOnly'', ''VideoInsightsOnly'', and ''AllInsights''.
    The default

    is AllInsights. If you set this to AllInsights and the input is audio only, then
    only audio

    insights are generated. Similarly if the input is video only, then only video
    insights are

    generated. It is recommended that you not use AudioInsightsOnly if you expect
    some of your

    inputs to be video only; or use VideoInsightsOnly if you expect some of your inputs
    to be audio

    only. Your Jobs in such conditions would error out. Known values are: "AudioInsightsOnly",

    "VideoInsightsOnly", and "AllInsights".'
  name: insights_to_extract
  types:
  - <xref:str>
  - <xref:azure.mgmt.media.models.InsightsType>
