### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_stream
  - azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_url
  - azure.cognitiveservices.vision.face.operations.FaceOperations.find_similar
  - azure.cognitiveservices.vision.face.operations.FaceOperations.group
  - azure.cognitiveservices.vision.face.operations.FaceOperations.identify
  - azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_face
  - azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_person
  - azure.cognitiveservices.vision.face.operations.FaceOperations.models
  class: azure.cognitiveservices.vision.face.operations.FaceOperations
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations
  inheritance:
  - type: builtins.object
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: FaceOperations
  summary: 'FaceOperations operations.


    You should not instantiate directly this class, but create a Client instance that
    will create it for you and attach it as attribute.'
  syntax:
    content: FaceOperations(client, config, serializer, deserializer)
    parameters:
    - description: Client for service requests.
      id: client
    - description: Configuration of service client.
      id: config
    - description: An object model serializer.
      id: serializer
    - description: An object model deserializer.
      id: deserializer
  type: class
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_stream
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: detect_with_stream(image, return_face_id=True, return_face_landmarks=False,
    return_face_attributes=None, recognition_model='recognition_01', return_recognition_model=False,
    detection_model='detection_01', custom_headers=None, raw=False, callback=None,
    **operation_config)
  namewithoutparameters: detect_with_stream
  summary: 'Detect human faces in an image, return face rectangles, and optionally

    with faceIds, landmarks, and attributes.<br />

    * No image will be stored. Only the extracted face feature will be

    stored on server. The faceId is an identifier of the face feature and

    will be used in [Face -

    Identify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify)),

    [Face -

    Verify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface)),

    and [Face - Find

    Similar]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar)).

    The stored face feature(s) will expire and be deleted 24 hours after

    the original detection call.

    * Optional parameters include faceId, landmarks, and attributes.

    Attributes include age, gender, headPose, smile, facialHair, glasses,

    emotion, hair, makeup, occlusion, accessories, blur, exposure and

    noise. Some of the results returned for specific attributes may not be

    highly accurate.

    * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

    allowed image file size is from 1KB to 6MB.

    * Up to 100 faces can be returned for an image. Faces are ranked by

    face rectangle size from large to small.

    * For optimal results when querying [Face -

    Identify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify)),

    [Face -

    Verify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface)),

    and [Face - Find

    Similar]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar))

    (''returnFaceId'' is true), please use faces that are: frontal, clear,

    and with a minimum size of 200x200 pixels (100 pixels between eyes).

    * The minimum detectable face size is 36x36 pixels in an image no

    larger than 1920x1080 pixels. Images with dimensions higher than

    1920x1080 pixels will need a proportionally larger minimum face size.

    * Different ''detectionModel'' values can be provided. To use and compare

    different detection models, please refer to [How to specify a detection

    model]([https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model))

    | Model | Recommended use-case(s) |

    | ---------- | -------- |

    | ''detection_01'': | The default detection model for [Face -

    Detect]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl)).

    Recommend for near frontal face detection. For scenarios with

    exceptionally large angle (head-pose) faces, occluded faces or wrong

    image orientation, the faces in such cases may not be detected. |

    | ''detection_02'': | Detection model released in 2019 May with improved

    accuracy especially on small, side and blurry faces. |

    * Different ''recognitionModel'' values are provided. If follow-up

    operations like Verify, Identify, Find Similar are needed, please

    specify the recognition model with ''recognitionModel'' parameter. The

    default value for ''recognitionModel'' is ''recognition_01'', if latest

    model needed, please explicitly specify the model you need in this

    parameter. Once specified, the detected faceIds will be associated with

    the specified recognition model. More details, please refer to [How to

    specify a recognition

    model]([https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model))

    | Model | Recommended use-case(s) |

    | ---------- | -------- |

    | ''recognition_01'': | The default recognition model for [Face -

    Detect]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl)).

    All those faceIds created before 2019 March are bonded with this

    recognition model. |

    | ''recognition_02'': | Recognition model released in 2019 March. |

    | ''recognition_03'': | Recognition model released in 2020 May.

    ''recognition_03'' is recommended since its overall accuracy is improved

    compared with ''recognition_01'' and ''recognition_02''. >>|<<.'
  syntax:
    content: detect_with_stream(image, return_face_id=True, return_face_landmarks=False,
      return_face_attributes=None, recognition_model='recognition_01', return_recognition_model=False,
      detection_model='detection_01', custom_headers=None, raw=False, callback=None,
      **operation_config)
    parameters:
    - description: An image stream.
      id: image
      isRequired: true
      type:
      - Generator
    - defaultValue: 'True'
      description: 'A value indicating whether the operation should

        return faceIds of detected faces.'
      id: return_face_id
      type:
      - bool
    - defaultValue: 'False'
      description: 'A value indicating whether the operation

        should return landmarks of the detected faces.'
      id: return_face_landmarks
      type:
      - bool
    - defaultValue: None
      description: 'Analyze and return the one or more

        specified face attributes in the comma-separated string like

        "returnFaceAttributes=age,gender". Supported face attributes include

        age, gender, headPose, smile, facialHair, glasses and emotion. Note

        that each face attribute analysis has additional computational and

        time cost.'
      id: return_face_attributes
      type:
      - list[str
      - azure.cognitiveservices.vision.face.models.FaceAttributeType]
    - defaultValue: recognition_01
      description: 'Name of recognition model. Recognition model

        is used when the face features are extracted and associated with

        detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition

        model name can be provided when performing Face - Detect or

        (Large)FaceList - Create or (Large)PersonGroup - Create. The default

        value is ''recognition_01'', if latest model needed, please explicitly

        specify the model you need. Possible values include: ''recognition_01'',

        ''recognition_02'', ''recognition_03'''
      id: recognition_model
      type:
      - str
      - azure.cognitiveservices.vision.face.models.RecognitionModel
    - defaultValue: 'False'
      description: 'A value indicating whether the

        operation should return ''recognitionModel'' in response.'
      id: return_recognition_model
      type:
      - bool
    - defaultValue: detection_01
      description: 'Name of detection model. Detection model is

        used to detect faces in the submitted image. A detection model name

        can be provided when performing Face - Detect or (Large)FaceList - Add

        Face or (Large)PersonGroup - Add Face. The default value is

        ''detection_01'', if another model is needed, please explicitly specify

        it. Possible values include: ''detection_01'', ''detection_02'''
      id: detection_model
      type:
      - str
      - azure.cognitiveservices.vision.face.models.DetectionModel
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - defaultValue: None
      description: 'When specified, will be called with each chunk of

        data that is streamed. The callback should take two arguments, the

        bytes of the current chunk of data and the response object. If the

        data is uploading, response will be None.'
      id: callback
      type:
      - Callable[Bytes, response=None]
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: list or ClientRawResponse if raw=true
      type:
      - list[azure.cognitiveservices.vision.face.models.DetectedFace]
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_stream
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_url
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: detect_with_url(url, return_face_id=True, return_face_landmarks=False, return_face_attributes=None,
    recognition_model='recognition_01', return_recognition_model=False, detection_model='detection_01',
    custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: detect_with_url
  summary: 'Detect human faces in an image, return face rectangles, and optionally

    with faceIds, landmarks, and attributes.<br />

    * No image will be stored. Only the extracted face feature will be

    stored on server. The faceId is an identifier of the face feature and

    will be used in [Face -

    Identify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify)),

    [Face -

    Verify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface)),

    and [Face - Find

    Similar]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar)).

    The stored face feature(s) will expire and be deleted 24 hours after

    the original detection call.

    * Optional parameters include faceId, landmarks, and attributes.

    Attributes include age, gender, headPose, smile, facialHair, glasses,

    emotion, hair, makeup, occlusion, accessories, blur, exposure and

    noise. Some of the results returned for specific attributes may not be

    highly accurate.

    * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

    allowed image file size is from 1KB to 6MB.

    * Up to 100 faces can be returned for an image. Faces are ranked by

    face rectangle size from large to small.

    * For optimal results when querying [Face -

    Identify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/identify)),

    [Face -

    Verify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface)),

    and [Face - Find

    Similar]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar))

    (''returnFaceId'' is true), please use faces that are: frontal, clear,

    and with a minimum size of 200x200 pixels (100 pixels between eyes).

    * The minimum detectable face size is 36x36 pixels in an image no

    larger than 1920x1080 pixels. Images with dimensions higher than

    1920x1080 pixels will need a proportionally larger minimum face size.

    * Different ''detectionModel'' values can be provided. To use and compare

    different detection models, please refer to [How to specify a detection

    model]([https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-detection-model))

    | Model | Recommended use-case(s) |

    | ---------- | -------- |

    | ''detection_01'': | The default detection model for [Face -

    Detect]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl)).

    Recommend for near frontal face detection. For scenarios with

    exceptionally large angle (head-pose) faces, occluded faces or wrong

    image orientation, the faces in such cases may not be detected. |

    | ''detection_02'': | Detection model released in 2019 May with improved

    accuracy especially on small, side and blurry faces. |

    * Different ''recognitionModel'' values are provided. If follow-up

    operations like Verify, Identify, Find Similar are needed, please

    specify the recognition model with ''recognitionModel'' parameter. The

    default value for ''recognitionModel'' is ''recognition_01'', if latest

    model needed, please explicitly specify the model you need in this

    parameter. Once specified, the detected faceIds will be associated with

    the specified recognition model. More details, please refer to [How to

    specify a recognition

    model]([https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model](https://docs.microsoft.com/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model))

    | Model | Recommended use-case(s) |

    | ---------- | -------- |

    | ''recognition_01'': | The default recognition model for [Face -

    Detect]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl)).

    All those faceIds created before 2019 March are bonded with this

    recognition model. |

    | ''recognition_02'': | Recognition model released in 2019 March. |

    | ''recognition_03'': | Recognition model released in 2020 May.

    ''recognition_03'' is recommended since its overall accuracy is improved

    compared with ''recognition_01'' and ''recognition_02''. >>|<<.'
  syntax:
    content: detect_with_url(url, return_face_id=True, return_face_landmarks=False,
      return_face_attributes=None, recognition_model='recognition_01', return_recognition_model=False,
      detection_model='detection_01', custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: Publicly reachable URL of an image
      id: url
      isRequired: true
      type:
      - str
    - defaultValue: 'True'
      description: 'A value indicating whether the operation should

        return faceIds of detected faces.'
      id: return_face_id
      type:
      - bool
    - defaultValue: 'False'
      description: 'A value indicating whether the operation

        should return landmarks of the detected faces.'
      id: return_face_landmarks
      type:
      - bool
    - defaultValue: None
      description: 'Analyze and return the one or more

        specified face attributes in the comma-separated string like

        "returnFaceAttributes=age,gender". Supported face attributes include

        age, gender, headPose, smile, facialHair, glasses and emotion. Note

        that each face attribute analysis has additional computational and

        time cost.'
      id: return_face_attributes
      type:
      - list[str
      - azure.cognitiveservices.vision.face.models.FaceAttributeType]
    - defaultValue: recognition_01
      description: 'Name of recognition model. Recognition model

        is used when the face features are extracted and associated with

        detected faceIds, (Large)FaceList or (Large)PersonGroup. A recognition

        model name can be provided when performing Face - Detect or

        (Large)FaceList - Create or (Large)PersonGroup - Create. The default

        value is ''recognition_01'', if latest model needed, please explicitly

        specify the model you need. Possible values include: ''recognition_01'',

        ''recognition_02'', ''recognition_03'''
      id: recognition_model
      type:
      - str
      - azure.cognitiveservices.vision.face.models.RecognitionModel
    - defaultValue: 'False'
      description: 'A value indicating whether the

        operation should return ''recognitionModel'' in response.'
      id: return_recognition_model
      type:
      - bool
    - defaultValue: detection_01
      description: 'Name of detection model. Detection model is

        used to detect faces in the submitted image. A detection model name

        can be provided when performing Face - Detect or (Large)FaceList - Add

        Face or (Large)PersonGroup - Add Face. The default value is

        ''detection_01'', if another model is needed, please explicitly specify

        it. Possible values include: ''detection_01'', ''detection_02'''
      id: detection_model
      type:
      - str
      - azure.cognitiveservices.vision.face.models.DetectionModel
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: list or ClientRawResponse if raw=true
      type:
      - list[azure.cognitiveservices.vision.face.models.DetectedFace]
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_url
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.find_similar
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: find_similar(face_id, face_list_id=None, large_face_list_id=None, face_ids=None,
    max_num_of_candidates_returned=20, mode='matchPerson', custom_headers=None, raw=False,
    **operation_config)
  namewithoutparameters: find_similar
  summary: 'Given query face''s faceId, to search the similar-looking faces from a

    faceId array, a face list or a large face list. faceId array contains

    the faces created by [Face -

    Detect]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/detectwithurl)),

    which will expire 24 hours after creation. A "faceListId" is created by

    [FaceList -

    Create]([https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/create](https://docs.microsoft.com/rest/api/cognitiveservices/face/facelist/create))

    containing persistedFaceIds that will not expire. And a

    "largeFaceListId" is created by [LargeFaceList -

    Create]([https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/create](https://docs.microsoft.com/rest/api/cognitiveservices/face/largefacelist/create))

    containing persistedFaceIds that will also not expire. Depending on the

    input the returned similar faces list contains faceIds or

    persistedFaceIds ranked by similarity.

    <br/>Find similar has two working modes, "matchPerson" and "matchFace".

    "matchPerson" is the default mode that it tries to find faces of the

    same person as possible by using internal same-person thresholds. It is

    useful to find a known person''s other photos. Note that an empty list

    will be returned if no faces pass the internal thresholds. "matchFace"

    mode ignores same-person thresholds and returns ranked similar faces

    anyway, even the similarity is low. It can be used in the cases like

    searching celebrity-looking faces.

    <br/>The ''recognitionModel'' associated with the query face''s faceId

    should be the same as the ''recognitionModel'' used by the target faceId

    array, face list or large face list.

    .'
  syntax:
    content: find_similar(face_id, face_list_id=None, large_face_list_id=None, face_ids=None,
      max_num_of_candidates_returned=20, mode='matchPerson', custom_headers=None,
      raw=False, **operation_config)
    parameters:
    - description: 'FaceId of the query face. User needs to call Face -

        Detect first to get a valid faceId. Note that this faceId is not

        persisted and will expire 24 hours after the detection call'
      id: face_id
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: 'An existing user-specified unique candidate face

        list, created in Face List - Create a Face List. Face list contains a

        set of persistedFaceIds which are persisted and will never expire.

        Parameter faceListId, largeFaceListId and faceIds should not be

        provided at the same time.'
      id: face_list_id
      type:
      - str
    - defaultValue: None
      description: 'An existing user-specified unique candidate

        large face list, created in LargeFaceList - Create. Large face list

        contains a set of persistedFaceIds which are persisted and will never

        expire. Parameter faceListId, largeFaceListId and faceIds should not

        be provided at the same time.'
      id: large_face_list_id
      type:
      - str
    - defaultValue: None
      description: 'An array of candidate faceIds. All of them are

        created by Face - Detect and the faceIds will expire 24 hours after

        the detection call. The number of faceIds is limited to 1000.

        Parameter faceListId, largeFaceListId and faceIds should not be

        provided at the same time.'
      id: face_ids
      type:
      - list[str]
    - defaultValue: '20'
      description: 'The number of top similar faces

        returned. The valid range is [1, 1000].'
      id: max_num_of_candidates_returned
      type:
      - int
    - defaultValue: matchPerson
      description: 'Similar face searching mode. It can be "matchPerson" or

        "matchFace". Possible values include: ''matchPerson'', ''matchFace'''
      id: mode
      type:
      - str
      - azure.cognitiveservices.vision.face.models.FindSimilarMatchMode
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: list or ClientRawResponse if raw=true
      type:
      - list[azure.cognitiveservices.vision.face.models.SimilarFace]
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.find_similar
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.group
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: group(face_ids, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: group
  summary: 'Divide candidate faces into groups based on face similarity.<br />

    * The output is one or more disjointed face groups and a messyGroup. A

    face group contains faces that have similar looking, often of the same

    person. Face groups are ranked by group size, i.e. number of faces.

    Notice that faces belonging to a same person might be split into

    several groups in the result.

    * MessyGroup is a special face group containing faces that cannot find

    any similar counterpart face from original faces. The messyGroup will

    not appear in the result if all faces found their counterparts.

    * Group API needs at least 2 candidate faces and 1000 at most. We

    suggest to try [Face -

    Verify]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/verifyfacetoface))

    when you only have 2 candidate faces.

    * The ''recognitionModel'' associated with the query faces'' faceIds

    should be the same.

    .'
  syntax:
    content: group(face_ids, custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: 'Array of candidate faceId created by Face - Detect.

        The maximum is 1000 faces'
      id: face_ids
      isRequired: true
      type:
      - list[str]
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: GroupResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.face.models.GroupResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.group
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.identify
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: identify(face_ids, person_group_id=None, large_person_group_id=None, max_num_of_candidates_returned=1,
    confidence_threshold=None, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: identify
  summary: '1-to-many identification to find the closest matches of the specific

    query person face from a person group or large person group.

    <br/> For each face in the faceIds array, Face Identify will compute

    similarities between the query face and all the faces in the person

    group (given by personGroupId) or large person group (given by

    largePersonGroupId), and return candidate person(s) for that face

    ranked by similarity confidence. The person group/large person group

    should be trained to make it ready for identification. See more in

    [PersonGroup -

    Train]([https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/train](https://docs.microsoft.com/rest/api/cognitiveservices/face/persongroup/train))

    and [LargePersonGroup -

    Train]([https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/train](https://docs.microsoft.com/rest/api/cognitiveservices/face/largepersongroup/train)).

    <br/>

    Remarks:<br />

    * The algorithm allows more than one face to be identified

    independently at the same request, but no more than 10 faces.

    * Each person in the person group/large person group could have more

    than one face, but no more than 248 faces.

    * Higher face image quality means better identification precision.

    Please consider high-quality faces: frontal, clear, and face size is

    200x200 pixels (100 pixels between eyes) or bigger.

    * Number of candidates returned is restricted by

    maxNumOfCandidatesReturned and confidenceThreshold. If no person is

    identified, the returned candidates will be an empty array.

    * Try [Face - Find

    Similar]([https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar](https://docs.microsoft.com/rest/api/cognitiveservices/face/face/findsimilar))

    when you need to find similar faces from a face list/large face list

    instead of a person group/large person group.

    * The ''recognitionModel'' associated with the query faces'' faceIds

    should be the same as the ''recognitionModel'' used by the target person

    group or large person group.

    .'
  syntax:
    content: identify(face_ids, person_group_id=None, large_person_group_id=None,
      max_num_of_candidates_returned=1, confidence_threshold=None, custom_headers=None,
      raw=False, **operation_config)
    parameters:
    - description: 'Array of query faces faceIds, created by the Face -

        Detect. Each of the faces are identified independently. The valid

        number of faceIds is between [1, 10].'
      id: face_ids
      isRequired: true
      type:
      - list[str]
    - defaultValue: None
      description: 'PersonGroupId of the target person group,

        created by PersonGroup - Create. Parameter personGroupId and

        largePersonGroupId should not be provided at the same time.'
      id: person_group_id
      type:
      - str
    - defaultValue: None
      description: 'LargePersonGroupId of the target large

        person group, created by LargePersonGroup - Create. Parameter

        personGroupId and largePersonGroupId should not be provided at the

        same time.'
      id: large_person_group_id
      type:
      - str
    - defaultValue: '1'
      description: 'The range of

        maxNumOfCandidatesReturned is between 1 and 5 (default is 1).'
      id: max_num_of_candidates_returned
      type:
      - int
    - defaultValue: None
      description: 'Confidence threshold of identification,

        used to judge whether one face belong to one person. The range of

        confidenceThreshold is [0, 1] (default specified by algorithm).'
      id: confidence_threshold
      type:
      - float
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: list or ClientRawResponse if raw=true
      type:
      - list[azure.cognitiveservices.vision.face.models.IdentifyResult]
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.identify
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_face
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: verify_face_to_face(face_id1, face_id2, custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: verify_face_to_face
  summary: 'Verify whether two faces belong to a same person or whether one face

    belongs to a person.

    <br/>

    Remarks:<br />

    * Higher face image quality means better identification precision.

    Please consider high-quality faces: frontal, clear, and face size is

    200x200 pixels (100 pixels between eyes) or bigger.

    * For the scenarios that are sensitive to accuracy please make your own

    judgment.

    * The ''recognitionModel'' associated with the query faces'' faceIds

    should be the same as the ''recognitionModel'' used by the target face,

    person group or large person group.

    .'
  syntax:
    content: verify_face_to_face(face_id1, face_id2, custom_headers=None, raw=False,
      **operation_config)
    parameters:
    - description: FaceId of the first face, comes from Face - Detect
      id: face_id1
      isRequired: true
      type:
      - str
    - description: FaceId of the second face, comes from Face - Detect
      id: face_id2
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: VerifyResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.face.models.VerifyResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_face
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  exceptions:
  - type: azure.cognitiveservices.vision.face.models.APIErrorException
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_person
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: verify_face_to_person(face_id, person_id, person_group_id=None, large_person_group_id=None,
    custom_headers=None, raw=False, **operation_config)
  namewithoutparameters: verify_face_to_person
  summary: 'Verify whether two faces belong to a same person. Compares a face Id

    with a Person Id.'
  syntax:
    content: verify_face_to_person(face_id, person_id, person_group_id=None, large_person_group_id=None,
      custom_headers=None, raw=False, **operation_config)
    parameters:
    - description: FaceId of the face, comes from Face - Detect
      id: face_id
      isRequired: true
      type:
      - str
    - description: 'Specify a certain person in a person group or a

        large person group. personId is created in PersonGroup Person - Create

        or LargePersonGroup Person - Create.'
      id: person_id
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: 'Using existing personGroupId and personId for

        fast loading a specified person. personGroupId is created in

        PersonGroup - Create. Parameter personGroupId and largePersonGroupId

        should not be provided at the same time.'
      id: person_group_id
      type:
      - str
    - defaultValue: None
      description: 'Using existing largePersonGroupId and

        personId for fast loading a specified person. largePersonGroupId is

        created in LargePersonGroup - Create. Parameter personGroupId and

        largePersonGroupId should not be provided at the same time.'
      id: large_person_group_id
      type:
      - str
    - defaultValue: None
      description: headers that will be added to the request
      id: custom_headers
      type:
      - dict
    - defaultValue: 'False'
      description: 'returns the direct response alongside the

        deserialized response'
      id: raw
      type:
      - bool
    - description: '*Operation configuration

        overrides*.'
      id: operation_config
      isRequired: true
    return:
      description: VerifyResult or ClientRawResponse if raw=true
      type:
      - azure.cognitiveservices.vision.face.models.VerifyResult
      - msrest.pipeline.ClientRawResponse
  type: method
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_person
- class: azure.cognitiveservices.vision.face.operations.FaceOperations
  fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.models
  langs:
  - python
  module: azure.cognitiveservices.vision.face.operations
  name: models
  syntax:
    content: models = <module 'azure.cognitiveservices.vision.face.models' from 'c:\\hostedtoolcache\\windows\\python\\3.6.8\\x64\\lib\\site-packages\\azure\\cognitiveservices\\vision\\face\\models\\__init__.py'>
  type: attribute
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.models
references:
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_stream
  isExternal: false
  name: detect_with_stream(image, return_face_id=True, return_face_landmarks=False,
    return_face_attributes=None, recognition_model='recognition_01', return_recognition_model=False,
    detection_model='detection_01', custom_headers=None, raw=False, callback=None,
    **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_stream
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_url
  isExternal: false
  name: detect_with_url(url, return_face_id=True, return_face_landmarks=False, return_face_attributes=None,
    recognition_model='recognition_01', return_recognition_model=False, detection_model='detection_01',
    custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.detect_with_url
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.find_similar
  isExternal: false
  name: find_similar(face_id, face_list_id=None, large_face_list_id=None, face_ids=None,
    max_num_of_candidates_returned=20, mode='matchPerson', custom_headers=None, raw=False,
    **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.find_similar
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.group
  isExternal: false
  name: group(face_ids, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.group
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.identify
  isExternal: false
  name: identify(face_ids, person_group_id=None, large_person_group_id=None, max_num_of_candidates_returned=1,
    confidence_threshold=None, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.identify
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_face
  isExternal: false
  name: verify_face_to_face(face_id1, face_id2, custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_face
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_person
  isExternal: false
  name: verify_face_to_person(face_id, person_id, person_group_id=None, large_person_group_id=None,
    custom_headers=None, raw=False, **operation_config)
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.verify_face_to_person
- fullName: azure.cognitiveservices.vision.face.operations.FaceOperations.models
  isExternal: false
  name: models
  parent: azure.cognitiveservices.vision.face.operations.FaceOperations
  uid: azure.cognitiveservices.vision.face.operations.FaceOperations.models
- fullName: list[str
  name: list[str
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  uid: list[str
- fullName: azure.cognitiveservices.vision.face.models.FaceAttributeType]
  name: FaceAttributeType]
  spec.python:
  - fullName: azure.cognitiveservices.vision.face.models.FaceAttributeType
    name: FaceAttributeType
    uid: azure.cognitiveservices.vision.face.models.FaceAttributeType
  - fullName: ']'
    name: ']'
  uid: azure.cognitiveservices.vision.face.models.FaceAttributeType]
- fullName: Callable[Bytes, response=None]
  name: Callable[Bytes, response=None]
  spec.python:
  - fullName: Callable
    name: Callable
    uid: Callable
  - fullName: '['
    name: '['
  - fullName: Bytes
    name: Bytes
    uid: Bytes
  - fullName: ', '
    name: ', '
  - fullName: response=None
    name: response=None
    uid: response=None
  - fullName: ']'
    name: ']'
  uid: Callable[Bytes, response=None]
- fullName: list[azure.cognitiveservices.vision.face.models.DetectedFace]
  name: list[DetectedFace]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: azure.cognitiveservices.vision.face.models.DetectedFace
    name: DetectedFace
    uid: azure.cognitiveservices.vision.face.models.DetectedFace
  - fullName: ']'
    name: ']'
  uid: list[azure.cognitiveservices.vision.face.models.DetectedFace]
- fullName: list[str]
  name: list[str]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ']'
    name: ']'
  uid: list[str]
- fullName: list[azure.cognitiveservices.vision.face.models.SimilarFace]
  name: list[SimilarFace]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: azure.cognitiveservices.vision.face.models.SimilarFace
    name: SimilarFace
    uid: azure.cognitiveservices.vision.face.models.SimilarFace
  - fullName: ']'
    name: ']'
  uid: list[azure.cognitiveservices.vision.face.models.SimilarFace]
- fullName: list[azure.cognitiveservices.vision.face.models.IdentifyResult]
  name: list[IdentifyResult]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: azure.cognitiveservices.vision.face.models.IdentifyResult
    name: IdentifyResult
    uid: azure.cognitiveservices.vision.face.models.IdentifyResult
  - fullName: ']'
    name: ']'
  uid: list[azure.cognitiveservices.vision.face.models.IdentifyResult]
