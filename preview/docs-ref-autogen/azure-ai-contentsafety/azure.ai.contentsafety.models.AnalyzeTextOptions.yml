### YamlMime:PythonClass
uid: azure.ai.contentsafety.models.AnalyzeTextOptions
name: AnalyzeTextOptions
fullName: azure.ai.contentsafety.models.AnalyzeTextOptions
module: azure.ai.contentsafety.models
inheritances:
- azure.ai.contentsafety._model_base.Model
summary: 'The analysis request of the text.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'AnalyzeTextOptions(*args: Any, **kwargs: Any)'
variables:
- description: 'The text needs to be scanned. We support at most 1000 characters (unicode
    code

    points) in text of one request. Required.'
  name: text
  types:
  - <xref:str>
- description: 'The categories will be analyzed. If not assigned, a default set of
    the

    categories'' analysis results will be returned.'
  name: categories
  types:
  - <xref:list>[<xref:str>
  - <xref:azure.ai.contentsafety.models.TextCategory>]
- description: The names of blocklists.
  name: blocklist_names
  types:
  - <xref:list>[<xref:str>]
- description: 'When set to true, further analyses of harmful content will not be

    performed in cases where blocklists are hit. When set to false, all analyses of
    harmful content

    will be performed, whether or not blocklists are hit.'
  name: break_by_blocklists
  types:
  - <xref:bool>
methods:
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.blocklist_names
  name: blocklist_names
  summary: The names of blocklists.
  signature: 'blocklist_names: List[str] | None'
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.break_by_blocklists
  name: break_by_blocklists
  summary: 'When set to true, further analyses of harmful content will not be performed
    in cases where

    blocklists are hit. When set to false, all analyses of harmful content will be
    performed,

    whether or not blocklists are hit.'
  signature: 'break_by_blocklists: bool | None'
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.categories
  name: categories
  summary: 'The categories will be analyzed. If not assigned, a default set of the
    categories'' analysis

    results will be returned.'
  signature: 'categories: List[str | _models.TextCategory] | None'
- uid: azure.ai.contentsafety.models.AnalyzeTextOptions.text
  name: text
  summary: 'The text needs to be scanned. We support at most 1000 characters (unicode
    code points) in text

    of one request. Required.'
  signature: 'text: str'
