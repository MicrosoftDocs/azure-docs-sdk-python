### YamlMime:PythonClass
uid: azure.ai.contentunderstanding.models.AudioVisualContent
name: AudioVisualContent
fullName: azure.ai.contentunderstanding.models.AudioVisualContent
module: azure.ai.contentunderstanding.models
summary: 'Audio visual content.  Ex. audio/wav, video/mp4.


  Patched __init__ that normalizes casing for KeyFrameTimesMs before calling parent.


  This patch is forward compatible: it only normalizes when the service returns incorrect
  casing.

  If the service returns the correct "keyFrameTimesMs" casing, the patch does nothing.'
constructor:
  syntax: 'AudioVisualContent(*args: Any, **kwargs: Any)'
  parameters:
  - name: args
    description: Positional arguments passed to __init__.
    isRequired: true
    types:
    - <xref:typing.Any>
variables:
- description: 'Detected MIME type of the content.  Ex. application/pdf, image/jpeg,
    etc.

    Required.'
  name: mime_type
  types:
  - <xref:str>
- description: The analyzer that generated this content.
  name: analyzer_id
  types:
  - <xref:str>
- description: Classified content category.
  name: category
  types:
  - <xref:str>
- description: The path of the content in the input.
  name: path
  types:
  - <xref:str>
- description: Markdown representation of the content.
  name: markdown
  types:
  - <xref:str>
- description: Extracted fields from the content.
  name: fields
  types:
  - <xref:dict>[<xref:str>, <xref:azure.ai.contentunderstanding.models.ContentField>]
- description: Content kind. Required. Audio visual content, such as mp3, mp4, etc.
  name: kind
  types:
  - <xref:str>
  - <xref:azure.ai.contentunderstanding.models.AUDIO_VISUAL>
- description: Start time of the content in milliseconds. Required.
  name: start_time_ms
  types:
  - <xref:int>
- description: End time of the content in milliseconds. Required.
  name: end_time_ms
  types:
  - <xref:int>
- description: Width of each video frame in pixels, if applicable.
  name: width
  types:
  - <xref:int>
- description: Height of each video frame in pixels, if applicable.
  name: height
  types:
  - <xref:int>
- description: 'List of camera shot changes in the video, represented by its

    timestamp in milliseconds.  Only if returnDetails is true.'
  name: camera_shot_times_ms
  types:
  - <xref:list>[<xref:int>]
- description: 'List of key frames in the video, represented by its timestamp in

    milliseconds.  Only if returnDetails is true.'
  name: key_frame_times_ms
  types:
  - <xref:list>[<xref:int>]
- description: List of transcript phrases.  Only if returnDetails is true.
  name: transcript_phrases
  types:
  - <xref:list>[<xref:azure.ai.contentunderstanding.models.TranscriptPhrase>]
- description: List of detected content segments.  Only if enableSegment is true.
  name: segments
  types:
  - <xref:list>[<xref:azure.ai.contentunderstanding.models.AudioVisualContentSegment>]
methods:
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> tuple[str, Any]
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.analyzer_id
  name: analyzer_id
  summary: The analyzer that generated this content.
  signature: 'analyzer_id: str | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.camera_shot_times_ms
  name: camera_shot_times_ms
  summary: 'List of camera shot changes in the video, represented by its timestamp
    in milliseconds.  Only

    if returnDetails is true.'
  signature: 'camera_shot_times_ms: list[int] | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.category
  name: category
  summary: Classified content category.
  signature: 'category: str | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.end_time_ms
  name: end_time_ms
  summary: End time of the content in milliseconds. Required.
  signature: 'end_time_ms: int'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.fields
  name: fields
  summary: Extracted fields from the content.
  signature: 'fields: dict[str, ''_models.ContentField''] | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.height
  name: height
  summary: Height of each video frame in pixels, if applicable.
  signature: 'height: int | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.key_frame_times_ms
  name: key_frame_times_ms
  summary: 'List of key frames in the video, represented by its timestamp in milliseconds.  Only
    if

    returnDetails is true.'
  signature: 'key_frame_times_ms: list[int] | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.kind
  name: kind
  summary: Content kind. Required. Audio visual content, such as mp3, mp4, etc.
  signature: 'kind: AUDIO_VISUAL: ''audioVisual''>]'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.markdown
  name: markdown
  summary: Markdown representation of the content.
  signature: 'markdown: str | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.mime_type
  name: mime_type
  summary: Detected MIME type of the content.  Ex. application/pdf, image/jpeg, etc.
    Required.
  signature: 'mime_type: str'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.path
  name: path
  summary: The path of the content in the input.
  signature: 'path: str | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.segments
  name: segments
  summary: List of detected content segments.  Only if enableSegment is true.
  signature: 'segments: list[''_models.AudioVisualContentSegment''] | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.start_time_ms
  name: start_time_ms
  summary: Start time of the content in milliseconds. Required.
  signature: 'start_time_ms: int'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.transcript_phrases
  name: transcript_phrases
  summary: List of transcript phrases.  Only if returnDetails is true.
  signature: 'transcript_phrases: list[''_models.TranscriptPhrase''] | None'
- uid: azure.ai.contentunderstanding.models.AudioVisualContent.width
  name: width
  summary: Width of each video frame in pixels, if applicable.
  signature: 'width: int | None'
