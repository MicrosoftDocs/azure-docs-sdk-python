### YamlMime:PythonClass
uid: azure.batch.models.JobManagerTask
name: JobManagerTask
fullName: azure.batch.models.JobManagerTask
module: azure.batch.models
inheritances:
- msrest.serialization.Model
summary: 'Specifies details of a Job Manager Task.


  The Job Manager Task is automatically started when the Job is created. The

  Batch service tries to schedule the Job Manager Task before any other Tasks

  in the Job. When shrinking a Pool, the Batch service tries to preserve

  Nodes where Job Manager Tasks are running for as long as possible (that is,

  Compute Nodes running ''normal'' Tasks are removed before Compute Nodes

  running Job Manager Tasks). When a Job Manager Task fails and needs to be

  restarted, the system tries to schedule it at the highest priority. If

  there are no idle Compute Nodes available, the system may terminate one of

  the running Tasks in the Pool and return it to the queue in order to make

  room for the Job Manager Task to restart. Note that a Job Manager Task in

  one Job does not have priority over Tasks in other Jobs. Across Jobs, only

  Job level priorities are observed. For example, if a Job Manager in a

  priority 0 Job needs to be restarted, it will not displace Tasks of a

  priority 1 Job. Batch will retry Tasks when a recovery operation is

  triggered on a Node. Examples of recovery operations include (but are not

  limited to) when an unhealthy Node is rebooted or a Compute Node

  disappeared due to host failure. Retries due to recovery operations are

  independent of and are not counted against the maxTaskRetryCount. Even if

  the maxTaskRetryCount is 0, an internal retry due to a recovery operation

  may occur. Because of this, all Tasks should be idempotent. This means

  Tasks need to tolerate being interrupted and restarted without causing any

  corruption or duplicate data. The best practice for long running Tasks is

  to use some form of checkpointing.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'JobManagerTask(*, id: str, command_line: str, display_name: str = None,
    container_settings=None, resource_files=None, output_files=None, environment_settings=None,
    constraints=None, required_slots: int = None, kill_job_on_completion: bool = None,
    user_identity=None, run_exclusive: bool = None, application_package_references=None,
    authentication_token_settings=None, allow_low_priority_node: bool = None, **kwargs)'
  parameters:
  - name: id
    description: 'Required. The ID can contain any combination of alphanumeric

      characters including hyphens and underscores and cannot contain more than

      64 characters.'
    isRequired: true
    types:
    - <xref:str>
  - name: display_name
    description: 'It need not be unique and can contain any Unicode

      characters up to a maximum length of 1024.'
    isRequired: true
    types:
    - <xref:str>
  - name: command_line
    description: 'Required. The command line does not run under a

      shell, and therefore cannot take advantage of shell features such as

      environment variable expansion. If you want to take advantage of such

      features, you should invoke the shell in the command line, for example

      using "cmd /c MyCommand" in Windows or "/bin/sh -c MyCommand" in Linux. If

      the command line refers to file paths, it should use a relative path

      (relative to the Task working directory), or use the Batch provided

      environment variable

      ([https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables](https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables)).'
    isRequired: true
    types:
    - <xref:str>
  - name: container_settings
    description: 'The settings for the container under which the

      Job Manager Task runs. If the Pool that will run this Task has

      containerConfiguration set, this must be set as well. If the Pool that

      will run this Task doesn''t have containerConfiguration set, this must not

      be set. When this is specified, all directories recursively below the

      AZ_BATCH_NODE_ROOT_DIR (the root of Azure Batch directories on the node)

      are mapped into the container, all Task environment variables are mapped

      into the container, and the Task command line is executed in the

      container. Files produced in the container outside of

      AZ_BATCH_NODE_ROOT_DIR might not be reflected to the host disk, meaning

      that Batch file APIs will not be able to access those files.'
    isRequired: true
    types:
    - <xref:azure.batch.models.TaskContainerSettings>
  - name: resource_files
    description: 'Files listed under this element are located in the

      Task''s working directory. There is a maximum size for the list of resource

      files.  When the max size is exceeded, the request will fail and the

      response error code will be RequestEntityTooLarge. If this occurs, the

      collection of ResourceFiles must be reduced in size. This can be achieved

      using .zip files, Application Packages, or Docker Containers.'
    isRequired: true
    types:
    - <xref:list>[<xref:azure.batch.models.ResourceFile>]
  - name: output_files
    description: 'For multi-instance Tasks, the files will only be

      uploaded from the Compute Node on which the primary Task is executed.'
    isRequired: true
    types:
    - <xref:list>[<xref:azure.batch.models.OutputFile>]
  - name: environment_settings
    isRequired: true
    types:
    - <xref:list>[<xref:azure.batch.models.EnvironmentSetting>]
  - name: constraints
    description: Constraints that apply to the Job Manager Task.
    isRequired: true
    types:
    - <xref:azure.batch.models.TaskConstraints>
  - name: required_slots
    description: 'The number of scheduling slots that the Task

      requires to run. The default is 1. A Task can only be scheduled to run on

      a compute node if the node has enough free scheduling slots available. For

      multi-instance Tasks, this property is not supported and must not be

      specified.'
    isRequired: true
    types:
    - <xref:int>
  - name: kill_job_on_completion
    description: 'Whether completion of the Job Manager Task

      signifies completion of the entire Job. If true, when the Job Manager Task

      completes, the Batch service marks the Job as complete. If any Tasks are

      still running at this time (other than Job Release), those Tasks are

      terminated. If false, the completion of the Job Manager Task does not

      affect the Job status. In this case, you should either use the

      onAllTasksComplete attribute to terminate the Job, or have a client or

      user terminate the Job explicitly. An example of this is if the Job

      Manager creates a set of Tasks but then takes no further role in their

      execution. The default value is true. If you are using the

      onAllTasksComplete and onTaskFailure attributes to control Job lifetime,

      and using the Job Manager Task only to create the Tasks for the Job (not

      to monitor progress), then it is important to set killJobOnCompletion to

      false.'
    isRequired: true
    types:
    - <xref:bool>
  - name: user_identity
    description: 'The user identity under which the Job Manager Task

      runs. If omitted, the Task runs as a non-administrative user unique to the

      Task.'
    isRequired: true
    types:
    - <xref:azure.batch.models.UserIdentity>
  - name: run_exclusive
    description: 'Whether the Job Manager Task requires exclusive use

      of the Compute Node where it runs. If true, no other Tasks will run on the

      same Node for as long as the Job Manager is running. If false, other Tasks

      can run simultaneously with the Job Manager on a Compute Node. The Job

      Manager Task counts normally against the Compute Node''s concurrent Task

      limit, so this is only relevant if the Compute Node allows multiple

      concurrent Tasks. The default value is true.'
    isRequired: true
    types:
    - <xref:bool>
  - name: application_package_references
    description: 'Application Packages are downloaded

      and deployed to a shared directory, not the Task working directory.

      Therefore, if a referenced Application Package is already on the Compute

      Node, and is up to date, then it is not re-downloaded; the existing copy

      on the Compute Node is used. If a referenced Application Package cannot be

      installed, for example because the package has been deleted or because

      download failed, the Task fails.'
    isRequired: true
    types:
    - <xref:list>[<xref:azure.batch.models.ApplicationPackageReference>]
  - name: authentication_token_settings
    description: 'The settings for an authentication

      token that the Task can use to perform Batch service operations. If this

      property is set, the Batch service provides the Task with an

      authentication token which can be used to authenticate Batch service

      operations without requiring an Account access key. The token is provided

      via the AZ_BATCH_AUTHENTICATION_TOKEN environment variable. The operations

      that the Task can carry out using the token depend on the settings. For

      example, a Task can request Job permissions in order to add other Tasks to

      the Job, or check the status of the Job or of other Tasks under the Job.'
    isRequired: true
    types:
    - <xref:azure.batch.models.AuthenticationTokenSettings>
  - name: allow_low_priority_node
    description: 'Whether the Job Manager Task may run on a

      Spot/Low-priority Compute Node. The default value is true.'
    isRequired: true
    types:
    - <xref:bool>
methods:
- uid: azure.batch.models.JobManagerTask.as_dict
  name: as_dict
  summary: "Return a dict that can be JSONify using json.dump.\n\nAdvanced usage might\
    \ optionally use a callback as parameter:\n\nKey is the attribute name used in\
    \ Python. Attr_desc\nis a dict of metadata. Currently contains 'type' with the\n\
    msrest type and 'key' with the RestAPI encoded key.\nValue is the current value\
    \ in this object.\n\nThe string returned will be used to serialize the key.\n\
    If the return type is a list, this is considered hierarchical\nresult dict.\n\n\
    See the three examples in this file:\n\n* attribute_transformer \n\n* full_restapi_key_transformer\
    \ \n\n* last_restapi_key_transformer \n\nIf you want XML serialization, you can\
    \ pass the kwargs is_xml=True."
  signature: as_dict(keep_readonly=True, key_transformer=<function attribute_transformer>,
    **kwargs)
  parameters:
  - name: key_transformer
    description: A key transformer function.
    types:
    - <xref:function>
  - name: keep_readonly
    defaultValue: 'True'
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.batch.models.JobManagerTask.deserialize
  name: deserialize
  summary: Parse a str using the RestAPI syntax and return a model.
  signature: deserialize(data, content_type=None)
  parameters:
  - name: data
    description: A str using RestAPI structure. JSON by default.
    isRequired: true
    types:
    - <xref:str>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.batch.models.JobManagerTask.enable_additional_properties_sending
  name: enable_additional_properties_sending
  signature: enable_additional_properties_sending()
- uid: azure.batch.models.JobManagerTask.from_dict
  name: from_dict
  summary: 'Parse a dict using given key extractor return a model.


    By default consider key

    extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor

    and last_rest_key_case_insensitive_extractor)'
  signature: from_dict(data, key_extractors=None, content_type=None)
  parameters:
  - name: data
    description: A dict using RestAPI structure
    isRequired: true
    types:
    - <xref:dict>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  - name: key_extractors
    defaultValue: None
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.batch.models.JobManagerTask.is_xml_model
  name: is_xml_model
  signature: is_xml_model()
- uid: azure.batch.models.JobManagerTask.serialize
  name: serialize
  summary: 'Return the JSON that would be sent to azure from this model.


    This is an alias to *as_dict(full_restapi_key_transformer, keep_readonly=False)*.


    If you want XML serialization, you can pass the kwargs is_xml=True.'
  signature: serialize(keep_readonly=False, **kwargs)
  parameters:
  - name: keep_readonly
    description: If you want to serialize the readonly attributes
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.batch.models.JobManagerTask.validate
  name: validate
  summary: Validate this model recursively and return a list of ValidationError.
  signature: validate()
  return:
    description: A list of validation error
    types:
    - <xref:list>
