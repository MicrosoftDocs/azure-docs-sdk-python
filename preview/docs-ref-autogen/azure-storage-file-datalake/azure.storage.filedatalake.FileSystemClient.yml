### YamlMime:PythonClass
uid: azure.storage.filedatalake.FileSystemClient
name: FileSystemClient
fullName: azure.storage.filedatalake.FileSystemClient
module: azure.storage.filedatalake
inheritances:
- azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
summary: 'A client to interact with a specific file system, even if that file system

  may not yet exist.


  For operations relating to a specific directory or file within this file system,
  a directory client or file client

  can be retrieved using the <xref:azure.storage.filedatalake.FileSystemClient.get_directory_client>
  or <xref:azure.storage.filedatalake.FileSystemClient.get_file_client> functions.'
constructor:
  syntax: 'FileSystemClient(account_url: str, file_system_name: str, credential: str
    | Dict[str, str] | AzureNamedKeyCredential | AzureSasCredential | TokenCredential
    | None = None, **kwargs: Any)'
  parameters:
  - name: account_url
    description: The URI to the storage account.
    isRequired: true
    types:
    - <xref:str>
  - name: file_system_name
    description: The file system for the directory or files.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token. The value can be a SAS token string,

      an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,

      an account shared access key, or an instance of a TokenCredentials class from
      azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.

      If using an instance of AzureNamedKeyCredential, "name" should be the storage
      account name, and "key"

      should be the storage account key.'
    defaultValue: None
    types:
    - <xref:azure.core.credentials.AzureNamedKeyCredential>
    - <xref:azure.core.credentials.AzureSasCredential>
    - <xref:azure.core.credentials.TokenCredential>
    - <xref:str>
    - <xref:dict>[<xref:str>, <xref:str>]
    - <xref:None>
  keywordOnlyParameters:
  - name: api_version
    description: 'The Storage API version to use for requests. Default value is the
      most recent service version that is

      compatible with the current SDK. Setting to an older version may result in reduced
      feature compatibility.'
    types:
    - <xref:str>
  - name: audience
    description: 'The audience to use when requesting tokens for Azure Active Directory

      authentication. Only has an effect when credential is of type TokenCredential.
      The value could be

      [https://storage.azure.com/](https://storage.azure.com/) (default) or [https:/](https:/)/<account>.blob.core.windows.net.'
    types:
    - <xref:str>
variables:
- description: The full endpoint URL to the file system, including SAS token if used.
  name: url
  types:
  - <xref:str>
- description: The full primary endpoint URL.
  name: primary_endpoint
  types:
  - <xref:str>
- description: The hostname of the primary endpoint.
  name: primary_hostname
  types:
  - <xref:str>
examples:
- "Get a FileSystemClient from an existing DataLakeServiceClient.<!--[!code-python[Main](les\\\
  datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\
  \\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\
  \\215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
  , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"highlight_args\"\
  : {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\n   # Instantiate\
  \ a DataLakeServiceClient using a connection string\n   from azure.storage.filedatalake\
  \ import DataLakeServiceClient\n   datalake_service_client = DataLakeServiceClient.from_connection_string(self.connection_string)\n\
  \n   # Instantiate a FileSystemClient\n   file_system_client = datalake_service_client.get_file_system_client(\"\
  mynewfilesystem\")\n\n   ````\n"
methods:
- uid: azure.storage.filedatalake.FileSystemClient.acquire_lease
  name: acquire_lease
  summary: 'Requests a new lease. If the file system does not have an active lease,

    the DataLake service creates a lease on the file system and returns a new

    lease ID.'
  signature: 'acquire_lease(lease_duration: int = -1, lease_id: str | None = None,
    **kwargs) -> DataLakeLeaseClient'
  parameters:
  - name: lease_duration
    description: 'Specifies the duration of the lease, in seconds, or negative one

      (-1) for a lease that never expires. A non-infinite lease can be

      between 15 and 60 seconds. A lease duration cannot be changed

      using renew or change. Default is -1 (infinite lease).'
    isRequired: true
    types:
    - <xref:int>
  - name: lease_id
    description: 'Proposed lease ID, in a GUID string format. The DataLake service
      returns

      400 (Invalid request) if the proposed lease ID is not in the correct format.'
    isRequired: true
    types:
    - <xref:str>
  keywordOnlyParameters:
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: A DataLakeLeaseClient object, that can be run in a context manager.
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
  examples:
  - "Acquiring a lease on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   # Acquire a lease on the file system\n   lease = file_system_client.acquire_lease()\n\
    \n   # Delete file system by passing in the lease\n   file_system_client.delete_file_system(lease=lease)\n\
    \n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.close
  name: close
  summary: 'This method is to close the sockets opened by the client.

    It need not be used when using with a context manager.'
  signature: close() -> None
- uid: azure.storage.filedatalake.FileSystemClient.create_directory
  name: create_directory
  summary: Create directory
  signature: 'create_directory(directory: DirectoryProperties | str, metadata: Dict[str,
    str] | None = None, **kwargs) -> DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  - name: metadata
    description: Name-value pairs associated with the file as metadata.
    isRequired: true
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  keywordOnlyParameters:
  - name: content_settings
    description: ContentSettings object used to set path properties.
    types:
    - <xref:azure.storage.filedatalake.ContentSettings>
  - name: lease
    description: 'Required if the file has an active lease. Value can be a DataLakeLeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: umask
    description: 'Optional and only valid if Hierarchical Namespace is enabled for
      the account.

      When creating a file or directory and the parent folder does not have a default
      ACL,

      the umask restricts the permissions of the file or directory to be created.

      The resulting permission is given by p & ^u, where p is the permission and u
      is the umask.

      For example, if p is 0777 and u is 0057, then the resulting permission is 0720.

      The default permission is 0777 for a directory and 0666 for a file. The default
      umask is 0027.

      The umask must be specified in 4-digit octal notation (e.g. 0766).'
    types:
    - <xref:str>
  - name: owner
    description: The owner of the file or directory.
    types:
    - <xref:str>
  - name: group
    description: The owning group of the file or directory.
    types:
    - <xref:str>
  - name: acl
    description: 'Sets POSIX access control rights on files and directories. The value
      is a

      comma-separated list of access control entries. Each access control entry (ACE)
      consists of a

      scope, a type, a user or group identifier, and permissions in the format

      "[scope:][type]:[id]:[permissions]".'
    types:
    - <xref:str>
  - name: lease_id
    description: 'Proposed lease ID, in a GUID string format. The DataLake service
      returns

      400 (Invalid request) if the proposed lease ID is not in the correct format.'
    types:
    - <xref:str>
  - name: lease_duration
    description: 'Specifies the duration of the lease, in seconds, or negative one

      (-1) for a lease that never expires. A non-infinite lease can be

      between 15 and 60 seconds. A lease duration cannot be changed

      using renew or change.'
    types:
    - <xref:int>
  - name: permissions
    description: 'Optional and only valid if Hierarchical Namespace

      is enabled for the account. Sets POSIX access permissions for the file

      owner, the file owning group, and others. Each class may be granted

      read, write, or execute permission.  The sticky bit is also supported.

      Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are

      supported.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: DataLakeDirectoryClient with new directory and metadata.
    types:
    - <xref:azure.storage.filedatalake.DataLakeDirectoryClient>
  examples:
  - "Create directory in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   directory_client = file_system_client.create_directory(\"mydirectory\")\n\
    \n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.create_file
  name: create_file
  summary: Create file
  signature: 'create_file(file: FileProperties | str, **kwargs) -> DataLakeFileClient'
  parameters:
  - name: file
    description: 'The file with which to interact. This can either be the name of
      the file,

      or an instance of FileProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  keywordOnlyParameters:
  - name: content_settings
    description: ContentSettings object used to set path properties.
    types:
    - <xref:azure.storage.filedatalake.ContentSettings>
  - name: metadata
    description: Name-value pairs associated with the file as metadata.
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: lease
    description: 'Required if the file has an active lease. Value can be a DataLakeLeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: umask
    description: 'Optional and only valid if Hierarchical Namespace is enabled for
      the account.

      When creating a file or directory and the parent folder does not have a default
      ACL,

      the umask restricts the permissions of the file or directory to be created.

      The resulting permission is given by p & ^u, where p is the permission and u
      is the umask.

      For example, if p is 0777 and u is 0057, then the resulting permission is 0720.

      The default permission is 0777 for a directory and 0666 for a file. The default
      umask is 0027.

      The umask must be specified in 4-digit octal notation (e.g. 0766).'
    types:
    - <xref:str>
  - name: owner
    description: The owner of the file or directory.
    types:
    - <xref:str>
  - name: group
    description: The owning group of the file or directory.
    types:
    - <xref:str>
  - name: acl
    description: 'Sets POSIX access control rights on files and directories. The value
      is a

      comma-separated list of access control entries. Each access control entry (ACE)
      consists of a

      scope, a type, a user or group identifier, and permissions in the format

      "[scope:][type]:[id]:[permissions]".'
    types:
    - <xref:str>
  - name: lease_id
    description: 'Proposed lease ID, in a GUID string format. The DataLake service
      returns

      400 (Invalid request) if the proposed lease ID is not in the correct format.'
    types:
    - <xref:str>
  - name: lease_duration
    description: 'Specifies the duration of the lease, in seconds, or negative one

      (-1) for a lease that never expires. A non-infinite lease can be

      between 15 and 60 seconds. A lease duration cannot be changed

      using renew or change.'
    types:
    - <xref:int>
  - name: expires_on
    description: 'The time to set the file to expiry.

      If the type of expires_on is an int, expiration time will be set

      as the number of milliseconds elapsed from creation time.

      If the type of expires_on is datetime, expiration time will be set

      absolute to the time provided. If no time zone info is provided, this

      will be interpreted as UTC.'
    types:
    - <xref:datetime>
    - <xref:int>
  - name: permissions
    description: 'Optional and only valid if Hierarchical Namespace

      is enabled for the account. Sets POSIX access permissions for the file

      owner, the file owning group, and others. Each class may be granted

      read, write, or execute permission.  The sticky bit is also supported.

      Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are

      supported.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: DataLakeFileClient with new file created.
    types:
    - <xref:azure.storage.filedatalake.DataLakeFileClient>
  examples:
  - "Create file in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_client = file_system_client.create_file(\"myfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.create_file_system
  name: create_file_system
  summary: 'Creates a new file system under the specified account.


    If the file system with the same name already exists, a ResourceExistsError will

    be raised. This method returns a client with which to interact with the newly

    created file system.'
  signature: 'create_file_system(metadata: Dict[str, str] | None = None, public_access:
    PublicAccess | None = None, **kwargs) -> Dict[str, str | datetime]'
  parameters:
  - name: metadata
    description: 'A dict with name-value pairs to associate with the

      file system as metadata. Example: *{''Category'':''test''}*'
    isRequired: true
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  - name: public_access
    description: To specify whether data in the file system may be accessed publicly
      and the level of access.
    isRequired: true
    types:
    - <xref:azure.storage.filedatalake.PublicAccess>
  keywordOnlyParameters:
  - name: encryption_scope_options
    description: 'Specifies the default encryption scope to set on the file system
      and use for

      all future writes.


      *New in version 12.9.0.*'
    types:
    - <xref:dict>
    - <xref:azure.storage.filedatalake.EncryptionScopeOptions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: A dictionary of response headers.
    types:
    - <xref:dict>[<xref:str>, <xref:typing.Union>[<xref:str>, <xref:datetime>]]
  examples:
  - "Creating a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\\
    hostedtoolcache\\\\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   file_system_client.create_file_system()\n\n \
    \  ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_directory
  name: delete_directory
  summary: Marks the specified path for deletion.
  signature: 'delete_directory(directory: DirectoryProperties | str, **kwargs) ->
    DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  keywordOnlyParameters:
  - name: lease
    description: 'Required if the file has an active lease. Value can be a LeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: DataLakeDirectoryClient after deleting specified directory.
    types:
    - <xref:azure.storage.filedatalake.DataLakeDirectoryClient>
  examples:
  - "Delete directory in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_system_client.delete_directory(\"mydirectory\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_file
  name: delete_file
  summary: Marks the specified file for deletion.
  signature: 'delete_file(file: FileProperties | str, **kwargs) -> DataLakeFileClient'
  parameters:
  - name: file
    description: 'The file with which to interact. This can either be the name of
      the file,

      or an instance of FileProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  keywordOnlyParameters:
  - name: lease
    description: 'Required if the file has an active lease. Value can be a LeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: DataLakeFileClient after deleting specified file.
    types:
    - <xref:azure.storage.file.datalake.DataLakeFileClient>
  examples:
  - "Delete file in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_system_client.delete_file(\"myfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_file_system
  name: delete_file_system
  summary: 'Marks the specified file system for deletion.


    The file system and any files contained within it are later deleted during garbage
    collection.

    If the file system is not found, a ResourceNotFoundError will be raised.'
  signature: 'delete_file_system(**kwargs: Any) -> None'
  keywordOnlyParameters:
  - name: lease
    description: 'If specified, delete_file_system only succeeds if the

      file system''s lease is active and matches this ID.

      Required if the file system has an active lease.'
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    types:
    - <xref:None>
  examples:
  - "Deleting a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\\
    hostedtoolcache\\\\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   file_system_client.delete_file_system()\n\n \
    \  ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.exists
  name: exists
  summary: Returns True if a file system exists and returns False otherwise.
  signature: 'exists(**kwargs: Any) -> bool'
  keywordOnlyParameters:
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: True if a file system exists, False otherwise.
    types:
    - <xref:bool>
- uid: azure.storage.filedatalake.FileSystemClient.from_connection_string
  name: from_connection_string
  summary: Create FileSystemClient from a Connection String.
  signature: 'from_connection_string(conn_str: str, file_system_name: str, credential:
    str | Dict[str, str] | AzureNamedKeyCredential | AzureSasCredential | TokenCredential
    | None = None, **kwargs: Any) -> Self'
  parameters:
  - name: conn_str
    description: A connection string to an Azure Storage account.
    isRequired: true
    types:
    - <xref:str>
  - name: file_system_name
    description: The name of file system to interact with.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token, or the connection string already has shared

      access key values. The value can be a SAS token string,

      an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,

      an account shared access key, or an instance of a TokenCredentials class from
      azure.identity.

      Credentials provided here will take precedence over those in the connection
      string.

      If using an instance of AzureNamedKeyCredential, "name" should be the storage
      account name, and "key"

      should be the storage account key.'
    defaultValue: None
    types:
    - <xref:azure.core.credentials.AzureNamedKeyCredential>
    - <xref:azure.core.credentials.AzureSasCredential>
    - <xref:azure.core.credentials.TokenCredential>
    - <xref:str>
    - <xref:dict>[<xref:str>, <xref:str>]
    - <xref:None>
  keywordOnlyParameters:
  - name: audience
    description: 'The audience to use when requesting tokens for Azure Active Directory

      authentication. Only has an effect when credential is of type TokenCredential.
      The value could be

      [https://storage.azure.com/](https://storage.azure.com/) (default) or [https:/](https:/)/<account>.blob.core.windows.net.'
    types:
    - <xref:str>
  return:
    description: A FileSystemClient.
    types:
    - <xref:azure.storage.filedatalake.FileSystemClient>
  examples:
  - "Create FileSystemClient from connection string<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   from azure.storage.filedatalake import FileSystemClient\n   file_system_client\
    \ = FileSystemClient.from_connection_string(self.connection_string, \"filesystem\"\
    )\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_directory_client
  name: get_directory_client
  summary: 'Get a client to interact with the specified directory.


    The directory need not already exist.'
  signature: 'get_directory_client(directory: DirectoryProperties | str) -> DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  return:
    description: A DataLakeDirectoryClient.
    types:
    - <xref:azure.storage.filedatalake.DataLakeDirectoryClient>
  examples:
  - "Getting the directory client to interact with a specific directory.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\\
    hostedtoolcache\\\\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   # Get the DataLakeDirectoryClient from the FileSystemClient\
    \ to interact with a specific file\n   directory_client = file_system_client.get_directory_client(\"\
    mynewdirectory\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_file_client
  name: get_file_client
  summary: 'Get a client to interact with the specified file.


    The file need not already exist.'
  signature: 'get_file_client(file_path: FileProperties | str) -> DataLakeFileClient'
  parameters:
  - name: file_path
    description: 'The file with which to interact. This can either be the path of
      the file(from root directory),

      or an instance of FileProperties. eg. directory/subdirectory/file'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  return:
    description: A DataLakeFileClient.
    types:
    - <xref:azure.storage.filedatalake.DataLakeFileClient>
  examples:
  - "Getting the file client to interact with a specific file.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\\
    hostedtoolcache\\\\windows\\\\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\
    \\py2docfx\\\\dist_temp\\\\215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   # Get the FileClient from the FileSystemClient\
    \ to interact with a specific file\n   file_client = file_system_client.get_file_client(\"\
    mynewfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_file_system_access_policy
  name: get_file_system_access_policy
  summary: 'Gets the permissions for the specified file system.

    The permissions indicate whether file system data may be accessed publicly.'
  signature: 'get_file_system_access_policy(**kwargs: Any) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: lease
    description: 'If specified, the operation only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: Access policy information in a dict.
    types:
    - <xref:dict>[<xref:str>, <xref:typing.Any>]
- uid: azure.storage.filedatalake.FileSystemClient.get_file_system_properties
  name: get_file_system_properties
  summary: 'Returns all user-defined metadata and system properties for the specified

    file system. The data returned does not include the file system''s list of paths.'
  signature: 'get_file_system_properties(**kwargs: Any) -> FileSystemProperties'
  keywordOnlyParameters:
  - name: lease
    description: 'If specified, get_file_system_properties only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: Properties for the specified file system within a file system object.
    types:
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  examples:
  - "Getting properties on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   properties = file_system_client.get_file_system_properties()\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_paths
  name: get_paths
  summary: 'Returns a generator to list the paths(could be files or directories) under
    the specified file system.

    The generator will lazily follow the continuation tokens returned by

    the service.'
  signature: 'get_paths(path: str | None = None, recursive: bool | None = True, max_results:
    int | None = None, **kwargs: Any) -> ItemPaged[PathProperties]'
  parameters:
  - name: path
    description: Filters the results to return only paths under the specified path.
    isRequired: true
    types:
    - <xref:str>
  - name: recursive
    description: Optional. Set True for recursive, False for iterative.
    isRequired: true
    types:
    - <xref:typing.Optional>[<xref:bool>]
  - name: max_results
    description: 'An optional value that specifies the maximum

      number of items to return per page. If omitted or greater than 5,000, the

      response will include up to 5,000 items per page.'
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: upn
    description: 'If True, the user identity values returned in the x-ms-owner, x-ms-group,

      and x-ms-acl response headers will be transformed from Azure Active Directory
      Object IDs to User

      Principal Names in the owner, group, and acl fields of

      <xref:azure.storage.filedatalake.PathProperties>. If False, the values will
      be returned

      as Azure Active Directory Object IDs. The default value is False. Note that
      group and application

      Object IDs are not translate because they do not have unique friendly names.'
    types:
    - <xref:bool>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: An iterable (auto-paging) response of PathProperties.
    types:
    - <xref:azure.core.paging.ItemPaged>[<xref:azure.storage.filedatalake.PathProperties>]
  examples:
  - "List the paths in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   path_list = file_system_client.get_paths()\n   for path in path_list:\n \
    \      print(path.name + '\\n')\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.list_deleted_paths
  name: list_deleted_paths
  summary: 'Returns a generator to list the deleted (file or directory) paths under
    the specified file system.

    The generator will lazily follow the continuation tokens returned by

    the service.


    *New in version 12.4.0:* This operation was introduced in API version ''2020-06-12''.'
  signature: 'list_deleted_paths(**kwargs: Any) -> ItemPaged[DeletedPathProperties]'
  keywordOnlyParameters:
  - name: path_prefix
    description: Filters the results to return only paths under the specified path.
    types:
    - <xref:str>
  - name: results_per_page
    description: 'An optional value that specifies the maximum number of items to
      return per page.

      If omitted or greater than 5,000, the response will include up to 5,000 items
      per page.'
    types:
    - <xref:int>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: An iterable (auto-paging) response of DeletedPathProperties.
    types:
    - <xref:azure.core.paging.ItemPaged>[<xref:azure.storage.filedatalake.DeletedPathProperties>]
- uid: azure.storage.filedatalake.FileSystemClient.set_file_system_access_policy
  name: set_file_system_access_policy
  summary: 'Sets the permissions for the specified file system or stored access

    policies that may be used with Shared Access Signatures. The permissions

    indicate whether files in a file system may be accessed publicly.'
  signature: 'set_file_system_access_policy(signed_identifiers: Dict[str, AccessPolicy],
    public_access: str | PublicAccess | None = None, **kwargs) -> Dict[str, str |
    datetime]'
  parameters:
  - name: signed_identifiers
    description: 'A dictionary of access policies to associate with the file system.
      The

      dictionary may contain up to 5 elements. An empty dictionary

      will clear the access policies set on the service.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:azure.storage.filedatalake.AccessPolicy>]
  - name: public_access
    description: To specify whether data in the file system may be accessed publicly
      and the level of access.
    isRequired: true
    types:
    - <xref:azure.storage.filedatalake.PublicAccess>
  keywordOnlyParameters:
  - name: lease
    description: 'Required if the file system has an active lease. Value can be a
      DataLakeLeaseClient object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A datetime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A datetime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: File System-updated property dict (Etag and last modified).
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
    - <xref:dict>[<xref:str>, <xref:datetime.datetime>]
- uid: azure.storage.filedatalake.FileSystemClient.set_file_system_metadata
  name: set_file_system_metadata
  summary: 'Sets one or more user-defined name-value pairs for the specified

    file system. Each call to this operation replaces all existing metadata

    attached to the file system. To remove all metadata from the file system,

    call this operation with no metadata dict.'
  signature: 'set_file_system_metadata(metadata: Dict[str, str], **kwargs) -> Dict[str,
    str | datetime]'
  parameters:
  - name: metadata
    description: 'A dict containing name-value pairs to associate with the file system
      as

      metadata. Example: {''category'':''test''}'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  keywordOnlyParameters:
  - name: lease
    description: 'If specified, set_file_system_metadata only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: 'Sets the server-side timeout for the operation in seconds. For more
      details see

      [https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations](https://learn.microsoft.com/rest/api/storageservices/setting-timeouts-for-blob-service-operations).

      This value is not tracked or validated on the client. To configure client-side
      network timesouts

      see [here](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/storage/azure-storage-file-datalake#other-client--per-operation-configuration).'
    types:
    - <xref:int>
  return:
    description: filesystem-updated property dict (Etag and last modified).
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
    - <xref:dict>[<xref:str>, <xref:datetime.datetime>]
  examples:
  - "Setting metadata on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"C:\\\\hostedtoolcache\\\\windows\\\
    \\Python\\\\3.11.9\\\\x64\\\\Lib\\\\site-packages\\\\py2docfx\\\\dist_temp\\\\\
    215\\\\azure-storage-file-datalake-12.16.0b1\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   # Create key, value pairs for metadata\n   metadata = {'type': 'test'}\n\n\
    \   # Set metadata on the file system\n   file_system_client.set_file_system_metadata(metadata=metadata)\n\
    \n   ````\n"
attributes:
- uid: azure.storage.filedatalake.FileSystemClient.api_version
  name: api_version
  summary: The version of the Storage API used for requests.
  return:
    types:
    - <xref:str>
- uid: azure.storage.filedatalake.FileSystemClient.location_mode
  name: location_mode
  summary: 'The location mode that the client is currently using.


    By default this will be "primary". Options include "primary" and "secondary".'
  return:
    types:
    - <xref:str>
- uid: azure.storage.filedatalake.FileSystemClient.primary_endpoint
  name: primary_endpoint
  summary: The full primary endpoint URL.
  return:
    types:
    - <xref:str>
- uid: azure.storage.filedatalake.FileSystemClient.primary_hostname
  name: primary_hostname
  summary: The hostname of the primary endpoint.
  return:
    types:
    - <xref:str>
- uid: azure.storage.filedatalake.FileSystemClient.secondary_endpoint
  name: secondary_endpoint
  summary: 'The full secondary endpoint URL if configured.


    If not available a ValueError will be raised. To explicitly specify a secondary
    hostname, use the optional

    *secondary_hostname* keyword argument on instantiation.'
  return:
    types:
    - <xref:str>
  exceptions:
  - type: ValueError
- uid: azure.storage.filedatalake.FileSystemClient.secondary_hostname
  name: secondary_hostname
  summary: 'The hostname of the secondary endpoint.


    If not available this will be None. To explicitly specify a secondary hostname,
    use the optional

    *secondary_hostname* keyword argument on instantiation.'
  return:
    types:
    - <xref:typing.Optional>[<xref:str>]
- uid: azure.storage.filedatalake.FileSystemClient.url
  name: url
  summary: 'The full endpoint URL to this entity, including SAS token if used.


    This could be either the primary endpoint,

    or the secondary endpoint depending on the current <xref:azure.storage.filedatalake.FileSystemClient.location_mode>.

    :returns: The full endpoint URL to this entity, including SAS token if used.

    :rtype: str'
