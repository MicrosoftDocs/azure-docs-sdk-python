### YamlMime:PythonClass
uid: azure.storage.filedatalake.FileSystemClient
name: FileSystemClient
fullName: azure.storage.filedatalake.FileSystemClient
module: azure.storage.filedatalake
inheritances:
- azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
summary: 'A client to interact with a specific file system, even if that file system

  may not yet exist.


  For operations relating to a specific directory or file within this file system,
  a directory client or file client

  can be retrieved using the <xref:azure.storage.filedatalake.FileSystemClient.get_directory_client>
  or <xref:azure.storage.filedatalake.FileSystemClient.get_file_client> functions.'
constructor:
  syntax: 'FileSystemClient(account_url: str, file_system_name: str, credential: Optional[Any]
    = None, **kwargs: Any)'
  parameters:
  - name: account_url
    description: The URI to the storage account.
    isRequired: true
    types:
    - <xref:str>
  - name: file_system_name
    description: The file system for the directory or files.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token. The value can be a SAS token string,

      an instance of a AzureSasCredential from azure.core.credentials, an account

      shared access key, or an instance of a TokenCredentials class from azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.'
    isRequired: true
variables:
- description: The full endpoint URL to the file system, including SAS token if used.
  name: url
  types:
  - <xref:str>
- description: The full primary endpoint URL.
  name: primary_endpoint
  types:
  - <xref:str>
- description: The hostname of the primary endpoint.
  name: primary_hostname
  types:
  - <xref:str>
examples:
- "Get a FileSystemClient from an existing DataLakeServiceClient.<!--[!code-python[Main](les\\\
  datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\
  \\1\\\\s\\\\dist_temp\\\\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\
  \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
  \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
  : false} -->\n\n````python\n\n   # Instantiate a DataLakeServiceClient using a connection\
  \ string\n   from azure.storage.filedatalake import DataLakeServiceClient\n   datalake_service_client\
  \ = DataLakeServiceClient.from_connection_string(self.connection_string)\n\n   #\
  \ Instantiate a FileSystemClient\n   file_system_client = datalake_service_client.get_file_system_client(\"\
  mynewfilesystem\")\n\n   ````\n"
methods:
- uid: azure.storage.filedatalake.FileSystemClient.acquire_lease
  name: acquire_lease
  summary: 'Requests a new lease. If the file system does not have an active lease,

    the DataLake service creates a lease on the file system and returns a new

    lease ID.'
  signature: 'acquire_lease(lease_duration: int = -1, lease_id: Optional[str] = None,
    **kwargs) -> azure.storage.filedatalake._data_lake_lease.DataLakeLeaseClient'
  parameters:
  - name: lease_duration
    description: 'Specifies the duration of the lease, in seconds, or negative one

      (-1) for a lease that never expires. A non-infinite lease can be

      between 15 and 60 seconds. A lease duration cannot be changed

      using renew or change. Default is -1 (infinite lease).'
    defaultValue: '-1'
    types:
    - <xref:int>
  - name: lease_id
    description: 'Proposed lease ID, in a GUID string format. The DataLake service
      returns

      400 (Invalid request) if the proposed lease ID is not in the correct format.'
    defaultValue: None
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: A DataLakeLeaseClient object, that can be run in a context manager.
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
  examples:
  - "Acquiring a lease on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   # Acquire a lease on the file system\n   lease = file_system_client.acquire_lease()\n\
    \n   # Delete file system by passing in the lease\n   file_system_client.delete_file_system(lease=lease)\n\
    \n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.close
  name: close
  summary: 'This method is to close the sockets opened by the client.

    It need not be used when using with a context manager.'
  signature: close() -> None
- uid: azure.storage.filedatalake.FileSystemClient.create_directory
  name: create_directory
  summary: Create directory
  signature: 'create_directory(directory: Union[DirectoryProperties, str], metadata:
    Optional[Dict[str, str]] = None, **kwargs) -> DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  - name: metadata
    description: Name-value pairs associated with the file as metadata.
    defaultValue: None
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  - name: content_settings
    description: ContentSettings object used to set path properties.
    types:
    - <xref:azure.storage.filedatalake.ContentSettings>
  - name: lease
    description: 'Required if the file has an active lease. Value can be a DataLakeLeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: umask
    description: 'Optional and only valid if Hierarchical Namespace is enabled for
      the account.

      When creating a file or directory and the parent folder does not have a default
      ACL,

      the umask restricts the permissions of the file or directory to be created.

      The resulting permission is given by p & ^u, where p is the permission and u
      is the umask.

      For example, if p is 0777 and u is 0057, then the resulting permission is 0720.

      The default permission is 0777 for a directory and 0666 for a file. The default
      umask is 0027.

      The umask must be specified in 4-digit octal notation (e.g. 0766).'
    types:
    - <xref:str>
  - name: permissions
    description: 'Optional and only valid if Hierarchical Namespace

      is enabled for the account. Sets POSIX access permissions for the file

      owner, the file owning group, and others. Each class may be granted

      read, write, or execute permission.  The sticky bit is also supported.

      Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are

      supported.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: DataLakeDirectoryClient
  examples:
  - "Create directory in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   directory_client = file_system_client.create_directory(\"mydirectory\")\n\
    \n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.create_file
  name: create_file
  summary: Create file
  signature: 'create_file(file: Union[azure.storage.filedatalake._models.FileProperties,
    str], **kwargs) -> azure.storage.filedatalake._data_lake_file_client.DataLakeFileClient'
  parameters:
  - name: file
    description: 'The file with which to interact. This can either be the name of
      the file,

      or an instance of FileProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  - name: content_settings
    description: ContentSettings object used to set path properties.
    isRequired: true
    types:
    - <xref:azure.storage.filedatalake.ContentSettings>
  - name: metadata
    description: Name-value pairs associated with the file as metadata.
    isRequired: true
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  - name: lease
    description: 'Required if the file has an active lease. Value can be a DataLakeLeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: umask
    description: 'Optional and only valid if Hierarchical Namespace is enabled for
      the account.

      When creating a file or directory and the parent folder does not have a default
      ACL,

      the umask restricts the permissions of the file or directory to be created.

      The resulting permission is given by p & ^u, where p is the permission and u
      is the umask.

      For example, if p is 0777 and u is 0057, then the resulting permission is 0720.

      The default permission is 0777 for a directory and 0666 for a file. The default
      umask is 0027.

      The umask must be specified in 4-digit octal notation (e.g. 0766).'
    types:
    - <xref:str>
  - name: permissions
    description: 'Optional and only valid if Hierarchical Namespace

      is enabled for the account. Sets POSIX access permissions for the file

      owner, the file owning group, and others. Each class may be granted

      read, write, or execute permission.  The sticky bit is also supported.

      Both symbolic (rwxrw-rw-) and 4-digit octal notation (e.g. 0766) are

      supported.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: DataLakeFileClient
  examples:
  - "Create file in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_client = file_system_client.create_file(\"myfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.create_file_system
  name: create_file_system
  summary: 'Creates a new file system under the specified account.


    If the file system with the same name already exists, a ResourceExistsError will

    be raised. This method returns a client with which to interact with the newly

    created file system.'
  signature: 'create_file_system(metadata: Optional[Dict[str, str]] = None, public_access:
    Optional[PublicAccess] = None, **kwargs) -> Dict[str, Union[str, datetime]]'
  parameters:
  - name: metadata
    description: 'A dict with name-value pairs to associate with the

      file system as metadata. Example: *{''Category'':''test''}*'
    defaultValue: None
    types:
    - <xref:dict>(<xref:str>, <xref:str>)
  - name: public_access
    description: To specify whether data in the file system may be accessed publicly
      and the level of access.
    defaultValue: None
    types:
    - <xref:azure.storage.filedatalake.PublicAccess>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    types:
    - <xref:azure.storage.filedatalake.FileSystemClient>
  examples:
  - "Creating a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   file_system_client.create_file_system()\n\n \
    \  ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_directory
  name: delete_directory
  summary: Marks the specified path for deletion.
  signature: 'delete_directory(directory: Union[azure.storage.filedatalake._models.DirectoryProperties,
    str], **kwargs) -> azure.storage.filedatalake._data_lake_directory_client.DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  - name: lease
    description: 'Required if the file has an active lease. Value can be a LeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: DataLakeDirectoryClient
  examples:
  - "Delete directory in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_system_client.delete_directory(\"mydirectory\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_file
  name: delete_file
  summary: Marks the specified file for deletion.
  signature: 'delete_file(file: Union[azure.storage.filedatalake._models.FileProperties,
    str], **kwargs) -> azure.storage.filedatalake._data_lake_file_client.DataLakeFileClient'
  parameters:
  - name: file
    description: 'The file with which to interact. This can either be the name of
      the file,

      or an instance of FileProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  - name: lease
    description: 'Required if the file has an active lease. Value can be a LeaseClient
      object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: DataLakeFileClient
  examples:
  - "Delete file in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   file_system_client.delete_file(\"myfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_file_system
  name: delete_file_system
  summary: 'Marks the specified file system for deletion.


    The file system and any files contained within it are later deleted during garbage
    collection.

    If the file system is not found, a ResourceNotFoundError will be raised.'
  signature: 'delete_file_system(**kwargs: Any) -> None'
  parameters:
  - name: or ~azure.storage.filedatalake.DataLakeLeaseClient lease
    description: 'If specified, delete_file_system only succeeds if the

      file system''s lease is active and matches this ID.

      Required if the file system has an active lease.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    types:
    - <xref:None>
  examples:
  - "Deleting a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   file_system_client.delete_file_system()\n\n \
    \  ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.delete_files
  name: delete_files
  summary: 'Marks the specified files or empty directories for deletion.


    The files/empty directories are later deleted during garbage collection.


    If a delete retention policy is enabled for the service, then this operation soft
    deletes the

    files/empty directories and retains the files or snapshots for specified number
    of days.

    After specified number of days, files'' data is removed from the service during
    garbage collection.

    Soft deleted files/empty directories are accessible through <xref:azure.storage.filedatalake.FileSystemClient.list_deleted_paths>.'
  signature: delete_files(*files, **kwargs) -> Iterator[azure.core.pipeline.transport._base.HttpResponse]
  parameters:
  - name: files
    description: "The files/empty directories to delete. This can be a single file/empty\
      \ directory, or multiple values can\nbe supplied, where each value is either\
      \ the name of the file/directory (str) or\nFileProperties/DirectoryProperties.\n\
      \n\n> [!NOTE]\n> When the file/dir type is dict, here's a list of keys, value\
      \ rules.\n>\n> \n>\n> blob name:\n>\n> \n>\n> key: 'name', value type: str\n\
      >\n> \n>\n> if the file modified or not:\n>\n> \n>\n> key: 'if_modified_since',\
      \ 'if_unmodified_since', value type: datetime\n>\n> \n>\n> etag:\n>\n> \n>\n\
      > key: 'etag', value type: str\n>\n> \n>\n> match the etag or not:\n>\n> \n\
      >\n> key: 'match_condition', value type: MatchConditions\n>\n> \n>\n> lease:\n\
      >\n> \n>\n> key: 'lease_id', value type: Union[str, LeaseClient]\n>\n> \n>\n\
      > timeout for subrequest:\n>\n> \n>\n> key: 'timeout', value type: int\n>"
    isRequired: true
    types:
    - <xref:list>[<xref:str>], <xref:list>[<xref:dict>]<xref:,>
    - <xref:list>[<xref:Union>[<xref:azure.storage.filedatalake.FileProperties>, <xref:azure.storage.filedatalake.DirectoryProperties>]
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: raise_on_any_failure
    description: 'This is a boolean param which defaults to True. When this is set,
      an exception

      is raised even if there is a single operation failure.'
    types:
    - <xref:bool>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: An iterator of responses, one for each blob in order
    types:
    - <xref:Iterator>[<xref:azure.core.pipeline.transport.HttpResponse>]
  examples:
  - "Deleting multiple files or empty directories.<!--[!code-python[Main](les\\datalake_samples_file_system_async.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system_async.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   async def batch_delete_files_or_empty_directories(self):\n       from azure.storage.filedatalake.aio\
    \ import FileSystemClient\n       file_system_client = FileSystemClient.from_connection_string(self.connection_string,\
    \ \"filesystemforcreate\")\n\n       async with file_system_client:\n        \
    \   await file_system_client.create_file_system()\n\n           data = b'hello\
    \ world'\n\n           try:\n               # create file1\n               await\
    \ file_system_client.get_file_client('file1').upload_data(data, overwrite=True)\n\
    \n               # create file2, then pass file properties in batch delete later\n\
    \               file2 = file_system_client.get_file_client('file2')\n        \
    \       await file2.upload_data(data, overwrite=True)\n               file2_properties\
    \ = await file2.get_file_properties()\n\n               # create file3 and batch\
    \ delete it later only etag matches this file3 etag\n               file3 = file_system_client.get_file_client('file3')\n\
    \               await file3.upload_data(data, overwrite=True)\n              \
    \ file3_props = await file3.get_file_properties()\n               file3_etag =\
    \ file3_props.etag\n\n               # create dir1\n               # empty directory\
    \ can be deleted using delete_files\n               await file_system_client.get_directory_client('dir1').create_directory(),\n\
    \n               # create dir2, then pass directory properties in batch delete\
    \ later\n               dir2 = file_system_client.get_directory_client('dir2')\n\
    \               await dir2.create_directory()\n               dir2_properties\
    \ = await dir2.get_directory_properties()\n\n           except:\n            \
    \   pass\n\n           # Act\n           response = await self._to_list(await\
    \ file_system_client.delete_files(\n               'file1',\n               file2_properties,\n\
    \               {'name': 'file3', 'etag': file3_etag},\n               'dir1',\n\
    \               dir2_properties,\n               raise_on_any_failure=False\n\
    \           ))\n           print(\"total number of sub-responses:\" + len(response))\n\
    \           print(response[0].status_code)\n           print(response[2].status_code)\n\
    \           print(response[3].status_code)\n\n   async def _to_list(self, async_iterator):\n\
    \       result = []\n       async for item in async_iterator:\n           result.append(item)\n\
    \       return result\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.exists
  name: exists
  summary: Returns True if a file system exists and returns False otherwise.
  signature: 'exists(**kwargs: Any) -> bool'
  parameters:
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: boolean
- uid: azure.storage.filedatalake.FileSystemClient.from_connection_string
  name: from_connection_string
  summary: 'Create FileSystemClient from a Connection String.


    :return a FileSystemClient

    :rtype ~azure.storage.filedatalake.FileSystemClient'
  signature: 'from_connection_string(conn_str: str, file_system_name: str, credential:
    Optional[Any] = None, **kwargs: Any) -> ClassType'
  parameters:
  - name: conn_str
    description: A connection string to an Azure Storage account.
    isRequired: true
    types:
    - <xref:str>
  - name: file_system_name
    description: The name of file system to interact with.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      account URL already has a SAS token, or the connection string already has shared

      access key values. The value can be a SAS token string,

      an instance of a AzureSasCredential from azure.core.credentials, an account
      shared access

      key, or an instance of a TokenCredentials class from azure.identity.

      Credentials provided here will take precedence over those in the connection
      string.'
    isRequired: true
  - name: credential
    defaultValue: None
  examples:
  - "Create FileSystemClient from connection string<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   from azure.storage.filedatalake import FileSystemClient\n   file_system_client\
    \ = FileSystemClient.from_connection_string(self.connection_string, \"filesystem\"\
    )\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_directory_client
  name: get_directory_client
  summary: 'Get a client to interact with the specified directory.


    The directory need not already exist.'
  signature: 'get_directory_client(directory: Union[azure.storage.filedatalake._models.DirectoryProperties,
    str]) -> azure.storage.filedatalake._data_lake_directory_client.DataLakeDirectoryClient'
  parameters:
  - name: directory
    description: 'The directory with which to interact. This can either be the name
      of the directory,

      or an instance of DirectoryProperties.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.DirectoryProperties>
  return:
    description: A DataLakeDirectoryClient.
    types:
    - <xref:azure.storage.filedatalake.DataLakeDirectoryClient>
  examples:
  - "Getting the directory client to interact with a specific directory.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   # Get the DataLakeDirectoryClient from the FileSystemClient\
    \ to interact with a specific file\n   directory_client = file_system_client.get_directory_client(\"\
    mynewdirectory\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_file_client
  name: get_file_client
  summary: 'Get a client to interact with the specified file.


    The file need not already exist.'
  signature: 'get_file_client(file_path: Union[azure.storage.filedatalake._models.FileProperties,
    str]) -> azure.storage.filedatalake._data_lake_file_client.DataLakeFileClient'
  parameters:
  - name: file_path
    description: 'The file with which to interact. This can either be the path of
      the file(from root directory),

      or an instance of FileProperties. eg. directory/subdirectory/file'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.storage.filedatalake.FileProperties>
  return:
    description: A DataLakeFileClient.
    types:
    - <xref:azure.storage.filedatalake.DataLakeFileClient>
  examples:
  - "Getting the file client to interact with a specific file.<!--[!code-python[Main](les\\\
    datalake_samples_file_system.py )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\"\
    : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\\
    a\\\\1\\\\s\\\\dist_temp\\\\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\
    \\datalake_samples_file_system.py\", \"xml:space\": \"preserve\", \"force\": false,\
    \ \"language\": \"python\", \"highlight_args\": {\"linenostart\": 1}, \"linenos\"\
    : false} -->\n\n````python\n\n   # Get the FileClient from the FileSystemClient\
    \ to interact with a specific file\n   file_client = file_system_client.get_file_client(\"\
    mynewfile\")\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_file_system_access_policy
  name: get_file_system_access_policy
  summary: 'Gets the permissions for the specified file system.

    The permissions indicate whether file system data may be accessed publicly.'
  signature: 'get_file_system_access_policy(**kwargs: Any) -> Dict[str, Any]'
  parameters:
  - name: lease
    description: 'If specified, the operation only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: Access policy information in a dict.
    types:
    - <xref:dict>[<xref:str>, <xref:Any>]
- uid: azure.storage.filedatalake.FileSystemClient.get_file_system_properties
  name: get_file_system_properties
  summary: 'Returns all user-defined metadata and system properties for the specified

    file system. The data returned does not include the file system''s list of paths.'
  signature: 'get_file_system_properties(**kwargs: Any) -> azure.storage.filedatalake._models.FileSystemProperties'
  parameters:
  - name: or ~azure.storage.filedatalake.DataLakeLeaseClient lease
    description: 'If specified, get_file_system_properties only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:str>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: Properties for the specified file system within a file system object.
    types:
    - <xref:azure.storage.filedatalake.FileSystemProperties>
  examples:
  - "Getting properties on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   properties = file_system_client.get_file_system_properties()\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.get_paths
  name: get_paths
  summary: 'Returns a generator to list the paths(could be files or directories) under
    the specified file system.

    The generator will lazily follow the continuation tokens returned by

    the service.'
  signature: 'get_paths(path: Optional[str] = None, recursive: Optional[bool] = True,
    max_results: Optional[int] = None, **kwargs) -> ItemPaged[PathProperties]'
  parameters:
  - name: path
    description: Filters the results to return only paths under the specified path.
    defaultValue: None
    types:
    - <xref:str>
  - name: max_results
    description: 'An optional value that specifies the maximum

      number of items to return per page. If omitted or greater than 5,000, the

      response will include up to 5,000 items per page.'
    defaultValue: 'True'
    types:
    - <xref:int>
  - name: upn
    description: 'Optional. Valid only when Hierarchical Namespace is

      enabled for the account. If "true", the user identity values returned

      in the x-ms-owner, x-ms-group, and x-ms-acl response headers will be

      transformed from Azure Active Directory Object IDs to User Principal

      Names.  If "false", the values will be returned as Azure Active

      Directory Object IDs. The default value is false. Note that group and

      application Object IDs are not translated because they do not have

      unique friendly names.'
    defaultValue: None
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: An iterable (auto-paging) response of PathProperties.
    types:
    - <xref:azure.core.paging.ItemPaged>[<xref:azure.storage.filedatalake.PathProperties>]
  examples:
  - "List the paths in the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   path_list = file_system_client.get_paths()\n   for path in path_list:\n \
    \      print(path.name + '\\n')\n\n   ````\n"
- uid: azure.storage.filedatalake.FileSystemClient.list_deleted_paths
  name: list_deleted_paths
  summary: 'Returns a generator to list the deleted (file or directory) paths under
    the specified file system.

    The generator will lazily follow the continuation tokens returned by

    the service.


    New in version 12.4.0: This operation was introduced in API version ''2020-06-12''.'
  signature: 'list_deleted_paths(**kwargs: Any) -> azure.core.paging.ItemPaged[azure.storage.filedatalake._models.DeletedPathProperties]'
  parameters:
  - name: path_prefix
    description: Filters the results to return only paths under the specified path.
    types:
    - <xref:str>
  - name: results_per_page
    description: 'An optional value that specifies the maximum number of items to
      return per page.

      If omitted or greater than 5,000, the response will include up to 5,000 items
      per page.'
    types:
    - <xref:int>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: An iterable (auto-paging) response of DeletedPathProperties.
    types:
    - <xref:azure.core.paging.ItemPaged>[<xref:azure.storage.filedatalake.DeletedPathProperties>]
- uid: azure.storage.filedatalake.FileSystemClient.set_file_system_access_policy
  name: set_file_system_access_policy
  summary: 'Sets the permissions for the specified file system or stored access

    policies that may be used with Shared Access Signatures. The permissions

    indicate whether files in a file system may be accessed publicly.'
  signature: 'set_file_system_access_policy(signed_identifiers: Dict[str, AccessPolicy],
    public_access: Optional[Union[str, PublicAccess]] = None, **kwargs) -> Dict[str,
    Union[str, datetime]]'
  parameters:
  - name: signed_identifiers
    description: 'A dictionary of access policies to associate with the file system.
      The

      dictionary may contain up to 5 elements. An empty dictionary

      will clear the access policies set on the service.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:azure.storage.filedatalake.AccessPolicy>]
  - name: public_access
    description: To specify whether data in the file system may be accessed publicly
      and the level of access.
    defaultValue: None
    types:
    - <xref:azure.storage.filedatalake.PublicAccess>
  - name: lease
    description: 'Required if the file system has an active lease. Value can be a
      DataLakeLeaseClient object

      or the lease ID as a string.'
    types:
    - <xref:azure.storage.filedatalake.DataLakeLeaseClient>
    - <xref:str>
  - name: if_modified_since
    description: 'A datetime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A datetime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: File System-updated property dict (Etag and last modified).
    types:
    - <xref:dict>[<xref:str>, <xref:str>
    - <xref:datetime.datetime>]
- uid: azure.storage.filedatalake.FileSystemClient.set_file_system_metadata
  name: set_file_system_metadata
  summary: 'Sets one or more user-defined name-value pairs for the specified

    file system. Each call to this operation replaces all existing metadata

    attached to the file system. To remove all metadata from the file system,

    call this operation with no metadata dict.'
  signature: 'set_file_system_metadata(metadata: Dict[str, str], **kwargs) -> Dict[str,
    Union[str, datetime]]'
  parameters:
  - name: metadata
    description: 'A dict containing name-value pairs to associate with the file system
      as

      metadata. Example: {''category'':''test''}'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: or ~azure.storage.filedatalake.DataLakeLeaseClient lease
    description: 'If specified, set_file_system_metadata only succeeds if the

      file system''s lease is active and matches this ID.'
    types:
    - <xref:str>
  - name: if_modified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only

      if the resource has been modified since the specified time.'
    types:
    - <xref:datetime.datetime>
  - name: if_unmodified_since
    description: 'A DateTime value. Azure expects the date value passed in to be UTC.

      If timezone is included, any non-UTC datetimes will be converted to UTC.

      If a date is passed in without timezone info, it is assumed to be UTC.

      Specify this header to perform the operation only if

      the resource has not been modified since the specified date/time.'
    types:
    - <xref:datetime.datetime>
  - name: etag
    description: 'An ETag value, or the wildcard character (*). Used to check if the
      resource has changed,

      and act according to the condition specified by the *match_condition* parameter.'
    types:
    - <xref:str>
  - name: match_condition
    description: The match condition to use upon the etag.
    types:
    - <xref:azure.core.MatchConditions>
  - name: timeout
    description: The timeout parameter is expressed in seconds.
    types:
    - <xref:int>
  return:
    description: filesystem-updated property dict (Etag and last modified).
  examples:
  - "Setting metadata on the file system.<!--[!code-python[Main](les\\datalake_samples_file_system.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\
    \\70\\\\azure-storage-file-datalake-12.6.0b2\\\\samples\\\\datalake_samples_file_system.py\"\
    , \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
    highlight_args\": {\"linenostart\": 1}, \"linenos\": false} -->\n\n````python\n\
    \n   # Create key, value pairs for metadata\n   metadata = {'type': 'test'}\n\n\
    \   # Set metadata on the file system\n   file_system_client.set_file_system_metadata(metadata=metadata)\n\
    \n   ````\n"
