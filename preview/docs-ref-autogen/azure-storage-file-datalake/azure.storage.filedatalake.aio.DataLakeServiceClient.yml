### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.filedatalake.aio.DataLakeServiceClient.close
  - azure.storage.filedatalake.aio.DataLakeServiceClient.create_file_system
  - azure.storage.filedatalake.aio.DataLakeServiceClient.delete_file_system
  - azure.storage.filedatalake.aio.DataLakeServiceClient.get_directory_client
  - azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_client
  - azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_system_client
  - azure.storage.filedatalake.aio.DataLakeServiceClient.get_user_delegation_key
  - azure.storage.filedatalake.aio.DataLakeServiceClient.list_file_systems
  class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Creating the DataLakeServiceClient from connection string.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   from azure.storage.filedatalake.aio import DataLakeServiceClient\n\
    \   datalake_service_client = DataLakeServiceClient.from_connection_string(connection_string)\n\
    \n   ````\n\nCreating the DataLakeServiceClient with Azure Identity credentials.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   from azure.identity.aio import ClientSecretCredential\n\
    \   token_credential = ClientSecretCredential(\n       active_directory_tenant_id,\n\
    \       active_directory_application_id,\n       active_directory_application_secret,\n\
    \   )\n   datalake_service_client = DataLakeServiceClient(\"https://{}.dfs.core.windows.net\"\
    .format(account_name),\n                                                   credential=token_credential)\n\
    \n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient
  inheritance:
  - inheritance:
    - type: builtins.object
    type: azure.storage.filedatalake._shared.base_client_async.AsyncStorageAccountHostsMixin
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
    type: azure.storage.filedatalake._data_lake_service_client.DataLakeServiceClient
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: DataLakeServiceClient
  summary: 'A client to interact with the DataLake Service at the account level.


    This client provides operations to retrieve and configure the account properties

    as well as list, create and delete file systems within the account.

    For operations relating to a specific file system, directory or file, clients
    for those entities

    can also be retrieved using the *get_client* functions.'
  syntax:
    content: DataLakeServiceClient(account_url, credential=None, **kwargs)
    parameters:
    - description: 'The URL to the DataLake storage account. Any other entities included

        in the URL path (e.g. file system or file) will be discarded. This URL can
        be optionally

        authenticated with a SAS token.'
      id: account_url
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token. The value can be a SAS token string,
        and account

        shared access key, or an instance of a TokenCredentials class from azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    variables:
    - description: The full endpoint URL to the datalake service endpoint.
      id: url
      type:
      - str
    - description: The full primary endpoint URL.
      id: primary_endpoint
      type:
      - str
    - description: The hostname of the primary endpoint.
      id: primary_hostname
      type:
      - str
  type: class
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.close
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: close()
  namewithoutparameters: close
  summary: 'This method is to close the sockets opened by the client.

    It need not be used when using with a context manager.'
  syntax:
    content: close()
    parameters: []
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.close
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Creating a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   await datalake_service_client.create_file_system(\"\
    filesystem\")\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.create_file_system
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: create_file_system(file_system, metadata=None, public_access=None, **kwargs)
  namewithoutparameters: create_file_system
  summary: 'Creates a new file system under the specified account.


    If the file system with the same name already exists, a ResourceExistsError will

    be raised. This method returns a client with which to interact with the newly

    created file system.'
  syntax:
    content: create_file_system(file_system, metadata=None, public_access=None, **kwargs)
    parameters:
    - description: The name of the file system to create.
      id: file_system
      isRequired: true
      type:
      - str
    - defaultValue: None
      description: 'A dict with name-value pairs to associate with the

        file system as metadata. Example: *{''Category'':''test''}*'
      id: metadata
      type:
      - dict(str, str)
    - defaultValue: None
      description: 'Possible values include: file system, file.'
      id: public_access
      type:
      - azure.storage.filedatalake.PublicAccess
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      type:
      - azure.storage.filedatalake.FileSystemClient
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.create_file_system
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Deleting a file system in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   await datalake_service_client.delete_file_system(\"\
    filesystem\")\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.delete_file_system
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: delete_file_system(file_system, **kwargs)
  namewithoutparameters: delete_file_system
  summary: 'Marks the specified file system for deletion.


    The file system and any files contained within it are later deleted during garbage
    collection.

    If the file system is not found, a ResourceNotFoundError will be raised.'
  syntax:
    content: delete_file_system(file_system, **kwargs)
    parameters:
    - description: 'The file system to delete. This can either be the name of the
        file system,

        or an instance of FileSystemProperties.'
      id: file_system
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.FileSystemProperties
    - description: 'If specified, delete_file_system only succeeds if the

        file system''s lease is active and matches this ID.

        Required if the file system has an active lease.'
      id: lease
      isRequired: true
      type:
      - azure.storage.filedatalake.aio.DataLakeLeaseClient
      - str
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only

        if the resource has been modified since the specified time.'
      id: if_modified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'A DateTime value. Azure expects the date value passed in to be
        UTC.

        If timezone is included, any non-UTC datetimes will be converted to UTC.

        If a date is passed in without timezone info, it is assumed to be UTC.

        Specify this header to perform the operation only if

        the resource has not been modified since the specified date/time.'
      id: if_unmodified_since
      isRequired: true
      type:
      - datetime.datetime
    - description: 'An ETag value, or the wildcard character (*). Used to check if
        the resource has changed,

        and act according to the condition specified by the *match_condition* parameter.'
      id: etag
      isRequired: true
      type:
      - str
    - description: The match condition to use upon the etag.
      id: match_condition
      isRequired: true
      type:
      - azure.core.MatchConditions
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      type:
      - None
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.delete_file_system
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Getting the directory client to interact with a specific directory.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   directory_client = datalake_service_client.get_directory_client(file_system_client.file_system_name,\n\
    \                                                                   \"mydirectory\"\
    )\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_directory_client
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: get_directory_client(file_system, directory)
  namewithoutparameters: get_directory_client
  summary: 'Get a client to interact with the specified directory.


    The directory need not already exist.'
  syntax:
    content: get_directory_client(file_system, directory)
    parameters:
    - description: 'The file system that the directory is in. This can either be the
        name of the file system,

        or an instance of FileSystemProperties.'
      id: file_system
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.FileSystemProperties
    - description: 'The directory with which to interact. This can either be the name
        of the directory,

        or an instance of DirectoryProperties.'
      id: directory
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.DirectoryProperties
    return:
      description: A DataLakeDirectoryClient.
      type:
      - azure.storage.filedatalake.aio.DataLakeDirectoryClient
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_directory_client
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Getting the file client to interact with a specific file.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   file_client = datalake_service_client.get_file_client(file_system_client.file_system_name,\
    \ \"myfile\")\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_client
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: get_file_client(file_system, file_path)
  namewithoutparameters: get_file_client
  summary: 'Get a client to interact with the specified file.


    The file need not already exist.'
  syntax:
    content: get_file_client(file_system, file_path)
    parameters:
    - description: 'The file system that the file is in. This can either be the name
        of the file system,

        or an instance of FileSystemProperties.'
      id: file_system
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.FileSystemProperties
    - description: 'The file with which to interact. This can either be the full path
        of the file(from the root directory),

        or an instance of FileProperties. eg. directory/subdirectory/file'
      id: file_path
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.FileProperties
    return:
      description: A DataLakeFileClient.
      type:
      - azure.storage.filedatalake.aio.DataLakeFileClient
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_client
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Getting the file system client to interact with a specific file system.<!--[!code-python[Main](les\\\
    datalake_samples_file_system_async.py )]-->\n\n<!-- literal_block {\"ids\": [],\
    \ \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\"\
    : \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_file_system_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   # Instantiate a DataLakeServiceClient using a connection\
    \ string\n   from azure.storage.filedatalake.aio import DataLakeServiceClient\n\
    \   datalake_service_client = DataLakeServiceClient.from_connection_string(self.connection_string)\n\
    \n   async with datalake_service_client:\n       # Instantiate a FileSystemClient\n\
    \       file_system_client = datalake_service_client.get_file_system_client(\"\
    mynewfilesystems\")\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_system_client
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: get_file_system_client(file_system)
  namewithoutparameters: get_file_system_client
  summary: 'Get a client to interact with the specified file system.


    The file system need not already exist.'
  syntax:
    content: get_file_system_client(file_system)
    parameters:
    - description: 'The file system. This can either be the name of the file system,

        or an instance of FileSystemProperties.'
      id: file_system
      isRequired: true
      type:
      - str
      - azure.storage.filedatalake.FileSystemProperties
    return:
      description: A FileSystemClient.
      type:
      - azure.storage.filedatalake.aio.FileSystemClient
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_system_client
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Get user delegation key from datalake service client.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   from datetime import datetime, timedelta\n   user_delegation_key\
    \ = await datalake_service_client.get_user_delegation_key(datetime.utcnow(),\n\
    \                                                                         datetime.utcnow()\
    \ + timedelta(hours=1))\n\n   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_user_delegation_key
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: get_user_delegation_key(key_start_time, key_expiry_time, **kwargs)
  namewithoutparameters: get_user_delegation_key
  summary: 'Obtain a user delegation key for the purpose of signing SAS tokens.

    A token credential must be present on the service object for this request to succeed.'
  syntax:
    content: get_user_delegation_key(key_start_time, key_expiry_time, **kwargs)
    parameters:
    - description: A DateTime value. Indicates when the key becomes valid.
      id: key_start_time
      isRequired: true
      type:
      - datetime.datetime
    - description: A DateTime value. Indicates when the key stops being valid.
      id: key_expiry_time
      isRequired: true
      type:
      - datetime.datetime
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: The user delegation key.
      type:
      - azure.storage.filedatalake.UserDelegationKey
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_user_delegation_key
- class: azure.storage.filedatalake.aio.DataLakeServiceClient
  example:
  - "Listing the file systems in the datalake service.<!--[!code-python[Main](les\\\
    datalake_samples_service_async.py )]-->\n\n<!-- literal_block {\"ids\": [], \"\
    classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\":\
    \ \"D:\\\\a\\\\1\\\\s\\\\dist_temp\\\\19\\\\azure-storage-file-datalake-12.1.0b1\\\
    \\samples\\\\datalake_samples_service_async.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   file_systems = datalake_service_client.list_file_systems()\n\
    \   async for file_system in file_systems:\n       print(file_system.name)\n\n\
    \   ````\n"
  fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.list_file_systems
  langs:
  - python
  module: azure.storage.filedatalake.aio
  name: list_file_systems(name_starts_with=None, include_metadata=None, **kwargs)
  namewithoutparameters: list_file_systems
  summary: 'Returns a generator to list the file systems under the specified account.


    The generator will lazily follow the continuation tokens returned by

    the service and stop when all file systems have been returned.'
  syntax:
    content: list_file_systems(name_starts_with=None, include_metadata=None, **kwargs)
    parameters:
    - defaultValue: None
      description: 'Filters the results to return only file systems whose names

        begin with the specified prefix.'
      id: name_starts_with
      type:
      - str
    - defaultValue: None
      description: 'Specifies that file system metadata be returned in the response.

        The default value is *False*.'
      id: include_metadata
      type:
      - bool
    - description: 'The maximum number of file system names to retrieve per API

        call. If the request does not specify the server will return up to 5,000 items
        per page.'
      id: results_per_page
      isRequired: true
      type:
      - int
    - description: The timeout parameter is expressed in seconds.
      id: timeout
      isRequired: true
      type:
      - int
    return:
      description: An iterable (auto-paging) of FileSystemProperties.
      type:
      - azure.core.paging.ItemPaged[azure.storage.filedatalake.FileSystemProperties]
  type: method
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.list_file_systems
references:
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.close
  isExternal: false
  name: close()
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.close
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.create_file_system
  isExternal: false
  name: create_file_system(file_system, metadata=None, public_access=None, **kwargs)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.create_file_system
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.delete_file_system
  isExternal: false
  name: delete_file_system(file_system, **kwargs)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.delete_file_system
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_directory_client
  isExternal: false
  name: get_directory_client(file_system, directory)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_directory_client
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_client
  isExternal: false
  name: get_file_client(file_system, file_path)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_client
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_system_client
  isExternal: false
  name: get_file_system_client(file_system)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_file_system_client
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.get_user_delegation_key
  isExternal: false
  name: get_user_delegation_key(key_start_time, key_expiry_time, **kwargs)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.get_user_delegation_key
- fullName: azure.storage.filedatalake.aio.DataLakeServiceClient.list_file_systems
  isExternal: false
  name: list_file_systems(name_starts_with=None, include_metadata=None, **kwargs)
  parent: azure.storage.filedatalake.aio.DataLakeServiceClient
  uid: azure.storage.filedatalake.aio.DataLakeServiceClient.list_file_systems
- fullName: dict(str, str)
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  uid: dict(str, str)
- fullName: azure.core.paging.ItemPaged[azure.storage.filedatalake.FileSystemProperties]
  name: ItemPaged[FileSystemProperties]
  spec.python:
  - fullName: azure.core.paging.ItemPaged
    name: ItemPaged
    uid: azure.core.paging.ItemPaged
  - fullName: '['
    name: '['
  - fullName: azure.storage.filedatalake.FileSystemProperties
    name: FileSystemProperties
    uid: azure.storage.filedatalake.FileSystemProperties
  - fullName: ']'
    name: ']'
  uid: azure.core.paging.ItemPaged[azure.storage.filedatalake.FileSystemProperties]
