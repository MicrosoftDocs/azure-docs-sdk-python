### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.PatternTokenizer
name: PatternTokenizer
fullName: azure.search.documents.indexes.models.PatternTokenizer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.LexicalTokenizer
summary: 'Tokenizer that uses regex pattern matching to construct distinct tokens.

  This tokenizer is implemented using Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: PatternTokenizer(**kwargs)
variables:
- description: 'Required. The name of the tokenizer. It must only contain letters,
    digits, spaces,

    dashes or underscores, can only start and end with alphanumeric characters, and
    is limited to

    128 characters.'
  name: name
  types:
  - <xref:str>
- description: 'A regular expression to match token separators. Default is an

    expression that matches one or more white space characters.'
  name: pattern
  types:
  - <xref:str>
- description: 'List of regular expression flags. Possible values of each flag include:
    ''CANON_EQ'',

    ''CASE_INSENSITIVE'', ''COMMENTS'', ''DOTALL'', ''LITERAL'', ''MULTILINE'', ''UNICODE_CASE'',
    ''UNIX_LINES''.'
  name: flags
  types:
  - <xref:list>[<xref:str>]
  - <xref:list>[<xref:azure.search.documents.indexes.models.RegexFlags>]
- description: 'The zero-based ordinal of the matching group in the regular expression
    to

    extract into tokens. Use -1 if you want to use the entire pattern to split the
    input into

    tokens, irrespective of matching groups. Default is -1.'
  name: group
  types:
  - <xref:int>
methods:
- uid: azure.search.documents.indexes.models.PatternTokenizer.as_dict
  name: as_dict
  summary: "Return a dict that can be serialized using json.dump.\n\nAdvanced usage\
    \ might optionally use a callback as parameter:\n\nKey is the attribute name used\
    \ in Python. Attr_desc\nis a dict of metadata. Currently contains 'type' with\
    \ the\nmsrest type and 'key' with the RestAPI encoded key.\nValue is the current\
    \ value in this object.\n\nThe string returned will be used to serialize the key.\n\
    If the return type is a list, this is considered hierarchical\nresult dict.\n\n\
    See the three examples in this file:\n\n* attribute_transformer \n\n* full_restapi_key_transformer\
    \ \n\n* last_restapi_key_transformer \n\nIf you want XML serialization, you can\
    \ pass the kwargs is_xml=True."
  signature: 'as_dict(keep_readonly: bool = True, key_transformer: ~typing.Callable[[str,
    ~typing.Dict[str, ~typing.Any], ~typing.Any], ~typing.Any] = <function attribute_transformer>,
    **kwargs: ~typing.Any) -> MutableMapping[str, Any]'
  parameters:
  - name: key_transformer
    description: A key transformer function.
    types:
    - <xref:function>
  - name: keep_readonly
    defaultValue: 'True'
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.search.documents.indexes.models.PatternTokenizer.deserialize
  name: deserialize
  summary: Parse a str using the RestAPI syntax and return a model.
  signature: 'deserialize(data: Any, content_type: str | None = None) -> ModelType'
  parameters:
  - name: data
    description: A str using RestAPI structure. JSON by default.
    isRequired: true
    types:
    - <xref:str>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.search.documents.indexes.models.PatternTokenizer.enable_additional_properties_sending
  name: enable_additional_properties_sending
  signature: enable_additional_properties_sending() -> None
- uid: azure.search.documents.indexes.models.PatternTokenizer.from_dict
  name: from_dict
  summary: 'Parse a dict using given key extractor return a model.


    By default consider key

    extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor

    and last_rest_key_case_insensitive_extractor)'
  signature: 'from_dict(data: Any, key_extractors: Callable[[str, Dict[str, Any],
    Any], Any] | None = None, content_type: str | None = None) -> ModelType'
  parameters:
  - name: data
    description: A dict using RestAPI structure
    isRequired: true
    types:
    - <xref:dict>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  - name: key_extractors
    defaultValue: None
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.search.documents.indexes.models.PatternTokenizer.is_xml_model
  name: is_xml_model
  signature: is_xml_model() -> bool
- uid: azure.search.documents.indexes.models.PatternTokenizer.serialize
  name: serialize
  summary: 'Return the JSON that would be sent to server from this model.


    This is an alias to *as_dict(full_restapi_key_transformer, keep_readonly=False)*.


    If you want XML serialization, you can pass the kwargs is_xml=True.'
  signature: 'serialize(keep_readonly: bool = False, **kwargs: Any) -> MutableMapping[str,
    Any]'
  parameters:
  - name: keep_readonly
    description: If you want to serialize the readonly attributes
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
