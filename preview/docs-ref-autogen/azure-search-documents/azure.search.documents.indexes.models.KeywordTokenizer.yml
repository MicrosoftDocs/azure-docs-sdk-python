### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.KeywordTokenizer
name: KeywordTokenizer
fullName: azure.search.documents.indexes.models.KeywordTokenizer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.KeywordTokenizerV2
constructor:
  syntax: 'KeywordTokenizer(*, name: str, max_token_length: int = 256, **kwargs: Any)'
  parameters:
  - name: name
    description: 'The name of the tokenizer. It must only contain letters, digits,
      spaces, dashes

      or underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters. Required.'
    types:
    - <xref:str>
  - name: max_token_length
    description: 'The maximum token length. Default is 256. Tokens longer than the

      maximum length are split. The maximum token length that can be used is 300 characters.'
    types:
    - <xref:int>
