### YamlMime:UniversalReference
api_name: []
items:
- children: []
  class: azure.search.documents.indexes.models.WordDelimiterTokenFilter
  fullName: azure.search.documents.indexes.models.WordDelimiterTokenFilter
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: msrest.serialization.Model
    type: azure.search.documents.indexes._internal._generated.models._models_py3.TokenFilter
  langs:
  - python
  module: azure.search.documents.indexes.models
  name: WordDelimiterTokenFilter
  summary: 'Splits words into subwords and performs optional transformations on subword
    groups. This token filter is implemented using Apache Lucene.


    All required parameters must be populated in order to send to Azure.'
  syntax:
    content: 'WordDelimiterTokenFilter(*, name: str, generate_word_parts: typing.Union[bool,
      NoneType] = True, generate_number_parts: typing.Union[bool, NoneType] = True,
      catenate_words: typing.Union[bool, NoneType] = False, catenate_numbers: typing.Union[bool,
      NoneType] = False, catenate_all: typing.Union[bool, NoneType] = False, split_on_case_change:
      typing.Union[bool, NoneType] = True, preserve_original: typing.Union[bool, NoneType]
      = False, split_on_numerics: typing.Union[bool, NoneType] = True, stem_english_possessive:
      typing.Union[bool, NoneType] = True, protected_words: typing.Union[typing.List[str],
      NoneType] = None, **kwargs)'
    parameters:
    - description: 'Required. Identifies the concrete type of the token filter.Constant
        filled

        by server.'
      id: odata_type
      type:
      - str
    - description: 'Required. The name of the token filter. It must only contain letters,
        digits,

        spaces, dashes or underscores, can only start and end with alphanumeric characters,
        and is

        limited to 128 characters.'
      id: name
      type:
      - str
    - description: 'A value indicating whether to generate part words. If set, causes

        parts of words to be generated; for example "AzureSearch" becomes "Azure"
        "Search". Default is

        true.'
      id: generate_word_parts
      type:
      - bool
    - description: 'A value indicating whether to generate number subwords. Default

        is true.'
      id: generate_number_parts
      type:
      - bool
    - description: 'A value indicating whether maximum runs of word parts will be
        catenated.

        For example, if this is set to true, "Azure-Search" becomes "AzureSearch".
        Default is false.'
      id: catenate_words
      type:
      - bool
    - description: 'A value indicating whether maximum runs of number parts will be

        catenated. For example, if this is set to true, "1-2" becomes "12". Default
        is false.'
      id: catenate_numbers
      type:
      - bool
    - description: 'A value indicating whether all subword parts will be catenated.
        For

        example, if this is set to true, "Azure-Search-1" becomes "AzureSearch1".
        Default is false.'
      id: catenate_all
      type:
      - bool
    - description: 'A value indicating whether to split words on caseChange. For

        example, if this is set to true, "AzureSearch" becomes "Azure" "Search". Default
        is true.'
      id: split_on_case_change
      type:
      - bool
    - description: 'A value indicating whether original words will be preserved and
        added

        to the subword list. Default is false.'
      id: preserve_original
      type:
      - bool
    - description: 'A value indicating whether to split on numbers. For example, if
        this

        is set to true, "Azure1Search" becomes "Azure" "1" "Search". Default is true.'
      id: split_on_numerics
      type:
      - bool
    - description: 'A value indicating whether to remove trailing "''s" for each

        subword. Default is true.'
      id: stem_english_possessive
      type:
      - bool
    - description: A list of tokens to protect from being delimited.
      id: protected_words
      type:
      - list[str]
  type: class
  uid: azure.search.documents.indexes.models.WordDelimiterTokenFilter
references:
- fullName: list[str]
  name: list[str]
  spec.python:
  - fullName: list
    name: list
    uid: list
  - fullName: '['
    name: '['
  - fullName: str
    name: str
    uid: str
  - fullName: ']'
    name: ']'
  uid: list[str]
