### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.StopAnalyzer
name: StopAnalyzer
fullName: azure.search.documents.indexes.models.StopAnalyzer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.LexicalAnalyzer
summary: 'Divides text at non-letters; Applies the lowercase and stopword token filters.
  This analyzer is

  implemented using Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'StopAnalyzer(*, name: str, stopwords: List[str] | None = None, **kwargs:
    Any)'
  parameters:
  - name: name
    description: 'The name of the analyzer. It must only contain letters, digits,
      spaces, dashes

      or underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters. Required.'
    types:
    - <xref:str>
  - name: stopwords
    description: A list of stopwords.
    types:
    - <xref:list>[<xref:str>]
variables:
- description: Identifies the concrete type of the analyzer. Required.
  name: odata_type
  types:
  - <xref:str>
- description: 'The name of the analyzer. It must only contain letters, digits, spaces,
    dashes or

    underscores, can only start and end with alphanumeric characters, and is limited
    to 128

    characters. Required.'
  name: name
  types:
  - <xref:str>
- description: A list of stopwords.
  name: stopwords
  types:
  - <xref:list>[<xref:str>]
