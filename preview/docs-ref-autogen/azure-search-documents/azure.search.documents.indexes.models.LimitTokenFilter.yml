### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.LimitTokenFilter
name: LimitTokenFilter
fullName: azure.search.documents.indexes.models.LimitTokenFilter
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.TokenFilter
summary: 'Limits the number of tokens while indexing. This token filter is implemented
  using Apache

  Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'LimitTokenFilter(*, name: str, max_token_count: int = 1, consume_all_tokens:
    bool = False, **kwargs: Any)'
  parameters:
  - name: name
    description: 'The name of the token filter. It must only contain letters, digits,
      spaces,

      dashes or underscores, can only start and end with alphanumeric characters,
      and is limited to

      128 characters. Required.'
    types:
    - <xref:str>
  - name: max_token_count
    description: The maximum number of tokens to produce. Default is 1.
    types:
    - <xref:int>
  - name: consume_all_tokens
    description: 'A value indicating whether all tokens from the input must be

      consumed even if maxTokenCount is reached. Default is false.'
    types:
    - <xref:bool>
variables:
- description: Identifies the concrete type of the token filter. Required.
  name: odata_type
  types:
  - <xref:str>
- description: 'The name of the token filter. It must only contain letters, digits,
    spaces, dashes

    or underscores, can only start and end with alphanumeric characters, and is limited
    to 128

    characters. Required.'
  name: name
  types:
  - <xref:str>
- description: The maximum number of tokens to produce. Default is 1.
  name: max_token_count
  types:
  - <xref:int>
- description: 'A value indicating whether all tokens from the input must be consumed

    even if maxTokenCount is reached. Default is false.'
  name: consume_all_tokens
  types:
  - <xref:bool>
