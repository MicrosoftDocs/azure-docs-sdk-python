### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.LimitTokenFilter
name: LimitTokenFilter
fullName: azure.search.documents.indexes.models.LimitTokenFilter
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.TokenFilter
summary: 'Limits the number of tokens while indexing. This token filter is implemented
  using Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'LimitTokenFilter(*, name: str, max_token_count: int | None = 1, consume_all_tokens:
    bool | None = False, **kwargs)'
variables:
- description: 'Required. Identifies the concrete type of the token filter.Constant
    filled by

    server.'
  name: odata_type
  types:
  - <xref:azure.search.documents.indexes.models.str>
- description: 'Required. The name of the token filter. It must only contain letters,
    digits,

    spaces, dashes or underscores, can only start and end with alphanumeric characters,
    and is

    limited to 128 characters.'
  name: name
  types:
  - <xref:azure.search.documents.indexes.models.str>
- description: The maximum number of tokens to produce. Default is 1.
  name: max_token_count
  types:
  - <xref:azure.search.documents.indexes.models.int>
- description: 'A value indicating whether all tokens from the input must be consumed

    even if maxTokenCount is reached. Default is false.'
  name: consume_all_tokens
  types:
  - <xref:azure.search.documents.indexes.models.bool>
