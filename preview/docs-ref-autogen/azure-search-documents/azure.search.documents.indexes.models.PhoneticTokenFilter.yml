### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.PhoneticTokenFilter
name: PhoneticTokenFilter
fullName: azure.search.documents.indexes.models.PhoneticTokenFilter
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.TokenFilter
summary: 'Create tokens for phonetic matches. This token filter is implemented using
  Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'PhoneticTokenFilter(*, name: str, encoder: str | _models.PhoneticEncoder
    | None = None, replace_original_tokens: bool = True, **kwargs)'
variables:
- description: Identifies the concrete type of the token filter. Required.
  name: odata_type
  types:
  - <xref:azure.search.documents.indexes.models.str>
- description: 'The name of the token filter. It must only contain letters, digits,
    spaces, dashes

    or underscores, can only start and end with alphanumeric characters, and is limited
    to 128

    characters. Required.'
  name: name
  types:
  - <xref:azure.search.documents.indexes.models.str>
- description: 'The phonetic encoder to use. Default is "metaphone". Known values
    are:

    "metaphone", "doubleMetaphone", "soundex", "refinedSoundex", "caverphone1", "caverphone2",

    "cologne", "nysiis", "koelnerPhonetik", "haasePhonetik", and "beiderMorse".'
  name: encoder
  types:
  - <xref:azure.search.documents.indexes.models.str>
  - <xref:search_service_client.models.PhoneticEncoder>
- description: 'A value indicating whether encoded tokens should replace

    original tokens. If false, encoded tokens are added as synonyms. Default is true.'
  name: replace_original_tokens
  types:
  - <xref:azure.search.documents.indexes.models.bool>
