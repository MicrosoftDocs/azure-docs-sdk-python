### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.PhoneticTokenFilter
name: PhoneticTokenFilter
fullName: azure.search.documents.indexes.models.PhoneticTokenFilter
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.TokenFilter
summary: 'Create tokens for phonetic matches. This token filter is implemented using
  Apache Lucene.

  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'PhoneticTokenFilter(*, name: str, encoder: Optional[Union[str, azure.search.documents.indexes._generated.models._search_client_enums.PhoneticEncoder]]
    = None, replace_original_tokens: Optional[bool] = True, **kwargs)'
variables:
- description: 'Required. Identifies the concrete type of the token filter.Constant
    filled by

    server.'
  name: odata_type
  types:
  - <xref:str>
- description: 'Required. The name of the token filter. It must only contain letters,
    digits,

    spaces, dashes or underscores, can only start and end with alphanumeric characters,
    and is

    limited to 128 characters.'
  name: name
  types:
  - <xref:str>
- description: 'The phonetic encoder to use. Default is "metaphone". Possible values
    include:

    "metaphone", "doubleMetaphone", "soundex", "refinedSoundex", "caverphone1", "caverphone2",

    "cologne", "nysiis", "koelnerPhonetik", "haasePhonetik", "beiderMorse".'
  name: encoder
  types:
  - <xref:str>
  - <xref:azure.search.documents.indexes.models.PhoneticEncoder>
- description: 'A value indicating whether encoded tokens should replace

    original tokens. If false, encoded tokens are added as synonyms. Default is true.'
  name: replace_original_tokens
  types:
  - <xref:bool>
