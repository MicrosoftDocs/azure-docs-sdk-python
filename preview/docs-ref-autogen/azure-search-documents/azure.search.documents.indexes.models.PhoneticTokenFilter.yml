### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.PhoneticTokenFilter
name: PhoneticTokenFilter
fullName: azure.search.documents.indexes.models.PhoneticTokenFilter
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._internal._generated.models._models_py3.TokenFilter
summary: 'Create tokens for phonetic matches. This token filter is implemented using
  Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'PhoneticTokenFilter(*, name: str, encoder: typing.Union[str, _ForwardRef(''PhoneticEncoder''),
    NoneType] = None, replace_original_tokens: typing.Union[bool, NoneType] = True,
    **kwargs)'
  parameters:
  - name: odata_type
    description: 'Required. Identifies the concrete type of the token filter.Constant
      filled

      by server.'
    types:
    - <xref:str>
  - name: name
    description: 'Required. The name of the token filter. It must only contain letters,
      digits,

      spaces, dashes or underscores, can only start and end with alphanumeric characters,
      and is

      limited to 128 characters.'
    types:
    - <xref:str>
  - name: encoder
    description: 'The phonetic encoder to use. Default is "metaphone". Possible values
      include:

      "metaphone", "doubleMetaphone", "soundex", "refinedSoundex", "caverphone1",
      "caverphone2",

      "cologne", "nysiis", "koelnerPhonetik", "haasePhonetik", "beiderMorse".'
    types:
    - <xref:str>
    - <xref:azure.search.documents.indexes.models.PhoneticEncoder>
  - name: replace_original_tokens
    description: 'A value indicating whether encoded tokens should replace

      original tokens. If false, encoded tokens are added as synonyms. Default is
      true.'
    types:
    - <xref:bool>
