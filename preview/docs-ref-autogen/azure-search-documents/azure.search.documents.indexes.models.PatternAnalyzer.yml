### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.PatternAnalyzer
name: PatternAnalyzer
fullName: azure.search.documents.indexes.models.PatternAnalyzer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.LexicalAnalyzer
summary: 'Flexibly separates text into terms via a regular expression.

  This analyzer is implemented using Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: PatternAnalyzer(**kwargs)
  parameters:
  - name: name
    description: 'Required. The name of the analyzer. It must only contain letters,
      digits, spaces,

      dashes or underscores, can only start and end with alphanumeric characters,
      and is limited to

      128 characters.'
    types:
    - <xref:str>
  - name: lower_case_terms
    description: 'A value indicating whether terms should be lower-cased. Default
      is

      true.'
    types:
    - <xref:bool>
  - name: pattern
    description: 'A regular expression to match token separators. Default is an

      expression that matches one or more white space characters.'
    types:
    - <xref:str>
  - name: flags
    description: 'List of regular expression flags. Possible values of each flag include:
      ''CANON_EQ'',

      ''CASE_INSENSITIVE'', ''COMMENTS'', ''DOTALL'', ''LITERAL'', ''MULTILINE'',
      ''UNICODE_CASE'', ''UNIX_LINES''.'
    types:
    - <xref:list>[<xref:str>]
    - <xref:list>[<xref:search_service_client.models.RegexFlags>]
  - name: stopwords
    description: A list of stopwords.
    types:
    - <xref:list>[<xref:str>]
