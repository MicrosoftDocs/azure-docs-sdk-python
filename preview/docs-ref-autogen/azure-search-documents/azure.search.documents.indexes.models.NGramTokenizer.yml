### YamlMime:PythonClass
uid: azure.search.documents.indexes.models.NGramTokenizer
name: NGramTokenizer
fullName: azure.search.documents.indexes.models.NGramTokenizer
module: azure.search.documents.indexes.models
inheritances:
- azure.search.documents.indexes._generated.models._models_py3.LexicalTokenizer
summary: 'Tokenizes the input into n-grams of the given size(s). This tokenizer is
  implemented using

  Apache Lucene.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'NGramTokenizer(*, name: str, min_gram: int = 1, max_gram: int = 2, token_chars:
    List[str | _models.TokenCharacterKind] | None = None, **kwargs: Any)'
  parameters:
  - name: name
    description: 'The name of the tokenizer. It must only contain letters, digits,
      spaces, dashes

      or underscores, can only start and end with alphanumeric characters, and is
      limited to 128

      characters. Required.'
    types:
    - <xref:str>
  - name: min_gram
    description: 'The minimum n-gram length. Default is 1. Maximum is 300. Must be
      less than

      the value of maxGram.'
    types:
    - <xref:int>
  - name: max_gram
    description: The maximum n-gram length. Default is 2. Maximum is 300.
    types:
    - <xref:int>
  - name: token_chars
    description: Character classes to keep in the tokens.
    types:
    - <xref:list>[<xref:str>
    - <xref:search_service_client.models.TokenCharacterKind>]
variables:
- description: Identifies the concrete type of the tokenizer. Required.
  name: odata_type
  types:
  - <xref:str>
- description: 'The name of the tokenizer. It must only contain letters, digits, spaces,
    dashes or

    underscores, can only start and end with alphanumeric characters, and is limited
    to 128

    characters. Required.'
  name: name
  types:
  - <xref:str>
- description: 'The minimum n-gram length. Default is 1. Maximum is 300. Must be less
    than the

    value of maxGram.'
  name: min_gram
  types:
  - <xref:int>
- description: The maximum n-gram length. Default is 2. Maximum is 300.
  name: max_gram
  types:
  - <xref:int>
- description: Character classes to keep in the tokens.
  name: token_chars
  types:
  - <xref:list>[<xref:str>
  - <xref:search_service_client.models.TokenCharacterKind>]
