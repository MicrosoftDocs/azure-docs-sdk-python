### YamlMime:PythonClass
uid: azure.media.videoanalyzeredge.CognitiveServicesVisionProcessor
name: CognitiveServicesVisionProcessor
fullName: azure.media.videoanalyzeredge.CognitiveServicesVisionProcessor
module: azure.media.videoanalyzeredge
inheritances:
- azure.media.videoanalyzeredge._generated.models._models_py3.ProcessorNodeBase
summary: 'A processor that allows the pipeline topology to send video frames to a
  Cognitive Services Vision extension. Inference results are relayed to downstream
  nodes.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'CognitiveServicesVisionProcessor(*, name: str, inputs: List[NodeInput],
    endpoint: EndpointBase, operation: SpatialAnalysisOperationBase, image: ImageProperties
    | None = None, sampling_options: SamplingOptions | None = None, **kwargs)'
  parameters:
  - name: name
    description: Required. Node name. Must be unique within the topology.
    types:
    - <xref:str>
  - name: inputs
    description: 'Required. An array of upstream node references within the topology
      to be used

      as inputs for this node.'
    types:
    - <xref:list>[<xref:azure.media.videoanalyzer.edge.models.NodeInput>]
  - name: endpoint
    description: Required. Endpoint to which this processor should connect.
    types:
    - <xref:azure.media.videoanalyzer.edge.models.EndpointBase>
  - name: image
    description: Describes the parameters of the image that is sent as input to the
      endpoint.
    types:
    - <xref:azure.media.videoanalyzer.edge.models.ImageProperties>
  - name: sampling_options
    description: 'Describes the sampling options to be applied when forwarding samples

      to the extension.'
    types:
    - <xref:azure.media.videoanalyzer.edge.models.SamplingOptions>
  - name: operation
    description: 'Required. Describes the Spatial Analysis operation to be used in
      the

      Cognitive Services Vision processor.'
    types:
    - <xref:azure.media.videoanalyzer.edge.models.SpatialAnalysisOperationBase>
variables:
- description: Required. Type discriminator for the derived types.Constant filled
    by server.
  name: type
  types:
  - <xref:str>
- description: Required. Node name. Must be unique within the topology.
  name: name
  types:
  - <xref:str>
- description: 'Required. An array of upstream node references within the topology
    to be used as

    inputs for this node.'
  name: inputs
  types:
  - <xref:list>[<xref:azure.media.videoanalyzer.edge.models.NodeInput>]
- description: Required. Endpoint to which this processor should connect.
  name: endpoint
  types:
  - <xref:azure.media.videoanalyzer.edge.models.EndpointBase>
- description: Describes the parameters of the image that is sent as input to the
    endpoint.
  name: image
  types:
  - <xref:azure.media.videoanalyzer.edge.models.ImageProperties>
- description: 'Describes the sampling options to be applied when forwarding samples
    to

    the extension.'
  name: sampling_options
  types:
  - <xref:azure.media.videoanalyzer.edge.models.SamplingOptions>
- description: 'Required. Describes the Spatial Analysis operation to be used in the
    Cognitive

    Services Vision processor.'
  name: operation
  types:
  - <xref:azure.media.videoanalyzer.edge.models.SpatialAnalysisOperationBase>
