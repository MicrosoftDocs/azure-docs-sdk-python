### YamlMime:PythonClass
uid: azure.media.videoanalyzeredge.SignalGateProcessor
name: SignalGateProcessor
fullName: azure.media.videoanalyzeredge.SignalGateProcessor
module: azure.media.videoanalyzeredge
inheritances:
- azure.media.videoanalyzeredge._generated.models._models_py3.ProcessorNodeBase
summary: 'A signal gate determines when to block (gate) incoming media, and when to
  allow it through. It gathers input events over the activationEvaluationWindow, and
  determines whether to open or close the gate. See [https://aka.ms/ava-signalgate](https://aka.ms/ava-signalgate)
  for more information.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SignalGateProcessor(*, name: str, inputs: List[NodeInput], activation_evaluation_window:
    str | None = None, activation_signal_offset: str | None = None, minimum_activation_time:
    str | None = None, maximum_activation_time: str | None = None, **kwargs)'
  parameters:
  - name: name
    description: Required. Node name. Must be unique within the topology.
    types:
    - <xref:str>
  - name: inputs
    description: 'Required. An array of upstream node references within the topology
      to be used

      as inputs for this node.'
    types:
    - <xref:list>[<xref:azure.media.videoanalyzer.edge.models.NodeInput>]
  - name: activation_evaluation_window
    description: 'The period of time over which the gate gathers input

      events before evaluating them.'
    types:
    - <xref:str>
  - name: activation_signal_offset
    description: 'Signal offset once the gate is activated (can be negative).

      It determines the how much farther behind of after the signal will be let through
      based on the

      activation time. A negative offset indicates that data prior the activation
      time must be

      included on the signal that is let through, once the gate is activated. When
      used upstream of a

      file or video sink, this allows for scenarios such as recording buffered media
      prior an event,

      such as: record video 5 seconds prior motions is detected.'
    types:
    - <xref:str>
  - name: minimum_activation_time
    description: 'The minimum period for which the gate remains open in the

      absence of subsequent triggers (events). When used upstream of a file or video
      sink, it

      determines the minimum length of the recorded video clip.'
    types:
    - <xref:str>
  - name: maximum_activation_time
    description: 'The maximum period for which the gate remains open in the

      presence of subsequent triggers (events). When used upstream of a file or video
      sink, it

      determines the maximum length of the recorded video clip.'
    types:
    - <xref:str>
variables:
- description: Required. Type discriminator for the derived types.Constant filled
    by server.
  name: type
  types:
  - <xref:str>
- description: Required. Node name. Must be unique within the topology.
  name: name
  types:
  - <xref:str>
- description: 'Required. An array of upstream node references within the topology
    to be used as

    inputs for this node.'
  name: inputs
  types:
  - <xref:list>[<xref:azure.media.videoanalyzer.edge.models.NodeInput>]
- description: 'The period of time over which the gate gathers input events

    before evaluating them.'
  name: activation_evaluation_window
  types:
  - <xref:str>
- description: 'Signal offset once the gate is activated (can be negative). It

    determines the how much farther behind of after the signal will be let through
    based on the

    activation time. A negative offset indicates that data prior the activation time
    must be

    included on the signal that is let through, once the gate is activated. When used
    upstream of a

    file or video sink, this allows for scenarios such as recording buffered media
    prior an event,

    such as: record video 5 seconds prior motions is detected.'
  name: activation_signal_offset
  types:
  - <xref:str>
- description: 'The minimum period for which the gate remains open in the

    absence of subsequent triggers (events). When used upstream of a file or video
    sink, it

    determines the minimum length of the recorded video clip.'
  name: minimum_activation_time
  types:
  - <xref:str>
- description: 'The maximum period for which the gate remains open in the

    presence of subsequent triggers (events). When used upstream of a file or video
    sink, it

    determines the maximum length of the recorded video clip.'
  name: maximum_activation_time
  types:
  - <xref:str>
methods:
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.as_dict
  name: as_dict
  summary: "Return a dict that can be JSONify using json.dump.\n\nAdvanced usage might\
    \ optionally use a callback as parameter:\n\nKey is the attribute name used in\
    \ Python. Attr_desc\nis a dict of metadata. Currently contains 'type' with the\n\
    msrest type and 'key' with the RestAPI encoded key.\nValue is the current value\
    \ in this object.\n\nThe string returned will be used to serialize the key.\n\
    If the return type is a list, this is considered hierarchical\nresult dict.\n\n\
    See the three examples in this file:\n\n* attribute_transformer \n\n* full_restapi_key_transformer\
    \ \n\n* last_restapi_key_transformer \n\nIf you want XML serialization, you can\
    \ pass the kwargs is_xml=True."
  signature: as_dict(keep_readonly=True, key_transformer=<function attribute_transformer>,
    **kwargs)
  parameters:
  - name: key_transformer
    description: A key transformer function.
    types:
    - <xref:function>
  - name: keep_readonly
    defaultValue: 'True'
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.deserialize
  name: deserialize
  summary: Parse a str using the RestAPI syntax and return a model.
  signature: deserialize(data, content_type=None)
  parameters:
  - name: data
    description: A str using RestAPI structure. JSON by default.
    isRequired: true
    types:
    - <xref:str>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.enable_additional_properties_sending
  name: enable_additional_properties_sending
  signature: enable_additional_properties_sending()
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.from_dict
  name: from_dict
  summary: 'Parse a dict using given key extractor return a model.


    By default consider key

    extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor

    and last_rest_key_case_insensitive_extractor)'
  signature: from_dict(data, key_extractors=None, content_type=None)
  parameters:
  - name: data
    description: A dict using RestAPI structure
    isRequired: true
    types:
    - <xref:dict>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  - name: key_extractors
    defaultValue: None
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.is_xml_model
  name: is_xml_model
  signature: is_xml_model()
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.serialize
  name: serialize
  summary: 'Return the JSON that would be sent to azure from this model.


    This is an alias to *as_dict(full_restapi_key_transformer, keep_readonly=False)*.


    If you want XML serialization, you can pass the kwargs is_xml=True.'
  signature: serialize(keep_readonly=False, **kwargs)
  parameters:
  - name: keep_readonly
    description: If you want to serialize the readonly attributes
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.media.videoanalyzeredge.SignalGateProcessor.validate
  name: validate
  summary: Validate this model recursively and return a list of ValidationError.
  signature: validate()
  return:
    description: A list of validation error
    types:
    - <xref:list>
