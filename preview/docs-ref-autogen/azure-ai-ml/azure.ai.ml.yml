### YamlMime:PythonPackage
uid: azure.ai.ml
name: ml
fullName: azure.ai.ml
type: import
functions:
- uid: azure.ai.ml.command
  name: command
  summary: 'Create a Command object which can be used inside dsl.pipeline as a

    function and can also be created as a standalone command job.'
  signature: 'command(*, name: str = None, description: str = None, tags: Dict = None,
    properties: Dict = None, display_name: str = None, command: str = None, experiment_name:
    str = None, environment: str | Environment = None, environment_variables: Dict
    = None, distribution: Dict | MpiDistribution | TensorFlowDistribution | PyTorchDistribution
    = None, compute: str = None, inputs: Dict = None, outputs: Dict = None, instance_count:
    int = None, instance_type: str = None, docker_args: str = None, shm_size: str
    = None, timeout: int = None, code: str | PathLike = None, identity: ManagedIdentity
    | AmlToken | UserIdentity = None, is_deterministic: bool = True, services: dict
    = None, **kwargs) -> Command'
  parameters:
  - name: name
    description: Name of the command job or component created
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: description
    description: a friendly description of the command
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: tags
    description: Tags to be attached to this command
    isRequired: true
    types:
    - <xref:azure.ai.ml.Dict>
  - name: properties
    description: The asset property dictionary.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>[<xref:azure.ai.ml.str>, <xref:azure.ai.ml.str>]
  - name: display_name
    description: a friendly name
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: experiment_name
    description: 'Name of the experiment the job will be created under,

      if None is provided, default will be set to current directory name. Will be
      ignored as a pipeline step.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: command
    description: the command string that will be run
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: environment
    description: the environment to use for this command
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.str>, <xref:azure.ai.ml.entities.Environment>]
  - name: environment_variables
    description: environment variables to set on the compute before this command is
      executed
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
  - name: distribution
    description: the distribution mode to use for this command
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.Dict>, <xref:azure.ai.ml.MpiDistribution>,
      <xref:azure.ai.ml.TensorFlowDistribution>, <xref:azure.ai.ml.PyTorchDistribution>]
  - name: compute
    description: 'the name of the compute where the command job is executed(

      will not be used if the command is used as a component/function)'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: inputs
    description: a dict of inputs used by this command.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Dict>
  - name: outputs
    description: the outputs of this command
    isRequired: true
    types:
    - <xref:azure.ai.ml.Dict>
  - name: instance_count
    description: Optional number of instances or nodes used by the compute target.
      Defaults to 1.
    isRequired: true
  - name: instance_type
    description: Optional type of VM used as supported by the compute target.
    isRequired: true
  - name: docker_args
    description: 'Extra arguments to pass to the Docker run command. This would override
      any

      parameters that have already been set by the system, or in this section. This
      parameter is only

      supported for Azure ML compute types.'
    isRequired: true
  - name: shm_size
    description: 'Size of the docker container''s shared memory block. This should
      be in the

      format of (number)(unit) where number as to be greater than 0 and the unit can
      be one of

      b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).'
    isRequired: true
  - name: timeout
    description: The number in seconds, after which the job will be cancelled.
    isRequired: true
  - name: code
    description: "the code folder to run \u2013 typically a local folder that will\
      \ be uploaded as the job is submitted"
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.str>, <xref:os.PathLike>]
  - name: identity
    description: Identity that training job will use while running on compute.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.ManagedIdentity>, <xref:azure.ai.ml.AmlToken>]
  - name: is_deterministic
    description: 'Specify whether the command will return same output given same input.

      If a command (component) is deterministic, when use it as a node/step in a pipeline,

      it will reuse results from a previous submitted job in current workspace which
      has same inputs and settings.

      In this case, this step will not use any compute resource.

      Default to be True, specify is_deterministic=False if you would like to avoid
      such reuse behavior.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.bool>
  - name: services
    description: Interactive services for the node.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
- uid: azure.ai.ml.load_batch_deployment
  name: load_batch_deployment
  summary: Construct a batch deployment object from yaml file.
  signature: 'load_batch_deployment(source: str | PathLike | IO, *, relative_origin:
    str = None, **kwargs) -> BatchDeployment'
  parameters:
  - name: source
    description: 'The local yaml source of a batch deployment object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed batch deployment object.
    types:
    - <xref:azure.ai.ml.entities.BatchDeployment>
- uid: azure.ai.ml.load_batch_endpoint
  name: load_batch_endpoint
  summary: Construct a batch endpoint object from yaml file.
  signature: 'load_batch_endpoint(source: str | PathLike | IO, relative_origin: str
    = None, **kwargs) -> BatchEndpoint'
  parameters:
  - name: source
    description: 'The local yaml source of a batch endpoint object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    defaultValue: None
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed batch endpoint object.
    types:
    - <xref:azure.ai.ml.entities.BatchEndpoint>
- uid: azure.ai.ml.load_component
  name: load_component
  summary: "Load component from local or remote to a component function.\n\nFor example:\n\
    \n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
    : [], \"backrefs\": [], \"xml:space\": \"preserve\", \"force\": false, \"language\"\
    : \"python\", \"highlight_args\": {}, \"linenos\": false} -->\n\n````python\n\n\
    \   # Load a local component to a component function.\n   component_func = load_component(source=\"\
    custom_component/component_spec.yaml\")\n   # Load a remote component to a component\
    \ function.\n   component_func = load_component(client=ml_client, name=\"my_component\"\
    , version=1)\n\n   # Consuming the component func\n   component = component_func(param1=xxx,\
    \ param2=xxx)\n   ````"
  signature: 'load_component(source: str | PathLike | IO = None, *, relative_origin:
    str = None, **kwargs) -> CommandComponent | ParallelComponent | PipelineComponent'
  parameters:
  - name: source
    description: 'The local yaml source of a component. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    defaultValue: None
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  - name: client
    description: An MLClient instance.
    isRequired: true
    types:
    - <xref:azure.ai.ml.MLClient>
  - name: name
    description: Name of the component.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: version
    description: Version of the component.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: kwargs
    description: A dictionary of additional configuration parameters.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
  return:
    description: A function that can be called with parameters to get a *azure.ai.ml.entities.Component*
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.entities.CommandComponent>, <xref:azure.ai.ml.entities.ParallelComponent>,
      <xref:azure.ai.ml.entities.PipelineComponent>]
- uid: azure.ai.ml.load_compute
  name: load_compute
  summary: Construct a compute object from a yaml file.
  signature: 'load_compute(source: str | PathLike | IO, *, relative_origin: str =
    None, **kwargs) -> Compute'
  parameters:
  - name: source
    description: 'The local yaml source of a compute. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Loaded compute object.
    types:
    - <xref:azure.ai.ml.entities.Compute>
- uid: azure.ai.ml.load_data
  name: load_data
  summary: Construct a data object from yaml file.
  signature: 'load_data(source: str | PathLike | IO, *, relative_origin: str = None,
    **kwargs) -> Data'
  parameters:
  - name: source
    description: 'The local yaml source of a data object. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed data object.
    types:
    - <xref:azure.ai.ml.entities.Data>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Data cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_datastore
  name: load_datastore
  summary: Construct a datastore object from a yaml file.
  signature: 'load_datastore(source: str | PathLike | IO, *, relative_origin: str
    = None, **kwargs) -> Datastore'
  parameters:
  - name: source
    description: 'The local yaml source of a datastore. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Loaded datastore object.
    types:
    - <xref:azure.ai.ml.entities.Datastore>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Datastore cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_environment
  name: load_environment
  summary: Construct a environment object from yaml file.
  signature: 'load_environment(source: str | PathLike | IO, *, relative_origin: str
    = None, **kwargs) -> Environment'
  parameters:
  - name: source
    description: 'The local yaml source of an environment. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed environment object.
    types:
    - <xref:azure.ai.ml.entities.Environment>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Environment cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_job
  name: load_job
  summary: Construct a job object from a yaml file.
  signature: 'load_job(source: str | PathLike | IO, *, relative_origin: str = None,
    **kwargs) -> Job'
  parameters:
  - name: source
    description: 'The local yaml source of a job. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Loaded job object.
    types:
    - <xref:azure.ai.ml.entities.Job>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Job cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_model
  name: load_model
  summary: Construct a model object from yaml file.
  signature: 'load_model(source: str | PathLike | IO, *, relative_origin: str = None,
    **kwargs) -> Model'
  parameters:
  - name: source
    description: 'The local yaml source of a model. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed model object.
    types:
    - <xref:azure.ai.ml.entities.Model>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Model cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_online_deployment
  name: load_online_deployment
  summary: Construct a online deployment object from yaml file.
  signature: 'load_online_deployment(source: str | PathLike | IO, *, relative_origin:
    str = None, **kwargs) -> OnlineDeployment'
  parameters:
  - name: source
    description: 'The local yaml source of an online deployment object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed online deployment object.
    types:
    - <xref:azure.ai.ml.entities.OnlineDeployment>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Online Deployment cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_online_endpoint
  name: load_online_endpoint
  summary: Construct a online endpoint object from yaml file.
  signature: 'load_online_endpoint(source: str | PathLike | IO, *, relative_origin:
    str = None, **kwargs) -> OnlineEndpoint'
  parameters:
  - name: source
    description: 'The local yaml source of an online endpoint object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed online endpoint object.
    types:
    - <xref:azure.ai.ml.entities.OnlineEndpoint>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Online Endpoint cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_registry
  name: load_registry
  summary: Load a registry object from a yaml file.
  signature: 'load_registry(source: str | PathLike | IO, *, relative_origin: str =
    None, **kwargs) -> Registry'
  parameters:
  - name: source
    description: 'The local yaml source of a registry. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Loaded registry object.
    types:
    - <xref:azure.ai.ml.entities.Registry>
- uid: azure.ai.ml.load_workspace
  name: load_workspace
  summary: Load a workspace object from a yaml file.
  signature: 'load_workspace(source: str | PathLike | IO, *, relative_origin: str
    = None, **kwargs) -> Workspace'
  parameters:
  - name: source
    description: 'The local yaml source of a workspace. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Loaded workspace object.
    types:
    - <xref:azure.ai.ml.entities.Workspace>
- uid: azure.ai.ml.load_workspace_connection
  name: load_workspace_connection
  summary: Construct a workspace connection object from yaml file.
  signature: 'load_workspace_connection(source: str | PathLike | IO, *, relative_origin:
    str = None, **kwargs) -> WorkspaceConnection'
  parameters:
  - name: source
    description: 'The local yaml source of a workspace connection object. Must be
      either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.PathLike>, <xref:azure.ai.ml.str>,
      <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:azure.ai.ml.List>[<xref:azure.ai.ml.Dict>]
  return:
    description: Constructed workspace connection object.
    types:
    - <xref:azure.ai.ml.entities.WorkspaceConnection>
- uid: azure.ai.ml.spark
  name: spark
  summary: 'Create a Spark object which can be used inside dsl.pipeline as a function
    and

    can also be created as a standalone spark job.'
  signature: 'spark(*, experiment_name: str = None, name: str = None, display_name:
    str = None, description: str = None, tags: Dict = None, code: str | PathLike =
    None, entry: Dict[str, str] | SparkJobEntry | None = None, py_files: List[str]
    | None = None, jars: List[str] | None = None, files: List[str] | None = None,
    archives: List[str] | None = None, identity: Dict[str, str] | ManagedIdentity
    | AmlToken | UserIdentity = None, driver_cores: int = None, driver_memory: str
    = None, executor_cores: int = None, executor_memory: str = None, executor_instances:
    int = None, dynamic_allocation_enabled: bool = None, dynamic_allocation_min_executors:
    int = None, dynamic_allocation_max_executors: int = None, conf: Dict[str, str]
    | None = None, environment: str | Environment = None, inputs: Dict = None, outputs:
    Dict = None, args: str = None, compute: str = None, resources: Dict | SparkResourceConfiguration
    = None, **kwargs) -> Spark'
  parameters:
  - name: experiment_name
    description: Name of the experiment the job will be created under.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: name
    description: The name of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: display_name
    description: Display name of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: description
    description: Description of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: tags
    description: Tag dictionary. Tags can be added, removed, and updated.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>[<xref:azure.ai.ml.str>, <xref:azure.ai.ml.str>]
  - name: code
    description: The source code to run the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.str>, <xref:os.PathLike>]
  - name: entry
    description: File or class entry point.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>[<xref:azure.ai.ml.str>, <xref:azure.ai.ml.str>]
  - name: py_files
    description: List of .zip, .egg or .py files to place on the PYTHONPATH for Python
      apps.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Optional>[<xref:typing.List>[<xref:azure.ai.ml.str>]]
  - name: jars
    description: List of jars to include on the driver and executor classpaths.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Optional>[<xref:typing.List>[<xref:azure.ai.ml.str>]]
  - name: files
    description: List of files to be placed in the working directory of each executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Optional>[<xref:typing.List>[<xref:azure.ai.ml.str>]]
  - name: archives
    description: List of archives to be extracted into the working directory of each
      executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Optional>[<xref:typing.List>[<xref:azure.ai.ml.str>]]
  - name: identity
    description: Identity that spark job will use while running on compute.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.Dict>, <xref:azure.ai.ml.ManagedIdentity>,
      <xref:azure.ai.ml.AmlToken>, <xref:azure.ai.ml.UserIdentity>]
  - name: driver_cores
    description: Number of cores to use for the driver process, only in cluster mode.
    isRequired: true
    types:
    - <xref:azure.ai.ml.int>
  - name: driver_memory
    description: Amount of memory to use for the driver process.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: executor_cores
    description: The number of cores to use on each executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.int>
  - name: executor_memory
    description: 'Amount of memory to use per executor process, in the same format
      as JVM memory strings with

      a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).'
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: executor_instances
    description: Initial number of executors.
    isRequired: true
    types:
    - <xref:azure.ai.ml.int>
  - name: dynamic_allocation_enabled
    description: 'Whether to use dynamic resource allocation, which scales the number
      of executors

      registered with this application up and down based on the workload.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.bool>
  - name: dynamic_allocation_min_executors
    description: Lower bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:azure.ai.ml.int>
  - name: dynamic_allocation_max_executors
    description: Upper bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:azure.ai.ml.int>
  - name: conf
    description: A dict with pre-defined spark configurations key and values.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
  - name: environment
    description: Azure ML environment to run the job in.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.str>, <xref:azure.ai.ml.entities.Environment>]
  - name: inputs
    description: Mapping of inputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
  - name: outputs
    description: Mapping of outputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.dict>
  - name: args
    description: Arguments for the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: compute
    description: The compute resource the job runs on.
    isRequired: true
    types:
    - <xref:azure.ai.ml.str>
  - name: resources
    description: Compute Resource configuration for the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.Union>[<xref:azure.ai.ml.Dict>, <xref:azure.ai.ml.entities.SparkResourceConfiguration>]
classes:
- azure.ai.ml.AmlToken
- azure.ai.ml.Input
- azure.ai.ml.MLClient
- azure.ai.ml.ManagedIdentity
- azure.ai.ml.MpiDistribution
- azure.ai.ml.Output
- azure.ai.ml.PyTorchDistribution
- azure.ai.ml.TensorFlowDistribution
- azure.ai.ml.UserIdentity
packages:
- azure.ai.ml.automl
- azure.ai.ml.constants
- azure.ai.ml.dsl
- azure.ai.ml.entities
- azure.ai.ml.identity
- azure.ai.ml.operations
- azure.ai.ml.parallel
- azure.ai.ml.sweep
modules:
- azure.ai.ml.exceptions
