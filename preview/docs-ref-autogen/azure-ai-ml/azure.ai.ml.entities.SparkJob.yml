### YamlMime:PythonClass
uid: azure.ai.ml.entities.SparkJob
name: SparkJob
fullName: azure.ai.ml.entities.SparkJob
module: azure.ai.ml.entities
inheritances:
- azure.ai.ml.entities._job.job.Job
- azure.ai.ml.entities._job.parameterized_spark.ParameterizedSpark
- azure.ai.ml.entities._job.job_io_mixin.JobIOMixin
- azure.ai.ml.entities._job.spark_job_entry_mixin.SparkJobEntryMixin
summary: Create a standalone spark job.
constructor:
  syntax: 'SparkJob(*, driver_cores: int = None, driver_memory: str = None, executor_cores:
    int = None, executor_memory: str = None, executor_instances: int = None, dynamic_allocation_enabled:
    bool = None, dynamic_allocation_min_executors: int = None, dynamic_allocation_max_executors:
    int = None, inputs: Dict = None, outputs: Dict = None, compute: str | None = None,
    identity: Dict[str, str] | ManagedIdentity | AmlToken | UserIdentity = None, resources:
    Dict | SparkResourceConfiguration | None = None, **kwargs)'
  parameters:
  - name: experiment_name
    description: Name of the experiment the job will be created under.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: name
    description: The name of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: display_name
    description: Display name of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: description
    description: Description of the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: tags
    description: Tag dictionary. Tags can be added, removed, and updated.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>[<xref:azure.ai.ml.entities.str>, <xref:azure.ai.ml.entities.str>]
  - name: code
    description: The source code to run the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Union>[<xref:azure.ai.ml.entities.str>, <xref:os.PathLike>]
  - name: entry
    description: File or class entry point.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>[<xref:azure.ai.ml.entities.str>, <xref:azure.ai.ml.entities.str>]
  - name: py_files
    description: List of .zip, .egg or .py files to place on the PYTHONPATH for Python
      apps.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Optional>[<xref:typing.List>[<xref:azure.ai.ml.entities.str>]]
  - name: jars
    description: List of jars to include on the driver and executor classpaths.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Optional>[<xref:typing.List>[<xref:azure.ai.ml.entities.str>]]
  - name: files
    description: List of files to be placed in the working directory of each executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Optional>[<xref:typing.List>[<xref:azure.ai.ml.entities.str>]]
  - name: archives
    description: List of archives to be extracted into the working directory of each
      executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Optional>[<xref:typing.List>[<xref:azure.ai.ml.entities.str>]]
  - name: identity
    description: Identity that spark job will use while running on compute.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Union>[<xref:azure.ai.ml.entities.Dict>, <xref:azure.ai.ml.ManagedIdentity>,
      <xref:azure.ai.ml.AmlToken>, <xref:azure.ai.ml.UserIdentity>]
  - name: driver_cores
    description: Number of cores to use for the driver process, only in cluster mode.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: driver_memory
    description: Amount of memory to use for the driver process.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: executor_cores
    description: The number of cores to use on each executor.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: executor_memory
    description: 'Amount of memory to use per executor process, in the same format
      as JVM memory strings with

      a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).'
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: executor_instances
    description: Initial number of executors.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: dynamic_allocation_enabled
    description: 'Whether to use dynamic resource allocation, which scales the number
      of executors

      registered with this application up and down based on the workload.'
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.bool>
  - name: dynamic_allocation_min_executors
    description: Lower bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: dynamic_allocation_max_executors
    description: Upper bound for the number of executors if dynamic allocation is
      enabled.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.int>
  - name: conf
    description: A dict with pre-defined spark configurations key and values.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>
  - name: environment
    description: Azure ML environment to run the job in.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Union>[<xref:azure.ai.ml.entities.str>, <xref:azure.ai.ml.entities.Environment>]
  - name: inputs
    description: Mapping of inputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>
  - name: outputs
    description: Mapping of outputs data bindings used in the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.dict>
  - name: args
    description: Arguments for the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: compute
    description: The compute resource the job runs on.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.str>
  - name: identity
    description: Identity that spark job will use while running on compute.
    isRequired: true
  - name: resources
    description: Compute Resource configuration for the job.
    isRequired: true
    types:
    - <xref:azure.ai.ml.entities.Union>[<xref:azure.ai.ml.entities.Dict>, <xref:azure.ai.ml.entities.SparkResourceConfiguration>]
methods:
- uid: azure.ai.ml.entities.SparkJob.filter_conf_fields
  name: filter_conf_fields
  signature: filter_conf_fields()
attributes:
- uid: azure.ai.ml.entities.SparkJob.identity
  name: identity
- uid: azure.ai.ml.entities.SparkJob.resources
  name: resources
