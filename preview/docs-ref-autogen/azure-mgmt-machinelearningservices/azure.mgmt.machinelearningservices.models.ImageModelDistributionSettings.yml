### YamlMime:PythonClass
uid: azure.mgmt.machinelearningservices.models.ImageModelDistributionSettings
name: ImageModelDistributionSettings
fullName: azure.mgmt.machinelearningservices.models.ImageModelDistributionSettings
module: azure.mgmt.machinelearningservices.models
inheritances:
- azure.mgmt.machinelearningservices._serialization.Model
summary: "Distribution expressions to sweep over values of model settings.\n\n`<example>\n\
  Some examples are:\n<code>\nModelName = \"choice('seresnext', 'resnest50')\";\n\
  LearningRate = \"uniform(0.001, 0.01)\";\nLayersToFreeze = \"choice(0, 2)\";\n</code></example>`\n\
  All distributions can be specified as distribution_name(min, max) or choice(val1,\
  \ val2, ..., valn)\nwhere distribution name can be: uniform, quniform, loguniform,\
  \ etc\nFor more details on how to compose distribution expressions please check\
  \ the documentation:\n[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)\n\
  For more information on the available settings please visit the official documentation:\n\
  [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   ivar ams_gradient:\n      Enable AMSGrad when optimizer is 'adam' or 'adamw'.\n\
  \n   vartype ams_gradient:\n      str\n\n   ivar augmentations:\n      Settings\
  \ for using Augmentations.\n\n   vartype augmentations:\n      str\n\n   ivar beta1:\n\
  \      Value of 'beta1' when optimizer is 'adam' or 'adamw'. Must be a float in\
  \ the range\n      [0, 1].\n\n   vartype beta1:\n      str\n\n   ivar beta2:\n \
  \     Value of 'beta2' when optimizer is 'adam' or 'adamw'. Must be a float in the\
  \ range\n      [0, 1].\n\n   vartype beta2:\n      str\n\n   ivar distributed:\n\
  \      Whether to use distributer training.\n\n   vartype distributed:\n      str\n\
  \n   ivar early_stopping:\n      Enable early stopping logic during training.\n\n\
  \   vartype early_stopping:\n      str\n\n   ivar early_stopping_delay:\n      Minimum\
  \ number of epochs or validation evaluations to wait before\n      primary metric\
  \ improvement\n      is tracked for early stopping. Must be a positive integer.\n\
  \n   vartype early_stopping_delay:\n      str\n\n   ivar early_stopping_patience:\n\
  \      Minimum number of epochs or validation evaluations with no\n      primary\
  \ metric improvement before\n      the run is stopped. Must be a positive integer.\n\
  \n   vartype early_stopping_patience:\n      str\n\n   ivar enable_onnx_normalization:\n\
  \      Enable normalization when exporting ONNX model.\n\n   vartype enable_onnx_normalization:\n\
  \      str\n\n   ivar evaluation_frequency:\n      Frequency to evaluate validation\
  \ dataset to get metric scores. Must\n      be a positive integer.\n\n   vartype\
  \ evaluation_frequency:\n      str\n\n   ivar gradient_accumulation_step:\n    \
  \  Gradient accumulation means running a configured number of\n      \"GradAccumulationStep\"\
  \ steps without\n      updating the model weights while accumulating the gradients\
  \ of those steps, and then using\n      the accumulated gradients to compute the\
  \ weight updates. Must be a positive integer.\n\n   vartype gradient_accumulation_step:\n\
  \      str\n\n   ivar layers_to_freeze:\n      Number of layers to freeze for the\
  \ model. Must be a positive integer.\n      For instance, passing 2 as value for\
  \ 'seresnext' means\n      freezing layer0 and layer1. For a full list of models\
  \ supported and details on layer freeze,\n      please\n      see: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   vartype layers_to_freeze:\n      str\n\n   ivar learning_rate:\n      Initial\
  \ learning rate. Must be a float in the range [0, 1].\n\n   vartype learning_rate:\n\
  \      str\n\n   ivar learning_rate_scheduler:\n      Type of learning rate scheduler.\
  \ Must be 'warmup_cosine' or\n      'step'.\n\n   vartype learning_rate_scheduler:\n\
  \      str\n\n   ivar model_name:\n      Name of the model to use for training.\n\
  \      For more information on the available models please visit the official documentation:\n\
  \      [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   vartype model_name:\n      str\n\n   ivar momentum:\n      Value of momentum\
  \ when optimizer is 'sgd'. Must be a float in the range [0, 1].\n\n   vartype momentum:\n\
  \      str\n\n   ivar nesterov:\n      Enable nesterov when optimizer is 'sgd'.\n\
  \n   vartype nesterov:\n      str\n\n   ivar number_of_epochs:\n      Number of\
  \ training epochs. Must be a positive integer.\n\n   vartype number_of_epochs:\n\
  \      str\n\n   ivar number_of_workers:\n      Number of data loader workers. Must\
  \ be a non-negative integer.\n\n   vartype number_of_workers:\n      str\n\n   ivar\
  \ optimizer:\n      Type of optimizer. Must be either 'sgd', 'adam', or 'adamw'.\n\
  \n   vartype optimizer:\n      str\n\n   ivar random_seed:\n      Random seed to\
  \ be used when using deterministic training.\n\n   vartype random_seed:\n      str\n\
  \n   ivar step_lr_gamma:\n      Value of gamma when learning rate scheduler is 'step'.\
  \ Must be a float in\n      the range [0, 1].\n\n   vartype step_lr_gamma:\n   \
  \   str\n\n   ivar step_lr_step_size:\n      Value of step size when learning rate\
  \ scheduler is 'step'. Must be a\n      positive integer.\n\n   vartype step_lr_step_size:\n\
  \      str\n\n   ivar training_batch_size:\n      Training batch size. Must be a\
  \ positive integer.\n\n   vartype training_batch_size:\n      str\n\n   ivar validation_batch_size:\n\
  \      Validation batch size. Must be a positive integer.\n\n   vartype validation_batch_size:\n\
  \      str\n\n   ivar warmup_cosine_lr_cycles:\n      Value of cosine cycle when\
  \ learning rate scheduler is\n      'warmup_cosine'. Must be a float in the range\
  \ [0, 1].\n\n   vartype warmup_cosine_lr_cycles:\n      str\n\n   ivar warmup_cosine_lr_warmup_epochs:\n\
  \      Value of warmup epochs when learning rate scheduler is\n      'warmup_cosine'.\
  \ Must be a positive integer.\n\n   vartype warmup_cosine_lr_warmup_epochs:\n  \
  \    str\n\n   ivar weight_decay:\n      Value of weight decay when optimizer is\
  \ 'sgd', 'adam', or 'adamw'. Must be\n      a float in the range[0, 1].\n\n   vartype\
  \ weight_decay:\n      str"
constructor:
  syntax: 'ImageModelDistributionSettings(*, ams_gradient: str | None = None, augmentations:
    str | None = None, beta1: str | None = None, beta2: str | None = None, distributed:
    str | None = None, early_stopping: str | None = None, early_stopping_delay: str
    | None = None, early_stopping_patience: str | None = None, enable_onnx_normalization:
    str | None = None, evaluation_frequency: str | None = None, gradient_accumulation_step:
    str | None = None, layers_to_freeze: str | None = None, learning_rate: str | None
    = None, learning_rate_scheduler: str | None = None, model_name: str | None = None,
    momentum: str | None = None, nesterov: str | None = None, number_of_epochs: str
    | None = None, number_of_workers: str | None = None, optimizer: str | None = None,
    random_seed: str | None = None, step_lr_gamma: str | None = None, step_lr_step_size:
    str | None = None, training_batch_size: str | None = None, validation_batch_size:
    str | None = None, warmup_cosine_lr_cycles: str | None = None, warmup_cosine_lr_warmup_epochs:
    str | None = None, weight_decay: str | None = None, **kwargs)'
