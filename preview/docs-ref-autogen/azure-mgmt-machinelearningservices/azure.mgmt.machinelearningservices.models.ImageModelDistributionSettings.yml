### YamlMime:PythonClass
uid: azure.mgmt.machinelearningservices.models.ImageModelDistributionSettings
name: ImageModelDistributionSettings
fullName: azure.mgmt.machinelearningservices.models.ImageModelDistributionSettings
module: azure.mgmt.machinelearningservices.models
inheritances:
- azure.mgmt.machinelearningservices._serialization.Model
summary: 'Distribution expressions to sweep over values of model settings.


  `<example>

  Some examples are:

  ```

  ModelName = "choice(''seresnext'', ''resnest50'')";

  LearningRate = "uniform(0.001, 0.01)";

  LayersToFreeze = "choice(0, 2)";

  >>``<<*</example>*

  All distributions can be specified as distribution_name(min, max) or choice(val1,
  val2, ...,

  valn)

  where distribution name can be: uniform, quniform, loguniform, etc

  For more details on how to compose distribution expressions please check the documentation:

  https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters

  For more information on the available settings please visit the official documentation:

  https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models.'
constructor:
  syntax: 'ImageModelDistributionSettings(*, ams_gradient: str | None = None, augmentations:
    str | None = None, beta1: str | None = None, beta2: str | None = None, distributed:
    str | None = None, early_stopping: str | None = None, early_stopping_delay: str
    | None = None, early_stopping_patience: str | None = None, enable_onnx_normalization:
    str | None = None, evaluation_frequency: str | None = None, gradient_accumulation_step:
    str | None = None, layers_to_freeze: str | None = None, learning_rate: str | None
    = None, learning_rate_scheduler: str | None = None, model_name: str | None = None,
    momentum: str | None = None, nesterov: str | None = None, number_of_epochs: str
    | None = None, number_of_workers: str | None = None, optimizer: str | None = None,
    random_seed: str | None = None, step_lr_gamma: str | None = None, step_lr_step_size:
    str | None = None, training_batch_size: str | None = None, validation_batch_size:
    str | None = None, warmup_cosine_lr_cycles: str | None = None, warmup_cosine_lr_warmup_epochs:
    str | None = None, weight_decay: str | None = None, **kwargs: Any)'
  parameters:
  - name: ams_gradient
    description: Enable AMSGrad when optimizer is 'adam' or 'adamw'.
    types:
    - <xref:str>
  - name: augmentations
    description: Settings for using Augmentations.
    types:
    - <xref:str>
  - name: beta1
    description: 'Value of ''beta1'' when optimizer is ''adam'' or ''adamw''. Must
      be a float in the

      range [0, 1].'
    types:
    - <xref:str>
  - name: beta2
    description: 'Value of ''beta2'' when optimizer is ''adam'' or ''adamw''. Must
      be a float in the

      range [0, 1].'
    types:
    - <xref:str>
  - name: distributed
    description: Whether to use distributer training.
    types:
    - <xref:str>
  - name: early_stopping
    description: Enable early stopping logic during training.
    types:
    - <xref:str>
  - name: early_stopping_delay
    description: 'Minimum number of epochs or validation evaluations to wait

      before primary metric improvement

      is tracked for early stopping. Must be a positive integer.'
    types:
    - <xref:str>
  - name: early_stopping_patience
    description: 'Minimum number of epochs or validation evaluations with no

      primary metric improvement before

      the run is stopped. Must be a positive integer.'
    types:
    - <xref:str>
  - name: enable_onnx_normalization
    description: Enable normalization when exporting ONNX model.
    types:
    - <xref:str>
  - name: evaluation_frequency
    description: 'Frequency to evaluate validation dataset to get metric scores.

      Must be a positive integer.'
    types:
    - <xref:str>
  - name: gradient_accumulation_step
    description: 'Gradient accumulation means running a configured number of

      "GradAccumulationStep" steps without

      updating the model weights while accumulating the gradients of those steps,
      and then using

      the accumulated gradients to compute the weight updates. Must be a positive
      integer.'
    types:
    - <xref:str>
  - name: layers_to_freeze
    description: 'Number of layers to freeze for the model. Must be a positive

      integer.

      For instance, passing 2 as value for ''seresnext'' means

      freezing layer0 and layer1. For a full list of models supported and details
      on layer freeze,

      please

      see: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models.'
    types:
    - <xref:str>
  - name: learning_rate
    description: Initial learning rate. Must be a float in the range [0, 1].
    types:
    - <xref:str>
  - name: learning_rate_scheduler
    description: 'Type of learning rate scheduler. Must be ''warmup_cosine'' or

      ''step''.'
    types:
    - <xref:str>
  - name: model_name
    description: 'Name of the model to use for training.

      For more information on the available models please visit the official documentation:

      https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models.'
    types:
    - <xref:str>
  - name: momentum
    description: 'Value of momentum when optimizer is ''sgd''. Must be a float in
      the range [0,

      1].'
    types:
    - <xref:str>
  - name: nesterov
    description: Enable nesterov when optimizer is 'sgd'.
    types:
    - <xref:str>
  - name: number_of_epochs
    description: Number of training epochs. Must be a positive integer.
    types:
    - <xref:str>
  - name: number_of_workers
    description: Number of data loader workers. Must be a non-negative integer.
    types:
    - <xref:str>
  - name: optimizer
    description: Type of optimizer. Must be either 'sgd', 'adam', or 'adamw'.
    types:
    - <xref:str>
  - name: random_seed
    description: Random seed to be used when using deterministic training.
    types:
    - <xref:str>
  - name: step_lr_gamma
    description: 'Value of gamma when learning rate scheduler is ''step''. Must be
      a float

      in the range [0, 1].'
    types:
    - <xref:str>
  - name: step_lr_step_size
    description: 'Value of step size when learning rate scheduler is ''step''. Must
      be

      a positive integer.'
    types:
    - <xref:str>
  - name: training_batch_size
    description: Training batch size. Must be a positive integer.
    types:
    - <xref:str>
  - name: validation_batch_size
    description: Validation batch size. Must be a positive integer.
    types:
    - <xref:str>
  - name: warmup_cosine_lr_cycles
    description: 'Value of cosine cycle when learning rate scheduler is

      ''warmup_cosine''. Must be a float in the range [0, 1].'
    types:
    - <xref:str>
  - name: warmup_cosine_lr_warmup_epochs
    description: 'Value of warmup epochs when learning rate scheduler is

      ''warmup_cosine''. Must be a positive integer.'
    types:
    - <xref:str>
  - name: weight_decay
    description: 'Value of weight decay when optimizer is ''sgd'', ''adam'', or ''adamw''.
      Must

      be a float in the range[0, 1].'
    types:
    - <xref:str>
variables:
- description: Enable AMSGrad when optimizer is 'adam' or 'adamw'.
  name: ams_gradient
  types:
  - <xref:str>
- description: Settings for using Augmentations.
  name: augmentations
  types:
  - <xref:str>
- description: 'Value of ''beta1'' when optimizer is ''adam'' or ''adamw''. Must be
    a float in the range

    [0, 1].'
  name: beta1
  types:
  - <xref:str>
- description: 'Value of ''beta2'' when optimizer is ''adam'' or ''adamw''. Must be
    a float in the range

    [0, 1].'
  name: beta2
  types:
  - <xref:str>
- description: Whether to use distributer training.
  name: distributed
  types:
  - <xref:str>
- description: Enable early stopping logic during training.
  name: early_stopping
  types:
  - <xref:str>
- description: 'Minimum number of epochs or validation evaluations to wait before

    primary metric improvement

    is tracked for early stopping. Must be a positive integer.'
  name: early_stopping_delay
  types:
  - <xref:str>
- description: 'Minimum number of epochs or validation evaluations with no

    primary metric improvement before

    the run is stopped. Must be a positive integer.'
  name: early_stopping_patience
  types:
  - <xref:str>
- description: Enable normalization when exporting ONNX model.
  name: enable_onnx_normalization
  types:
  - <xref:str>
- description: 'Frequency to evaluate validation dataset to get metric scores. Must

    be a positive integer.'
  name: evaluation_frequency
  types:
  - <xref:str>
- description: 'Gradient accumulation means running a configured number of

    "GradAccumulationStep" steps without

    updating the model weights while accumulating the gradients of those steps, and
    then using

    the accumulated gradients to compute the weight updates. Must be a positive integer.'
  name: gradient_accumulation_step
  types:
  - <xref:str>
- description: 'Number of layers to freeze for the model. Must be a positive integer.

    For instance, passing 2 as value for ''seresnext'' means

    freezing layer0 and layer1. For a full list of models supported and details on
    layer freeze,

    please

    see: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models.'
  name: layers_to_freeze
  types:
  - <xref:str>
- description: Initial learning rate. Must be a float in the range [0, 1].
  name: learning_rate
  types:
  - <xref:str>
- description: 'Type of learning rate scheduler. Must be ''warmup_cosine'' or

    ''step''.'
  name: learning_rate_scheduler
  types:
  - <xref:str>
- description: 'Name of the model to use for training.

    For more information on the available models please visit the official documentation:

    https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models.'
  name: model_name
  types:
  - <xref:str>
- description: Value of momentum when optimizer is 'sgd'. Must be a float in the range
    [0, 1].
  name: momentum
  types:
  - <xref:str>
- description: Enable nesterov when optimizer is 'sgd'.
  name: nesterov
  types:
  - <xref:str>
- description: Number of training epochs. Must be a positive integer.
  name: number_of_epochs
  types:
  - <xref:str>
- description: Number of data loader workers. Must be a non-negative integer.
  name: number_of_workers
  types:
  - <xref:str>
- description: Type of optimizer. Must be either 'sgd', 'adam', or 'adamw'.
  name: optimizer
  types:
  - <xref:str>
- description: Random seed to be used when using deterministic training.
  name: random_seed
  types:
  - <xref:str>
- description: 'Value of gamma when learning rate scheduler is ''step''. Must be a
    float in

    the range [0, 1].'
  name: step_lr_gamma
  types:
  - <xref:str>
- description: 'Value of step size when learning rate scheduler is ''step''. Must
    be a

    positive integer.'
  name: step_lr_step_size
  types:
  - <xref:str>
- description: Training batch size. Must be a positive integer.
  name: training_batch_size
  types:
  - <xref:str>
- description: Validation batch size. Must be a positive integer.
  name: validation_batch_size
  types:
  - <xref:str>
- description: 'Value of cosine cycle when learning rate scheduler is

    ''warmup_cosine''. Must be a float in the range [0, 1].'
  name: warmup_cosine_lr_cycles
  types:
  - <xref:str>
- description: 'Value of warmup epochs when learning rate scheduler is

    ''warmup_cosine''. Must be a positive integer.'
  name: warmup_cosine_lr_warmup_epochs
  types:
  - <xref:str>
- description: 'Value of weight decay when optimizer is ''sgd'', ''adam'', or ''adamw''.
    Must be

    a float in the range[0, 1].'
  name: weight_decay
  types:
  - <xref:str>
