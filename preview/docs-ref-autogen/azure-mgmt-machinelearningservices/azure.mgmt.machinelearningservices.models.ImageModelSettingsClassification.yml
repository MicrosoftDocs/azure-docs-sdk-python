### YamlMime:PythonClass
uid: azure.mgmt.machinelearningservices.models.ImageModelSettingsClassification
name: ImageModelSettingsClassification
fullName: azure.mgmt.machinelearningservices.models.ImageModelSettingsClassification
module: azure.mgmt.machinelearningservices.models
inheritances:
- azure.mgmt.machinelearningservices.models._models_py3.ImageModelSettings
summary: "Settings used for training the model.\nFor more information on the available\
  \ settings please visit the official documentation:\n[https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   ivar advanced_settings:\n      Settings for advanced scenarios.\n\n   vartype\
  \ advanced_settings:\n      str\n\n   ivar ams_gradient:\n      Enable AMSGrad when\
  \ optimizer is 'adam' or 'adamw'.\n\n   vartype ams_gradient:\n      bool\n\n  \
  \ ivar augmentations:\n      Settings for using Augmentations.\n\n   vartype augmentations:\n\
  \      str\n\n   ivar beta1:\n      Value of 'beta1' when optimizer is 'adam' or\
  \ 'adamw'. Must be a float in the range\n      [0, 1].\n\n   vartype beta1:\n  \
  \    float\n\n   ivar beta2:\n      Value of 'beta2' when optimizer is 'adam' or\
  \ 'adamw'. Must be a float in the range\n      [0, 1].\n\n   vartype beta2:\n  \
  \    float\n\n   ivar checkpoint_frequency:\n      Frequency to store model checkpoints.\
  \ Must be a positive integer.\n\n   vartype checkpoint_frequency:\n      int\n\n\
  \   ivar checkpoint_model:\n      The pretrained checkpoint model for incremental\
  \ training.\n\n   vartype checkpoint_model:\n      ~azure.mgmt.machinelearningservices.models.MLFlowModelJobInput\n\
  \n   ivar checkpoint_run_id:\n      The id of a previous run that has a pretrained\
  \ checkpoint for\n      incremental training.\n\n   vartype checkpoint_run_id:\n\
  \      str\n\n   ivar distributed:\n      Whether to use distributed training.\n\
  \n   vartype distributed:\n      bool\n\n   ivar early_stopping:\n      Enable early\
  \ stopping logic during training.\n\n   vartype early_stopping:\n      bool\n\n\
  \   ivar early_stopping_delay:\n      Minimum number of epochs or validation evaluations\
  \ to wait before\n      primary metric improvement\n      is tracked for early stopping.\
  \ Must be a positive integer.\n\n   vartype early_stopping_delay:\n      int\n\n\
  \   ivar early_stopping_patience:\n      Minimum number of epochs or validation\
  \ evaluations with no\n      primary metric improvement before\n      the run is\
  \ stopped. Must be a positive integer.\n\n   vartype early_stopping_patience:\n\
  \      int\n\n   ivar enable_onnx_normalization:\n      Enable normalization when\
  \ exporting ONNX model.\n\n   vartype enable_onnx_normalization:\n      bool\n\n\
  \   ivar evaluation_frequency:\n      Frequency to evaluate validation dataset to\
  \ get metric scores. Must\n      be a positive integer.\n\n   vartype evaluation_frequency:\n\
  \      int\n\n   ivar gradient_accumulation_step:\n      Gradient accumulation means\
  \ running a configured number of\n      \"GradAccumulationStep\" steps without\n\
  \      updating the model weights while accumulating the gradients of those steps,\
  \ and then using\n      the accumulated gradients to compute the weight updates.\
  \ Must be a positive integer.\n\n   vartype gradient_accumulation_step:\n      int\n\
  \n   ivar layers_to_freeze:\n      Number of layers to freeze for the model. Must\
  \ be a positive integer.\n      For instance, passing 2 as value for 'seresnext'\
  \ means\n      freezing layer0 and layer1. For a full list of models supported and\
  \ details on layer freeze,\n      please\n      see: [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   vartype layers_to_freeze:\n      int\n\n   ivar learning_rate:\n      Initial\
  \ learning rate. Must be a float in the range [0, 1].\n\n   vartype learning_rate:\n\
  \      float\n\n   ivar learning_rate_scheduler:\n      Type of learning rate scheduler.\
  \ Must be 'warmup_cosine' or\n      'step'. Known values are: \"None\", \"WarmupCosine\"\
  , and \"Step\".\n\n   vartype learning_rate_scheduler:\n      str or\n      ~azure.mgmt.machinelearningservices.models.LearningRateScheduler\n\
  \n   ivar model_name:\n      Name of the model to use for training.\n      For more\
  \ information on the available models please visit the official documentation:\n\
  \      [https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models).\n\
  \n   vartype model_name:\n      str\n\n   ivar momentum:\n      Value of momentum\
  \ when optimizer is 'sgd'. Must be a float in the range [0, 1].\n\n   vartype momentum:\n\
  \      float\n\n   ivar nesterov:\n      Enable nesterov when optimizer is 'sgd'.\n\
  \n   vartype nesterov:\n      bool\n\n   ivar number_of_epochs:\n      Number of\
  \ training epochs. Must be a positive integer.\n\n   vartype number_of_epochs:\n\
  \      int\n\n   ivar number_of_workers:\n      Number of data loader workers. Must\
  \ be a non-negative integer.\n\n   vartype number_of_workers:\n      int\n\n   ivar\
  \ optimizer:\n      Type of optimizer. Known values are: \"None\", \"Sgd\", \"Adam\"\
  , and \"Adamw\".\n\n   vartype optimizer:\n      str or ~azure.mgmt.machinelearningservices.models.StochasticOptimizer\n\
  \n   ivar random_seed:\n      Random seed to be used when using deterministic training.\n\
  \n   vartype random_seed:\n      int\n\n   ivar step_lr_gamma:\n      Value of gamma\
  \ when learning rate scheduler is 'step'. Must be a float in\n      the range [0,\
  \ 1].\n\n   vartype step_lr_gamma:\n      float\n\n   ivar step_lr_step_size:\n\
  \      Value of step size when learning rate scheduler is 'step'. Must be a\n  \
  \    positive integer.\n\n   vartype step_lr_step_size:\n      int\n\n   ivar training_batch_size:\n\
  \      Training batch size. Must be a positive integer.\n\n   vartype training_batch_size:\n\
  \      int\n\n   ivar validation_batch_size:\n      Validation batch size. Must\
  \ be a positive integer.\n\n   vartype validation_batch_size:\n      int\n\n   ivar\
  \ warmup_cosine_lr_cycles:\n      Value of cosine cycle when learning rate scheduler\
  \ is\n      'warmup_cosine'. Must be a float in the range [0, 1].\n\n   vartype\
  \ warmup_cosine_lr_cycles:\n      float\n\n   ivar warmup_cosine_lr_warmup_epochs:\n\
  \      Value of warmup epochs when learning rate scheduler is\n      'warmup_cosine'.\
  \ Must be a positive integer.\n\n   vartype warmup_cosine_lr_warmup_epochs:\n  \
  \    int\n\n   ivar weight_decay:\n      Value of weight decay when optimizer is\
  \ 'sgd', 'adam', or 'adamw'. Must be\n      a float in the range[0, 1].\n\n   vartype\
  \ weight_decay:\n      float\n\n   ivar training_crop_size:\n      Image crop size\
  \ that is input to the neural network for the training\n      dataset. Must be a\
  \ positive integer.\n\n   vartype training_crop_size:\n      int\n\n   ivar validation_crop_size:\n\
  \      Image crop size that is input to the neural network for the\n      validation\
  \ dataset. Must be a positive integer.\n\n   vartype validation_crop_size:\n   \
  \   int\n\n   ivar validation_resize_size:\n      Image size to which to resize\
  \ before cropping for validation\n      dataset. Must be a positive integer.\n\n\
  \   vartype validation_resize_size:\n      int\n\n   ivar weighted_loss:\n     \
  \ Weighted loss. The accepted values are 0 for no weighted loss.\n      1 for weighted\
  \ loss with sqrt.(class_weights). 2 for weighted loss with class_weights. Must be\n\
  \      0 or 1 or 2.\n\n   vartype weighted_loss:\n      int"
constructor:
  syntax: 'ImageModelSettingsClassification(*, advanced_settings: Optional[str] =
    None, ams_gradient: Optional[bool] = None, augmentations: Optional[str] = None,
    beta1: Optional[float] = None, beta2: Optional[float] = None, checkpoint_frequency:
    Optional[int] = None, checkpoint_model: Optional[_models.MLFlowModelJobInput]
    = None, checkpoint_run_id: Optional[str] = None, distributed: Optional[bool] =
    None, early_stopping: Optional[bool] = None, early_stopping_delay: Optional[int]
    = None, early_stopping_patience: Optional[int] = None, enable_onnx_normalization:
    Optional[bool] = None, evaluation_frequency: Optional[int] = None, gradient_accumulation_step:
    Optional[int] = None, layers_to_freeze: Optional[int] = None, learning_rate: Optional[float]
    = None, learning_rate_scheduler: Optional[Union[str, _models.LearningRateScheduler]]
    = None, model_name: Optional[str] = None, momentum: Optional[float] = None, nesterov:
    Optional[bool] = None, number_of_epochs: Optional[int] = None, number_of_workers:
    Optional[int] = None, optimizer: Optional[Union[str, _models.StochasticOptimizer]]
    = None, random_seed: Optional[int] = None, step_lr_gamma: Optional[float] = None,
    step_lr_step_size: Optional[int] = None, training_batch_size: Optional[int] =
    None, validation_batch_size: Optional[int] = None, warmup_cosine_lr_cycles: Optional[float]
    = None, warmup_cosine_lr_warmup_epochs: Optional[int] = None, weight_decay: Optional[float]
    = None, training_crop_size: Optional[int] = None, validation_crop_size: Optional[int]
    = None, validation_resize_size: Optional[int] = None, weighted_loss: Optional[int]
    = None, **kwargs)'
