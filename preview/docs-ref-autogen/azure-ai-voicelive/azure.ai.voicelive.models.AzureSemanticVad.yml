### YamlMime:PythonClass
uid: azure.ai.voicelive.models.AzureSemanticVad
name: AzureSemanticVad
fullName: azure.ai.voicelive.models.AzureSemanticVad
module: azure.ai.voicelive.models
summary: 'Server Speech Detection (Azure semantic VAD, default variant).


  Default discriminator is `"azure_semantic_vad"`. You may also pass

  `type="azure_semantic_vad_en"` (English-labeled) or `type="server_sd"`

  (legacy alias) for compatibility; the field set is the same.'
constructor:
  syntax: 'AzureSemanticVad(*args: Any, **kwargs: Any)'
variables:
- description: 'Discriminator for this VAD. Defaults to `"azure_semantic_vad"`.

    May also be `"azure_semantic_vad_en"` or (legacy) `"server_sd"`.'
  name: type
  types:
  - <xref:str>
- description: "Primary detection threshold (0.0\u20131.0)."
  name: threshold
  types:
  - <xref:float> | <xref:None>
- description: Audio kept before detected speech (ms).
  name: prefix_padding_ms
  types:
  - <xref:int> | <xref:None>
- description: Required trailing silence to mark end (ms).
  name: silence_duration_ms
  types:
  - <xref:int> | <xref:None>
- description: Optional semantic EOU detector config.
  name: end_of_utterance_detection
  types:
  - <xref:azure.ai.voicelive.models.EOUDetection> | <xref:None>
- description: "Negative evidence threshold (0.0\u20131.0)."
  name: neg_threshold
  types:
  - <xref:float> | <xref:None>
- description: Minimum speech duration to trigger (ms).
  name: speech_duration_ms
  types:
  - <xref:int> | <xref:None>
- description: Sliding window size for scoring (ms).
  name: window_size
  types:
  - <xref:int> | <xref:None>
- description: Distinct case-insensitive phones required.
  name: distinct_ci_phones
  types:
  - <xref:int> | <xref:None>
- description: If `True`, require a vowel to mark end.
  name: require_vowel
  types:
  - <xref:bool> | <xref:None>
- description: If `True`, drop common fillers from ASR cues.
  name: remove_filler_words
  types:
  - <xref:bool> | <xref:None>
- description: Optional list of language tags (e.g., `"en-US"`).
  name: languages
  types:
  - <xref:list>[<xref:str>] | <xref:None>
- description: If `True`, truncate long speech segments automatically.
  name: auto_truncate
  types:
  - <xref:bool> | <xref:None>
methods:
- uid: azure.ai.voicelive.models.AzureSemanticVad.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.voicelive.models.AzureSemanticVad.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.voicelive.models.AzureSemanticVad.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.voicelive.models.AzureSemanticVad.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.voicelive.models.AzureSemanticVad.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.voicelive.models.AzureSemanticVad.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.voicelive.models.AzureSemanticVad.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.AzureSemanticVad.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.voicelive.models.AzureSemanticVad.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.AzureSemanticVad.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.voicelive.models.AzureSemanticVad.auto_truncate
  name: auto_truncate
  signature: 'auto_truncate: bool | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.distinct_ci_phones
  name: distinct_ci_phones
  signature: 'distinct_ci_phones: int | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.end_of_utterance_detection
  name: end_of_utterance_detection
  signature: 'end_of_utterance_detection: _models.EOUDetection | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.languages
  name: languages
  signature: 'languages: List[str] | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.neg_threshold
  name: neg_threshold
  signature: 'neg_threshold: float | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.prefix_padding_ms
  name: prefix_padding_ms
  signature: 'prefix_padding_ms: int | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.remove_filler_words
  name: remove_filler_words
  signature: 'remove_filler_words: bool | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.require_vowel
  name: require_vowel
  signature: 'require_vowel: bool | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.silence_duration_ms
  name: silence_duration_ms
  signature: 'silence_duration_ms: int | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.speech_duration_ms
  name: speech_duration_ms
  signature: 'speech_duration_ms: int | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.threshold
  name: threshold
  signature: 'threshold: float | None'
- uid: azure.ai.voicelive.models.AzureSemanticVad.type
  name: type
  summary: 'Literal["none"], Literal["server_vad"],

    Literal["azure_semantic_vad"], Literal["azure_semantic_vad_en"], Literal["server_sd"],

    Literal["azure_semantic_vad_multilingual"]'
  signature: 'type: str'
- uid: azure.ai.voicelive.models.AzureSemanticVad.window_size
  name: window_size
  signature: 'window_size: int | None'
