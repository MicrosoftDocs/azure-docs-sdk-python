### YamlMime:PythonClass
uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped
name: ServerEventInputAudioBufferSpeechStopped
fullName: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped
module: azure.ai.voicelive.models
summary: 'Returned in `server_vad` mode when the server detects the end of speech
  in

  the audio buffer. The server will also send an `conversation.item.created`

  event with the user message item that is created from the audio buffer.'
constructor:
  syntax: 'ServerEventInputAudioBufferSpeechStopped(*args: Any, **kwargs: Any)'
variables:
- name: event_id
  types:
  - <xref:str>
- description: The event type, must be `input_audio_buffer.speech_stopped`. Required.
  name: type
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.INPUT_AUDIO_BUFFER_SPEECH_STOPPED>
- description: 'Milliseconds since the session started when speech stopped. This will

    correspond to the end of audio sent to the model, and thus includes the

    `min_silence_duration_ms` configured in the Session. Required.'
  name: audio_end_ms
  types:
  - <xref:int>
- description: The ID of the user message item that will be created. Required.
  name: item_id
  types:
  - <xref:str>
methods:
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.deserialize
  name: deserialize
  signature: 'deserialize(payload: dict) -> ServerEvent'
  parameters:
  - name: payload
    isRequired: true
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.audio_end_ms
  name: audio_end_ms
  summary: 'Milliseconds since the session started when speech stopped. This will

    correspond to the end of audio sent to the model, and thus includes the

    `min_silence_duration_ms` configured in the Session. Required.'
  signature: 'audio_end_ms: int'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.item_id
  name: item_id
  summary: The ID of the user message item that will be created. Required.
  signature: 'item_id: str'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.type
  name: type
  summary: The event type, must be `input_audio_buffer.speech_stopped`. Required.
  signature: 'type: speech_stopped''>]'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStopped.event_id
  name: event_id
  signature: 'event_id: str | None'
