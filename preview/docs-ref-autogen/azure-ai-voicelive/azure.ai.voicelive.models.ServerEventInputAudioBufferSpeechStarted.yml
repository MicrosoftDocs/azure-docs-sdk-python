### YamlMime:PythonClass
uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted
name: ServerEventInputAudioBufferSpeechStarted
fullName: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted
module: azure.ai.voicelive.models
summary: 'Sent by the server when in `server_vad` mode to indicate that speech has
  been

  detected in the audio buffer. This can happen any time audio is added to the

  buffer (unless speech is already detected). The client may want to use this

  event to interrupt audio playback or provide visual feedback to the user.


  The client should expect to receive a `input_audio_buffer.speech_stopped` event

  when speech stops. The `item_id` property is the ID of the user message item

  that will be created when speech stops and will also be included in the

  `input_audio_buffer.speech_stopped` event (unless the client manually commits

  the audio buffer during VAD activation).'
constructor:
  syntax: 'ServerEventInputAudioBufferSpeechStarted(*args: Any, **kwargs: Any)'
variables:
- name: event_id
  types:
  - <xref:str>
- description: The event type, must be `input_audio_buffer.speech_started`. Required.
  name: type
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.INPUT_AUDIO_BUFFER_SPEECH_STARTED>
- description: 'Milliseconds from the start of all audio written to the buffer during
    the

    session when speech was first detected. This will correspond to the

    beginning of audio sent to the model, and thus includes the

    `prefix_padding_ms` configured in the Session. Required.'
  name: audio_start_ms
  types:
  - <xref:int>
- description: 'The ID of the user message item that will be created when speech stops.

    Required.'
  name: item_id
  types:
  - <xref:str>
methods:
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.deserialize
  name: deserialize
  signature: 'deserialize(payload: dict[str, Any]) -> ServerEvent'
  parameters:
  - name: payload
    isRequired: true
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.audio_start_ms
  name: audio_start_ms
  summary: 'Milliseconds from the start of all audio written to the buffer during
    the

    session when speech was first detected. This will correspond to the

    beginning of audio sent to the model, and thus includes the

    `prefix_padding_ms` configured in the Session. Required.'
  signature: 'audio_start_ms: int'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.item_id
  name: item_id
  summary: The ID of the user message item that will be created when speech stops.
    Required.
  signature: 'item_id: str'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.type
  name: type
  summary: The event type, must be `input_audio_buffer.speech_started`. Required.
  signature: 'type: speech_started''>]'
- uid: azure.ai.voicelive.models.ServerEventInputAudioBufferSpeechStarted.event_id
  name: event_id
  signature: 'event_id: str | None'
