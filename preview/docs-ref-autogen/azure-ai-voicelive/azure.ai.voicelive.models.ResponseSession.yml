### YamlMime:PythonClass
uid: azure.ai.voicelive.models.ResponseSession
name: ResponseSession
fullName: azure.ai.voicelive.models.ResponseSession
module: azure.ai.voicelive.models
summary: Base for session configuration in the response.
constructor:
  syntax: 'ResponseSession(*args: Any, **kwargs: Any)'
variables:
- description: The model for the session.
  name: model
  types:
  - <xref:str>
- description: The modalities to be used in the session.
  name: modalities
  types:
  - <xref:list>[<xref:str>
  - <xref:azure.ai.voicelive.models.Modality>]
- description: The animation configuration for the session.
  name: animation
  types:
  - <xref:azure.ai.voicelive.models.Animation>
- description: 'The voice configuration for the session. Is one of the following types:
    Union[str,

    "_models.OAIVoice"], OpenAIVoice, AzureVoice'
  name: voice
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.OAIVoice>
  - <xref:azure.ai.voicelive.models.OpenAIVoice>
  - <xref:azure.ai.voicelive.models.AzureVoice>
- description: Optional instructions to guide the model's behavior throughout the
    session.
  name: instructions
  types:
  - <xref:str>
- description: "Input audio sampling rate in Hz. Available values:\n\n* For pcm16:\
    \ 8000, 16000, 24000 \n\n* For g711_alaw/g711_ulaw: 8000."
  name: input_audio_sampling_rate
  types:
  - <xref:int>
- description: 'Input audio format. Default is ''pcm16''. Known values are: "pcm16",

    "g711_ulaw", and "g711_alaw".'
  name: input_audio_format
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.InputAudioFormat>
- description: 'Output audio format. Default is ''pcm16''. Known values are: "pcm16",

    "pcm16-8000hz", "pcm16-16000hz", "g711_ulaw", and "g711_alaw".'
  name: output_audio_format
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.OutputAudioFormat>
- description: Type of turn detection to use.
  name: turn_detection
  types:
  - <xref:azure.ai.voicelive.models.TurnDetection>
- description: Configuration for input audio noise reduction.
  name: input_audio_noise_reduction
  types:
  - <xref:azure.ai.voicelive.models.AudioNoiseReduction>
- description: 'Configuration for echo cancellation during server-side

    audio processing.'
  name: input_audio_echo_cancellation
  types:
  - <xref:azure.ai.voicelive.models.AudioEchoCancellation>
- description: Configuration for avatar streaming and behavior during the session.
  name: avatar
  types:
  - <xref:azure.ai.voicelive.models.AvatarConfig>
- description: Configuration for input audio transcription.
  name: input_audio_transcription
  types:
  - <xref:azure.ai.voicelive.models.AudioInputTranscriptionOptions>
- description: Types of timestamps to include in audio response content.
  name: output_audio_timestamp_types
  types:
  - <xref:list>[<xref:str>
  - <xref:azure.ai.voicelive.models.AudioTimestampType>]
- description: Configuration for tools to be used during the session, if applicable.
  name: tools
  types:
  - <xref:list>[<xref:azure.ai.voicelive.models.Tool>]
- description: 'Specifies which tools the model is allowed to call during the session.
    Is

    either a Union[str, "_models.ToolChoiceLiteral"] type or a ToolChoiceObject type.'
  name: tool_choice
  types:
  - <xref:str>
  - <xref:azure.ai.voicelive.models.ToolChoiceLiteral>
  - <xref:azure.ai.voicelive.models.ToolChoiceObject>
- description: 'Controls the randomness of the model''s output. Range: 0.0 to 1.0.
    Default is

    0.7.'
  name: temperature
  types:
  - <xref:float>
- description: 'Maximum number of tokens to generate in the response. Default

    is unlimited. Is either a int type or a Literal["inf"] type.'
  name: max_response_output_tokens
  types:
  - <xref:int>
  - <xref:str>
- description: The agent configuration for the session, if applicable.
  name: agent
  types:
  - <xref:azure.ai.voicelive.models.AgentConfig>
- description: The unique identifier for the session.
  name: id
  types:
  - <xref:str>
methods:
- uid: azure.ai.voicelive.models.ResponseSession.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.voicelive.models.ResponseSession.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.voicelive.models.ResponseSession.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.voicelive.models.ResponseSession.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.voicelive.models.ResponseSession.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.voicelive.models.ResponseSession.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.voicelive.models.ResponseSession.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ResponseSession.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> tuple[str, Any]
- uid: azure.ai.voicelive.models.ResponseSession.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.voicelive.models.ResponseSession.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.voicelive.models.ResponseSession.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.voicelive.models.ResponseSession.agent
  name: agent
  summary: The agent configuration for the session, if applicable.
  signature: 'agent: _models.AgentConfig | None'
- uid: azure.ai.voicelive.models.ResponseSession.animation
  name: animation
  summary: The animation configuration for the session.
  signature: 'animation: ''_models.Animation'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.avatar
  name: avatar
  summary: Configuration for avatar streaming and behavior during the session.
  signature: 'avatar: ''_models.AvatarConfig'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.id
  name: id
  summary: The unique identifier for the session.
  signature: 'id: str | None'
- uid: azure.ai.voicelive.models.ResponseSession.input_audio_echo_cancellation
  name: input_audio_echo_cancellation
  summary: Configuration for echo cancellation during server-side audio processing.
  signature: 'input_audio_echo_cancellation: ''_models.AudioEchoCancellation'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.input_audio_format
  name: input_audio_format
  summary: '"pcm16", "g711_ulaw", and

    "g711_alaw".'
  signature: 'input_audio_format: str | ''_models.InputAudioFormat'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.input_audio_noise_reduction
  name: input_audio_noise_reduction
  summary: Configuration for input audio noise reduction.
  signature: 'input_audio_noise_reduction: ''_models.AudioNoiseReduction'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.input_audio_sampling_rate
  name: input_audio_sampling_rate
  summary: "Input audio sampling rate in Hz. Available values:\n\n* For pcm16: 8000,\
    \ 16000, 24000 \n\n* For g711_alaw/g711_ulaw: 8000. "
  signature: 'input_audio_sampling_rate: int | None'
- uid: azure.ai.voicelive.models.ResponseSession.input_audio_transcription
  name: input_audio_transcription
  summary: Configuration for input audio transcription.
  signature: 'input_audio_transcription: ''_models.AudioInputTranscriptionOptions''
    | None'
- uid: azure.ai.voicelive.models.ResponseSession.instructions
  name: instructions
  summary: Optional instructions to guide the model's behavior throughout the session.
  signature: 'instructions: str | None'
- uid: azure.ai.voicelive.models.ResponseSession.max_response_output_tokens
  name: max_response_output_tokens
  summary: 'Maximum number of tokens to generate in the response. Default is unlimited.
    Is either a int

    type or a Literal["inf"] type.'
  signature: 'max_response_output_tokens: int | Literal[''inf''] | None'
- uid: azure.ai.voicelive.models.ResponseSession.modalities
  name: modalities
  summary: The modalities to be used in the session.
  signature: 'modalities: list[str | ''_models.Modality''] | None'
- uid: azure.ai.voicelive.models.ResponseSession.model
  name: model
  summary: The model for the session.
  signature: 'model: str | None'
- uid: azure.ai.voicelive.models.ResponseSession.output_audio_format
  name: output_audio_format
  summary: '"pcm16", "pcm16-8000hz",

    "pcm16-16000hz", "g711_ulaw", and "g711_alaw".'
  signature: 'output_audio_format: str | ''_models.OutputAudioFormat'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.output_audio_timestamp_types
  name: output_audio_timestamp_types
  summary: Types of timestamps to include in audio response content.
  signature: 'output_audio_timestamp_types: list[str | ''_models.AudioTimestampType'']
    | None'
- uid: azure.ai.voicelive.models.ResponseSession.temperature
  name: temperature
  summary: 0.0 to 1.0. Default is 0.7.
  signature: 'temperature: float | None'
- uid: azure.ai.voicelive.models.ResponseSession.tool_choice
  name: tool_choice
  summary: 'Specifies which tools the model is allowed to call during the session.
    Is either a Union[str,

    "_models.ToolChoiceLiteral"] type or a ToolChoiceObject type.'
  signature: 'tool_choice: ''_types.ToolChoice'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.tools
  name: tools
  summary: Configuration for tools to be used during the session, if applicable.
  signature: 'tools: list[''_models.Tool''] | None'
- uid: azure.ai.voicelive.models.ResponseSession.turn_detection
  name: turn_detection
  summary: Type of turn detection to use.
  signature: 'turn_detection: ''_models.TurnDetection'' | None'
- uid: azure.ai.voicelive.models.ResponseSession.voice
  name: voice
  summary: 'Union[str,

    "_models.OAIVoice"], OpenAIVoice, AzureVoice'
  signature: 'voice: ''_types.Voice'' | None'
