### YamlMime:PythonClass
uid: azure.ai.inference.models.StreamingChatCompletionsUpdate
name: StreamingChatCompletionsUpdate
fullName: azure.ai.inference.models.StreamingChatCompletionsUpdate
module: azure.ai.inference.models
inheritances:
- azure.ai.inference._model_base.Model
summary: 'Represents a response update to a chat completions request, when the service
  is streaming

  updates

  using Server Sent Events (SSE).

  Completions support a wide variety of tasks and generate text that continues from
  or

  "completes"

  provided prompt data.'
constructor:
  syntax: 'StreamingChatCompletionsUpdate(*args: Any, **kwargs: Any)'
variables:
- description: A unique identifier associated with this chat completions response.
    Required.
  name: id
  types:
  - <xref:str>
- description: 'The first timestamp associated with generation activity for this completions

    response,

    represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan
    1970. Required.'
  name: created
  types:
  - <xref:datetime.datetime>
- description: The model used for the chat completion. Required.
  name: model
  types:
  - <xref:str>
- description: 'Usage information for tokens processed and generated as part of this
    completions

    operation. Required.'
  name: usage
  types:
  - <xref:azure.ai.inference.models.CompletionsUsage>
- description: 'An update to the collection of completion choices associated with
    this

    completions response.

    Generally, `n` choices are generated per provided prompt with a default value
    of 1.

    Token limits and other settings may limit the number of choices generated. Required.'
  name: choices
  types:
  - <xref:list>[<xref:azure.ai.inference.models.StreamingChatChoiceUpdate>]
methods:
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.as_dict
  name: as_dict
  summary: Return a dict that can be JSONify using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.choices
  name: choices
  summary: 'An update to the collection of completion choices associated with this
    completions response.

    Generally, `n` choices are generated per provided prompt with a default value
    of 1.

    Token limits and other settings may limit the number of choices generated. Required.'
  signature: 'choices: List[_models.StreamingChatChoiceUpdate]'
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.created
  name: created
  summary: 'The first timestamp associated with generation activity for this completions
    response,

    represented as seconds since the beginning of the Unix epoch of 00:00 on 1 Jan
    1970. Required.'
  signature: 'created: datetime'
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.id
  name: id
  summary: A unique identifier associated with this chat completions response. Required.
  signature: 'id: str'
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.model
  name: model
  summary: The model used for the chat completion. Required.
  signature: 'model: str'
- uid: azure.ai.inference.models.StreamingChatCompletionsUpdate.usage
  name: usage
  summary: 'Usage information for tokens processed and generated as part of this completions
    operation.

    Required.'
  signature: 'usage: _models.CompletionsUsage'
