### YamlMime:PythonClass
uid: azure.ai.inference.EmbeddingsClient
name: EmbeddingsClient
fullName: azure.ai.inference.EmbeddingsClient
module: azure.ai.inference
inheritances:
- azure.ai.inference._client.EmbeddingsClient
summary: EmbeddingsClient.
constructor:
  syntax: 'EmbeddingsClient(endpoint: str, credential: AzureKeyCredential | TokenCredential,
    *, dimensions: int | None = None, encoding_format: str | EmbeddingEncodingFormat
    | None = None, input_type: str | EmbeddingInputType | None = None, model: str
    | None = None, model_extras: Dict[str, Any] | None = None, **kwargs: Any)'
  parameters:
  - name: endpoint
    description: Service host. Required.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'Credential used to authenticate requests to the service. Is either
      a

      AzureKeyCredential type or a TokenCredential type. Required.'
    isRequired: true
    types:
    - <xref:azure.core.credentials.AzureKeyCredential>
    - <xref:azure.core.credentials.TokenCredential>
  keywordOnlyParameters:
  - name: dimensions
    description: 'Optional. The number of dimensions the resulting output embeddings
      should

      have. Default value is None.'
    types:
    - <xref:int>
  - name: encoding_format
    description: 'Optional. The desired format for the returned embeddings.

      Known values are:

      "base64", "binary", "float", "int8", "ubinary", and "uint8". Default value is
      None.'
    types:
    - <xref:str>
    - <xref:azure.ai.inference.models.EmbeddingEncodingFormat>
  - name: input_type
    description: 'Optional. The type of the input. Known values are:

      "text", "query", and "document". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.inference.models.EmbeddingInputType>
  - name: model
    description: 'ID of the specific AI model to use, if more than one model is available
      on the

      endpoint. Default value is None.'
    types:
    - <xref:str>
  - name: model_extras
    description: 'Additional, model-specific parameters that are not in the

      standard request payload. They will be added as-is to the root of the JSON in
      the request body.

      How the service handles these extra parameters depends on the value of the

      `extra-parameters` request header. Default value is None.'
    types:
    - <xref:dict>[<xref:str>, <xref:typing.Any>]
  - name: api_version
    description: 'The API version to use for this operation. Default value is

      "2024-05-01-preview". Note that overriding this default value may result in
      unsupported

      behavior.'
    types:
    - <xref:str>
methods:
- uid: azure.ai.inference.EmbeddingsClient.close
  name: close
  signature: close() -> None
- uid: azure.ai.inference.EmbeddingsClient.embed
  name: embed
  summary: 'Return the embedding vectors for given text prompts.

    The method makes a REST API call to the */embeddings* route on the given endpoint.'
  signature: 'embed(*, input: List[str], dimensions: int | None = None, encoding_format:
    str | _models.EmbeddingEncodingFormat | None = None, input_type: str | _models.EmbeddingInputType
    | None = None, model: str | None = None, model_extras: Dict[str, Any] | None =
    None, **kwargs: Any) -> _models.EmbeddingsResult'
  parameters:
  - name: body
    description: 'Is either a MutableMapping[str, Any] type (like a dictionary) or
      a IO[bytes] type

      that specifies the full request payload. Required.'
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: input
    description: 'Input text to embed, encoded as a string or array of tokens.

      To embed multiple inputs in a single request, pass an array

      of strings or array of token arrays. Required.'
    types:
    - <xref:list>[<xref:str>]
  - name: dimensions
    description: 'Optional. The number of dimensions the resulting output embeddings
      should

      have. Default value is None.'
    types:
    - <xref:int>
  - name: encoding_format
    description: 'Optional. The desired format for the returned embeddings.

      Known values are:

      "base64", "binary", "float", "int8", "ubinary", and "uint8". Default value is
      None.'
    types:
    - <xref:str>
    - <xref:azure.ai.inference.models.EmbeddingEncodingFormat>
  - name: input_type
    description: 'Optional. The type of the input. Known values are:

      "text", "query", and "document". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.inference.models.EmbeddingInputType>
  - name: model
    description: 'ID of the specific AI model to use, if more than one model is available
      on the

      endpoint. Default value is None.'
    types:
    - <xref:str>
  - name: model_extras
    description: 'Additional, model-specific parameters that are not in the

      standard request payload. They will be added as-is to the root of the JSON in
      the request body.

      How the service handles these extra parameters depends on the value of the

      `extra-parameters` request header. Default value is None.'
    types:
    - <xref:dict>[<xref:str>, <xref:typing.Any>]
  return:
    description: EmbeddingsResult. The EmbeddingsResult is compatible with MutableMapping
    types:
    - <xref:azure.ai.inference.models.EmbeddingsResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.inference.EmbeddingsClient.get_model_info
  name: get_model_info
  summary: Returns information about the AI model.
  signature: 'get_model_info(**kwargs: Any) -> ModelInfo'
  return:
    description: ModelInfo. The ModelInfo is compatible with MutableMapping
    types:
    - <xref:azure.ai.inference.models.ModelInfo>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.inference.EmbeddingsClient.send_request
  name: send_request
  summary: 'Runs the network request through the client''s chained policies.


    ```


    >>> from azure.core.rest import HttpRequest

    >>> request = HttpRequest("GET", "https://www.example.org/")

    <HttpRequest [GET], url: ''https://www.example.org/''>

    >>> response = client.send_request(request)

    <HttpResponse: 200 OK>

    ```


    For more information on this code flow, see [https://aka.ms/azsdk/dpcodegen/python/send_request](https://aka.ms/azsdk/dpcodegen/python/send_request)'
  signature: 'send_request(request: HttpRequest, *, stream: bool = False, **kwargs:
    Any) -> HttpResponse'
  parameters:
  - name: request
    description: The network request you want to make. Required.
    isRequired: true
    types:
    - <xref:azure.core.rest.HttpRequest>
  keywordOnlyParameters:
  - name: stream
    description: Whether the response payload will be streamed. Defaults to False.
    types:
    - <xref:bool>
  return:
    description: The response of your network call. Does not do error handling on
      your response.
    types:
    - <xref:azure.core.rest.HttpResponse>
