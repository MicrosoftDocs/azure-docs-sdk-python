### YamlMime:PythonPackage
uid: azure.ai.inference.aio
name: aio
fullName: azure.ai.inference.aio
type: import
functions:
- uid: azure.ai.inference.aio.load_client
  name: load_client
  summary: 'Load a client from a given endpoint URL. The method makes a REST API call
    to the */info* route

    on the given endpoint, to determine the model type and therefore which client
    to instantiate.

    Keyword arguments are passed to the appropriate client constructor, so if you
    need to set things like

    *api_version*, *logging_enable*, *user_agent*, etc., you can do so here.

    This method will only work when using Serverless API or Managed Compute endpoint.

    It will not work for GitHub Models endpoint or Azure OpenAI endpoint.'
  signature: 'async load_client(endpoint: str, credential: AzureKeyCredential | AsyncTokenCredential,
    **kwargs: Any) -> ChatCompletionsClient | EmbeddingsClient | ImageEmbeddingsClient'
  parameters:
  - name: endpoint
    description: Service host. Required.
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'Credential used to authenticate requests to the service. Is either
      a

      AzureKeyCredential type or a AsyncTokenCredential type. Required.'
    isRequired: true
    types:
    - <xref:azure.core.credentials.AzureKeyCredential>
    - <xref:azure.core.credentials_async.AsyncTokenCredential>
  return:
    description: The appropriate asynchronous client associated with the given endpoint
    types:
    - <xref:azure.ai.inference.aio.ChatCompletionsClient>
    - <xref:azure.ai.inference.aio.EmbeddingsClient>
    - <xref:azure.ai.inference.aio.ImageEmbeddingsClient>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
classes:
- azure.ai.inference.aio.ChatCompletionsClient
- azure.ai.inference.aio.EmbeddingsClient
- azure.ai.inference.aio.ImageEmbeddingsClient
