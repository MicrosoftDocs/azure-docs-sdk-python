### YamlMime:PythonClass
uid: azure.ai.inference.models.ChatResponseMessage
name: ChatResponseMessage
fullName: azure.ai.inference.models.ChatResponseMessage
module: azure.ai.inference.models
inheritances:
- azure.ai.inference._model_base.Model
summary: 'A representation of a chat message as received in a response.


  All required parameters must be populated in order to send to server.'
constructor:
  syntax: 'ChatResponseMessage(*args: Any, **kwargs: Any)'
variables:
- description: 'The chat role associated with the message. Required. Known values
    are: "system",

    "user", "assistant", and "tool".'
  name: role
  types:
  - <xref:str>
  - <xref:azure.ai.inference.models.ChatRole>
- description: The content of the message. Required.
  name: content
  types:
  - <xref:str>
- description: 'The tool calls that must be resolved and have their outputs appended
    to

    subsequent input messages for the chat

    completions request to resolve as configured.'
  name: tool_calls
  types:
  - <xref:list>[<xref:azure.ai.inference.models.ChatCompletionsToolCall>]
methods:
- uid: azure.ai.inference.models.ChatResponseMessage.as_dict
  name: as_dict
  summary: Return a dict that can be JSONify using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.ChatResponseMessage.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.ChatResponseMessage.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.ChatResponseMessage.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.ChatResponseMessage.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.ChatResponseMessage.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.ChatResponseMessage.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.ChatResponseMessage.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.ChatResponseMessage.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.ChatResponseMessage.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.ChatResponseMessage.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.ChatResponseMessage.content
  name: content
  summary: The content of the message. Required.
  signature: 'content: str'
- uid: azure.ai.inference.models.ChatResponseMessage.role
  name: role
  summary: '"system", "user",

    "assistant", and "tool".'
  signature: 'role: str | _models.ChatRole'
- uid: azure.ai.inference.models.ChatResponseMessage.tool_calls
  name: tool_calls
  summary: 'The tool calls that must be resolved and have their outputs appended to
    subsequent input

    messages for the chat

    completions request to resolve as configured.'
  signature: 'tool_calls: List[_models.ChatCompletionsToolCall] | None'
