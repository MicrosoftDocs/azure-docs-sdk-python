### YamlMime:PythonClass
uid: azure.ai.inference.models.InputAudio
name: InputAudio
fullName: azure.ai.inference.models.InputAudio
module: azure.ai.inference.models
inheritances:
- azure.ai.inference.models._models.InputAudio
constructor:
  syntax: 'InputAudio(*args: Any, **kwargs: Any)'
methods:
- uid: azure.ai.inference.models.InputAudio.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.InputAudio.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.InputAudio.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.InputAudio.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.InputAudio.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.InputAudio.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.InputAudio.load
  name: load
  summary: 'Create an InputAudio object from a local audio file. The method reads
    the audio

    file and encodes it as a base64 string, which together with the audio format

    is then used to create the InputAudio object passed to the request payload.'
  signature: 'load(*, audio_file: str, audio_format: str) -> Self'
  keywordOnlyParameters:
  - name: audio_file
    description: The name of the local audio file to load. Required.
  - name: audio_format
    description: 'The MIME type format of the audio. For example: "wav", "mp3". Required.'
  return:
    description: An InputAudio object with the audio data encoded as a base64 string.
    types:
    - <xref:azure.ai.inference.models.InputAudio>
  exceptions:
  - type: FileNotFoundError
    description: when the image file could not be opened.
- uid: azure.ai.inference.models.InputAudio.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.InputAudio.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.InputAudio.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.InputAudio.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.InputAudio.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.InputAudio.data
  name: data
  summary: Base64 encoded audio data. Required.
  signature: 'data: str'
- uid: azure.ai.inference.models.InputAudio.format
  name: format
  summary: '"wav" and "mp3".'
  signature: 'format: str | ''_models.AudioContentFormat'''
