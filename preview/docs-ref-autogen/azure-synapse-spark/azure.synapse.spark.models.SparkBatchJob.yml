### YamlMime:PythonClass
uid: azure.synapse.spark.models.SparkBatchJob
name: SparkBatchJob
fullName: azure.synapse.spark.models.SparkBatchJob
module: azure.synapse.spark.models
inheritances:
- msrest.serialization.Model
summary: 'SparkBatchJob.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkBatchJob(*, id: int, livy_info: Optional[azure.synapse.spark.models._models_py3.SparkBatchJobState]
    = None, name: Optional[str] = None, workspace_name: Optional[str] = None, spark_pool_name:
    Optional[str] = None, submitter_name: Optional[str] = None, submitter_id: Optional[str]
    = None, artifact_id: Optional[str] = None, job_type: Optional[Union[str, azure.synapse.spark.models._spark_client_enums.SparkJobType]]
    = None, result: Optional[Union[str, azure.synapse.spark.models._spark_client_enums.SparkBatchJobResultType]]
    = None, scheduler: Optional[azure.synapse.spark.models._models_py3.SparkScheduler]
    = None, plugin: Optional[azure.synapse.spark.models._models_py3.SparkServicePlugin]
    = None, errors: Optional[List[azure.synapse.spark.models._models_py3.SparkServiceError]]
    = None, tags: Optional[Dict[str, str]] = None, app_id: Optional[str] = None, app_info:
    Optional[Dict[str, str]] = None, state: Optional[Union[str, azure.synapse.spark.models._spark_client_enums.LivyStates]]
    = None, log_lines: Optional[List[str]] = None, **kwargs)'
  parameters:
  - name: livy_info
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkBatchJobState>
  - name: name
    description: The batch name.
    isRequired: true
    types:
    - <xref:str>
  - name: workspace_name
    description: The workspace name.
    isRequired: true
    types:
    - <xref:str>
  - name: spark_pool_name
    description: The Spark pool name.
    isRequired: true
    types:
    - <xref:str>
  - name: submitter_name
    description: The submitter name.
    isRequired: true
    types:
    - <xref:str>
  - name: submitter_id
    description: The submitter identifier.
    isRequired: true
    types:
    - <xref:str>
  - name: artifact_id
    description: The artifact identifier.
    isRequired: true
    types:
    - <xref:str>
  - name: job_type
    description: 'The job type. Possible values include: "SparkBatch", "SparkSession".'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.synapse.spark.models.SparkJobType>
  - name: result
    description: 'The Spark batch job result. Possible values include: "Uncertain",
      "Succeeded",

      "Failed", "Cancelled".'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.synapse.spark.models.SparkBatchJobResultType>
  - name: scheduler
    description: The scheduler information.
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkScheduler>
  - name: plugin
    description: The plugin information.
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkServicePlugin>
  - name: errors
    description: The error information.
    isRequired: true
    types:
    - <xref:list>[<xref:azure.synapse.spark.models.SparkServiceError>]
  - name: tags
    description: A set of tags. The tags.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: id
    description: Required. The session Id.
    isRequired: true
    types:
    - <xref:int>
  - name: app_id
    description: The application id of this session.
    isRequired: true
    types:
    - <xref:str>
  - name: app_info
    description: The detailed application info.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: state
    description: 'The batch state. Possible values include: "not_started", "starting",
      "idle",

      "busy", "shutting_down", "error", "dead", "killed", "success", "running", "recovering".'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.synapse.spark.models.LivyStates>
  - name: log_lines
    description: The log lines.
    isRequired: true
    types:
    - <xref:list>[<xref:str>]
