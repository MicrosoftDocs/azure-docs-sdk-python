### YamlMime:PythonClass
uid: azure.mgmt.datafactory.models.HDInsightSparkActivity
name: HDInsightSparkActivity
fullName: azure.mgmt.datafactory.models.HDInsightSparkActivity
module: azure.mgmt.datafactory.models
inheritances:
- azure.mgmt.datafactory.models._models_py3.ExecutionActivity
summary: 'HDInsight Spark activity.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'HDInsightSparkActivity(*, name: str, root_path: object, entry_file_path:
    object, additional_properties: typing.Union[typing.Dict[str, object], NoneType]
    = None, description: typing.Union[str, NoneType] = None, depends_on: typing.Union[typing.List[_ForwardRef(''ActivityDependency'')],
    NoneType] = None, user_properties: typing.Union[typing.List[_ForwardRef(''UserProperty'')],
    NoneType] = None, linked_service_name: typing.Union[_ForwardRef(''LinkedServiceReference''),
    NoneType] = None, policy: typing.Union[_ForwardRef(''ActivityPolicy''), NoneType]
    = None, arguments: typing.Union[typing.List[object], NoneType] = None, get_debug_info:
    typing.Union[str, _ForwardRef(''HDInsightActivityDebugInfoOption''), NoneType]
    = None, spark_job_linked_service: typing.Union[_ForwardRef(''LinkedServiceReference''),
    NoneType] = None, class_name: typing.Union[str, NoneType] = None, proxy_user:
    object = None, spark_config: typing.Union[typing.Dict[str, object], NoneType]
    = None, **kwargs)'
  parameters:
  - name: additional_properties
    description: 'Unmatched properties from the message are deserialized to this

      collection.'
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: name
    description: Required. Activity name.
    types:
    - <xref:str>
  - name: type
    description: Required. Type of activity.Constant filled by server.
    types:
    - <xref:str>
  - name: description
    description: Activity description.
    types:
    - <xref:str>
  - name: depends_on
    description: Activity depends on condition.
    types:
    - <xref:list>[<xref:azure.mgmt.datafactory.models.ActivityDependency>]
  - name: user_properties
    description: Activity user properties.
    types:
    - <xref:list>[<xref:azure.mgmt.datafactory.models.UserProperty>]
  - name: linked_service_name
    description: Linked service reference.
    types:
    - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
  - name: policy
    description: Activity policy.
    types:
    - <xref:azure.mgmt.datafactory.models.ActivityPolicy>
  - name: root_path
    description: "Required. The root path in 'sparkJobLinkedService' for all the job\u2019\
      s files.\nType: string (or Expression with resultType string)."
    types:
    - <xref:object>
  - name: entry_file_path
    description: 'Required. The relative path to the root folder of the code/package
      to

      be executed. Type: string (or Expression with resultType string).'
    types:
    - <xref:object>
  - name: arguments
    description: The user-specified arguments to HDInsightSparkActivity.
    types:
    - <xref:list>[<xref:object>]
  - name: get_debug_info
    description: 'Debug info option. Possible values include: "None", "Always", "Failure".'
    types:
    - <xref:str>
    - <xref:azure.mgmt.datafactory.models.HDInsightActivityDebugInfoOption>
  - name: spark_job_linked_service
    description: 'The storage linked service for uploading the entry file and

      dependencies, and for receiving logs.'
    types:
    - <xref:azure.mgmt.datafactory.models.LinkedServiceReference>
  - name: class_name
    description: The application's Java/Spark main class.
    types:
    - <xref:str>
  - name: proxy_user
    description: 'The user to impersonate that will execute the job. Type: string
      (or

      Expression with resultType string).'
    types:
    - <xref:object>
  - name: spark_config
    description: Spark configuration property.
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
