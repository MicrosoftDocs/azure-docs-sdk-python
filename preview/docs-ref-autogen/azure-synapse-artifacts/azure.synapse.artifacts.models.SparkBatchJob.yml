### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SparkBatchJob
name: SparkBatchJob
fullName: azure.synapse.artifacts.models.SparkBatchJob
module: azure.synapse.artifacts.models
inheritances:
- msrest.serialization.Model
summary: 'SparkBatchJob.

  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkBatchJob(*, id: int, livy_info: Optional[azure.synapse.artifacts.models._models_py3.SparkBatchJobState]
    = None, name: Optional[str] = None, workspace_name: Optional[str] = None, spark_pool_name:
    Optional[str] = None, submitter_name: Optional[str] = None, submitter_id: Optional[str]
    = None, artifact_id: Optional[str] = None, job_type: Optional[Union[str, azure.synapse.artifacts.models._artifacts_client_enums.SparkJobType]]
    = None, result: Optional[Union[str, azure.synapse.artifacts.models._artifacts_client_enums.SparkBatchJobResultType]]
    = None, scheduler: Optional[azure.synapse.artifacts.models._models_py3.SparkScheduler]
    = None, plugin: Optional[azure.synapse.artifacts.models._models_py3.SparkServicePlugin]
    = None, errors: Optional[List[azure.synapse.artifacts.models._models_py3.SparkServiceError]]
    = None, tags: Optional[Dict[str, str]] = None, app_id: Optional[str] = None, app_info:
    Optional[Dict[str, str]] = None, state: Optional[Union[str, azure.synapse.artifacts.models._artifacts_client_enums.LivyStates]]
    = None, log_lines: Optional[List[str]] = None, **kwargs)'
variables:
- name: livy_info
  types:
  - <xref:azure.synapse.artifacts.models.SparkBatchJobState>
- description: The batch name.
  name: name
  types:
  - <xref:str>
- description: The workspace name.
  name: workspace_name
  types:
  - <xref:str>
- description: The Spark pool name.
  name: spark_pool_name
  types:
  - <xref:str>
- description: The submitter name.
  name: submitter_name
  types:
  - <xref:str>
- description: The submitter identifier.
  name: submitter_id
  types:
  - <xref:str>
- description: The artifact identifier.
  name: artifact_id
  types:
  - <xref:str>
- description: 'The job type. Possible values include: "SparkBatch", "SparkSession".'
  name: job_type
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.SparkJobType>
- description: 'The Spark batch job result. Possible values include: "Uncertain",
    "Succeeded",

    "Failed", "Cancelled".'
  name: result
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.SparkBatchJobResultType>
- description: The scheduler information.
  name: scheduler
  types:
  - <xref:azure.synapse.artifacts.models.SparkScheduler>
- description: The plugin information.
  name: plugin
  types:
  - <xref:azure.synapse.artifacts.models.SparkServicePlugin>
- description: The error information.
  name: errors
  types:
  - <xref:list>[<xref:azure.synapse.artifacts.models.SparkServiceError>]
- description: A set of tags. The tags.
  name: tags
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
- description: Required. The session Id.
  name: id
  types:
  - <xref:int>
- description: The application id of this session.
  name: app_id
  types:
  - <xref:str>
- description: The detailed application info.
  name: app_info
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
- description: 'The batch state. Possible values include: "not_started", "starting",
    "idle",

    "busy", "shutting_down", "error", "dead", "killed", "success", "running", "recovering".'
  name: state
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.LivyStates>
- description: The log lines.
  name: log_lines
  types:
  - <xref:list>[<xref:str>]
