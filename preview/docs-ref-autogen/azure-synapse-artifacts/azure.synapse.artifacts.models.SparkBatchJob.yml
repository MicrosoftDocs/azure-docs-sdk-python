### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SparkBatchJob
name: SparkBatchJob
fullName: azure.synapse.artifacts.models.SparkBatchJob
module: azure.synapse.artifacts.models
inheritances:
- azure.synapse.artifacts._serialization.Model
summary: 'SparkBatchJob.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkBatchJob(*, id: int, livy_info: _models.SparkBatchJobState | None
    = None, name: str | None = None, workspace_name: str | None = None, spark_pool_name:
    str | None = None, submitter_name: str | None = None, submitter_id: str | None
    = None, artifact_id: str | None = None, job_type: str | _models.SparkJobType |
    None = None, result: str | _models.SparkBatchJobResultType | None = None, scheduler:
    _models.SparkScheduler | None = None, plugin: _models.SparkServicePlugin | None
    = None, errors: List[_models.SparkServiceError] | None = None, tags: Dict[str,
    str] | None = None, app_id: str | None = None, app_info: Dict[str, str] | None
    = None, state: str | _models.LivyStates | None = None, log_lines: List[str] |
    None = None, **kwargs: Any)'
  keywordOnlyParameters:
  - name: livy_info
    types:
    - <xref:azure.synapse.artifacts.models.SparkBatchJobState>
  - name: name
    description: The batch name.
    types:
    - <xref:str>
  - name: workspace_name
    description: The workspace name.
    types:
    - <xref:str>
  - name: spark_pool_name
    description: The Spark pool name.
    types:
    - <xref:str>
  - name: submitter_name
    description: The submitter name.
    types:
    - <xref:str>
  - name: submitter_id
    description: The submitter identifier.
    types:
    - <xref:str>
  - name: artifact_id
    description: The artifact identifier.
    types:
    - <xref:str>
  - name: job_type
    description: 'The job type. Known values are: "SparkBatch" and "SparkSession".'
    types:
    - <xref:str>
    - <xref:azure.synapse.artifacts.models.SparkJobType>
  - name: result
    description: 'The Spark batch job result. Known values are: "Uncertain", "Succeeded",

      "Failed", and "Cancelled".'
    types:
    - <xref:str>
    - <xref:azure.synapse.artifacts.models.SparkBatchJobResultType>
  - name: scheduler
    description: The scheduler information.
    types:
    - <xref:azure.synapse.artifacts.models.SparkScheduler>
  - name: plugin
    description: The plugin information.
    types:
    - <xref:azure.synapse.artifacts.models.SparkServicePlugin>
  - name: errors
    description: The error information.
    types:
    - <xref:list>[<xref:azure.synapse.artifacts.models.SparkServiceError>]
  - name: tags
    description: The tags.
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: id
    description: The session Id. Required.
    types:
    - <xref:int>
  - name: app_id
    description: The application id of this session.
    types:
    - <xref:str>
  - name: app_info
    description: The detailed application info.
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: state
    description: 'The batch state. Known values are: "not_started", "starting", "idle",
      "busy",

      "shutting_down", "error", "dead", "killed", "success", "running", and "recovering".'
    types:
    - <xref:str>
    - <xref:azure.synapse.artifacts.models.LivyStates>
  - name: log_lines
    description: The log lines.
    types:
    - <xref:list>[<xref:str>]
variables:
- name: livy_info
  types:
  - <xref:azure.synapse.artifacts.models.SparkBatchJobState>
- description: The batch name.
  name: name
  types:
  - <xref:str>
- description: The workspace name.
  name: workspace_name
  types:
  - <xref:str>
- description: The Spark pool name.
  name: spark_pool_name
  types:
  - <xref:str>
- description: The submitter name.
  name: submitter_name
  types:
  - <xref:str>
- description: The submitter identifier.
  name: submitter_id
  types:
  - <xref:str>
- description: The artifact identifier.
  name: artifact_id
  types:
  - <xref:str>
- description: 'The job type. Known values are: "SparkBatch" and "SparkSession".'
  name: job_type
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.SparkJobType>
- description: 'The Spark batch job result. Known values are: "Uncertain", "Succeeded",
    "Failed",

    and "Cancelled".'
  name: result
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.SparkBatchJobResultType>
- description: The scheduler information.
  name: scheduler
  types:
  - <xref:azure.synapse.artifacts.models.SparkScheduler>
- description: The plugin information.
  name: plugin
  types:
  - <xref:azure.synapse.artifacts.models.SparkServicePlugin>
- description: The error information.
  name: errors
  types:
  - <xref:list>[<xref:azure.synapse.artifacts.models.SparkServiceError>]
- description: The tags.
  name: tags
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
- description: The session Id. Required.
  name: id
  types:
  - <xref:int>
- description: The application id of this session.
  name: app_id
  types:
  - <xref:str>
- description: The detailed application info.
  name: app_info
  types:
  - <xref:dict>[<xref:str>, <xref:str>]
- description: 'The batch state. Known values are: "not_started", "starting", "idle",
    "busy",

    "shutting_down", "error", "dead", "killed", "success", "running", and "recovering".'
  name: state
  types:
  - <xref:str>
  - <xref:azure.synapse.artifacts.models.LivyStates>
- description: The log lines.
  name: log_lines
  types:
  - <xref:list>[<xref:str>]
methods:
- uid: azure.synapse.artifacts.models.SparkBatchJob.as_dict
  name: as_dict
  summary: "Return a dict that can be serialized using json.dump.\n\nAdvanced usage\
    \ might optionally use a callback as parameter:\n\nKey is the attribute name used\
    \ in Python. Attr_desc\nis a dict of metadata. Currently contains 'type' with\
    \ the\nmsrest type and 'key' with the RestAPI encoded key.\nValue is the current\
    \ value in this object.\n\nThe string returned will be used to serialize the key.\n\
    If the return type is a list, this is considered hierarchical\nresult dict.\n\n\
    See the three examples in this file:\n\n* attribute_transformer \n\n* full_restapi_key_transformer\
    \ \n\n* last_restapi_key_transformer \n\nIf you want XML serialization, you can\
    \ pass the kwargs is_xml=True."
  signature: 'as_dict(keep_readonly: bool = True, key_transformer: ~typing.Callable[[str,
    ~typing.Dict[str, ~typing.Any], ~typing.Any], ~typing.Any] = <function attribute_transformer>,
    **kwargs: ~typing.Any) -> MutableMapping[str, Any]'
  parameters:
  - name: key_transformer
    description: A key transformer function.
    types:
    - <xref:function>
  - name: keep_readonly
    defaultValue: 'True'
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.synapse.artifacts.models.SparkBatchJob.deserialize
  name: deserialize
  summary: Parse a str using the RestAPI syntax and return a model.
  signature: 'deserialize(data: Any, content_type: str | None = None) -> ModelType'
  parameters:
  - name: data
    description: A str using RestAPI structure. JSON by default.
    isRequired: true
    types:
    - <xref:str>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.synapse.artifacts.models.SparkBatchJob.enable_additional_properties_sending
  name: enable_additional_properties_sending
  signature: enable_additional_properties_sending() -> None
- uid: azure.synapse.artifacts.models.SparkBatchJob.from_dict
  name: from_dict
  summary: 'Parse a dict using given key extractor return a model.


    By default consider key

    extractors (rest_key_case_insensitive_extractor, attribute_key_case_insensitive_extractor

    and last_rest_key_case_insensitive_extractor)'
  signature: 'from_dict(data: Any, key_extractors: Callable[[str, Dict[str, Any],
    Any], Any] | None = None, content_type: str | None = None) -> ModelType'
  parameters:
  - name: data
    description: A dict using RestAPI structure
    isRequired: true
    types:
    - <xref:dict>
  - name: content_type
    description: JSON by default, set application/xml if XML.
    defaultValue: None
    types:
    - <xref:str>
  - name: key_extractors
    defaultValue: None
  return:
    description: An instance of this model
  exceptions:
  - type: DeserializationError if something went wrong
- uid: azure.synapse.artifacts.models.SparkBatchJob.is_xml_model
  name: is_xml_model
  signature: is_xml_model() -> bool
- uid: azure.synapse.artifacts.models.SparkBatchJob.serialize
  name: serialize
  summary: 'Return the JSON that would be sent to azure from this model.


    This is an alias to *as_dict(full_restapi_key_transformer, keep_readonly=False)*.


    If you want XML serialization, you can pass the kwargs is_xml=True.'
  signature: 'serialize(keep_readonly: bool = False, **kwargs: Any) -> MutableMapping[str,
    Any]'
  parameters:
  - name: keep_readonly
    description: If you want to serialize the readonly attributes
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
