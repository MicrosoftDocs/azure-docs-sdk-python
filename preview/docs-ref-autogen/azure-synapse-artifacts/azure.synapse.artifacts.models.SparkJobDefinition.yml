### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SparkJobDefinition
name: SparkJobDefinition
fullName: azure.synapse.artifacts.models.SparkJobDefinition
module: azure.synapse.artifacts.models
inheritances:
- msrest.serialization.Model
summary: 'Spark job definition.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkJobDefinition(*, target_big_data_pool: azure.synapse.artifacts.models._models_py3.BigDataPoolReference,
    job_properties: azure.synapse.artifacts.models._models_py3.SparkJobProperties,
    additional_properties: Optional[Dict[str, Any]] = None, description: Optional[str]
    = None, required_spark_version: Optional[str] = None, language: Optional[str]
    = None, folder: Optional[azure.synapse.artifacts.models._models_py3.SparkJobDefinitionFolder]
    = None, **kwargs)'
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:dict>[<xref:str>, <xref:any>]
- description: The description of the Spark job definition.
  name: description
  types:
  - <xref:str>
- description: Required. Big data pool reference.
  name: target_big_data_pool
  types:
  - <xref:azure.synapse.artifacts.models.BigDataPoolReference>
- description: The required Spark version of the application.
  name: required_spark_version
  types:
  - <xref:str>
- description: The language of the Spark application.
  name: language
  types:
  - <xref:str>
- description: Required. The properties of the Spark job.
  name: job_properties
  types:
  - <xref:azure.synapse.artifacts.models.SparkJobProperties>
- description: 'The folder that this Spark job definition is in. If not specified,
    this Spark job

    definition will appear at the root level.'
  name: folder
  types:
  - <xref:azure.synapse.artifacts.models.SparkJobDefinitionFolder>
