### YamlMime:PythonClass
uid: azure.synapse.artifacts.v2020_12_01.models.BigDataPoolResourceInfo
name: BigDataPoolResourceInfo
fullName: azure.synapse.artifacts.v2020_12_01.models.BigDataPoolResourceInfo
module: azure.synapse.artifacts.v2020_12_01.models
inheritances:
- azure.synapse.artifacts.v2020_12_01.models._models_py3.TrackedResource
summary: 'A Big Data pool.


  Variables are only populated by the server, and will be ignored when sending a request.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'BigDataPoolResourceInfo(*, location: str, tags: Optional[Dict[str, str]]
    = None, provisioning_state: Optional[str] = None, auto_scale: Optional[azure.synapse.artifacts.v2020_12_01.models._models_py3.AutoScaleProperties]
    = None, creation_date: Optional[datetime.datetime] = None, auto_pause: Optional[azure.synapse.artifacts.v2020_12_01.models._models_py3.AutoPauseProperties]
    = None, is_compute_isolation_enabled: Optional[bool] = None, session_level_packages_enabled:
    Optional[bool] = None, cache_size: Optional[int] = None, dynamic_executor_allocation:
    Optional[azure.synapse.artifacts.v2020_12_01.models._models_py3.DynamicExecutorAllocation]
    = None, spark_events_folder: Optional[str] = None, node_count: Optional[int] =
    None, library_requirements: Optional[azure.synapse.artifacts.v2020_12_01.models._models_py3.LibraryRequirements]
    = None, custom_libraries: Optional[List[azure.synapse.artifacts.v2020_12_01.models._models_py3.LibraryInfo]]
    = None, spark_config_properties: Optional[azure.synapse.artifacts.v2020_12_01.models._models_py3.LibraryRequirements]
    = None, spark_version: Optional[str] = None, default_spark_log_folder: Optional[str]
    = None, node_size: Optional[str] = None, node_size_family: Optional[str] = None,
    **kwargs)'
  parameters:
  - name: tags
    description: A set of tags. Resource tags.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:str>]
  - name: location
    description: Required. The geo-location where the resource lives.
    isRequired: true
    types:
    - <xref:str>
  - name: provisioning_state
    description: The state of the Big Data pool.
    isRequired: true
    types:
    - <xref:str>
  - name: auto_scale
    description: Auto-scaling properties.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.v2020_12_01.models.AutoScaleProperties>
  - name: creation_date
    description: The time when the Big Data pool was created.
    isRequired: true
    types:
    - <xref:datetime.datetime>
  - name: auto_pause
    description: Auto-pausing properties.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.v2020_12_01.models.AutoPauseProperties>
  - name: is_compute_isolation_enabled
    description: Whether compute isolation is required or not.
    isRequired: true
    types:
    - <xref:bool>
  - name: session_level_packages_enabled
    description: Whether session level packages enabled.
    isRequired: true
    types:
    - <xref:bool>
  - name: cache_size
    description: The cache size.
    isRequired: true
    types:
    - <xref:int>
  - name: dynamic_executor_allocation
    description: Dynamic Executor Allocation.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.v2020_12_01.models.DynamicExecutorAllocation>
  - name: spark_events_folder
    description: The Spark events folder.
    isRequired: true
    types:
    - <xref:str>
  - name: node_count
    description: The number of nodes in the Big Data pool.
    isRequired: true
    types:
    - <xref:int>
  - name: library_requirements
    description: Library version requirements.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.v2020_12_01.models.LibraryRequirements>
  - name: custom_libraries
    description: List of custom libraries/packages associated with the spark pool.
    isRequired: true
    types:
    - <xref:list>[<xref:azure.synapse.artifacts.v2020_12_01.models.LibraryInfo>]
  - name: spark_config_properties
    description: Spark configuration file to specify additional properties.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.v2020_12_01.models.LibraryRequirements>
  - name: spark_version
    description: The Apache Spark version.
    isRequired: true
    types:
    - <xref:str>
  - name: default_spark_log_folder
    description: The default folder where Spark logs will be written.
    isRequired: true
    types:
    - <xref:str>
  - name: node_size
    description: 'The level of compute power that each node in the Big Data pool has.
      Possible

      values include: "None", "Small", "Medium", "Large", "XLarge", "XXLarge", "XXXLarge".'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.synapse.artifacts.v2020_12_01.models.NodeSize>
  - name: node_size_family
    description: 'The kind of nodes that the Big Data pool provides. Possible values

      include: "None", "MemoryOptimized".'
    isRequired: true
    types:
    - <xref:str>
    - <xref:azure.synapse.artifacts.v2020_12_01.models.NodeSizeFamily>
variables:
- description: 'Fully qualified resource ID for the resource. Ex -

    /subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/{resourceProviderNamespace}/{resourceType}/{resourceName}.'
  name: id
  types:
  - <xref:str>
- description: The name of the resource.
  name: name
  types:
  - <xref:str>
- description: 'The type of the resource. E.g. "Microsoft.Compute/virtualMachines"
    or

    "Microsoft.Storage/storageAccounts".'
  name: type
  types:
  - <xref:str>
- description: The time when the Big Data pool was updated successfully.
  name: last_succeeded_timestamp
  types:
  - <xref:datetime.datetime>
