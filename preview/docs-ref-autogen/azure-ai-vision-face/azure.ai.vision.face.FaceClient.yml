### YamlMime:PythonClass
uid: azure.ai.vision.face.FaceClient
name: FaceClient
fullName: azure.ai.vision.face.FaceClient
module: azure.ai.vision.face
summary: FaceClient.
constructor:
  syntax: 'FaceClient(endpoint: str, credential: AzureKeyCredential | TokenCredential,
    **kwargs: Any)'
  parameters:
  - name: endpoint
    description: 'Supported Cognitive Services endpoints (protocol and hostname, for
      example:

      [https:/](https:/)/{resource-name}.cognitiveservices.azure.com). Required.'
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'Credential used to authenticate requests to the service. Is either
      a

      AzureKeyCredential type or a TokenCredential type. Required.'
    isRequired: true
    types:
    - <xref:azure.core.credentials.AzureKeyCredential>
    - <xref:azure.core.credentials.TokenCredential>
  keywordOnlyParameters:
  - name: api_version
    description: 'API Version. Default value is "v1.2-preview.1". Note that overriding
      this

      default value may result in unsupported behavior.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.Versions>
methods:
- uid: azure.ai.vision.face.FaceClient.close
  name: close
  signature: close() -> None
- uid: azure.ai.vision.face.FaceClient.detect
  name: detect
  summary: 'Detect human faces in an image, return face rectangles, and optionally
    with faceIds, landmarks,

    and attributes.


    Please refer to [https://learn.microsoft.com/rest/api/face/face-detection-operations/detect](https://learn.microsoft.com/rest/api/face/face-detection-operations/detect)
    for

    more details.'
  signature: 'detect(image_content: bytes, *, detection_model: str | FaceDetectionModel,
    recognition_model: str | FaceRecognitionModel, return_face_id: bool, return_face_attributes:
    List[str | FaceAttributeType] | None = None, return_face_landmarks: bool | None
    = None, return_recognition_model: bool | None = None, face_id_time_to_live: int
    | None = None, **kwargs: Any) -> List[FaceDetectionResult]'
  parameters:
  - name: image_content
    description: The input image binary. Required.
    isRequired: true
    types:
    - <xref:bytes>
  keywordOnlyParameters:
  - name: detection_model
    description: 'The ''detectionModel'' associated with the detected faceIds. Supported

      ''detectionModel'' values include ''detection_01'', ''detection_02'' and ''detection_03''.
      The default

      value is ''detection_01''. ''detection_03'' is recommended since its accuracy
      is improved on

      smaller faces (64x64 pixels) and rotated face orientations. Known values are:
      "detection_01",

      "detection_02", and "detection_03". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceDetectionModel>
  - name: recognition_model
    description: 'The ''recognitionModel'' associated with the detected faceIds.

      Supported ''recognitionModel'' values include ''recognition_01'', ''recognition_02'',

      ''recognition_03'' or ''recognition_04''. The default value is ''recognition_01''.
      ''recognition_04''

      is recommended since its accuracy is improved on faces wearing masks compared
      with

      ''recognition_03'', and its overall accuracy is improved compared with ''recognition_01''
      and

      ''recognition_02''. Known values are: "recognition_01", "recognition_02", "recognition_03",
      and

      "recognition_04". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceRecognitionModel>
  - name: return_face_id
    description: 'Return faceIds of the detected faces or not. The default value is

      true. Default value is None.'
    types:
    - <xref:bool>
  - name: return_face_attributes
    description: 'Analyze and return the one or more specified face attributes

      in the comma-separated string like ''returnFaceAttributes=headPose,glasses''.
      Face attribute

      analysis has additional computational and time cost. Default value is None.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.ai.vision.face.models.FaceAttributeType>]
  - name: return_face_landmarks
    description: 'Return face landmarks of the detected faces or not. The default

      value is false. Default value is None.'
    defaultValue: None
    types:
    - <xref:bool>
  - name: return_recognition_model
    description: 'Return ''recognitionModel'' or not. The default value is

      false. This is only applicable when returnFaceId = true. Default value is None.'
    defaultValue: None
    types:
    - <xref:bool>
  - name: face_id_time_to_live
    description: 'The number of seconds for the face ID being cached. Supported

      range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
      Default value

      is None.'
    defaultValue: None
    types:
    - <xref:int>
  return:
    description: list of FaceDetectionResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceDetectionResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.detect_from_url
  name: detect_from_url
  summary: 'Detect human faces in an image, return face rectangles, and optionally
    with faceIds, landmarks,

    and attributes.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-detection-operations/detect-from-url](https://learn.microsoft.com/rest/api/face/face-detection-operations/detect-from-url)
    for more

    details.'
  signature: 'detect_from_url(*, url: str, content_type: str = ''application/json'',
    detection_model: str | _models.FaceDetectionModel, recognition_model: str | _models.FaceRecognitionModel,
    return_face_id: bool, return_face_attributes: List[str | _models.FaceAttributeType]
    | None = None, return_face_landmarks: bool | None = None, return_recognition_model:
    bool | None = None, face_id_time_to_live: int | None = None, **kwargs: Any) ->
    List[_models.FaceDetectionResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: url
    description: URL of input image. Required.
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: detection_model
    description: 'The ''detectionModel'' associated with the detected faceIds. Supported

      ''detectionModel'' values include ''detection_01'', ''detection_02'' and ''detection_03''.
      The default

      value is ''detection_01''. ''detection_03'' is recommended since its accuracy
      is improved on

      smaller faces (64x64 pixels) and rotated face orientations. Known values are:
      "detection_01",

      "detection_02", and "detection_03". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceDetectionModel>
  - name: recognition_model
    description: 'The ''recognitionModel'' associated with the detected faceIds.

      Supported ''recognitionModel'' values include ''recognition_01'', ''recognition_02'',

      ''recognition_03'' or ''recognition_04''. The default value is ''recognition_01''.
      ''recognition_04''

      is recommended since its accuracy is improved on faces wearing masks compared
      with

      ''recognition_03'', and its overall accuracy is improved compared with ''recognition_01''
      and

      ''recognition_02''. Known values are: "recognition_01", "recognition_02", "recognition_03",
      and

      "recognition_04". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceRecognitionModel>
  - name: return_face_id
    description: 'Return faceIds of the detected faces or not. The default value is

      true. Default value is None.'
    types:
    - <xref:bool>
  - name: return_face_attributes
    description: 'Analyze and return the one or more specified face attributes

      in the comma-separated string like ''returnFaceAttributes=headPose,glasses''.
      Face attribute

      analysis has additional computational and time cost. Default value is None.'
    defaultValue: None
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.ai.vision.face.models.FaceAttributeType>]
  - name: return_face_landmarks
    description: 'Return face landmarks of the detected faces or not. The default

      value is false. Default value is None.'
    defaultValue: None
    types:
    - <xref:bool>
  - name: return_recognition_model
    description: 'Return ''recognitionModel'' or not. The default value is

      false. This is only applicable when returnFaceId = true. Default value is None.'
    defaultValue: None
    types:
    - <xref:bool>
  - name: face_id_time_to_live
    description: 'The number of seconds for the face ID being cached. Supported

      range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
      Default value

      is None.'
    defaultValue: None
    types:
    - <xref:int>
  return:
    description: list of FaceDetectionResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceDetectionResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.find_similar
  name: find_similar
  summary: 'Given query face''s faceId, to search the similar-looking faces from a
    faceId array. A faceId

    array contains the faces created by Detect.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar](https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar)
    for more

    details.'
  signature: 'find_similar(body: ~collections.abc.MutableMapping[str, ~typing.Any]
    | ~typing.IO[bytes] = <object object>, *, face_id: str = <object object>, face_ids:
    ~typing.List[str] = <object object>, max_num_of_candidates_returned: int | None
    = None, mode: str | ~azure.ai.vision.face.models._enums.FindSimilarMatchMode |
    None = None, **kwargs: ~typing.Any) -> List[FaceFindSimilarResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: 'faceId of the query face. User needs to call "Detect" first to get
      a valid

      faceId. Note that this faceId is not persisted and will expire 24 hours after
      the detection

      call. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: face_ids
    description: 'An array of candidate faceIds. All of them are created by "Detect"
      and the

      faceIds will expire 24 hours after the detection call. The number of faceIds
      is limited to

      1000. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:list>[<xref:str>]
  - name: max_num_of_candidates_returned
    description: 'The number of top similar faces returned. The valid

      range is [1, 1000]. Default value is 20. Default value is None.'
    defaultValue: None
    types:
    - <xref:int>
  - name: mode
    description: 'Similar face searching mode. It can be ''matchPerson'' or ''matchFace''.
      Default

      value is ''matchPerson''. Known values are: "matchPerson" and "matchFace". Default
      value is None.'
    defaultValue: None
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FindSimilarMatchMode>
  return:
    description: list of FaceFindSimilarResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceFindSimilarResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.find_similar_from_large_face_list
  name: find_similar_from_large_face_list
  summary: 'Given query face''s faceId, to search the similar-looking faces from a
    Large Face List. A

    ''largeFaceListId'' is created by Create Large Face List.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar-from-large-face-list](https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar-from-large-face-list)

    for more details.'
  signature: 'find_similar_from_large_face_list(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_id: str = <object
    object>, large_face_list_id: str = <object object>, max_num_of_candidates_returned:
    int | None = None, mode: str | ~azure.ai.vision.face.models._enums.FindSimilarMatchMode
    | None = None, **kwargs: ~typing.Any) -> List[FaceFindSimilarResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: 'faceId of the query face. User needs to call "Detect" first to get
      a valid

      faceId. Note that this faceId is not persisted and will expire 24 hours after
      the detection

      call. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: large_face_list_id
    description: 'An existing user-specified unique candidate Large Face List,

      created in "Create Large Face List". Large Face List contains a set of persistedFaceIds
      which

      are persisted and will never expire. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: max_num_of_candidates_returned
    description: 'The number of top similar faces returned. The valid

      range is [1, 1000]. Default value is 20. Default value is None.'
    defaultValue: None
    types:
    - <xref:int>
  - name: mode
    description: 'Similar face searching mode. It can be ''matchPerson'' or ''matchFace''.
      Default

      value is ''matchPerson''. Known values are: "matchPerson" and "matchFace". Default
      value is None.'
    defaultValue: None
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FindSimilarMatchMode>
  return:
    description: list of FaceFindSimilarResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceFindSimilarResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.group
  name: group
  summary: 'Divide candidate faces into groups based on face similarity.


    Please refer to [https://learn.microsoft.com/rest/api/face/face-recognition-operations/group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/group)
    for

    more details.'
  signature: 'group(body: ~collections.abc.MutableMapping[str, ~typing.Any] | ~typing.IO[bytes]
    = <object object>, *, face_ids: ~typing.List[str] = <object object>, **kwargs:
    ~typing.Any) -> FaceGroupingResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_ids
    description: 'Array of candidate faceIds created by "Detect". The maximum is 1000
      faces.

      Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:list>[<xref:str>]
  return:
    description: FaceGroupingResult. The FaceGroupingResult is compatible with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceGroupingResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.identify_from_large_person_group
  name: identify_from_large_person_group
  summary: '1-to-many identification to find the closest matches of the specific query
    person face from a

    Large Person Group.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/identify-from-person-group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/identify-from-person-group)

    for more details.'
  signature: 'identify_from_large_person_group(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_ids: ~typing.List[str]
    = <object object>, large_person_group_id: str = <object object>, max_num_of_candidates_returned:
    int | None = None, confidence_threshold: float | None = None, **kwargs: ~typing.Any)
    -> List[FaceIdentificationResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_ids
    description: 'Array of query faces faceIds, created by the "Detect". Each of the
      faces are

      identified independently. The valid number of faceIds is between [1, 10]. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:list>[<xref:str>]
  - name: large_person_group_id
    description: 'largePersonGroupId of the target Large Person Group, created by

      "Create Large Person Group". Parameter personGroupId and largePersonGroupId
      should not be

      provided at the same time. Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: max_num_of_candidates_returned
    description: 'The range of maxNumOfCandidatesReturned is between 1

      and 100. Default value is 10. Default value is None.'
    defaultValue: None
    types:
    - <xref:int>
  - name: confidence_threshold
    description: 'Customized identification confidence threshold, in the range of

      [0, 1]. Advanced user can tweak this value to override default internal threshold
      for better

      precision on their scenario data. Note there is no guarantee of this threshold
      value working on

      other data and after algorithm updates. Default value is None.'
    defaultValue: None
    types:
    - <xref:float>
  return:
    description: list of FaceIdentificationResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceIdentificationResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.send_request
  name: send_request
  summary: 'Runs the network request through the client''s chained policies.


    ```


    >>> from azure.core.rest import HttpRequest

    >>> request = HttpRequest("GET", "https://www.example.org/")

    <HttpRequest [GET], url: ''https://www.example.org/''>

    >>> response = client.send_request(request)

    <HttpResponse: 200 OK>

    ```


    For more information on this code flow, see [https://aka.ms/azsdk/dpcodegen/python/send_request](https://aka.ms/azsdk/dpcodegen/python/send_request)'
  signature: 'send_request(request: HttpRequest, *, stream: bool = False, **kwargs:
    Any) -> HttpResponse'
  parameters:
  - name: request
    description: The network request you want to make. Required.
    isRequired: true
    types:
    - <xref:azure.core.rest.HttpRequest>
  keywordOnlyParameters:
  - name: stream
    description: Whether the response payload will be streamed. Defaults to False.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: The response of your network call. Does not do error handling on
      your response.
    types:
    - <xref:azure.core.rest.HttpResponse>
- uid: azure.ai.vision.face.FaceClient.verify_face_to_face
  name: verify_face_to_face
  summary: 'Verify whether two faces belong to a same person.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-face-to-face](https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-face-to-face)
    for

    more details.'
  signature: 'verify_face_to_face(body: ~collections.abc.MutableMapping[str, ~typing.Any]
    | ~typing.IO[bytes] = <object object>, *, face_id1: str = <object object>, face_id2:
    str = <object object>, **kwargs: ~typing.Any) -> FaceVerificationResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id1
    description: The faceId of one face, come from "Detect". Required.
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: face_id2
    description: The faceId of another face, come from "Detect". Required.
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  return:
    description: FaceVerificationResult. The FaceVerificationResult is compatible
      with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceVerificationResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.FaceClient.verify_from_large_person_group
  name: verify_from_large_person_group
  summary: 'Verify whether a face belongs to a person in a Large Person Group.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-from-large-person-group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-from-large-person-group)

    for more details.'
  signature: 'verify_from_large_person_group(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_id: str = <object
    object>, large_person_group_id: str = <object object>, person_id: str = <object
    object>, **kwargs: ~typing.Any) -> FaceVerificationResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: The faceId of the face, come from "Detect". Required.
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: large_person_group_id
    description: 'Using existing largePersonGroupId and personId for fast loading

      a specified person. largePersonGroupId is created in "Create Large Person Group".
      Required.'
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  - name: person_id
    description: Specify a certain person in Large Person Group. Required.
    defaultValue: <object object at 0x000001E2A0D76610>
    types:
    - <xref:str>
  return:
    description: FaceVerificationResult. The FaceVerificationResult is compatible
      with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceVerificationResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
