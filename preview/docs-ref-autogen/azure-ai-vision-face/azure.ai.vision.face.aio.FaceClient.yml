### YamlMime:PythonClass
uid: azure.ai.vision.face.aio.FaceClient
name: FaceClient
fullName: azure.ai.vision.face.aio.FaceClient
module: azure.ai.vision.face.aio
summary: FaceClient.
constructor:
  syntax: 'FaceClient(endpoint: str, credential: AzureKeyCredential | AsyncTokenCredential,
    **kwargs: Any)'
  parameters:
  - name: endpoint
    description: 'Supported Cognitive Services endpoints (protocol and hostname, for
      example:

      [https:/](https:/)/{resource-name}.cognitiveservices.azure.com). Required.'
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: 'Credential used to authenticate requests to the service. Is either
      a

      AzureKeyCredential type or a TokenCredential type. Required.'
    isRequired: true
    types:
    - <xref:azure.core.credentials.AzureKeyCredential>
    - <xref:azure.core.credentials_async.AsyncTokenCredential>
  keywordOnlyParameters:
  - name: api_version
    description: 'API Version. Default value is "v1.2-preview.1". Note that overriding
      this

      default value may result in unsupported behavior.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.Versions>
methods:
- uid: azure.ai.vision.face.aio.FaceClient.close
  name: close
  signature: async close() -> None
- uid: azure.ai.vision.face.aio.FaceClient.detect
  name: detect
  summary: 'Detect human faces in an image, return face rectangles, and optionally
    with faceIds, landmarks,

    and attributes.


    Please refer to [https://learn.microsoft.com/rest/api/face/face-detection-operations/detect](https://learn.microsoft.com/rest/api/face/face-detection-operations/detect)
    for

    more details.'
  signature: 'async detect(image_content: bytes, *, detection_model: str | FaceDetectionModel,
    recognition_model: str | FaceRecognitionModel, return_face_id: bool, return_face_attributes:
    List[str | FaceAttributeType] | None = None, return_face_landmarks: bool | None
    = None, return_recognition_model: bool | None = None, face_id_time_to_live: int
    | None = None, **kwargs: Any) -> List[FaceDetectionResult]'
  parameters:
  - name: image_content
    description: The input image binary. Required.
    isRequired: true
    types:
    - <xref:bytes>
  keywordOnlyParameters:
  - name: detection_model
    description: 'The ''detectionModel'' associated with the detected faceIds. Supported

      ''detectionModel'' values include ''detection_01'', ''detection_02'' and ''detection_03''.
      The default

      value is ''detection_01''. ''detection_03'' is recommended since its accuracy
      is improved on

      smaller faces (64x64 pixels) and rotated face orientations. Known values are:
      "detection_01",

      "detection_02", and "detection_03". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceDetectionModel>
  - name: recognition_model
    description: 'The ''recognitionModel'' associated with the detected faceIds.

      Supported ''recognitionModel'' values include ''recognition_01'', ''recognition_02'',

      ''recognition_03'' or ''recognition_04''. The default value is ''recognition_01''.
      ''recognition_04''

      is recommended since its accuracy is improved on faces wearing masks compared
      with

      ''recognition_03'', and its overall accuracy is improved compared with ''recognition_01''
      and

      ''recognition_02''. Known values are: "recognition_01", "recognition_02", "recognition_03",
      and

      "recognition_04". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceRecognitionModel>
  - name: return_face_id
    description: 'Return faceIds of the detected faces or not. The default value is

      true. Default value is None.'
    types:
    - <xref:bool>
  - name: return_face_attributes
    description: 'Analyze and return the one or more specified face attributes

      in the comma-separated string like ''returnFaceAttributes=headPose,glasses''.
      Face attribute

      analysis has additional computational and time cost. Default value is None.'
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.ai.vision.face.models.FaceAttributeType>]
  - name: return_face_landmarks
    description: 'Return face landmarks of the detected faces or not. The default

      value is false. Default value is None.'
    types:
    - <xref:bool>
  - name: return_recognition_model
    description: 'Return ''recognitionModel'' or not. The default value is

      false. This is only applicable when returnFaceId = true. Default value is None.'
    types:
    - <xref:bool>
  - name: face_id_time_to_live
    description: 'The number of seconds for the face ID being cached. Supported

      range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
      Default value

      is None.'
    types:
    - <xref:int>
  return:
    description: list of FaceDetectionResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceDetectionResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.detect_from_url
  name: detect_from_url
  summary: 'Detect human faces in an image, return face rectangles, and optionally
    with faceIds, landmarks,

    and attributes.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-detection-operations/detect-from-url](https://learn.microsoft.com/rest/api/face/face-detection-operations/detect-from-url)
    for more

    details.'
  signature: 'async detect_from_url(*, url: str, content_type: str = ''application/json'',
    detection_model: str | _models.FaceDetectionModel, recognition_model: str | _models.FaceRecognitionModel,
    return_face_id: bool, return_face_attributes: List[str | _models.FaceAttributeType]
    | None = None, return_face_landmarks: bool | None = None, return_recognition_model:
    bool | None = None, face_id_time_to_live: int | None = None, **kwargs: Any) ->
    List[_models.FaceDetectionResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: url
    description: URL of input image. Required.
    types:
    - <xref:str>
  - name: detection_model
    description: 'The ''detectionModel'' associated with the detected faceIds. Supported

      ''detectionModel'' values include ''detection_01'', ''detection_02'' and ''detection_03''.
      The default

      value is ''detection_01''. ''detection_03'' is recommended since its accuracy
      is improved on

      smaller faces (64x64 pixels) and rotated face orientations. Known values are:
      "detection_01",

      "detection_02", and "detection_03". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceDetectionModel>
  - name: recognition_model
    description: 'The ''recognitionModel'' associated with the detected faceIds.

      Supported ''recognitionModel'' values include ''recognition_01'', ''recognition_02'',

      ''recognition_03'' or ''recognition_04''. The default value is ''recognition_01''.
      ''recognition_04''

      is recommended since its accuracy is improved on faces wearing masks compared
      with

      ''recognition_03'', and its overall accuracy is improved compared with ''recognition_01''
      and

      ''recognition_02''. Known values are: "recognition_01", "recognition_02", "recognition_03",
      and

      "recognition_04". Default value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FaceRecognitionModel>
  - name: return_face_id
    description: 'Return faceIds of the detected faces or not. The default value is

      true. Default value is None.'
    types:
    - <xref:bool>
  - name: return_face_attributes
    description: 'Analyze and return the one or more specified face attributes

      in the comma-separated string like ''returnFaceAttributes=headPose,glasses''.
      Face attribute

      analysis has additional computational and time cost. Default value is None.'
    types:
    - <xref:list>[<xref:str>
    - <xref:azure.ai.vision.face.models.FaceAttributeType>]
  - name: return_face_landmarks
    description: 'Return face landmarks of the detected faces or not. The default

      value is false. Default value is None.'
    types:
    - <xref:bool>
  - name: return_recognition_model
    description: 'Return ''recognitionModel'' or not. The default value is

      false. This is only applicable when returnFaceId = true. Default value is None.'
    types:
    - <xref:bool>
  - name: face_id_time_to_live
    description: 'The number of seconds for the face ID being cached. Supported

      range from 60 seconds up to 86400 seconds. The default value is 86400 (24 hours).
      Default value

      is None.'
    types:
    - <xref:int>
  return:
    description: list of FaceDetectionResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceDetectionResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.find_similar
  name: find_similar
  summary: 'Given query face''s faceId, to search the similar-looking faces from a
    faceId array. A faceId

    array contains the faces created by Detect.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar](https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar)
    for more

    details.'
  signature: 'async find_similar(body: ~collections.abc.MutableMapping[str, ~typing.Any]
    | ~typing.IO[bytes] = <object object>, *, face_id: str = <object object>, face_ids:
    ~typing.List[str] = <object object>, max_num_of_candidates_returned: int | None
    = None, mode: str | ~azure.ai.vision.face.models._enums.FindSimilarMatchMode |
    None = None, **kwargs: ~typing.Any) -> List[FaceFindSimilarResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: 'faceId of the query face. User needs to call "Detect" first to get
      a valid

      faceId. Note that this faceId is not persisted and will expire 24 hours after
      the detection

      call. Required.'
    types:
    - <xref:str>
  - name: face_ids
    description: 'An array of candidate faceIds. All of them are created by "Detect"
      and the

      faceIds will expire 24 hours after the detection call. The number of faceIds
      is limited to

      1000. Required.'
    types:
    - <xref:list>[<xref:str>]
  - name: max_num_of_candidates_returned
    description: 'The number of top similar faces returned. The valid

      range is [1, 1000]. Default value is 20. Default value is None.'
    types:
    - <xref:int>
  - name: mode
    description: 'Similar face searching mode. It can be ''matchPerson'' or ''matchFace''.
      Default

      value is ''matchPerson''. Known values are: "matchPerson" and "matchFace". Default
      value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FindSimilarMatchMode>
  return:
    description: list of FaceFindSimilarResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceFindSimilarResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.find_similar_from_large_face_list
  name: find_similar_from_large_face_list
  summary: 'Given query face''s faceId, to search the similar-looking faces from a
    Large Face List. A

    ''largeFaceListId'' is created by Create Large Face List.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar-from-large-face-list](https://learn.microsoft.com/rest/api/face/face-recognition-operations/find-similar-from-large-face-list)

    for more details.'
  signature: 'async find_similar_from_large_face_list(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_id: str = <object
    object>, large_face_list_id: str = <object object>, max_num_of_candidates_returned:
    int | None = None, mode: str | ~azure.ai.vision.face.models._enums.FindSimilarMatchMode
    | None = None, **kwargs: ~typing.Any) -> List[FaceFindSimilarResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: 'faceId of the query face. User needs to call "Detect" first to get
      a valid

      faceId. Note that this faceId is not persisted and will expire 24 hours after
      the detection

      call. Required.'
    types:
    - <xref:str>
  - name: large_face_list_id
    description: 'An existing user-specified unique candidate Large Face List,

      created in "Create Large Face List". Large Face List contains a set of persistedFaceIds
      which

      are persisted and will never expire. Required.'
    types:
    - <xref:str>
  - name: max_num_of_candidates_returned
    description: 'The number of top similar faces returned. The valid

      range is [1, 1000]. Default value is 20. Default value is None.'
    types:
    - <xref:int>
  - name: mode
    description: 'Similar face searching mode. It can be ''matchPerson'' or ''matchFace''.
      Default

      value is ''matchPerson''. Known values are: "matchPerson" and "matchFace". Default
      value is None.'
    types:
    - <xref:str>
    - <xref:azure.ai.vision.face.models.FindSimilarMatchMode>
  return:
    description: list of FaceFindSimilarResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceFindSimilarResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.group
  name: group
  summary: 'Divide candidate faces into groups based on face similarity.


    Please refer to [https://learn.microsoft.com/rest/api/face/face-recognition-operations/group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/group)
    for

    more details.'
  signature: 'async group(body: ~collections.abc.MutableMapping[str, ~typing.Any]
    | ~typing.IO[bytes] = <object object>, *, face_ids: ~typing.List[str] = <object
    object>, **kwargs: ~typing.Any) -> FaceGroupingResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_ids
    description: 'Array of candidate faceIds created by "Detect". The maximum is 1000
      faces.

      Required.'
    types:
    - <xref:list>[<xref:str>]
  return:
    description: FaceGroupingResult. The FaceGroupingResult is compatible with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceGroupingResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.identify_from_large_person_group
  name: identify_from_large_person_group
  summary: '1-to-many identification to find the closest matches of the specific query
    person face from a

    Large Person Group.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/identify-from-person-group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/identify-from-person-group)

    for more details.'
  signature: 'async identify_from_large_person_group(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_ids: ~typing.List[str]
    = <object object>, large_person_group_id: str = <object object>, max_num_of_candidates_returned:
    int | None = None, confidence_threshold: float | None = None, **kwargs: ~typing.Any)
    -> List[FaceIdentificationResult]'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_ids
    description: 'Array of query faces faceIds, created by the "Detect". Each of the
      faces are

      identified independently. The valid number of faceIds is between [1, 10]. Required.'
    types:
    - <xref:list>[<xref:str>]
  - name: large_person_group_id
    description: 'largePersonGroupId of the target Large Person Group, created by

      "Create Large Person Group". Parameter personGroupId and largePersonGroupId
      should not be

      provided at the same time. Required.'
    types:
    - <xref:str>
  - name: max_num_of_candidates_returned
    description: 'The range of maxNumOfCandidatesReturned is between 1

      and 100. Default value is 10. Default value is None.'
    types:
    - <xref:int>
  - name: confidence_threshold
    description: 'Customized identification confidence threshold, in the range of

      [0, 1]. Advanced user can tweak this value to override default internal threshold
      for better

      precision on their scenario data. Note there is no guarantee of this threshold
      value working on

      other data and after algorithm updates. Default value is None.'
    types:
    - <xref:float>
  return:
    description: list of FaceIdentificationResult
    types:
    - <xref:list>[<xref:azure.ai.vision.face.models.FaceIdentificationResult>]
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.send_request
  name: send_request
  summary: 'Runs the network request through the client''s chained policies.


    ```


    >>> from azure.core.rest import HttpRequest

    >>> request = HttpRequest("GET", "https://www.example.org/")

    <HttpRequest [GET], url: ''https://www.example.org/''>

    >>> response = await client.send_request(request)

    <AsyncHttpResponse: 200 OK>

    ```


    For more information on this code flow, see [https://aka.ms/azsdk/dpcodegen/python/send_request](https://aka.ms/azsdk/dpcodegen/python/send_request)'
  signature: 'send_request(request: HttpRequest, *, stream: bool = False, **kwargs:
    Any) -> Awaitable[AsyncHttpResponse]'
  parameters:
  - name: request
    description: The network request you want to make. Required.
    isRequired: true
    types:
    - <xref:azure.core.rest.HttpRequest>
  keywordOnlyParameters:
  - name: stream
    description: Whether the response payload will be streamed. Defaults to False.
    types:
    - <xref:bool>
  return:
    description: The response of your network call. Does not do error handling on
      your response.
    types:
    - <xref:azure.core.rest.AsyncHttpResponse>
- uid: azure.ai.vision.face.aio.FaceClient.verify_face_to_face
  name: verify_face_to_face
  summary: 'Verify whether two faces belong to a same person.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-face-to-face](https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-face-to-face)
    for

    more details.'
  signature: 'async verify_face_to_face(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_id1: str = <object
    object>, face_id2: str = <object object>, **kwargs: ~typing.Any) -> FaceVerificationResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id1
    description: The faceId of one face, come from "Detect". Required.
    types:
    - <xref:str>
  - name: face_id2
    description: The faceId of another face, come from "Detect". Required.
    types:
    - <xref:str>
  return:
    description: FaceVerificationResult. The FaceVerificationResult is compatible
      with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceVerificationResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.face.aio.FaceClient.verify_from_large_person_group
  name: verify_from_large_person_group
  summary: 'Verify whether a face belongs to a person in a Large Person Group.


    Please refer to

    [https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-from-large-person-group](https://learn.microsoft.com/rest/api/face/face-recognition-operations/verify-from-large-person-group)

    for more details.'
  signature: 'async verify_from_large_person_group(body: ~collections.abc.MutableMapping[str,
    ~typing.Any] | ~typing.IO[bytes] = <object object>, *, face_id: str = <object
    object>, large_person_group_id: str = <object object>, person_id: str = <object
    object>, **kwargs: ~typing.Any) -> FaceVerificationResult'
  parameters:
  - name: body
    description: Is either a JSON type or a IO[bytes] type. Required.
    isRequired: true
    types:
    - <xref:JSON>
    - <xref:typing.IO>[<xref:bytes>]
  keywordOnlyParameters:
  - name: face_id
    description: The faceId of the face, come from "Detect". Required.
    types:
    - <xref:str>
  - name: large_person_group_id
    description: 'Using existing largePersonGroupId and personId for fast loading

      a specified person. largePersonGroupId is created in "Create Large Person Group".
      Required.'
    types:
    - <xref:str>
  - name: person_id
    description: Specify a certain person in Large Person Group. Required.
    types:
    - <xref:str>
  return:
    description: FaceVerificationResult. The FaceVerificationResult is compatible
      with MutableMapping
    types:
    - <xref:azure.ai.vision.face.models.FaceVerificationResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
