### YamlMime:PythonClass
uid: azure.ai.agentserver.core.models.projects.Response
name: Response
fullName: azure.ai.agentserver.core.models.projects.Response
module: azure.ai.agentserver.core.models.projects
summary: "Response.\n\n   ivar metadata:\n      Set of 16 key-value pairs that can\
  \ be attached to an object. This can be\n\nuseful for storing additional information\
  \ about the object in a structured\nformat, and querying for objects via API or\
  \ the dashboard.\nKeys are strings with a maximum length of 64 characters. Values\
  \ are strings\nwith a maximum length of 512 characters. Required.\n\n   vartype\
  \ metadata:\n      dict[str, str]\n\n   ivar temperature:\n      What sampling temperature\
  \ to use, between 0 and 2. Higher values like 0.8\n\n   will make the output more\
  \ random, while lower values like 0.2 will make it more focused and\n   deterministic.\n\
  \nWe generally recommend altering this or `top_p` but not both. Required.\n   vartype\
  \ temperature:\n      float\n\n   ivar top_p:\n      An alternative to sampling\
  \ with temperature, called nucleus sampling,\n\nwhere the model considers the results\
  \ of the tokens with top_p probability\nmass. So 0.1 means only the tokens comprising\
  \ the top 10% probability mass\nare considered.\nWe generally recommend altering\
  \ this or `temperature` but not both. Required.\n\n   vartype top_p:\n      float\n\
  \n   ivar user:\n      A unique identifier representing your end-user, which can\
  \ help OpenAI to monitor\n\n   and detect abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids).\
  \ Required.\n   :vartype user: str\n   :ivar service_tier: Note: service_tier is\
  \ not applicable to Azure OpenAI. Known values are:\n   \"auto\", \"default\", \"\
  flex\", \"scale\", and \"priority\".\n   :vartype service_tier: str or ~azure.ai.projects.models.ServiceTier\n\
  \   :ivar top_logprobs: An integer between 0 and 20 specifying the number of most\
  \ likely tokens to\n   return at each token position, each with an associated log\
  \ probability.\n   :vartype top_logprobs: int\n   :ivar previous_response_id: The\
  \ unique ID of the previous response to the model. Use this to\n\ncreate multi-turn\
  \ conversations. Learn more about\n[conversation state](/docs/guides/conversation-state).\n\
  \n   vartype previous_response_id:\n      str\n\n   ivar model:\n      The model\
  \ deployment to use for the creation of this response.\n\n   vartype model:\n  \
  \    str\n\n   ivar reasoning:\n   vartype reasoning:\n      ~azure.ai.projects.models.Reasoning\n\
  \n   ivar background:\n      Whether to run the model response in the background.\n\
  \n[Learn more](/docs/guides/background).\n   vartype background:\n      bool\n\n\
  \   ivar max_output_tokens:\n      An upper bound for the number of tokens that\
  \ can be generated for a\n\n   response, including visible output tokens and [reasoning\
  \ tokens](/docs/guides/reasoning).\n   :vartype max_output_tokens: int\n   :ivar\
  \ max_tool_calls: The maximum number of total calls to built-in tools that can be\
  \ processed\n   in a response. This maximum number applies across all built-in tool\
  \ calls, not per individual\n   tool. Any further attempts to call a tool by the\
  \ model will be ignored.\n   :vartype max_tool_calls: int\n   :ivar text: Configuration\
  \ options for a text response from the model. Can be plain\n\ntext or structured\
  \ JSON data. Learn more:\n   * [Text inputs and outputs](/docs/guides/text) \n\n\
  \   * [Structured Outputs](/docs/guides/structured-outputs). \n\n   vartype text:\n\
  \      ~azure.ai.projects.models.ResponseText\n\n   ivar tools:\n      An array\
  \ of tools the model may call while generating a response. You\n\ncan specify which\
  \ tool to use by setting the `tool_choice` parameter.\nThe two categories of tools\
  \ you can provide the model are:\n\n   * **Built-in tools**: Tools that are provided\
  \ by OpenAI that extend the \n\nmodel's capabilities, like [web search](/docs/guides/tools-web-search)\n\
  or [file search](/docs/guides/tools-file-search). Learn more about\n[built-in tools](/docs/guides/tools).\n\
  \n   * **Function calls (custom tools)**: Functions that are defined by you, \n\n\
  enabling the model to call your own code. Learn more about\n[function calling](/docs/guides/function-calling).\n\
  \n   vartype tools:\n      list[~azure.ai.projects.models.Tool]\n\n   ivar tool_choice:\n\
  \      How the model should select which tool (or tools) to use when generating\n\
  \na response. See the `tools` parameter to see how to specify which tools\nthe model\
  \ can call. Is either a Union[str, \"_models.ToolChoiceOptions\"] type or a\n\n\
  \   ToolChoiceObject type.\n   :vartype tool_choice: str or ~azure.ai.projects.models.ToolChoiceOptions\
  \ or\n   ~azure.ai.projects.models.ToolChoiceObject\n   :ivar prompt:\n   :vartype\
  \ prompt: ~azure.ai.projects.models.Prompt\n   :ivar truncation: The truncation\
  \ strategy to use for the model response.\n   * *auto*: If the context of this response\
  \ and previous ones exceeds\n\nthe model's context window size, the model will truncate\
  \ the\nresponse to fit the context window by dropping input items in the\nmiddle\
  \ of the conversation.\n\n   * *disabled* (default): If a model response will exceed\
  \ the context window \n\nsize for a model, the request will fail with a 400 error.\
  \ Is either a Literal[\"auto\"] type or a\n   Literal[\"disabled\"] type.\n   :vartype\
  \ truncation: str or str\n   :ivar id: Unique identifier for this Response. Required.\n\
  \   :vartype id: str\n   :ivar object: The object type of this resource - always\
  \ set to `response`. Required. Default\n   value is \"response\".\n   :vartype object:\
  \ str\n   :ivar status: The status of the response generation. One of `completed`,\
  \ `failed`,\n\n`in_progress`, `cancelled`, `queued`, or `incomplete`. Is one of\
  \ the following types:\n   Literal[\"completed\"], Literal[\"failed\"], Literal[\"\
  in_progress\"], Literal[\"cancelled\"],\n   Literal[\"queued\"], Literal[\"incomplete\"\
  ]\n   :vartype status: str or str or str or str or str or str\n   :ivar created_at:\
  \ Unix timestamp (in seconds) of when this Response was created. Required.\n   :vartype\
  \ created_at: ~datetime.datetime\n   :ivar error: Required.\n   :vartype error:\
  \ ~azure.ai.projects.models.ResponseError\n   :ivar incomplete_details: Details\
  \ about why the response is incomplete. Required.\n   :vartype incomplete_details:\
  \ ~azure.ai.projects.models.ResponseIncompleteDetails1\n   :ivar output: An array\
  \ of content items generated by the model.\n   * The length and order of items in\
  \ the *output* array is dependent\n\non the model's response.\n   * Rather than\
  \ accessing the first item in the *output* array and \n\nassuming it's an *assistant*\
  \ message with the content generated by\nthe model, you might consider using the\
  \ *output_text* property where\nsupported in SDKs. Required.\n\n   vartype output:\n\
  \      list[~azure.ai.projects.models.ItemResource]\n\n   ivar instructions:\n \
  \     A system (or developer) message inserted into the model's context.\n\nWhen\
  \ using along with `previous_response_id`, the instructions from a previous\nresponse\
  \ will not be carried over to the next response. This makes it simple\nto swap out\
  \ system (or developer) messages in new responses. Required. Is either a str type\
  \ or\n\n   a [ItemParam] type.\n   :vartype instructions: str or list[~azure.ai.projects.models.ItemParam]\n\
  \   :ivar output_text: SDK-only convenience property that contains the aggregated\
  \ text output\n\nfrom all `output_text` items in the `output` array, if any are\
  \ present.\nSupported in the Python and JavaScript SDKs.\n\n   vartype output_text:\n\
  \      str\n\n   ivar usage:\n   vartype usage:\n      ~azure.ai.projects.models.ResponseUsage\n\
  \n   ivar parallel_tool_calls:\n      Whether to allow the model to run tool calls\
  \ in parallel. Required.\n\n   vartype parallel_tool_calls:\n      bool\n\n   ivar\
  \ conversation:\n      Required.\n\n   vartype conversation:\n      ~azure.ai.projects.models.ResponseConversation1\n\
  \n   ivar agent:\n      The agent used for this response.\n\n   vartype agent:\n\
  \      ~azure.ai.projects.models.AgentId\n\n   ivar structured_inputs:\n      The\
  \ structured inputs to the response that can participate in prompt\n\n   template\
  \ substitution or tool argument bindings.\n   :vartype structured_inputs: dict[str,\
  \ any]"
constructor:
  syntax: 'Response(*args: Any, **kwargs: Any)'
methods:
- uid: azure.ai.agentserver.core.models.projects.Response.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    defaultValue: 'False'
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.agentserver.core.models.projects.Response.clear
  name: clear
  summary: Remove all items from D.
  signature: clear() -> None
- uid: azure.ai.agentserver.core.models.projects.Response.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.agentserver.core.models.projects.Response.get
  name: get
  summary: 'Get the value for key if key is in the dictionary, else default.

    :param str key: The key to look up.

    :param any default: The value to return if key is not in the dictionary. Defaults
    to None

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.agentserver.core.models.projects.Response.items
  name: items
  signature: items() -> ItemsView[str, Any]
  return:
    description: set-like object providing a view on D's items
    types:
    - <xref:typing.ItemsView>
- uid: azure.ai.agentserver.core.models.projects.Response.keys
  name: keys
  signature: keys() -> KeysView[str]
  return:
    description: a set-like object providing a view on D's keys
    types:
    - <xref:typing.KeysView>
- uid: azure.ai.agentserver.core.models.projects.Response.pop
  name: pop
  summary: 'Removes specified key and return the corresponding value.

    :param str key: The key to pop.

    :param any default: The value to return if key is not in the dictionary

    :returns: The value corresponding to the key.

    :rtype: any

    :raises KeyError: If key is not found and default is not given.'
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.agentserver.core.models.projects.Response.popitem
  name: popitem
  summary: 'Removes and returns some (key, value) pair

    :returns: The (key, value) pair.

    :rtype: tuple

    :raises KeyError: if D is empty.'
  signature: popitem() -> tuple[str, Any]
- uid: azure.ai.agentserver.core.models.projects.Response.setdefault
  name: setdefault
  summary: 'Same as calling D.get(k, d), and setting D[k]=d if k not found

    :param str key: The key to look up.

    :param any default: The value to set if key is not in the dictionary

    :returns: D[k] if k in D, else d.

    :rtype: any'
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.agentserver.core.models.projects.Response.update
  name: update
  summary: 'Updates D from mapping/iterable E and F.

    :param any args: Either a mapping object or an iterable of key-value pairs.'
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.agentserver.core.models.projects.Response.values
  name: values
  signature: values() -> ValuesView[Any]
  return:
    description: an object providing a view on D's values
    types:
    - <xref:typing.ValuesView>
attributes:
- uid: azure.ai.agentserver.core.models.projects.Response.agent
  name: agent
  summary: The agent used for this response.
  signature: 'agent: _models.AgentId | None'
- uid: azure.ai.agentserver.core.models.projects.Response.background
  name: background
  summary: 'Whether to run the model response in the background.

    [Learn more](/docs/guides/background).'
  signature: 'background: bool | None'
- uid: azure.ai.agentserver.core.models.projects.Response.conversation
  name: conversation
  summary: Required.
  signature: 'conversation: _models.ResponseConversation1'
- uid: azure.ai.agentserver.core.models.projects.Response.created_at
  name: created_at
  summary: Unix timestamp (in seconds) of when this Response was created. Required.
  signature: 'created_at: datetime'
- uid: azure.ai.agentserver.core.models.projects.Response.error
  name: error
  summary: Required.
  signature: 'error: _models.ResponseError'
- uid: azure.ai.agentserver.core.models.projects.Response.id
  name: id
  summary: Unique identifier for this Response. Required.
  signature: 'id: str'
- uid: azure.ai.agentserver.core.models.projects.Response.incomplete_details
  name: incomplete_details
  summary: Details about why the response is incomplete. Required.
  signature: 'incomplete_details: _models.ResponseIncompleteDetails1'
- uid: azure.ai.agentserver.core.models.projects.Response.instructions
  name: instructions
  summary: "A system (or developer) message inserted into the model's context.\nWhen\
    \ using along with `previous_response_id`, the instructions from a previous\n\
    response will not be carried over to the next response. This makes it simple\n\
    to swap out system (or developer) messages in new responses. Required. Is either\
    \ a str type or\n\n   a [ItemParam] type."
  signature: 'instructions: str | list[''_models.ItemParam'']'
- uid: azure.ai.agentserver.core.models.projects.Response.max_output_tokens
  name: max_output_tokens
  summary: 'An upper bound for the number of tokens that can be generated for a response,
    including visible

    output tokens and [reasoning tokens](/docs/guides/reasoning).'
  signature: 'max_output_tokens: int | None'
- uid: azure.ai.agentserver.core.models.projects.Response.max_tool_calls
  name: max_tool_calls
  summary: 'The maximum number of total calls to built-in tools that can be processed
    in a response. This

    maximum number applies across all built-in tool calls, not per individual tool.
    Any further

    attempts to call a tool by the model will be ignored.'
  signature: 'max_tool_calls: int | None'
- uid: azure.ai.agentserver.core.models.projects.Response.metadata
  name: metadata
  summary: 'Set of 16 key-value pairs that can be attached to an object. This can
    be

    useful for storing additional information about the object in a structured

    format, and querying for objects via API or the dashboard.

    Keys are strings with a maximum length of 64 characters. Values are strings

    with a maximum length of 512 characters. Required.'
  signature: 'metadata: dict[str, str]'
- uid: azure.ai.agentserver.core.models.projects.Response.model
  name: model
  summary: The model deployment to use for the creation of this response.
  signature: 'model: str | None'
- uid: azure.ai.agentserver.core.models.projects.Response.object
  name: object
  summary: 'The object type of this resource - always set to `response`. Required.
    Default value is

    "response".'
  signature: 'object: Literal[''response'']'
- uid: azure.ai.agentserver.core.models.projects.Response.output
  name: output
  summary: "An array of content items generated by the model.\n   * The length and\
    \ order of items in the *output* array is dependent \n\non the model's response.\n\
    \   * Rather than accessing the first item in the *output* array and \n\nassuming\
    \ it's an *assistant* message with the content generated by\nthe model, you might\
    \ consider using the *output_text* property where\nsupported in SDKs. Required."
  signature: 'output: list[''_models.ItemResource'']'
- uid: azure.ai.agentserver.core.models.projects.Response.output_text
  name: output_text
  summary: 'SDK-only convenience property that contains the aggregated text output

    from all `output_text` items in the `output` array, if any are present.

    Supported in the Python and JavaScript SDKs.'
  signature: 'output_text: str | None'
- uid: azure.ai.agentserver.core.models.projects.Response.parallel_tool_calls
  name: parallel_tool_calls
  summary: Whether to allow the model to run tool calls in parallel. Required.
  signature: 'parallel_tool_calls: bool'
- uid: azure.ai.agentserver.core.models.projects.Response.previous_response_id
  name: previous_response_id
  summary: 'The unique ID of the previous response to the model. Use this to

    create multi-turn conversations. Learn more about

    [conversation state](/docs/guides/conversation-state).'
  signature: 'previous_response_id: str | None'
- uid: azure.ai.agentserver.core.models.projects.Response.prompt
  name: prompt
  signature: 'prompt: _models.Prompt | None'
- uid: azure.ai.agentserver.core.models.projects.Response.reasoning
  name: reasoning
  signature: 'reasoning: _models.Reasoning | None'
- uid: azure.ai.agentserver.core.models.projects.Response.service_tier
  name: service_tier
  summary: '"auto", "default",

    "flex", "scale", and "priority".'
  signature: 'service_tier: str | _models.ServiceTier | None'
- uid: azure.ai.agentserver.core.models.projects.Response.status
  name: status
  summary: "The status of the response generation. One of `completed`, `failed`,\n\
    `in_progress`, `cancelled`, `queued`, or `incomplete`. Is one of the following\
    \ types:\n\n   Literal[\"completed\"], Literal[\"failed\"], Literal[\"in_progress\"\
    ], Literal[\"cancelled\"],\n   Literal[\"queued\"], Literal[\"incomplete\"]"
  signature: 'status: Literal[''completed'', ''failed'', ''in_progress'', ''cancelled'',
    ''queued'', ''incomplete''] | None'
- uid: azure.ai.agentserver.core.models.projects.Response.structured_inputs
  name: structured_inputs
  summary: 'The structured inputs to the response that can participate in prompt template
    substitution or

    tool argument bindings.'
  signature: 'structured_inputs: dict[str, Any] | None'
- uid: azure.ai.agentserver.core.models.projects.Response.temperature
  name: temperature
  summary: "What sampling temperature to use, between 0 and 2. Higher values like\
    \ 0.8 will make the output\n   more random, while lower values like 0.2 will make\
    \ it more focused and deterministic.\n\nWe generally recommend altering this or\
    \ `top_p` but not both. Required."
  signature: 'temperature: float'
- uid: azure.ai.agentserver.core.models.projects.Response.text
  name: text
  summary: "Configuration options for a text response from the model. Can be plain\n\
    text or structured JSON data. Learn more:\n\n   * [Text inputs and outputs](/docs/guides/text)\
    \ \n\n   * [Structured Outputs](/docs/guides/structured-outputs). "
  signature: 'text: _models.ResponseText | None'
- uid: azure.ai.agentserver.core.models.projects.Response.tool_choice
  name: tool_choice
  summary: "How the model should select which tool (or tools) to use when generating\n\
    a response. See the `tools` parameter to see how to specify which tools\nthe model\
    \ can call. Is either a Union[str, \"_models.ToolChoiceOptions\"] type or a\n\n\
    \   ToolChoiceObject type."
  signature: 'tool_choice: str | _models.ToolChoiceOptions | _models.ToolChoiceObject
    | None'
- uid: azure.ai.agentserver.core.models.projects.Response.tools
  name: tools
  summary: "An array of tools the model may call while generating a response. You\n\
    can specify which tool to use by setting the `tool_choice` parameter.\nThe two\
    \ categories of tools you can provide the model are:\n\n   * **Built-in tools**:\
    \ Tools that are provided by OpenAI that extend the \n\nmodel's capabilities,\
    \ like [web search](/docs/guides/tools-web-search)\nor [file search](/docs/guides/tools-file-search).\
    \ Learn more about\n[built-in tools](/docs/guides/tools).\n\n   * **Function calls\
    \ (custom tools)**: Functions that are defined by you, \n\nenabling the model\
    \ to call your own code. Learn more about\n[function calling](/docs/guides/function-calling)."
  signature: 'tools: list[''_models.Tool''] | None'
- uid: azure.ai.agentserver.core.models.projects.Response.top_logprobs
  name: top_logprobs
  summary: 'An integer between 0 and 20 specifying the number of most likely tokens
    to return at each token

    position, each with an associated log probability.'
  signature: 'top_logprobs: int | None'
- uid: azure.ai.agentserver.core.models.projects.Response.top_p
  name: top_p
  summary: 'An alternative to sampling with temperature, called nucleus sampling,

    where the model considers the results of the tokens with top_p probability

    mass. So 0.1 means only the tokens comprising the top 10% probability mass

    are considered.

    We generally recommend altering this or `temperature` but not both. Required.'
  signature: 'top_p: float'
- uid: azure.ai.agentserver.core.models.projects.Response.truncation
  name: truncation
  summary: "The truncation strategy to use for the model response.\n   * *auto*: If\
    \ the context of this response and previous ones exceeds \n\nthe model's context\
    \ window size, the model will truncate the\nresponse to fit the context window\
    \ by dropping input items in the\nmiddle of the conversation.\n\n   * *disabled*\
    \ (default): If a model response will exceed the context window \n\nsize for a\
    \ model, the request will fail with a 400 error. Is either a Literal[\"auto\"\
    ] type or\n   a Literal[\"disabled\"] type."
  signature: 'truncation: Literal[''auto'', ''disabled''] | None'
- uid: azure.ai.agentserver.core.models.projects.Response.usage
  name: usage
  signature: 'usage: _models.ResponseUsage | None'
- uid: azure.ai.agentserver.core.models.projects.Response.user
  name: user
  summary: 'A unique identifier representing your end-user, which can help OpenAI
    to monitor and detect

    abuse. [Learn more](/docs/guides/safety-best-practices#end-user-ids). Required.'
  signature: 'user: str'
