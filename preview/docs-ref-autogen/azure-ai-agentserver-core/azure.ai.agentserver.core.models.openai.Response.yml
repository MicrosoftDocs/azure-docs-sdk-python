### YamlMime:PythonClass
uid: azure.ai.agentserver.core.models.openai.Response
name: Response
fullName: azure.ai.agentserver.core.models.openai.Response
module: azure.ai.agentserver.core.models.openai
summary: 'Create a new model by parsing and validating input data from keyword arguments.


  Raises [*ValidationError*][pydantic_core.ValidationError] if the input data cannot
  be

  validated to form a valid model.


  *self* is explicitly positional-only to allow *self* as a field name.'
constructor:
  syntax: 'Response(**data: Any)'
methods:
- uid: azure.ai.agentserver.core.models.openai.Response.construct
  name: construct
  signature: 'construct(_fields_set: set[str] | None = None, **values: object) ->
    ModelT'
  parameters:
  - name: _fields_set
    defaultValue: None
- uid: azure.ai.agentserver.core.models.openai.Response.copy
  name: copy
  summary: "Returns a copy of the model.\n\n!!! warning \"Deprecated\"\n   This method\
    \ is now deprecated; use *model_copy* instead.\n\nIf you need *include* or *exclude*,\
    \ use:\n\n``python {test=\"skip\" lint=\"skip\"}\ndata = self.model_dump(include=include,\
    \ exclude=exclude, round_trip=True)\ndata = {**data, **(update or {})}\ncopied\
    \ = self.model_validate(data)\n``"
  signature: 'copy(*, include: AbstractSetIntStr | MappingIntStrAny | None = None,
    exclude: AbstractSetIntStr | MappingIntStrAny | None = None, update: Dict[str,
    Any] | None = None, deep: bool = False) -> Self'
  parameters:
  - name: include
    description: Optional set or mapping specifying which fields to include in the
      copied model.
    isRequired: true
  - name: exclude
    description: Optional set or mapping specifying which fields to exclude in the
      copied model.
    isRequired: true
  - name: update
    description: Optional dictionary of field-value pairs to override field values
      in the copied model.
    isRequired: true
  - name: deep
    description: If True, the values of fields that are Pydantic models will be deep-copied.
    isRequired: true
  keywordOnlyParameters:
  - name: include
    defaultValue: None
  - name: exclude
    defaultValue: None
  - name: update
    defaultValue: None
  - name: deep
    defaultValue: 'False'
  return:
    description: A copy of the model with included, excluded and updated fields as
      specified.
- uid: azure.ai.agentserver.core.models.openai.Response.dict
  name: dict
  signature: 'dict(*, include: set[int] | set[str] | Mapping[int, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str,
    set[int] | set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool]
    | bool] | None = None, exclude: set[int] | set[str] | Mapping[int, set[int] |
    set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str,
    set[int] | set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool]
    | bool] | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults:
    bool = False, exclude_none: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: include
    defaultValue: None
  - name: exclude
    defaultValue: None
  - name: by_alias
    defaultValue: 'False'
  - name: exclude_unset
    defaultValue: 'False'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
- uid: azure.ai.agentserver.core.models.openai.Response.from_orm
  name: from_orm
  signature: 'from_orm(obj: Any) -> Self'
  parameters:
  - name: obj
    isRequired: true
- uid: azure.ai.agentserver.core.models.openai.Response.json
  name: json
  signature: 'json(*, include: set[int] | set[str] | Mapping[int, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str,
    set[int] | set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool]
    | bool] | None = None, exclude: set[int] | set[str] | Mapping[int, set[int] |
    set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str,
    set[int] | set[str] | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool]
    | bool] | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults:
    bool = False, exclude_none: bool = False, encoder: Callable[[Any], Any] | None
    = PydanticUndefined, models_as_dict: bool = PydanticUndefined, **dumps_kwargs:
    Any) -> str'
  keywordOnlyParameters:
  - name: include
    defaultValue: None
  - name: exclude
    defaultValue: None
  - name: by_alias
    defaultValue: 'False'
  - name: exclude_unset
    defaultValue: 'False'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
  - name: encoder
    defaultValue: PydanticUndefined
  - name: models_as_dict
    defaultValue: PydanticUndefined
- uid: azure.ai.agentserver.core.models.openai.Response.model_construct
  name: model_construct
  signature: 'model_construct(_fields_set: set[str] | None = None, **values: object)
    -> ModelT'
  parameters:
  - name: _fields_set
    defaultValue: None
- uid: azure.ai.agentserver.core.models.openai.Response.model_copy
  name: model_copy
  summary: "!!! abstract \"Usage Documentation\"\n   [*model_copy*](../concepts/models.md#model-copy)\n\
    \nReturns a copy of the model.\n\n!!! note\n   The underlying instance's [*__dict__*][object.__dict__]\
    \ attribute is copied. This\n   might have unexpected side effects if you store\
    \ anything in it, on top of the model\n   fields (e.g. the value of [cached properties][functools.cached_property])."
  signature: 'model_copy(*, update: Mapping[str, Any] | None = None, deep: bool =
    False) -> Self'
  parameters:
  - name: update
    description: 'Values to change/add in the new model. Note: the data is not validated

      before creating the new model. You should trust this data.'
    isRequired: true
  - name: deep
    description: Set to *True* to make a deep copy of the model.
    isRequired: true
  keywordOnlyParameters:
  - name: update
    defaultValue: None
  - name: deep
    defaultValue: 'False'
  return:
    description: New model instance.
- uid: azure.ai.agentserver.core.models.openai.Response.model_dump
  name: model_dump
  summary: "!!! abstract \"Usage Documentation\"\n   [*model_dump*](../concepts/serialization.md#python-mode)\n\
    \nGenerate a dictionary representation of the model, optionally specifying which\
    \ fields to include or exclude."
  signature: 'model_dump(*, mode: Literal[''json'', ''python''] | str = ''python'',
    include: set[int] | set[str] | Mapping[int, set[int] | set[str] | Mapping[int,
    IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | None = None,
    exclude: set[int] | set[str] | Mapping[int, set[int] | set[str] | Mapping[int,
    IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | None = None,
    context: Any | None = None, by_alias: bool | None = None, exclude_unset: bool
    = False, exclude_defaults: bool = False, exclude_none: bool = False, exclude_computed_fields:
    bool = False, round_trip: bool = False, warnings: bool | Literal[''none'', ''warn'',
    ''error''] = True, fallback: Callable[[Any], Any] | None = None, serialize_as_any:
    bool = False) -> dict[str, Any]'
  parameters:
  - name: mode
    description: 'The mode in which *to_python* should run.

      If mode is ''json'', the output will only contain JSON serializable types.

      If mode is ''python'', the output may contain non-JSON-serializable Python objects.'
    isRequired: true
  - name: include
    description: A set of fields to include in the output.
    isRequired: true
  - name: exclude
    description: A set of fields to exclude from the output.
    isRequired: true
  - name: context
    description: Additional context to pass to the serializer.
    isRequired: true
  - name: by_alias
    description: Whether to use the field's alias in the dictionary key if defined.
    isRequired: true
  - name: exclude_unset
    description: Whether to exclude fields that have not been explicitly set.
    isRequired: true
  - name: exclude_defaults
    description: Whether to exclude fields that are set to their default value.
    isRequired: true
  - name: exclude_none
    description: Whether to exclude fields that have a value of *None*.
    isRequired: true
  - name: exclude_computed_fields
    description: 'Whether to exclude computed fields.

      While this can be useful for round-tripping, it is usually recommended to use
      the dedicated

      *round_trip* parameter instead.'
    isRequired: true
  - name: round_trip
    description: If True, dumped values should be valid as input for non-idempotent
      types such as Json[T].
    isRequired: true
  - name: warnings
    description: 'How to handle serialization errors. False/"none" ignores them, True/"warn"
      logs errors,

      "error" raises a [*PydanticSerializationError*][pydantic_core.PydanticSerializationError].'
    isRequired: true
  - name: fallback
    description: 'A function to call when an unknown value is encountered. If not
      provided,

      a [*PydanticSerializationError*][pydantic_core.PydanticSerializationError] error
      is raised.'
    isRequired: true
  - name: serialize_as_any
    description: Whether to serialize fields with duck-typing serialization behavior.
    isRequired: true
  keywordOnlyParameters:
  - name: mode
    defaultValue: python
  - name: include
    defaultValue: None
  - name: exclude
    defaultValue: None
  - name: context
    defaultValue: None
  - name: by_alias
    defaultValue: None
  - name: exclude_unset
    defaultValue: 'False'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
  - name: exclude_computed_fields
    defaultValue: 'False'
  - name: round_trip
    defaultValue: 'False'
  - name: warnings
    defaultValue: 'True'
  - name: fallback
    defaultValue: None
  - name: serialize_as_any
    defaultValue: 'False'
  return:
    description: A dictionary representation of the model.
- uid: azure.ai.agentserver.core.models.openai.Response.model_dump_json
  name: model_dump_json
  summary: "!!! abstract \"Usage Documentation\"\n   [*model_dump_json*](../concepts/serialization.md#json-mode)\n\
    \nGenerates a JSON representation of the model using Pydantic's *to_json* method."
  signature: 'model_dump_json(*, indent: int | None = None, ensure_ascii: bool = False,
    include: set[int] | set[str] | Mapping[int, set[int] | set[str] | Mapping[int,
    IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | None = None,
    exclude: set[int] | set[str] | Mapping[int, set[int] | set[str] | Mapping[int,
    IncEx | bool] | Mapping[str, IncEx | bool] | bool] | Mapping[str, set[int] | set[str]
    | Mapping[int, IncEx | bool] | Mapping[str, IncEx | bool] | bool] | None = None,
    context: Any | None = None, by_alias: bool | None = None, exclude_unset: bool
    = False, exclude_defaults: bool = False, exclude_none: bool = False, exclude_computed_fields:
    bool = False, round_trip: bool = False, warnings: bool | Literal[''none'', ''warn'',
    ''error''] = True, fallback: Callable[[Any], Any] | None = None, serialize_as_any:
    bool = False) -> str'
  parameters:
  - name: indent
    description: Indentation to use in the JSON output. If None is passed, the output
      will be compact.
    isRequired: true
  - name: ensure_ascii
    description: 'If *True*, the output is guaranteed to have all incoming non-ASCII
      characters escaped.

      If *False* (the default), these characters will be output as-is.'
    isRequired: true
  - name: include
    description: Field(s) to include in the JSON output.
    isRequired: true
  - name: exclude
    description: Field(s) to exclude from the JSON output.
    isRequired: true
  - name: context
    description: Additional context to pass to the serializer.
    isRequired: true
  - name: by_alias
    description: Whether to serialize using field aliases.
    isRequired: true
  - name: exclude_unset
    description: Whether to exclude fields that have not been explicitly set.
    isRequired: true
  - name: exclude_defaults
    description: Whether to exclude fields that are set to their default value.
    isRequired: true
  - name: exclude_none
    description: Whether to exclude fields that have a value of *None*.
    isRequired: true
  - name: exclude_computed_fields
    description: 'Whether to exclude computed fields.

      While this can be useful for round-tripping, it is usually recommended to use
      the dedicated

      *round_trip* parameter instead.'
    isRequired: true
  - name: round_trip
    description: If True, dumped values should be valid as input for non-idempotent
      types such as Json[T].
    isRequired: true
  - name: warnings
    description: 'How to handle serialization errors. False/"none" ignores them, True/"warn"
      logs errors,

      "error" raises a [*PydanticSerializationError*][pydantic_core.PydanticSerializationError].'
    isRequired: true
  - name: fallback
    description: 'A function to call when an unknown value is encountered. If not
      provided,

      a [*PydanticSerializationError*][pydantic_core.PydanticSerializationError] error
      is raised.'
    isRequired: true
  - name: serialize_as_any
    description: Whether to serialize fields with duck-typing serialization behavior.
    isRequired: true
  keywordOnlyParameters:
  - name: indent
    defaultValue: None
  - name: ensure_ascii
    defaultValue: 'False'
  - name: include
    defaultValue: None
  - name: exclude
    defaultValue: None
  - name: context
    defaultValue: None
  - name: by_alias
    defaultValue: None
  - name: exclude_unset
    defaultValue: 'False'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
  - name: exclude_computed_fields
    defaultValue: 'False'
  - name: round_trip
    defaultValue: 'False'
  - name: warnings
    defaultValue: 'True'
  - name: fallback
    defaultValue: None
  - name: serialize_as_any
    defaultValue: 'False'
  return:
    description: A JSON string representation of the model.
- uid: azure.ai.agentserver.core.models.openai.Response.model_json_schema
  name: model_json_schema
  summary: Generates a JSON schema for a model class.
  signature: 'model_json_schema(by_alias: bool = True, ref_template: str = ''#/$defs/{model}'',
    schema_generator: type[pydantic.json_schema.GenerateJsonSchema] = <class ''pydantic.json_schema.GenerateJsonSchema''>,
    mode: ~typing.Literal[''validation'', ''serialization''] = ''validation'', *,
    union_format: ~typing.Literal[''any_of'', ''primitive_type_array''] = ''any_of'')
    -> dict[str, Any]'
  parameters:
  - name: by_alias
    description: Whether to use attribute aliases or not.
    defaultValue: 'True'
  - name: ref_template
    description: The reference template.
    defaultValue: '#/$defs/{model}'
  - name: union_format
    description: "The format to use when combining schemas from unions together. Can\
      \ be one of:\n\n* *'any_of'*: Use the [*anyOf*](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)\
      \ \n\nkeyword to combine schemas (the default).\n- *'primitive_type_array'*:\
      \ Use the [*type*](https://json-schema.org/understanding-json-schema/reference/type)\n\
      keyword as an array of strings, containing each type of the combination. If\
      \ any of the schemas is not a primitive\ntype (*string*, *boolean*, *null*,\
      \ *integer* or *number*) or contains constraints/metadata, falls back to\n*any_of*."
    isRequired: true
  - name: schema_generator
    description: 'To override the logic used to generate the JSON schema, as a subclass
      of

      *GenerateJsonSchema* with your desired modifications'
    defaultValue: <class 'pydantic.json_schema.GenerateJsonSchema'>
  - name: mode
    description: The mode in which to generate the schema.
    defaultValue: validation
  keywordOnlyParameters:
  - name: union_format
    defaultValue: any_of
  return:
    description: The JSON schema for the given model class.
- uid: azure.ai.agentserver.core.models.openai.Response.model_parametrized_name
  name: model_parametrized_name
  summary: 'Compute the class name for parametrizations of generic classes.


    This method can be overridden to achieve a custom naming scheme for generic BaseModels.'
  signature: 'model_parametrized_name(params: tuple[type[Any], ...]) -> str'
  parameters:
  - name: params
    description: 'Tuple of types of the class. Given a generic class

      *Model* with 2 type variables and a concrete model *Model[str, int]*,

      the value *(str, int)* would be passed to *params*.'
    isRequired: true
  return:
    description: String representing the new class where *params* are passed to *cls*
      as type variables.
  exceptions:
  - type: TypeError
    description: Raised when trying to generate concrete names for non-generic models.
- uid: azure.ai.agentserver.core.models.openai.Response.model_post_init
  name: model_post_init
  summary: 'Override this method to perform additional initialization after *__init__*
    and *model_construct*.

    This is useful if you want to do some validation that requires the entire model
    to be initialized.'
  signature: 'model_post_init(context: Any, /) -> None'
  positionalOnlyParameters:
  - name: context
    isRequired: true
- uid: azure.ai.agentserver.core.models.openai.Response.model_rebuild
  name: model_rebuild
  summary: 'Try to rebuild the pydantic-core schema for the model.


    This may be necessary when one of the annotations is a ForwardRef which could
    not be resolved during

    the initial attempt to build the schema, and automatic rebuilding fails.'
  signature: 'model_rebuild(*, force: bool = False, raise_errors: bool = True, _parent_namespace_depth:
    int = 2, _types_namespace: MappingNamespace | None = None) -> bool | None'
  parameters:
  - name: force
    description: Whether to force the rebuilding of the model schema, defaults to
      *False*.
    isRequired: true
  - name: raise_errors
    description: Whether to raise errors, defaults to *True*.
    isRequired: true
  - name: _parent_namespace_depth
    description: The depth level of the parent namespace, defaults to 2.
    isRequired: true
  - name: _types_namespace
    description: The types namespace, defaults to *None*.
    isRequired: true
  keywordOnlyParameters:
  - name: force
    defaultValue: 'False'
  - name: raise_errors
    defaultValue: 'True'
  - name: _parent_namespace_depth
    defaultValue: '2'
  - name: _types_namespace
    defaultValue: None
  return:
    description: 'Returns *None* if the schema is already "complete" and rebuilding
      was not required.

      If rebuilding _was_ required, returns *True* if rebuilding was successful, otherwise
      *False*.'
- uid: azure.ai.agentserver.core.models.openai.Response.model_validate
  name: model_validate
  summary: Validate a pydantic model instance.
  signature: 'model_validate(obj: Any, *, strict: bool | None = None, extra: Literal[''allow'',
    ''ignore'', ''forbid''] | None = None, from_attributes: bool | None = None, context:
    Any | None = None, by_alias: bool | None = None, by_name: bool | None = None)
    -> Self'
  parameters:
  - name: obj
    description: The object to validate.
    isRequired: true
  - name: strict
    description: Whether to enforce types strictly.
    isRequired: true
  - name: extra
    description: 'Whether to ignore, allow, or forbid extra data during model validation.

      See the [*extra* configuration value][pydantic.ConfigDict.extra] for details.'
    isRequired: true
  - name: from_attributes
    description: Whether to extract data from object attributes.
    isRequired: true
  - name: context
    description: Additional context to pass to the validator.
    isRequired: true
  - name: by_alias
    description: Whether to use the field's alias when validating against the provided
      input data.
    isRequired: true
  - name: by_name
    description: Whether to use the field's name when validating against the provided
      input data.
    isRequired: true
  keywordOnlyParameters:
  - name: strict
    defaultValue: None
  - name: extra
    defaultValue: None
  - name: from_attributes
    defaultValue: None
  - name: context
    defaultValue: None
  - name: by_alias
    defaultValue: None
  - name: by_name
    defaultValue: None
  return:
    description: The validated model instance.
  exceptions:
  - type: ValidationError
    description: If the object could not be validated.
- uid: azure.ai.agentserver.core.models.openai.Response.model_validate_json
  name: model_validate_json
  summary: "!!! abstract \"Usage Documentation\"\n   [JSON Parsing](../concepts/json.md#json-parsing)\n\
    \nValidate the given JSON data against the Pydantic model."
  signature: 'model_validate_json(json_data: str | bytes | bytearray, *, strict: bool
    | None = None, extra: Literal[''allow'', ''ignore'', ''forbid''] | None = None,
    context: Any | None = None, by_alias: bool | None = None, by_name: bool | None
    = None) -> Self'
  parameters:
  - name: json_data
    description: The JSON data to validate.
    isRequired: true
  - name: strict
    description: Whether to enforce types strictly.
    isRequired: true
  - name: extra
    description: 'Whether to ignore, allow, or forbid extra data during model validation.

      See the [*extra* configuration value][pydantic.ConfigDict.extra] for details.'
    isRequired: true
  - name: context
    description: Extra variables to pass to the validator.
    isRequired: true
  - name: by_alias
    description: Whether to use the field's alias when validating against the provided
      input data.
    isRequired: true
  - name: by_name
    description: Whether to use the field's name when validating against the provided
      input data.
    isRequired: true
  keywordOnlyParameters:
  - name: strict
    defaultValue: None
  - name: extra
    defaultValue: None
  - name: context
    defaultValue: None
  - name: by_alias
    defaultValue: None
  - name: by_name
    defaultValue: None
  return:
    description: The validated Pydantic model.
  exceptions:
  - type: ValidationError
    description: If *json_data* is not a JSON string or the object could not be validated.
- uid: azure.ai.agentserver.core.models.openai.Response.model_validate_strings
  name: model_validate_strings
  summary: Validate the given object with string data against the Pydantic model.
  signature: 'model_validate_strings(obj: Any, *, strict: bool | None = None, extra:
    Literal[''allow'', ''ignore'', ''forbid''] | None = None, context: Any | None
    = None, by_alias: bool | None = None, by_name: bool | None = None) -> Self'
  parameters:
  - name: obj
    description: The object containing string data to validate.
    isRequired: true
  - name: strict
    description: Whether to enforce types strictly.
    isRequired: true
  - name: extra
    description: 'Whether to ignore, allow, or forbid extra data during model validation.

      See the [*extra* configuration value][pydantic.ConfigDict.extra] for details.'
    isRequired: true
  - name: context
    description: Extra variables to pass to the validator.
    isRequired: true
  - name: by_alias
    description: Whether to use the field's alias when validating against the provided
      input data.
    isRequired: true
  - name: by_name
    description: Whether to use the field's name when validating against the provided
      input data.
    isRequired: true
  keywordOnlyParameters:
  - name: strict
    defaultValue: None
  - name: extra
    defaultValue: None
  - name: context
    defaultValue: None
  - name: by_alias
    defaultValue: None
  - name: by_name
    defaultValue: None
  return:
    description: The validated Pydantic model.
- uid: azure.ai.agentserver.core.models.openai.Response.parse_file
  name: parse_file
  signature: 'parse_file(path: str | Path, *, content_type: str | None = None, encoding:
    str = ''utf8'', proto: DeprecatedParseProtocol | None = None, allow_pickle: bool
    = False) -> Self'
  parameters:
  - name: path
    isRequired: true
  keywordOnlyParameters:
  - name: content_type
    defaultValue: None
  - name: encoding
    defaultValue: utf8
  - name: proto
    defaultValue: None
  - name: allow_pickle
    defaultValue: 'False'
- uid: azure.ai.agentserver.core.models.openai.Response.parse_obj
  name: parse_obj
  signature: 'parse_obj(obj: Any) -> Self'
  parameters:
  - name: obj
    isRequired: true
- uid: azure.ai.agentserver.core.models.openai.Response.parse_raw
  name: parse_raw
  signature: 'parse_raw(b: str | bytes, *, content_type: str | None = None, encoding:
    str = ''utf8'', proto: DeprecatedParseProtocol | None = None, allow_pickle: bool
    = False) -> Self'
  parameters:
  - name: b
    isRequired: true
  keywordOnlyParameters:
  - name: content_type
    defaultValue: None
  - name: encoding
    defaultValue: utf8
  - name: proto
    defaultValue: None
  - name: allow_pickle
    defaultValue: 'False'
- uid: azure.ai.agentserver.core.models.openai.Response.schema
  name: schema
  signature: 'schema(by_alias: bool = True, ref_template: str = ''#/$defs/{model}'')
    -> Dict[str, Any]'
  parameters:
  - name: by_alias
    defaultValue: 'True'
  - name: ref_template
    defaultValue: '#/$defs/{model}'
- uid: azure.ai.agentserver.core.models.openai.Response.schema_json
  name: schema_json
  signature: 'schema_json(*, by_alias: bool = True, ref_template: str = ''#/$defs/{model}'',
    **dumps_kwargs: Any) -> str'
  keywordOnlyParameters:
  - name: by_alias
    defaultValue: 'True'
  - name: ref_template
    defaultValue: '#/$defs/{model}'
- uid: azure.ai.agentserver.core.models.openai.Response.to_dict
  name: to_dict
  summary: 'Recursively generate a dictionary representation of the model, optionally
    specifying which fields to include or exclude.


    By default, fields that were not set by the API will not be included,

    and keys will match the API response, *not* the property names from the model.


    For example, if the API responds with *"fooBar": true* but we''ve defined a *foo_bar:
    bool* property,

    the output will use the *"fooBar"* key (unless *use_api_names=False* is passed).'
  signature: 'to_dict(*, mode: Literal[''json'', ''python''] = ''python'', use_api_names:
    bool = True, exclude_unset: bool = True, exclude_defaults: bool = False, exclude_none:
    bool = False, warnings: bool = True) -> dict[str, object]'
  parameters:
  - name: mode
    description: 'If mode is ''json'', the dictionary will only contain JSON serializable
      types. e.g. *datetime* will be turned into a string, *"2024-3-22T18:11:19.117000Z"*.

      If mode is ''python'', the dictionary may contain any Python objects. e.g. *datetime(2024,
      3, 22)*'
    isRequired: true
  - name: use_api_names
    description: Whether to use the key that the API responded with or the property
      name. Defaults to *True*.
    isRequired: true
  - name: exclude_unset
    description: Whether to exclude fields that have not been explicitly set.
    isRequired: true
  - name: exclude_defaults
    description: Whether to exclude fields that are set to their default value from
      the output.
    isRequired: true
  - name: exclude_none
    description: Whether to exclude fields that have a value of *None* from the output.
    isRequired: true
  - name: warnings
    description: Whether to log warnings when invalid fields are encountered. This
      is only supported in Pydantic v2.
    isRequired: true
  keywordOnlyParameters:
  - name: mode
    defaultValue: python
  - name: use_api_names
    defaultValue: 'True'
  - name: exclude_unset
    defaultValue: 'True'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
  - name: warnings
    defaultValue: 'True'
- uid: azure.ai.agentserver.core.models.openai.Response.to_json
  name: to_json
  summary: 'Generates a JSON string representing this model as it would be received
    from or sent to the API (but with indentation).


    By default, fields that were not set by the API will not be included,

    and keys will match the API response, *not* the property names from the model.


    For example, if the API responds with *"fooBar": true* but we''ve defined a *foo_bar:
    bool* property,

    the output will use the *"fooBar"* key (unless *use_api_names=False* is passed).'
  signature: 'to_json(*, indent: int | None = 2, use_api_names: bool = True, exclude_unset:
    bool = True, exclude_defaults: bool = False, exclude_none: bool = False, warnings:
    bool = True) -> str'
  parameters:
  - name: indent
    description: Indentation to use in the JSON output. If *None* is passed, the output
      will be compact. Defaults to *2*
    isRequired: true
  - name: use_api_names
    description: Whether to use the key that the API responded with or the property
      name. Defaults to *True*.
    isRequired: true
  - name: exclude_unset
    description: Whether to exclude fields that have not been explicitly set.
    isRequired: true
  - name: exclude_defaults
    description: Whether to exclude fields that have the default value.
    isRequired: true
  - name: exclude_none
    description: Whether to exclude fields that have a value of *None*.
    isRequired: true
  - name: warnings
    description: Whether to show any warnings that occurred during serialization.
      This is only supported in Pydantic v2.
    isRequired: true
  keywordOnlyParameters:
  - name: indent
    defaultValue: '2'
  - name: use_api_names
    defaultValue: 'True'
  - name: exclude_unset
    defaultValue: 'True'
  - name: exclude_defaults
    defaultValue: 'False'
  - name: exclude_none
    defaultValue: 'False'
  - name: warnings
    defaultValue: 'True'
- uid: azure.ai.agentserver.core.models.openai.Response.update_forward_refs
  name: update_forward_refs
  signature: 'update_forward_refs(**localns: Any) -> None'
- uid: azure.ai.agentserver.core.models.openai.Response.validate
  name: validate
  signature: 'validate(value: Any) -> Self'
  parameters:
  - name: value
    isRequired: true
attributes:
- uid: azure.ai.agentserver.core.models.openai.Response.background
  name: background
  summary: 'Whether to run the model response in the background.

    [Learn more](https://platform.openai.com/docs/guides/background).'
  signature: 'background: bool | None'
- uid: azure.ai.agentserver.core.models.openai.Response.completed_at
  name: completed_at
  summary: 'Unix timestamp (in seconds) of when this Response was completed. Only
    present

    when the status is *completed*.'
  signature: 'completed_at: float | None'
- uid: azure.ai.agentserver.core.models.openai.Response.conversation
  name: conversation
  summary: 'The conversation that this response belonged to.


    Input items and output items from this response were automatically added to this

    conversation.'
  signature: 'conversation: Conversation | None'
- uid: azure.ai.agentserver.core.models.openai.Response.created_at
  name: created_at
  summary: Unix timestamp (in seconds) of when this Response was created.
  signature: 'created_at: float'
- uid: azure.ai.agentserver.core.models.openai.Response.error
  name: error
  summary: An error object returned when the model fails to generate a Response.
  signature: 'error: ResponseError | None'
- uid: azure.ai.agentserver.core.models.openai.Response.id
  name: id
  summary: Unique identifier for this Response.
  signature: 'id: str'
- uid: azure.ai.agentserver.core.models.openai.Response.incomplete_details
  name: incomplete_details
  summary: Details about why the response is incomplete.
  signature: 'incomplete_details: IncompleteDetails | None'
- uid: azure.ai.agentserver.core.models.openai.Response.instructions
  name: instructions
  summary: 'A system (or developer) message inserted into the model''s context.


    When using along with *previous_response_id*, the instructions from a previous

    response will not be carried over to the next response. This makes it simple to

    swap out system (or developer) messages in new responses.'
  signature: 'instructions: str | List[EasyInputMessage | Message | ResponseOutputMessage
    | ResponseFileSearchToolCall | ResponseComputerToolCall | ComputerCallOutput |
    ResponseFunctionWebSearch | ResponseFunctionToolCall | FunctionCallOutput | ResponseReasoningItem
    | ResponseCompactionItemParam | ImageGenerationCall | ResponseCodeInterpreterToolCall
    | LocalShellCall | LocalShellCallOutput | ShellCall | ShellCallOutput | ApplyPatchCall
    | ApplyPatchCallOutput | McpListTools | McpApprovalRequest | McpApprovalResponse
    | McpCall | ResponseCustomToolCallOutput | ResponseCustomToolCall | ItemReference]
    | None'
- uid: azure.ai.agentserver.core.models.openai.Response.max_output_tokens
  name: max_output_tokens
  summary: 'An upper bound for the number of tokens that can be generated for a response,

    including visible output tokens and

    [reasoning tokens](https://platform.openai.com/docs/guides/reasoning).'
  signature: 'max_output_tokens: int | None'
- uid: azure.ai.agentserver.core.models.openai.Response.max_tool_calls
  name: max_tool_calls
  summary: 'The maximum number of total calls to built-in tools that can be processed
    in a

    response. This maximum number applies across all built-in tool calls, not per

    individual tool. Any further attempts to call a tool by the model will be

    ignored.'
  signature: 'max_tool_calls: int | None'
- uid: azure.ai.agentserver.core.models.openai.Response.metadata
  name: metadata
  summary: 'Set of 16 key-value pairs that can be attached to an object.


    This can be useful for storing additional information about the object in a

    structured format, and querying for objects via API or the dashboard.


    Keys are strings with a maximum length of 64 characters. Values are strings with

    a maximum length of 512 characters.'
  signature: 'metadata: Dict[str, str] | None'
- uid: azure.ai.agentserver.core.models.openai.Response.model
  name: model
  summary: 'Model ID used to generate the response, like *gpt-4o* or *o3*.


    OpenAI offers a wide range of models with different capabilities, performance

    characteristics, and price points. Refer to the

    [model guide](https://platform.openai.com/docs/models) to browse and compare

    available models.'
  signature: 'model: str | Literal[''gpt-5.2'', ''gpt-5.2-2025-12-11'', ''gpt-5.2-chat-latest'',
    ''gpt-5.2-pro'', ''gpt-5.2-pro-2025-12-11'', ''gpt-5.1'', ''gpt-5.1-2025-11-13'',
    ''gpt-5.1-codex'', ''gpt-5.1-mini'', ''gpt-5.1-chat-latest'', ''gpt-5'', ''gpt-5-mini'',
    ''gpt-5-nano'', ''gpt-5-2025-08-07'', ''gpt-5-mini-2025-08-07'', ''gpt-5-nano-2025-08-07'',
    ''gpt-5-chat-latest'', ''gpt-4.1'', ''gpt-4.1-mini'', ''gpt-4.1-nano'', ''gpt-4.1-2025-04-14'',
    ''gpt-4.1-mini-2025-04-14'', ''gpt-4.1-nano-2025-04-14'', ''o4-mini'', ''o4-mini-2025-04-16'',
    ''o3'', ''o3-2025-04-16'', ''o3-mini'', ''o3-mini-2025-01-31'', ''o1'', ''o1-2024-12-17'',
    ''o1-preview'', ''o1-preview-2024-09-12'', ''o1-mini'', ''o1-mini-2024-09-12'',
    ''gpt-4o'', ''gpt-4o-2024-11-20'', ''gpt-4o-2024-08-06'', ''gpt-4o-2024-05-13'',
    ''gpt-4o-audio-preview'', ''gpt-4o-audio-preview-2024-10-01'', ''gpt-4o-audio-preview-2024-12-17'',
    ''gpt-4o-audio-preview-2025-06-03'', ''gpt-4o-mini-audio-preview'', ''gpt-4o-mini-audio-preview-2024-12-17'',
    ''gpt-4o-search-preview'', ''gpt-4o-mini-search-preview'', ''gpt-4o-search-preview-2025-03-11'',
    ''gpt-4o-mini-search-preview-2025-03-11'', ''chatgpt-4o-latest'', ''codex-mini-latest'',
    ''gpt-4o-mini'', ''gpt-4o-mini-2024-07-18'', ''gpt-4-turbo'', ''gpt-4-turbo-2024-04-09'',
    ''gpt-4-0125-preview'', ''gpt-4-turbo-preview'', ''gpt-4-1106-preview'', ''gpt-4-vision-preview'',
    ''gpt-4'', ''gpt-4-0314'', ''gpt-4-0613'', ''gpt-4-32k'', ''gpt-4-32k-0314'',
    ''gpt-4-32k-0613'', ''gpt-3.5-turbo'', ''gpt-3.5-turbo-16k'', ''gpt-3.5-turbo-0301'',
    ''gpt-3.5-turbo-0613'', ''gpt-3.5-turbo-1106'', ''gpt-3.5-turbo-0125'', ''gpt-3.5-turbo-16k-0613'']
    | Literal[''o1-pro'', ''o1-pro-2025-03-19'', ''o3-pro'', ''o3-pro-2025-06-10'',
    ''o3-deep-research'', ''o3-deep-research-2025-06-26'', ''o4-mini-deep-research'',
    ''o4-mini-deep-research-2025-06-26'', ''computer-use-preview'', ''computer-use-preview-2025-03-11'',
    ''gpt-5-codex'', ''gpt-5-pro'', ''gpt-5-pro-2025-10-06'', ''gpt-5.1-codex-max'']'
- uid: azure.ai.agentserver.core.models.openai.Response.model_config
  name: model_config
  summary: Configuration for the model, should be a dictionary conforming to [*ConfigDict*][pydantic.config.ConfigDict].
  signature: 'model_config: ClassVar[ConfigDict] = {''defer_build'': True, ''extra'':
    ''allow''}'
- uid: azure.ai.agentserver.core.models.openai.Response.model_extra
  name: model_extra
  summary: Get extra fields set during validation.
  return:
    description: A dictionary of extra fields, or *None* if *config.extra* is not
      set to *"allow"*.
- uid: azure.ai.agentserver.core.models.openai.Response.model_fields_set
  name: model_fields_set
  summary: Returns the set of fields that have been explicitly set on this model instance.
  return:
    description: "A set of strings representing the fields that have been set,\n \
      \  i.e. that were not filled from defaults."
- uid: azure.ai.agentserver.core.models.openai.Response.object
  name: object
  summary: The object type of this resource - always set to *response*.
  signature: 'object: Literal[''response'']'
- uid: azure.ai.agentserver.core.models.openai.Response.output
  name: output
  summary: "An array of content items generated by the model.\n\n* The length and\
    \ order of items in the *output* array is dependent on the model's response. \n\
    \n* Rather than accessing the first item in the *output* array and assuming it's\
    \ an *assistant* message with the content generated by the model, you might consider\
    \ using the *output_text* property where supported in SDKs. "
  signature: 'output: List[ResponseOutputMessage | ResponseFileSearchToolCall | ResponseFunctionToolCall
    | ResponseFunctionWebSearch | ResponseComputerToolCall | ResponseReasoningItem
    | ResponseCompactionItem | ImageGenerationCall | ResponseCodeInterpreterToolCall
    | LocalShellCall | ResponseFunctionShellToolCall | ResponseFunctionShellToolCallOutput
    | ResponseApplyPatchToolCall | ResponseApplyPatchToolCallOutput | McpCall | McpListTools
    | McpApprovalRequest | ResponseCustomToolCall]'
- uid: azure.ai.agentserver.core.models.openai.Response.output_text
  name: output_text
  summary: 'Convenience property that aggregates all *output_text* items from the
    *output* list.


    If no *output_text* content blocks exist, then an empty string is returned.'
- uid: azure.ai.agentserver.core.models.openai.Response.parallel_tool_calls
  name: parallel_tool_calls
  summary: Whether to allow the model to run tool calls in parallel.
  signature: 'parallel_tool_calls: bool'
- uid: azure.ai.agentserver.core.models.openai.Response.previous_response_id
  name: previous_response_id
  summary: 'The unique ID of the previous response to the model.


    Use this to create multi-turn conversations. Learn more about

    [conversation state](https://platform.openai.com/docs/guides/conversation-state).

    Cannot be used in conjunction with *conversation*.'
  signature: 'previous_response_id: str | None'
- uid: azure.ai.agentserver.core.models.openai.Response.prompt
  name: prompt
  summary: 'Reference to a prompt template and its variables.

    [Learn more](https://platform.openai.com/docs/guides/text?api-mode=responses#reusable-prompts).'
  signature: 'prompt: ResponsePrompt | None'
- uid: azure.ai.agentserver.core.models.openai.Response.prompt_cache_key
  name: prompt_cache_key
  summary: 'Used by OpenAI to cache responses for similar requests to optimize your
    cache

    hit rates. Replaces the *user* field.

    [Learn more](https://platform.openai.com/docs/guides/prompt-caching).'
  signature: 'prompt_cache_key: str | None'
- uid: azure.ai.agentserver.core.models.openai.Response.prompt_cache_retention
  name: prompt_cache_retention
  summary: 'The retention policy for the prompt cache.


    Set to *24h* to enable extended prompt caching, which keeps cached prefixes

    active for longer, up to a maximum of 24 hours.

    [Learn more](https://platform.openai.com/docs/guides/prompt-caching#prompt-cache-retention).'
  signature: 'prompt_cache_retention: Literal[''in-memory'', ''24h''] | None'
- uid: azure.ai.agentserver.core.models.openai.Response.reasoning
  name: reasoning
  summary: '**gpt-5 and o-series models only**


    Configuration options for

    [reasoning models](https://platform.openai.com/docs/guides/reasoning).'
  signature: 'reasoning: Reasoning | None'
- uid: azure.ai.agentserver.core.models.openai.Response.safety_identifier
  name: safety_identifier
  summary: 'A stable identifier used to help detect users of your application that
    may be

    violating OpenAI''s usage policies. The IDs should be a string that uniquely

    identifies each user. We recommend hashing their username or email address, in

    order to avoid sending us any identifying information.

    [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).'
  signature: 'safety_identifier: str | None'
- uid: azure.ai.agentserver.core.models.openai.Response.service_tier
  name: service_tier
  summary: "Specifies the processing type used for serving the request.\n\n* If set\
    \ to 'auto', then the request will be processed with the service tier configured\
    \ in the Project settings. Unless otherwise configured, the Project will use 'default'.\
    \ \n\n* If set to 'default', then the request will be processed with the standard\
    \ pricing and performance for the selected model. \n\n* If set to '[flex](https://platform.openai.com/docs/guides/flex-processing)'\
    \ or '[priority](https://openai.com/api-priority-processing/)', then the request\
    \ will be processed with the corresponding service tier. \n\n* When not set, the\
    \ default behavior is 'auto'. \n\nWhen the *service_tier* parameter is set, the\
    \ response body will include the\n*service_tier* value based on the processing\
    \ mode actually used to serve the\nrequest. This response value may be different\
    \ from the value set in the\nparameter."
  signature: 'service_tier: Literal[''auto'', ''default'', ''flex'', ''scale'', ''priority'']
    | None'
- uid: azure.ai.agentserver.core.models.openai.Response.status
  name: status
  summary: 'The status of the response generation.


    One of *completed*, *failed*, *in_progress*, *cancelled*, *queued*, or

    *incomplete*.'
  signature: 'status: Literal[''completed'', ''failed'', ''in_progress'', ''cancelled'',
    ''queued'', ''incomplete''] | None'
- uid: azure.ai.agentserver.core.models.openai.Response.temperature
  name: temperature
  summary: 'What sampling temperature to use, between 0 and 2.


    Higher values like 0.8 will make the output more random, while lower values like

    0.2 will make it more focused and deterministic. We generally recommend altering

    this or *top_p* but not both.'
  signature: 'temperature: float | None'
- uid: azure.ai.agentserver.core.models.openai.Response.text
  name: text
  summary: "Configuration options for a text response from the model.\n\nCan be plain\
    \ text or structured JSON data. Learn more:\n\n* [Text inputs and outputs](https://platform.openai.com/docs/guides/text)\
    \ \n\n* [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs) "
  signature: 'text: ResponseTextConfig | None'
- uid: azure.ai.agentserver.core.models.openai.Response.tool_choice
  name: tool_choice
  summary: 'How the model should select which tool (or tools) to use when generating
    a

    response. See the *tools* parameter to see how to specify which tools the model

    can call.'
  signature: 'tool_choice: Literal[''none'', ''auto'', ''required''] | ToolChoiceAllowed
    | ToolChoiceTypes | ToolChoiceFunction | ToolChoiceMcp | ToolChoiceCustom | ToolChoiceApplyPatch
    | ToolChoiceShell'
- uid: azure.ai.agentserver.core.models.openai.Response.tools
  name: tools
  summary: "An array of tools the model may call while generating a response.\n\n\
    You can specify which tool to use by setting the *tool_choice* parameter.\n\n\
    We support the following categories of tools:\n\n* **Built-in tools**: Tools that\
    \ are provided by OpenAI that extend the model's capabilities, like [web search](https://platform.openai.com/docs/guides/tools-web-search)\
    \ or [file search](https://platform.openai.com/docs/guides/tools-file-search).\
    \ Learn more about [built-in tools](https://platform.openai.com/docs/guides/tools).\
    \ \n\n* **MCP Tools**: Integrations with third-party systems via custom MCP servers\
    \ or predefined connectors such as Google Drive and SharePoint. Learn more about\
    \ [MCP Tools](https://platform.openai.com/docs/guides/tools-connectors-mcp). \n\
    \n* **Function calls (custom tools)**: Functions that are defined by you, enabling\
    \ the model to call your own code with strongly typed arguments and outputs. Learn\
    \ more about [function calling](https://platform.openai.com/docs/guides/function-calling).\
    \ You can also use custom tools to call your own code. "
  signature: 'tools: List[FunctionTool | FileSearchTool | ComputerTool | WebSearchTool
    | Mcp | CodeInterpreter | ImageGeneration | LocalShell | FunctionShellTool | CustomTool
    | WebSearchPreviewTool | ApplyPatchTool]'
- uid: azure.ai.agentserver.core.models.openai.Response.top_logprobs
  name: top_logprobs
  summary: 'An integer between 0 and 20 specifying the number of most likely tokens
    to

    return at each token position, each with an associated log probability.'
  signature: 'top_logprobs: int | None'
- uid: azure.ai.agentserver.core.models.openai.Response.top_p
  name: top_p
  summary: 'An alternative to sampling with temperature, called nucleus sampling,
    where the

    model considers the results of the tokens with top_p probability mass. So 0.1

    means only the tokens comprising the top 10% probability mass are considered.


    We generally recommend altering this or *temperature* but not both.'
  signature: 'top_p: float | None'
- uid: azure.ai.agentserver.core.models.openai.Response.truncation
  name: truncation
  summary: "The truncation strategy to use for the model response.\n\n* *auto*: If\
    \ the input to this Response exceeds the model's context window size, the model\
    \ will truncate the response to fit the context window by dropping items from\
    \ the beginning of the conversation. \n\n* *disabled* (default): If the input\
    \ size will exceed the context window size for a model, the request will fail\
    \ with a 400 error. "
  signature: 'truncation: Literal[''auto'', ''disabled''] | None'
- uid: azure.ai.agentserver.core.models.openai.Response.usage
  name: usage
  summary: 'Represents token usage details including input tokens, output tokens,
    a

    breakdown of output tokens, and the total tokens used.'
  signature: 'usage: ResponseUsage | None'
- uid: azure.ai.agentserver.core.models.openai.Response.user
  name: user
  summary: 'This field is being replaced by *safety_identifier* and *prompt_cache_key*.


    Use *prompt_cache_key* instead to maintain caching optimizations. A stable

    identifier for your end-users. Used to boost cache hit rates by better bucketing

    similar requests and to help OpenAI detect and prevent abuse.

    [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#safety-identifiers).'
  signature: 'user: str | None'
- uid: azure.ai.agentserver.core.models.openai.Response.model_computed_fields
  name: model_computed_fields
  signature: model_computed_fields = {}
- uid: azure.ai.agentserver.core.models.openai.Response.model_fields
  name: model_fields
  signature: 'model_fields = {''background'': FieldInfo(annotation=Union[bool, NoneType],
    required=False, default=None), ''completed_at'': FieldInfo(annotation=Union[float,
    NoneType], required=False, default=None), ''conversation'': FieldInfo(annotation=Union[Conversation,
    NoneType], required=False, default=None), ''created_at'': FieldInfo(annotation=float,
    required=True), ''error'': FieldInfo(annotation=Union[ResponseError, NoneType],
    required=False, default=None), ''id'': FieldInfo(annotation=str, required=True),
    ''incomplete_details'': FieldInfo(annotation=Union[IncompleteDetails, NoneType],
    required=False, default=None), ''instructions'': FieldInfo(annotation=Union[str,
    List[Annotated[Union[EasyInputMessage, Message, ResponseOutputMessage, ResponseFileSearchToolCall,
    ResponseComputerToolCall, ComputerCallOutput, ResponseFunctionWebSearch, ResponseFunctionToolCall,
    FunctionCallOutput, ResponseReasoningItem, ResponseCompactionItemParam, ImageGenerationCall,
    ResponseCodeInterpreterToolCall, LocalShellCall, LocalShellCallOutput, ShellCall,
    ShellCallOutput, ApplyPatchCall, ApplyPatchCallOutput, McpListTools, McpApprovalRequest,
    McpApprovalResponse, McpCall, ResponseCustomToolCallOutput, ResponseCustomToolCall,
    ItemReference], PropertyInfo]], NoneType], required=False, default=None), ''max_output_tokens'':
    FieldInfo(annotation=Union[int, NoneType], required=False, default=None), ''max_tool_calls'':
    FieldInfo(annotation=Union[int, NoneType], required=False, default=None), ''metadata'':
    FieldInfo(annotation=Union[Dict[str, str], NoneType], required=False, default=None),
    ''model'': FieldInfo(annotation=Union[str, Literal[''gpt-5.2'', ''gpt-5.2-2025-12-11'',
    ''gpt-5.2-chat-latest'', ''gpt-5.2-pro'', ''gpt-5.2-pro-2025-12-11'', ''gpt-5.1'',
    ''gpt-5.1-2025-11-13'', ''gpt-5.1-codex'', ''gpt-5.1-mini'', ''gpt-5.1-chat-latest'',
    ''gpt-5'', ''gpt-5-mini'', ''gpt-5-nano'', ''gpt-5-2025-08-07'', ''gpt-5-mini-2025-08-07'',
    ''gpt-5-nano-2025-08-07'', ''gpt-5-chat-latest'', ''gpt-4.1'', ''gpt-4.1-mini'',
    ''gpt-4.1-nano'', ''gpt-4.1-2025-04-14'', ''gpt-4.1-mini-2025-04-14'', ''gpt-4.1-nano-2025-04-14'',
    ''o4-mini'', ''o4-mini-2025-04-16'', ''o3'', ''o3-2025-04-16'', ''o3-mini'', ''o3-mini-2025-01-31'',
    ''o1'', ''o1-2024-12-17'', ''o1-preview'', ''o1-preview-2024-09-12'', ''o1-mini'',
    ''o1-mini-2024-09-12'', ''gpt-4o'', ''gpt-4o-2024-11-20'', ''gpt-4o-2024-08-06'',
    ''gpt-4o-2024-05-13'', ''gpt-4o-audio-preview'', ''gpt-4o-audio-preview-2024-10-01'',
    ''gpt-4o-audio-preview-2024-12-17'', ''gpt-4o-audio-preview-2025-06-03'', ''gpt-4o-mini-audio-preview'',
    ''gpt-4o-mini-audio-preview-2024-12-17'', ''gpt-4o-search-preview'', ''gpt-4o-mini-search-preview'',
    ''gpt-4o-search-preview-2025-03-11'', ''gpt-4o-mini-search-preview-2025-03-11'',
    ''chatgpt-4o-latest'', ''codex-mini-latest'', ''gpt-4o-mini'', ''gpt-4o-mini-2024-07-18'',
    ''gpt-4-turbo'', ''gpt-4-turbo-2024-04-09'', ''gpt-4-0125-preview'', ''gpt-4-turbo-preview'',
    ''gpt-4-1106-preview'', ''gpt-4-vision-preview'', ''gpt-4'', ''gpt-4-0314'', ''gpt-4-0613'',
    ''gpt-4-32k'', ''gpt-4-32k-0314'', ''gpt-4-32k-0613'', ''gpt-3.5-turbo'', ''gpt-3.5-turbo-16k'',
    ''gpt-3.5-turbo-0301'', ''gpt-3.5-turbo-0613'', ''gpt-3.5-turbo-1106'', ''gpt-3.5-turbo-0125'',
    ''gpt-3.5-turbo-16k-0613''], Literal[''o1-pro'', ''o1-pro-2025-03-19'', ''o3-pro'',
    ''o3-pro-2025-06-10'', ''o3-deep-research'', ''o3-deep-research-2025-06-26'',
    ''o4-mini-deep-research'', ''o4-mini-deep-research-2025-06-26'', ''computer-use-preview'',
    ''computer-use-preview-2025-03-11'', ''gpt-5-codex'', ''gpt-5-pro'', ''gpt-5-pro-2025-10-06'',
    ''gpt-5.1-codex-max'']], required=True), ''object'': FieldInfo(annotation=Literal[''response''],
    required=True), ''output'': FieldInfo(annotation=List[Annotated[Union[ResponseOutputMessage,
    ResponseFileSearchToolCall, ResponseFunctionToolCall, ResponseFunctionWebSearch,
    ResponseComputerToolCall, ResponseReasoningItem, ResponseCompactionItem, ImageGenerationCall,
    ResponseCodeInterpreterToolCall, LocalShellCall, ResponseFunctionShellToolCall,
    ResponseFunctionShellToolCallOutput, ResponseApplyPatchToolCall, ResponseApplyPatchToolCallOutput,
    McpCall, McpListTools, McpApprovalRequest, ResponseCustomToolCall], PropertyInfo]],
    required=True), ''parallel_tool_calls'': FieldInfo(annotation=bool, required=True),
    ''previous_response_id'': FieldInfo(annotation=Union[str, NoneType], required=False,
    default=None), ''prompt'': FieldInfo(annotation=Union[ResponsePrompt, NoneType],
    required=False, default=None), ''prompt_cache_key'': FieldInfo(annotation=Union[str,
    NoneType], required=False, default=None), ''prompt_cache_retention'': FieldInfo(annotation=Union[Literal[''in-memory'',
    ''24h''], NoneType], required=False, default=None), ''reasoning'': FieldInfo(annotation=Union[Reasoning,
    NoneType], required=False, default=None), ''safety_identifier'': FieldInfo(annotation=Union[str,
    NoneType], required=False, default=None), ''service_tier'': FieldInfo(annotation=Union[Literal[''auto'',
    ''default'', ''flex'', ''scale'', ''priority''], NoneType], required=False, default=None),
    ''status'': FieldInfo(annotation=Union[Literal[''completed'', ''failed'', ''in_progress'',
    ''cancelled'', ''queued'', ''incomplete''], NoneType], required=False, default=None),
    ''temperature'': FieldInfo(annotation=Union[float, NoneType], required=False,
    default=None), ''text'': FieldInfo(annotation=Union[ResponseTextConfig, NoneType],
    required=False, default=None), ''tool_choice'': FieldInfo(annotation=Union[Literal[''none'',
    ''auto'', ''required''], ToolChoiceAllowed, ToolChoiceTypes, ToolChoiceFunction,
    ToolChoiceMcp, ToolChoiceCustom, ToolChoiceApplyPatch, ToolChoiceShell], required=True),
    ''tools'': FieldInfo(annotation=List[Annotated[Union[FunctionTool, FileSearchTool,
    ComputerTool, WebSearchTool, Mcp, CodeInterpreter, ImageGeneration, LocalShell,
    FunctionShellTool, CustomTool, WebSearchPreviewTool, ApplyPatchTool], PropertyInfo]],
    required=True), ''top_logprobs'': FieldInfo(annotation=Union[int, NoneType], required=False,
    default=None), ''top_p'': FieldInfo(annotation=Union[float, NoneType], required=False,
    default=None), ''truncation'': FieldInfo(annotation=Union[Literal[''auto'', ''disabled''],
    NoneType], required=False, default=None), ''usage'': FieldInfo(annotation=Union[ResponseUsage,
    NoneType], required=False, default=None), ''user'': FieldInfo(annotation=Union[str,
    NoneType], required=False, default=None)}'
