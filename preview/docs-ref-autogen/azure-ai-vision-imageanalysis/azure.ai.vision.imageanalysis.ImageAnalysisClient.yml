### YamlMime:PythonClass
uid: azure.ai.vision.imageanalysis.ImageAnalysisClient
name: ImageAnalysisClient
fullName: azure.ai.vision.imageanalysis.ImageAnalysisClient
module: azure.ai.vision.imageanalysis
inheritances:
- azure.ai.vision.imageanalysis._client.ImageAnalysisClient
summary: ImageAnalysisClient.
constructor:
  syntax: 'ImageAnalysisClient(endpoint: str, credential: AzureKeyCredential, **kwargs:
    Any)'
  parameters:
  - name: endpoint
    description: 'Azure AI Computer Vision endpoint (protocol and hostname, for example:

      [https://](https://)`<resource-name>`.cognitiveservices.azure.com). Required.'
    isRequired: true
    types:
    - <xref:str>
  - name: credential
    description: Credential needed for the client to connect to Azure. Required.
    isRequired: true
    types:
    - <xref:azure.core.credentials.AzureKeyCredential>
  keywordOnlyParameters:
  - name: api_version
    description: 'The API version to use for this operation. Default value is "2023-10-01".

      Note that overriding this default value may result in unsupported behavior.'
    types:
    - <xref:str>
methods:
- uid: azure.ai.vision.imageanalysis.ImageAnalysisClient.analyze
  name: analyze
  summary: Performs a single Image Analysis operation.
  signature: 'analyze(image_data: bytes, visual_features: List[VisualFeatures], *,
    language: str | None = None, gender_neutral_caption: bool | None = None, smart_crops_aspect_ratios:
    List[float] | None = None, model_version: str | None = None, **kwargs: Any) ->
    ImageAnalysisResult'
  parameters:
  - name: image_data
    description: A buffer containing the whole image to be analyzed.
    isRequired: true
    types:
    - <xref:bytes>
  - name: visual_features
    description: 'A list of visual features to analyze. Required. Seven visual features

      are supported: Caption, DenseCaptions, Read (OCR), Tags, Objects, SmartCrops,
      and People. At

      least one visual feature must be specified.'
    isRequired: true
    types:
    - <xref:list>[<xref:azure.ai.vision.imageanalysis.models.VisualFeatures>]
  keywordOnlyParameters:
  - name: language
    description: 'The desired language for result generation (a two-letter language
      code).

      Defaults to ''en'' (English). See [https://aka.ms/cv-languages](https://aka.ms/cv-languages)
      for a list of supported languages.'
    types:
    - <xref:str>
  - name: gender_neutral_caption
    description: 'Boolean flag for enabling gender-neutral captioning for

      Caption and Dense Captions features. Defaults to ''false''.

      Captions may contain gender terms (for example: ''man'', ''woman'', or ''boy'',
      ''girl'').

      If you set this to ''true'', those will be replaced with gender-neutral terms
      (for example:

      ''person'' or ''child'').'
    types:
    - <xref:bool>
  - name: smart_crops_aspect_ratios
    description: 'A list of aspect ratios to use for smart cropping.

      Defaults to one crop region with an aspect ratio the service sees fit between

      0.5 and 2.0 (inclusive). Aspect ratios are calculated by dividing the target
      crop

      width in pixels by the height in pixels. When set, supported values are

      between 0.75 and 1.8 (inclusive).'
    types:
    - <xref:list>[<xref:float>]
  - name: model_version
    description: 'The version of cloud AI-model used for analysis. Defaults to ''latest'',

      for the latest AI model with recent improvements.

      The format is the following: ''latest'' or ''YYYY-MM-DD'' or ''YYYY-MM-DD-preview'',

      where ''YYYY'', ''MM'', ''DD'' are the year, month and day associated with the
      model.

      If you would like to make sure analysis results do not change over time, set
      this

      value to a specific model version.'
    types:
    - <xref:str>
  return:
    description: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
    types:
    - <xref:azure.ai.vision.imageanalysis.models.ImageAnalysisResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.imageanalysis.ImageAnalysisClient.analyze_from_url
  name: analyze_from_url
  summary: Performs a single Image Analysis operation.
  signature: 'analyze_from_url(image_url: str, visual_features: List[VisualFeatures],
    *, language: str | None = None, gender_neutral_caption: bool | None = None, smart_crops_aspect_ratios:
    List[float] | None = None, model_version: str | None = None, **kwargs: Any) ->
    ImageAnalysisResult'
  parameters:
  - name: image_url
    description: The publicly accessible URL of the image to analyze.
    isRequired: true
    types:
    - <xref:str>
  - name: visual_features
    description: 'A list of visual features to analyze. Required. Seven visual features

      are supported: Caption, DenseCaptions, Read (OCR), Tags, Objects, SmartCrops,
      and People. At

      least one visual feature must be specified.'
    isRequired: true
    types:
    - <xref:list>[<xref:azure.ai.vision.imageanalysis.models.VisualFeatures>]
  keywordOnlyParameters:
  - name: language
    description: 'The desired language for result generation (a two-letter language
      code).

      Defaults to ''en'' (English). See [https://aka.ms/cv-languages](https://aka.ms/cv-languages)
      for a list of supported languages.'
    types:
    - <xref:str>
  - name: gender_neutral_caption
    description: 'Boolean flag for enabling gender-neutral captioning for

      Caption and Dense Captions features. Defaults to ''false''.

      Captions may contain gender terms (for example: ''man'', ''woman'', or ''boy'',
      ''girl'').

      If you set this to ''true'', those will be replaced with gender-neutral terms
      (for example:

      ''person'' or ''child'').'
    types:
    - <xref:bool>
  - name: smart_crops_aspect_ratios
    description: 'A list of aspect ratios to use for smart cropping.

      Defaults to one crop region with an aspect ratio the service sees fit between

      0.5 and 2.0 (inclusive). Aspect ratios are calculated by dividing the target
      crop

      width in pixels by the height in pixels. When set, supported values are

      between 0.75 and 1.8 (inclusive).'
    types:
    - <xref:list>[<xref:float>]
  - name: model_version
    description: 'The version of cloud AI-model used for analysis. Defaults to ''latest'',

      for the latest AI model with recent improvements.

      The format is the following: ''latest'' or ''YYYY-MM-DD'' or ''YYYY-MM-DD-preview'',

      where ''YYYY'', ''MM'', ''DD'' are the year, month and day associated with the
      model.

      If you would like to make sure analysis results do not change over time, set
      this

      value to a specific model version.'
    types:
    - <xref:str>
  return:
    description: ImageAnalysisResult. The ImageAnalysisResult is compatible with MutableMapping
    types:
    - <xref:azure.ai.vision.imageanalysis.models.ImageAnalysisResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.vision.imageanalysis.ImageAnalysisClient.close
  name: close
  signature: close() -> None
- uid: azure.ai.vision.imageanalysis.ImageAnalysisClient.send_request
  name: send_request
  summary: 'Runs the network request through the client''s chained policies.


    ```


    >>> from azure.core.rest import HttpRequest

    >>> request = HttpRequest("GET", "https://www.example.org/")

    <HttpRequest [GET], url: ''https://www.example.org/''>

    >>> response = client.send_request(request)

    <HttpResponse: 200 OK>

    ```


    For more information on this code flow, see [https://aka.ms/azsdk/dpcodegen/python/send_request](https://aka.ms/azsdk/dpcodegen/python/send_request)'
  signature: 'send_request(request: HttpRequest, *, stream: bool = False, **kwargs:
    Any) -> HttpResponse'
  parameters:
  - name: request
    description: The network request you want to make. Required.
    isRequired: true
    types:
    - <xref:azure.core.rest.HttpRequest>
  keywordOnlyParameters:
  - name: stream
    description: Whether the response payload will be streamed. Defaults to False.
    types:
    - <xref:bool>
  return:
    description: The response of your network call. Does not do error handling on
      your response.
    types:
    - <xref:azure.core.rest.HttpResponse>
