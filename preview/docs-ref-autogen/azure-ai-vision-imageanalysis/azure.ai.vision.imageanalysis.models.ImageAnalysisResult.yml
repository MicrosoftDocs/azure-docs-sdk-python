### YamlMime:PythonClass
uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult
name: ImageAnalysisResult
fullName: azure.ai.vision.imageanalysis.models.ImageAnalysisResult
module: azure.ai.vision.imageanalysis.models
inheritances:
- azure.ai.vision.imageanalysis._model_base.Model
summary: 'Represents the outcome of an Image Analysis operation.


  All required parameters must be populated in order to send to server.'
constructor:
  syntax: 'ImageAnalysisResult(*args: Any, **kwargs: Any)'
variables:
- description: The generated phrase that describes the content of the analyzed image.
  name: caption
  types:
  - <xref:azure.ai.vision.imageanalysis.models.CaptionResult>
- description: 'The up to 10 generated phrases, the first describing the content of
    the

    whole image,

    and the others describing the content of different regions of the image.'
  name: dense_captions
  types:
  - <xref:azure.ai.vision.imageanalysis.models.DenseCaptionsResult>
- description: Metadata associated with the analyzed image. Required.
  name: metadata
  types:
  - <xref:azure.ai.vision.imageanalysis.models.ImageMetadata>
- description: The cloud AI model used for the analysis. Required.
  name: model_version
  types:
  - <xref:str>
- description: A list of detected physical objects in the analyzed image, and their
    location.
  name: objects
  types:
  - <xref:azure.ai.vision.imageanalysis.models.ObjectsResult>
- description: A list of detected people in the analyzed image, and their location.
  name: people
  types:
  - <xref:azure.ai.vision.imageanalysis.models.PeopleResult>
- description: 'The extracted printed and hand-written text in the analyze image.
    Also knows as

    OCR.'
  name: read
  types:
  - <xref:azure.ai.vision.imageanalysis.models.ReadResult>
- description: 'A list of crop regions at the desired as aspect ratios (if provided)
    that

    can be used as image thumbnails.

    These regions preserve as much content as possible from the analyzed image, with
    priority

    given to detected faces.'
  name: smart_crops
  types:
  - <xref:azure.ai.vision.imageanalysis.models.SmartCropsResult>
- description: A list of content tags in the analyzed image.
  name: tags
  types:
  - <xref:azure.ai.vision.imageanalysis.models.TagsResult>
methods:
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.as_dict
  name: as_dict
  summary: Return a dict that can be JSONify using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.caption
  name: caption
  summary: The generated phrase that describes the content of the analyzed image.
  signature: 'caption: _models.CaptionResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.dense_captions
  name: dense_captions
  summary: 'The up to 10 generated phrases, the first describing the content of the
    whole image,

    and the others describing the content of different regions of the image.'
  signature: 'dense_captions: _models.DenseCaptionsResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.metadata
  name: metadata
  summary: Metadata associated with the analyzed image. Required.
  signature: 'metadata: _models.ImageMetadata'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.model_version
  name: model_version
  summary: The cloud AI model used for the analysis. Required.
  signature: 'model_version: str'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.objects
  name: objects
  summary: A list of detected physical objects in the analyzed image, and their location.
  signature: 'objects: _models.ObjectsResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.people
  name: people
  summary: A list of detected people in the analyzed image, and their location.
  signature: 'people: _models.PeopleResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.read
  name: read
  summary: The extracted printed and hand-written text in the analyze image. Also
    knows as OCR.
  signature: 'read: _models.ReadResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.smart_crops
  name: smart_crops
  summary: 'A list of crop regions at the desired as aspect ratios (if provided) that
    can be used as image

    thumbnails.

    These regions preserve as much content as possible from the analyzed image, with
    priority given

    to detected faces.'
  signature: 'smart_crops: _models.SmartCropsResult | None'
- uid: azure.ai.vision.imageanalysis.models.ImageAnalysisResult.tags
  name: tags
  summary: A list of content tags in the analyzed image.
  signature: 'tags: _models.TagsResult | None'
