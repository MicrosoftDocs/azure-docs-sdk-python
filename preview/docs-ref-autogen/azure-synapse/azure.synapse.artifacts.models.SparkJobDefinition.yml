### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SparkJobDefinition
name: SparkJobDefinition
fullName: azure.synapse.artifacts.models.SparkJobDefinition
module: azure.synapse.artifacts.models
inheritances:
- msrest.serialization.Model
summary: 'Spark job definition.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SparkJobDefinition(*, target_big_data_pool: BigDataPoolReference, job_properties:
    SparkJobProperties, additional_properties: Dict[str, object] | None = None, description:
    str | None = None, required_spark_version: str | None = None, language: str |
    None = None, **kwargs)'
  parameters:
  - name: additional_properties
    description: 'Unmatched properties from the message are deserialized to this

      collection.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: description
    description: The description of the Spark job definition.
    isRequired: true
    types:
    - <xref:str>
  - name: target_big_data_pool
    description: Required. Big data pool reference.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.BigDataPoolReference>
  - name: required_spark_version
    description: The required Spark version of the application.
    isRequired: true
    types:
    - <xref:str>
  - name: language
    description: The language of the Spark application.
    isRequired: true
    types:
    - <xref:str>
  - name: job_properties
    description: Required. The properties of the Spark job.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.SparkJobProperties>
