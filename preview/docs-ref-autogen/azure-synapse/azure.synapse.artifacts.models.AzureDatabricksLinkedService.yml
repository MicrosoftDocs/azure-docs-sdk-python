### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.AzureDatabricksLinkedService
name: AzureDatabricksLinkedService
fullName: azure.synapse.artifacts.models.AzureDatabricksLinkedService
module: azure.synapse.artifacts.models
inheritances:
- azure.synapse.artifacts.models._models_py3.LinkedService
summary: 'Azure Databricks linked service.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'AzureDatabricksLinkedService(*, domain: object, access_token: SecretBase,
    additional_properties: Dict[str, object] | None = None, connect_via: IntegrationRuntimeReference
    | None = None, description: str | None = None, parameters: Dict[str, ParameterSpecification]
    | None = None, annotations: List[object] | None = None, existing_cluster_id: object
    | None = None, instance_pool_id: object | None = None, new_cluster_version: object
    | None = None, new_cluster_num_of_worker: object | None = None, new_cluster_node_type:
    object | None = None, new_cluster_spark_conf: Dict[str, object] | None = None,
    new_cluster_spark_env_vars: Dict[str, object] | None = None, new_cluster_custom_tags:
    Dict[str, object] | None = None, new_cluster_driver_node_type: object | None =
    None, new_cluster_init_scripts: object | None = None, new_cluster_enable_elastic_disk:
    object | None = None, encrypted_credential: object | None = None, **kwargs)'
  parameters:
  - name: additional_properties
    description: 'Unmatched properties from the message are deserialized to this

      collection.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: type
    description: Required. Type of linked service.Constant filled by server.
    isRequired: true
    types:
    - <xref:str>
  - name: connect_via
    description: The integration runtime reference.
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.IntegrationRuntimeReference>
  - name: description
    description: Linked service description.
    isRequired: true
    types:
    - <xref:str>
  - name: parameters
    description: Parameters for linked service.
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:azure.synapse.artifacts.models.ParameterSpecification>]
  - name: annotations
    description: List of tags that can be used for describing the linked service.
    isRequired: true
    types:
    - <xref:list>[<xref:object>]
  - name: domain
    description: 'Required. `<REGION>`.azuredatabricks.net, domain name of your Databricks

      deployment. Type: string (or Expression with resultType string).'
    isRequired: true
    types:
    - <xref:object>
  - name: access_token
    description: 'Required. Access token for databricks REST API. Refer to

      https://docs.azuredatabricks.net/api/latest/authentication.html. Type: string
      (or Expression

      with resultType string).'
    isRequired: true
    types:
    - <xref:azure.synapse.artifacts.models.SecretBase>
  - name: existing_cluster_id
    description: 'The id of an existing interactive cluster that will be used for
      all

      runs of this activity. Type: string (or Expression with resultType string).'
    isRequired: true
    types:
    - <xref:object>
  - name: instance_pool_id
    description: 'The id of an existing instance pool that will be used for all runs
      of

      this activity. Type: string (or Expression with resultType string).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_version
    description: 'If not using an existing interactive cluster, this specifies the

      Spark version of a new job cluster or instance pool nodes created for each run
      of this

      activity. Required if instancePoolId is specified. Type: string (or Expression
      with resultType

      string).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_num_of_worker
    description: 'If not using an existing interactive cluster, this specifies

      the number of worker nodes to use for the new job cluster or instance pool.
      For new job

      clusters, this a string-formatted Int32, like ''1'' means numOfWorker is 1 or
      ''1:10'' means auto-

      scale from 1 (min) to 10 (max). For instance pools, this is a string-formatted
      Int32, and can

      only specify a fixed number of worker nodes, such as ''2''. Required if newClusterVersion
      is

      specified. Type: string (or Expression with resultType string).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_node_type
    description: 'The node type of the new job cluster. This property is required

      if newClusterVersion is specified and instancePoolId is not specified. If instancePoolId
      is

      specified, this property is ignored. Type: string (or Expression with resultType
      string).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_spark_conf
    description: 'A set of optional, user-specified Spark configuration key-value

      pairs.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: new_cluster_spark_env_vars
    description: 'A set of optional, user-specified Spark environment

      variables key-value pairs.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: new_cluster_custom_tags
    description: 'Additional tags for cluster resources. This property is ignored

      in instance pool configurations.'
    isRequired: true
    types:
    - <xref:dict>[<xref:str>, <xref:object>]
  - name: new_cluster_driver_node_type
    description: 'The driver node type for the new job cluster. This

      property is ignored in instance pool configurations. Type: string (or Expression
      with

      resultType string).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_init_scripts
    description: 'User-defined initialization scripts for the new cluster. Type:

      array of strings (or Expression with resultType array of strings).'
    isRequired: true
    types:
    - <xref:object>
  - name: new_cluster_enable_elastic_disk
    description: 'Enable the elastic disk on the new cluster. This

      property is now ignored, and takes the default elastic disk behavior in Databricks
      (elastic

      disks are always enabled). Type: boolean (or Expression with resultType boolean).'
    isRequired: true
    types:
    - <xref:object>
  - name: encrypted_credential
    description: 'The encrypted credential used for authentication. Credentials are

      encrypted using the integration runtime credential manager. Type: string (or
      Expression with

      resultType string).'
    isRequired: true
    types:
    - <xref:object>
