### YamlMime:PythonClass
uid: azure.synapse.spark.operations.SparkSessionOperations
name: SparkSessionOperations
fullName: azure.synapse.spark.operations.SparkSessionOperations
module: azure.synapse.spark.operations
inheritances:
- builtins.object
summary: 'SparkSessionOperations operations.


  You should not instantiate this class directly. Instead, you should create a Client
  instance that

  instantiates it for you and attaches it as an attribute.'
constructor:
  syntax: SparkSessionOperations(client, config, serializer, deserializer)
  parameters:
  - name: client
    description: Client for service requests.
    isRequired: true
  - name: config
    description: Configuration of service client.
    isRequired: true
  - name: serializer
    description: An object model serializer.
    isRequired: true
  - name: deserializer
    description: An object model deserializer.
    isRequired: true
variables:
- description: Alias to model classes used in this operation group.
  name: models
methods:
- uid: azure.synapse.spark.operations.SparkSessionOperations.cancel_spark_session
  name: cancel_spark_session
  summary: Cancels a running spark session.
  signature: 'cancel_spark_session(session_id: int, **kwargs: Any) -> None'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: None, or the result of cls(response)
    types:
    - <xref:None>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.cancel_spark_statement
  name: cancel_spark_statement
  summary: Kill a statement within a session.
  signature: 'cancel_spark_statement(session_id: int, statement_id: int, **kwargs:
    Any) -> models.SparkStatementCancellationResult'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  - name: statement_id
    description: Identifier for the statement.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkStatementCancellationResult, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkStatementCancellationResult>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.create_spark_session
  name: create_spark_session
  summary: Create new spark session.
  signature: 'create_spark_session(spark_session_options: ''models.SparkSessionOptions'',
    detailed: bool | None = None, **kwargs: Any) -> models.SparkSession'
  parameters:
  - name: spark_session_options
    description: Livy compatible batch job request payload.
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkSessionOptions>
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - <xref:bool>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkSession, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkSession>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.create_spark_statement
  name: create_spark_statement
  summary: Create statement within a spark session.
  signature: 'create_spark_statement(session_id: int, spark_statement_options: ''models.SparkStatementOptions'',
    **kwargs: Any) -> models.SparkStatement'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  - name: spark_statement_options
    description: Livy compatible batch job request payload.
    isRequired: true
    types:
    - <xref:azure.synapse.spark.models.SparkStatementOptions>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkStatement, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkStatement>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.get_spark_session
  name: get_spark_session
  summary: Gets a single spark session.
  signature: 'get_spark_session(session_id: int, detailed: bool | None = None, **kwargs:
    Any) -> models.SparkSession'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - <xref:bool>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkSession, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkSession>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.get_spark_sessions
  name: get_spark_sessions
  summary: List all spark sessions which are running under a particular spark pool.
  signature: 'get_spark_sessions(from_parameter: int | None = None, size: int | None
    = None, detailed: bool | None = None, **kwargs: Any) -> models.SparkSessionCollection'
  parameters:
  - name: from_parameter
    description: Optional param specifying which index the list should begin from.
    defaultValue: None
    types:
    - <xref:int>
  - name: size
    description: 'Optional param specifying the size of the returned list.

      By default it is 20 and that is the maximum.'
    defaultValue: None
    types:
    - <xref:int>
  - name: detailed
    description: 'Optional query param specifying whether detailed response is returned
      beyond

      plain livy.'
    defaultValue: None
    types:
    - <xref:bool>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkSessionCollection, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkSessionCollection>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.get_spark_statement
  name: get_spark_statement
  summary: Gets a single statement within a spark session.
  signature: 'get_spark_statement(session_id: int, statement_id: int, **kwargs: Any)
    -> models.SparkStatement'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  - name: statement_id
    description: Identifier for the statement.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkStatement, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkStatement>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.get_spark_statements
  name: get_spark_statements
  summary: Gets a list of statements within a spark session.
  signature: 'get_spark_statements(session_id: int, **kwargs: Any) -> models.SparkStatementCollection'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: SparkStatementCollection, or the result of cls(response)
    types:
    - <xref:azure.synapse.spark.models.SparkStatementCollection>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.synapse.spark.operations.SparkSessionOperations.reset_spark_session_timeout
  name: reset_spark_session_timeout
  summary: Sends a keep alive call to the current session to reset the session timeout.
  signature: 'reset_spark_session_timeout(session_id: int, **kwargs: Any) -> None'
  parameters:
  - name: session_id
    description: Identifier for the session.
    isRequired: true
    types:
    - <xref:int>
  keywordOnlyParameters:
  - name: cls
    description: A custom type or function that will be passed the direct response
    types:
    - <xref:callable>
  return:
    description: None, or the result of cls(response)
    types:
    - <xref:None>
  exceptions:
  - type: azure.core.exceptions.HttpResponseError
attributes:
- uid: azure.synapse.spark.operations.SparkSessionOperations.models
  name: models
  signature: models = <module 'azure.synapse.spark.models' from 'C:\\hostedtoolcache\\windows\\Python\\3.11.9\\x64\\Lib\\site-packages\\azure\\synapse\\spark\\models\\__init__.py'>
