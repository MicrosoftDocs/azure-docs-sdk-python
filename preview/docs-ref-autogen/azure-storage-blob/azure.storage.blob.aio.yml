### YamlMime:PythonPackage
uid: azure.storage.blob.aio
name: aio
fullName: azure.storage.blob.aio
type: import
functions:
- uid: azure.storage.blob.aio.download_blob_from_url
  name: download_blob_from_url
  summary: Download the contents of a blob to a local file or stream.
  signature: 'async download_blob_from_url(blob_url: str, output: str, credential:
    Optional[Union[str, Dict[str, str], AzureNamedKeyCredential, AzureSasCredential,
    "TokenCredential"]] # pylint: disable=line-too-long = None, **kwargs) -> None'
  parameters:
  - name: blob_url
    description: The full URI to the blob. This can also include a SAS token.
    isRequired: true
    types:
    - <xref:str>
  - name: output
    description: 'Where the data should be downloaded to. This could be either a file
      path to write to,

      or an open IO handle to write to.'
    isRequired: true
    types:
    - <xref:str>
    - <xref:<xref:writable stream>>
  - name: credential
    description: 'The credentials with which to authenticate. This is optional if
      the

      blob URL already has a SAS token or the blob is public. The value can be a SAS
      token string,

      an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,

      an account shared access key, or an instance of a TokenCredentials class from
      azure.identity.

      If the resource URI already contains a SAS token, this will be ignored in favor
      of an explicit credential

      - except in the case of AzureSasCredential, where the conflicting SAS tokens
      will raise a ValueError.

      If using an instance of AzureNamedKeyCredential, "name" should be the storage
      account name, and "key"

      should be the storage account key.'
    defaultValue: None
  - name: overwrite
    description: 'Whether the local file should be overwritten if it already exists.
      The default value is

      *False* - in which case a ValueError will be raised if the file already exists.
      If set to

      *True*, an attempt will be made to write to the existing file. If a stream handle
      is passed

      in, this value is ignored.'
    types:
    - <xref:bool>
  - name: max_concurrency
    description: The number of parallel connections with which to download.
    types:
    - <xref:int>
  - name: offset
    description: 'Start of byte range to use for downloading a section of the blob.

      Must be set if length is provided.'
    types:
    - <xref:int>
  - name: length
    description: 'Number of bytes to read from the stream. This is optional, but

      should be supplied for optimal performance.'
    types:
    - <xref:int>
  - name: validate_content
    description: 'If true, calculates an MD5 hash for each chunk of the blob. The
      storage

      service checks the hash of the content that has arrived with the hash

      that was sent. This is primarily valuable for detecting bitflips on

      the wire if using http instead of https as https (the default) will

      already validate. Note that this MD5 hash is not stored with the

      blob. Also note that if enabled, the memory-efficient upload algorithm

      will not be used, because computing the MD5 hash requires buffering

      entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
    types:
    - <xref:bool>
  return:
    types:
    - <xref:None>
- uid: azure.storage.blob.aio.upload_blob_to_url
  name: upload_blob_to_url
  summary: "Upload data to a given URL\n\n   The data will be uploaded as a block\
    \ blob.\n\n   param str blob_url:\n      The full URI to the blob. This can also\
    \ include a SAS token.\n\n   param data:\n      The data to upload. This can be\
    \ bytes, text, an iterable or a file-like object.\n\n   type data:\n      bytes\
    \ or str or Iterable"
  signature: 'async upload_blob_to_url(blob_url: str, data: Union[Iterable[AnyStr],
    IO[AnyStr]], credential: Optional[Union[str, Dict[str, str], AzureNamedKeyCredential,
    AzureSasCredential, "TokenCredential"]] # pylint: disable=line-too-long = None,
    **kwargs) -> dict[str, Any]'
  parameters:
  - name: credential
    description: "The credentials with which to authenticate. This is optional if\
      \ the\n   blob URL already has a SAS token. The value can be a SAS token string,\n\
      \   an instance of a AzureSasCredential or AzureNamedKeyCredential from azure.core.credentials,\n\
      \   an account shared access key, or an instance of a TokenCredentials class\
      \ from azure.identity.\n   If the resource URI already contains a SAS token,\
      \ this will be ignored in favor of an explicit credential\n   - except in the\
      \ case of AzureSasCredential, where the conflicting SAS tokens will raise a\
      \ ValueError.\n   If using an instance of AzureNamedKeyCredential, \"name\"\
      \ should be the storage account name, and \"key\"\n   should be the storage\
      \ account key.\n\nparamtype credential:\n   Optional[Union[str, Dict[str, str],\
      \ AzureNamedKeyCredential, AzureSasCredential, \"TokenCredential\"]] # pylint:\
      \ disable=line-too-long\n\nkeyword bool overwrite:\n   Whether the blob to be\
      \ uploaded should overwrite the current data.\n   If True, upload_blob_to_url\
      \ will overwrite any existing data. If set to False, the\n   operation will\
      \ fail with a ResourceExistsError.\n\nkeyword int max_concurrency:\n   The number\
      \ of parallel connections with which to download.\n\nkeyword int length:\n \
      \  Number of bytes to read from the stream. This is optional, but\n   should\
      \ be supplied for optimal performance.\n\nkeyword dict(str,str) metadata:\n\
      \   Name-value pairs associated with the blob as metadata.\n\nkeyword bool validate_content:\n\
      \   If true, calculates an MD5 hash for each chunk of the blob. The storage\n\
      \   service checks the hash of the content that has arrived with the hash\n\
      \   that was sent. This is primarily valuable for detecting bitflips on\n  \
      \ the wire if using http instead of https as https (the default) will\n   already\
      \ validate. Note that this MD5 hash is not stored with the\n   blob. Also note\
      \ that if enabled, the memory-efficient upload algorithm\n   will not be used,\
      \ because computing the MD5 hash requires buffering\n   entire blocks, and doing\
      \ so defeats the purpose of the memory-efficient algorithm.\n\nkeyword str encoding:\n\
      \   Encoding to use if text is supplied as input. Defaults to UTF-8.\n\nreturns:\n\
      \   Blob-updated property dict (Etag and last modified)\n\nrtype:\n   dict(str,\
      \ Any)"
    defaultValue: None
  - name: blob_url
  - name: data
classes:
- azure.storage.blob.aio.BlobClient
- azure.storage.blob.aio.BlobLeaseClient
- azure.storage.blob.aio.BlobPrefix
- azure.storage.blob.aio.BlobServiceClient
- azure.storage.blob.aio.ContainerClient
- azure.storage.blob.aio.ExponentialRetry
- azure.storage.blob.aio.LinearRetry
- azure.storage.blob.aio.StorageStreamDownloader
