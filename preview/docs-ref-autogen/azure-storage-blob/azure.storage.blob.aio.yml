### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.blob.aio.upload_blob_to_url
  - azure.storage.blob.aio.download_blob_from_url
  - azure.storage.blob.aio.BlobServiceClient
  - azure.storage.blob.aio.ContainerClient
  - azure.storage.blob.aio.BlobClient
  - azure.storage.blob.aio.BlobLeaseClient
  - azure.storage.blob.aio.ExponentialRetry
  - azure.storage.blob.aio.LinearRetry
  - azure.storage.blob.aio.StorageStreamDownloader
  fullName: azure.storage.blob.aio
  kind: import
  langs:
  - python
  module: azure.storage.blob.aio
  name: aio
  type: package
  uid: azure.storage.blob.aio
- fullName: azure.storage.blob.aio.upload_blob_to_url
  langs:
  - python
  module: azure.storage.blob.aio
  name: upload_blob_to_url(blob_url, data, credential=None, **kwargs)
  summary: 'Upload data to a given URL


    The data will be uploaded as a block blob.'
  syntax:
    content: upload_blob_to_url(blob_url, data, credential=None, **kwargs)
    parameters:
    - description: The full URI to the blob. This can also include a SAS token.
      id: blob_url
      type:
      - str
    - description: The data to upload. This can be bytes, text, an iterable or a file-like
        object.
      id: data
      type:
      - bytes
      - str
      - Iterable
    - defaultValue: None
      description: 'The credentials with which to authenticate. This is optional if
        the

        blob URL already has a SAS token. The value can be a SAS token string, an
        account

        shared access key, or an instance of a TokenCredentials class from azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    - description: 'Whether the blob to be uploaded should overwrite the current data.

        If True, upload_blob_to_url will overwrite any existing data. If set to False,
        the

        operation will fail with a ResourceExistsError.'
      id: overwrite
      type:
      - bool
    - description: The number of parallel connections with which to download.
      id: max_concurrency
      type:
      - int
    - description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      type:
      - int
    - description: Name-value pairs associated with the blob as metadata.
      id: metadata
      type:
      - dict(str,str)
    - description: 'If true, calculates an MD5 hash for each chunk of the blob. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        blob. Also note that if enabled, the memory-efficient upload algorithm

        will not be used, because computing the MD5 hash requires buffering

        entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
      id: validate_content
      type:
      - bool
    - description: Encoding to use if text is supplied as input. Defaults to UTF-8.
      id: encoding
      type:
      - str
    return:
      description: Blob-updated property dict (Etag and last modified)
      type:
      - dict(str, Any)
  type: function
  uid: azure.storage.blob.aio.upload_blob_to_url
- fullName: azure.storage.blob.aio.download_blob_from_url
  langs:
  - python
  module: azure.storage.blob.aio
  name: download_blob_from_url(blob_url, output, credential=None, **kwargs)
  summary: Download the contents of a blob to a local file or stream.
  syntax:
    content: download_blob_from_url(blob_url, output, credential=None, **kwargs)
    parameters:
    - description: The full URI to the blob. This can also include a SAS token.
      id: blob_url
      type:
      - str
    - description: 'Where the data should be downloaded to. This could be either a
        file path to write to,

        or an open IO handle to write to.'
      id: output
      type:
      - str
      - writable stream
    - defaultValue: None
      description: 'The credentials with which to authenticate. This is optional if
        the

        blob URL already has a SAS token or the blob is public. The value can be a
        SAS token string,

        an account shared access key, or an instance of a TokenCredentials class from
        azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    - description: 'Whether the local file should be overwritten if it already exists.
        The default value is

        *False* - in which case a ValueError will be raised if the file already exists.
        If set to

        *True*, an attempt will be made to write to the existing file. If a stream
        handle is passed

        in, this value is ignored.'
      id: overwrite
      type:
      - bool
    - description: The number of parallel connections with which to download.
      id: max_concurrency
      type:
      - int
    - description: 'Start of byte range to use for downloading a section of the blob.

        Must be set if length is provided.'
      id: offset
      type:
      - int
    - description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      type:
      - int
    - description: 'If true, calculates an MD5 hash for each chunk of the blob. The
        storage

        service checks the hash of the content that has arrived with the hash

        that was sent. This is primarily valuable for detecting bitflips on

        the wire if using http instead of https as https (the default) will

        already validate. Note that this MD5 hash is not stored with the

        blob. Also note that if enabled, the memory-efficient upload algorithm

        will not be used, because computing the MD5 hash requires buffering

        entire blocks, and doing so defeats the purpose of the memory-efficient algorithm.'
      id: validate_content
      type:
      - bool
    return:
      type:
      - None
  type: function
  uid: azure.storage.blob.aio.download_blob_from_url
references:
- fullName: azure.storage.blob.aio.upload_blob_to_url
  isExternal: false
  name: upload_blob_to_url(blob_url, data, credential=None, **kwargs)
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.upload_blob_to_url
- fullName: azure.storage.blob.aio.download_blob_from_url
  isExternal: false
  name: download_blob_from_url(blob_url, output, credential=None, **kwargs)
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.download_blob_from_url
- fullName: azure.storage.blob.aio.BlobServiceClient
  isExternal: false
  name: BlobServiceClient
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.BlobServiceClient
- fullName: azure.storage.blob.aio.ContainerClient
  isExternal: false
  name: ContainerClient
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.ContainerClient
- fullName: azure.storage.blob.aio.BlobClient
  isExternal: false
  name: BlobClient
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.BlobClient
- fullName: azure.storage.blob.aio.BlobLeaseClient
  isExternal: false
  name: BlobLeaseClient
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.BlobLeaseClient
- fullName: azure.storage.blob.aio.ExponentialRetry
  isExternal: false
  name: ExponentialRetry
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.ExponentialRetry
- fullName: azure.storage.blob.aio.LinearRetry
  isExternal: false
  name: LinearRetry
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.LinearRetry
- fullName: azure.storage.blob.aio.StorageStreamDownloader
  isExternal: false
  name: StorageStreamDownloader
  parent: azure.storage.blob.aio
  uid: azure.storage.blob.aio.StorageStreamDownloader
- fullName: dict(str,str)
  name: dict(str,str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str,str
    name: str,str
    uid: str,str
  - fullName: )
    name: )
  uid: dict(str,str)
- fullName: dict(str, Any)
  name: dict(str, Any)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: Any
    name: Any
    uid: Any
  - fullName: )
    name: )
  uid: dict(str, Any)
