### YamlMime:PythonClass
uid: azure.ai.projects.aio.operations.InferenceOperations
name: InferenceOperations
fullName: azure.ai.projects.aio.operations.InferenceOperations
module: azure.ai.projects.aio.operations
constructor:
  syntax: InferenceOperations(outer_instance)
  parameters:
  - name: outer_instance
    isRequired: true
methods:
- uid: azure.ai.projects.aio.operations.InferenceOperations.get_azure_openai_client
  name: get_azure_openai_client
  summary: 'Get an authenticated AsyncAzureOpenAI client (from the *openai* package)
    for the default

    Azure OpenAI connection (if *connection_name* is not specificed), or from the
    Azure OpenAI

    resource given by its connection name.


    > [!NOTE]

    > The package openai must be installed prior to calling this method.

    >'
  signature: 'async get_azure_openai_client(*, api_version: str | None = None, connection_name:
    str | None = None, **kwargs) -> AsyncAzureOpenAI'
  keywordOnlyParameters:
  - name: api_version
    description: 'The Azure OpenAI api-version to use when creating the client. Optional.

      See "Data plane - Inference" row in the table at

      [https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs](https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs).
      If this keyword

      is not specified, you must set the environment variable *OPENAI_API_VERSION*
      instead.'
    defaultValue: None
    types:
    - <xref:str>
  - name: connection_name
    description: 'The name of a connection to an Azure OpenAI resource in your AI
      Foundry project.

      resource. Optional. If not provided, the default Azure OpenAI connection will
      be used.'
    defaultValue: None
  return:
    description: An authenticated AsyncAzureOpenAI client
    types:
    - <xref:openai.AsyncAzureOpenAI>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
    description: 'if an Azure OpenAI connection

      does not exist.'
  - type: azure.core.exceptions.ModuleNotFoundError
    description: 'if the *openai* package

      is not installed.'
  - type: ValueError
    description: if the connection name is an empty string.
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.projects.aio.operations.InferenceOperations.get_chat_completions_client
  name: get_chat_completions_client
  summary: 'Get an authenticated asynchronous ChatCompletionsClient (from the package
    azure-ai-inference) for the default

    Azure AI Services connected resource (if *connection_name* is not specificed),
    or from the Azure AI

    Services resource given by its connection name. Keyword arguments are passed to
    the constructor of

    ChatCompletionsClient.


    At least one AI model that supports chat completions must be deployed in this
    resource.


    > [!NOTE]

    > The packages azure-ai-inference and aiohttp must be installed prior to calling
    this method.

    >'
  signature: 'async get_chat_completions_client(*, connection_name: str | None = None,
    **kwargs) -> ChatCompletionsClient'
  keywordOnlyParameters:
  - name: connection_name
    description: 'The name of a connection to an Azure AI Services resource in your
      AI Foundry project.

      resource. Optional. If not provided, the default Azure AI Services connection
      will be used.'
    defaultValue: None
  return:
    description: An authenticated chat completions client.
    types:
    - <xref:azure.ai.inference.ChatCompletionsClient>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
    description: 'if an Azure AI Services connection

      does not exist.'
  - type: azure.core.exceptions.ModuleNotFoundError
    description: 'if the *azure-ai-inference* package

      is not installed.'
  - type: ValueError
    description: if the connection name is an empty string.
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.projects.aio.operations.InferenceOperations.get_embeddings_client
  name: get_embeddings_client
  summary: 'Get an authenticated asynchronous EmbeddingsClient (from the package azure-ai-inference)
    for the default

    Azure AI Services connected resource (if *connection_name* is not specificed),
    or from the Azure AI

    Services resource given by its connection name. Keyword arguments are passed to
    the constructor of

    EmbeddingsClient.


    At least one AI model that supports text embeddings must be deployed in this resource.


    > [!NOTE]

    > The packages azure-ai-inference and aiohttp must be installed prior to calling
    this method.

    >'
  signature: 'async get_embeddings_client(*, connection_name: str | None = None, **kwargs)
    -> EmbeddingsClient'
  keywordOnlyParameters:
  - name: connection_name
    description: 'The name of a connection to an Azure AI Services resource in your
      AI Foundry project.

      resource. Optional. If not provided, the default Azure AI Services connection
      will be used.'
    defaultValue: None
  return:
    description: An authenticated text embeddings client
    types:
    - <xref:azure.ai.inference.EmbeddingsClient>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
    description: 'if an Azure AI Services connection

      does not exist.'
  - type: azure.core.exceptions.ModuleNotFoundError
    description: 'if the *azure-ai-inference* package

      is not installed.'
  - type: ValueError
    description: if the connection name is an empty string.
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.projects.aio.operations.InferenceOperations.get_image_embeddings_client
  name: get_image_embeddings_client
  summary: 'Get an authenticated asynchronous ImageEmbeddingsClient (from the package
    azure-ai-inference) for the default

    Azure AI Services connected resource (if *connection_name* is not specificed),
    or from the Azure AI

    Services resource given by its connection name. Keyword arguments are passed to
    the constructor of

    ImageEmbeddingsClient.


    At least one AI model that supports image embeddings must be deployed in this
    resource.


    > [!NOTE]

    > The packages azure-ai-inference and aiohttp must be installed prior to calling
    this method.

    >'
  signature: 'async get_image_embeddings_client(*, connection_name: str | None = None,
    **kwargs) -> ImageEmbeddingsClient'
  keywordOnlyParameters:
  - name: connection_name
    description: 'The name of a connection to an Azure AI Services resource in your
      AI Foundry project.

      resource. Optional. If not provided, the default Azure AI Services connection
      will be used.'
    defaultValue: None
  return:
    description: An authenticated image embeddings client
    types:
    - <xref:azure.ai.inference.ImageEmbeddingsClient>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
    description: 'if an Azure AI Services connection

      does not exist.'
  - type: azure.core.exceptions.ModuleNotFoundError
    description: 'if the *azure-ai-inference* package

      is not installed.'
  - type: ValueError
    description: if the connection name is an empty string.
  - type: azure.core.exceptions.HttpResponseError
